[2022-11-18 16:01:30,514][__main__][INFO] - Setting random seed to 17
[2022-11-18 16:01:30,515][__main__][INFO] - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Mixed precision type: no

[2022-11-18 16:01:30,517][__main__][INFO] - output_dir: tuned-model
bittensor:
  network: nobunaga
dataset:
  name: ViktorThink/mountain_combined_813306
  config_name: null
  num_batches: 5000
  block_size: 256
  overwrite_cache: false
  keep_linebreaks: true
  concatenate_raw: false
  load_tokenized_data: false
model:
  name: facebook/opt-2.7b
  config_name: null
tokenizer:
  name: null
  use_fast: true
  preprocessing_num_workers: null
  pad_token: '[PAD]'
training:
  seed: 17
  val_split_percent: 20
  train_batch_size: 32
  eval_batch_size: 16
  learning_rate: 3.0e-06
  weight_decay: 0.05
  num_epochs: 4
  max_train_steps: null
  gradient_accumulation_steps: 2
  lr_scheduler: constant
  lr_warmup_steps: 5
  eval_every: 250
  max_eval_steps: 500
  checkpoint:
    resume_from_checkpoint: 0
    every_n_steps: null
tracking:
  enabled: true
  report_to: all
testing:
  enabled: false

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--EleutherAI--gpt-neo-2.7B/snapshots/51568a6e0ae813a3f2a9da558ab7beac5e3acc24/config.json
Model config GPTNeoConfig {
  "_name_or_path": "EleutherAI/gpt-neo-2.7B",
  "activation_function": "gelu_new",
  "architectures": [
    "GPTNeoForCausalLM"
  ],
  "attention_dropout": 0,
  "attention_layers": [
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local"
  ],
  "attention_types": [
    [
      [
        "global",
        "local"
      ],
      16
    ]
  ],
  "bos_token_id": 50256,
  "embed_dropout": 0,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "hidden_size": 2560,
  "initializer_range": 0.02,
  "intermediate_size": null,
  "layer_norm_epsilon": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neo",
  "num_heads": 20,
  "num_layers": 32,
  "resid_dropout": 0,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50,
      "temperature": 0.9
    }
  },
  "tokenizer_class": "GPT2Tokenizer",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50257,
  "window_size": 256
}

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading file vocab.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/vocab.json
loading file merges.txt from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/merges.txt
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/tokenizer_config.json
loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading weights file flax_model.msgpack from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Loading Flax weights from /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Some weights of the Flax model were not used when initializing the PyTorch model GPTNeoForCausalLM: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.18.fc1.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.bias']
- This IS expected if you are initializing GPTNeoForCausalLM from a Flax model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a FlaxBertForPreTraining model).
- This IS NOT expected if you are initializing GPTNeoForCausalLM from a Flax model that you expect to be exactly identical (e.g. initializing a BertForSequenceClassification model from a FlaxBertForSequenceClassification model).
Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['transformer.h.2.attn.attention.out_proj.weight', 'transformer.h.27.mlp.c_fc.weight', 'transformer.h.30.attn.attention.masked_bias', 'transformer.h.18.ln_2.weight', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.2.ln_2.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.0.attn.attention.q_proj.weight', 'transformer.h.30.mlp.c_fc.weight', 'transformer.h.10.attn.attention.q_proj.weight', 'transformer.h.2.ln_2.weight', 'transformer.h.29.attn.attention.v_proj.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.4.attn.attention.out_proj.weight', 'transformer.h.31.mlp.c_fc.bias', 'transformer.h.14.attn.attention.bias', 'transformer.h.14.mlp.c_fc.bias', 'transformer.h.24.ln_2.bias', 'transformer.h.9.ln_1.bias', 'lm_head.weight', 'transformer.h.21.attn.attention.q_proj.weight', 'transformer.h.11.attn.attention.masked_bias', 'transformer.h.19.attn.attention.out_proj.weight', 'transformer.h.6.attn.attention.masked_bias', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.22.mlp.c_proj.bias', 'transformer.h.26.mlp.c_proj.weight', 'transformer.h.7.attn.attention.q_proj.weight', 'transformer.h.14.attn.attention.masked_bias', 'transformer.h.3.ln_1.bias', 'transformer.h.5.attn.attention.v_proj.weight', 'transformer.h.17.attn.attention.out_proj.bias', 'transformer.h.26.ln_2.bias', 'transformer.h.27.attn.attention.k_proj.weight', 'transformer.h.8.attn.attention.out_proj.bias', 'transformer.h.2.ln_1.bias', 'transformer.h.30.ln_2.weight', 'transformer.h.31.mlp.c_proj.bias', 'transformer.h.4.attn.attention.out_proj.bias', 'transformer.h.9.attn.attention.out_proj.weight', 'transformer.h.20.mlp.c_proj.bias', 'transformer.h.22.mlp.c_fc.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.26.attn.attention.bias', 'transformer.h.20.mlp.c_fc.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.17.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.18.ln_1.weight', 'transformer.h.12.attn.attention.k_proj.weight', 'transformer.h.25.ln_1.bias', 'transformer.h.16.attn.attention.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.12.ln_1.weight', 'transformer.h.8.ln_2.weight', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.10.attn.attention.out_proj.bias', 'transformer.h.12.ln_2.bias', 'transformer.h.26.ln_1.weight', 'transformer.h.28.attn.attention.out_proj.bias', 'transformer.h.14.attn.attention.v_proj.weight', 'transformer.h.29.ln_1.weight', 'transformer.h.25.attn.attention.k_proj.weight', 'transformer.h.7.attn.attention.out_proj.bias', 'transformer.h.1.attn.attention.bias', 'transformer.h.9.attn.attention.v_proj.weight', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.7.ln_2.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.18.mlp.c_proj.bias', 'transformer.h.24.ln_2.weight', 'transformer.h.15.attn.attention.masked_bias', 'transformer.h.8.attn.attention.v_proj.weight', 'transformer.h.15.attn.attention.q_proj.weight', 'transformer.h.6.attn.attention.v_proj.weight', 'transformer.h.20.mlp.c_fc.weight', 'transformer.h.22.ln_2.weight', 'transformer.h.22.attn.attention.bias', 'transformer.h.30.ln_1.weight', 'transformer.h.25.attn.attention.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.1.attn.attention.masked_bias', 'transformer.h.0.attn.attention.k_proj.weight', 'transformer.h.28.mlp.c_fc.weight', 'transformer.h.21.attn.attention.k_proj.weight', 'transformer.h.20.ln_1.bias', 'transformer.h.9.attn.attention.q_proj.weight', 'transformer.h.25.ln_2.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.31.mlp.c_fc.weight', 'transformer.h.23.attn.attention.k_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.12.attn.attention.out_proj.bias', 'transformer.h.28.attn.attention.masked_bias', 'transformer.h.7.attn.attention.masked_bias', 'transformer.h.16.mlp.c_fc.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.30.attn.attention.bias', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.26.ln_2.weight', 'transformer.h.26.mlp.c_fc.weight', 'transformer.h.11.ln_2.weight', 'transformer.h.24.attn.attention.bias', 'transformer.h.22.attn.attention.out_proj.weight', 'transformer.h.24.ln_1.bias', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.30.attn.attention.out_proj.weight', 'transformer.h.10.attn.attention.v_proj.weight', 'transformer.h.31.attn.attention.out_proj.bias', 'transformer.h.18.mlp.c_proj.weight', 'transformer.h.30.mlp.c_proj.bias', 'transformer.h.5.attn.attention.masked_bias', 'transformer.h.23.attn.attention.out_proj.bias', 'transformer.h.21.ln_2.bias', 'transformer.h.27.attn.attention.out_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.25.mlp.c_fc.weight', 'transformer.h.6.attn.attention.out_proj.weight', 'transformer.h.18.attn.attention.out_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.4.attn.attention.masked_bias', 'transformer.h.8.attn.attention.masked_bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.24.mlp.c_fc.weight', 'transformer.h.30.attn.attention.k_proj.weight', 'transformer.h.23.attn.attention.out_proj.weight', 'transformer.h.6.ln_1.weight', 'transformer.h.0.ln_2.weight', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.28.attn.attention.v_proj.weight', 'transformer.h.1.attn.attention.v_proj.weight', 'transformer.h.13.attn.attention.bias', 'transformer.h.23.ln_2.bias', 'transformer.h.18.ln_2.bias', 'transformer.h.21.attn.attention.v_proj.weight', 'transformer.wpe.weight', 'transformer.h.3.attn.attention.out_proj.bias', 'transformer.h.3.ln_2.bias', 'transformer.h.14.ln_1.weight', 'transformer.h.22.attn.attention.v_proj.weight', 'transformer.h.22.attn.attention.out_proj.bias', 'transformer.h.22.mlp.c_proj.weight', 'transformer.h.18.attn.attention.bias', 'transformer.h.26.attn.attention.masked_bias', 'transformer.h.23.mlp.c_fc.bias', 'transformer.h.13.attn.attention.out_proj.weight', 'transformer.h.13.attn.attention.out_proj.bias', 'transformer.h.22.mlp.c_fc.bias', 'transformer.h.19.attn.attention.masked_bias', 'transformer.h.30.ln_2.bias', 'transformer.h.17.mlp.c_fc.weight', 'transformer.h.29.attn.attention.out_proj.bias', 'transformer.h.0.ln_2.bias', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.24.attn.attention.k_proj.weight', 'transformer.h.5.attn.attention.out_proj.weight', 'transformer.h.27.attn.attention.v_proj.weight', 'transformer.h.12.attn.attention.masked_bias', 'transformer.h.3.attn.attention.bias', 'transformer.h.27.ln_1.weight', 'transformer.h.20.mlp.c_proj.weight', 'transformer.h.21.ln_2.weight', 'transformer.h.21.mlp.c_fc.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.19.mlp.c_fc.weight', 'transformer.h.9.ln_2.weight', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.13.ln_1.bias', 'transformer.h.12.ln_2.weight', 'transformer.h.11.attn.attention.q_proj.weight', 'transformer.h.26.attn.attention.q_proj.weight', 'transformer.h.27.attn.attention.masked_bias', 'transformer.h.7.attn.attention.v_proj.weight', 'transformer.h.20.attn.attention.v_proj.weight', 'transformer.h.24.mlp.c_proj.bias', 'transformer.h.24.attn.attention.q_proj.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.3.attn.attention.q_proj.weight', 'transformer.h.4.attn.attention.k_proj.weight', 'transformer.h.22.ln_2.bias', 'transformer.h.22.attn.attention.k_proj.weight', 'transformer.h.11.attn.attention.k_proj.weight', 'transformer.h.29.ln_2.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.26.attn.attention.out_proj.bias', 'transformer.h.17.attn.attention.masked_bias', 'transformer.h.28.mlp.c_fc.bias', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.21.ln_1.weight', 'transformer.h.25.attn.attention.out_proj.bias', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.27.mlp.c_proj.bias', 'transformer.h.10.attn.attention.out_proj.weight', 'transformer.h.24.mlp.c_fc.bias', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.28.ln_2.weight', 'transformer.h.19.attn.attention.k_proj.weight', 'transformer.h.25.attn.attention.out_proj.weight', 'transformer.h.28.ln_1.bias', 'transformer.h.25.mlp.c_proj.bias', 'transformer.h.5.attn.attention.k_proj.weight', 'transformer.h.19.mlp.c_proj.bias', 'transformer.h.0.attn.attention.v_proj.weight', 'transformer.h.2.attn.attention.v_proj.weight', 'transformer.h.27.mlp.c_proj.weight', 'transformer.h.19.mlp.c_proj.weight', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.25.attn.attention.q_proj.weight', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.23.attn.attention.q_proj.weight', 'transformer.h.7.attn.attention.bias', 'transformer.h.5.ln_1.bias', 'transformer.h.26.mlp.c_proj.bias', 'transformer.h.15.ln_2.bias', 'transformer.h.28.mlp.c_proj.weight', 'transformer.h.13.mlp.c_fc.bias', 'transformer.h.0.attn.attention.masked_bias', 'transformer.h.0.attn.attention.out_proj.weight', 'transformer.h.31.attn.attention.v_proj.weight', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.21.ln_1.bias', 'transformer.h.11.ln_1.bias', 'transformer.h.21.attn.attention.masked_bias', 'transformer.h.7.ln_2.bias', 'transformer.h.15.attn.attention.k_proj.weight', 'transformer.h.16.ln_1.weight', 'transformer.h.27.attn.attention.bias', 'transformer.h.25.mlp.c_proj.weight', 'transformer.h.28.attn.attention.k_proj.weight', 'transformer.h.16.ln_2.weight', 'transformer.h.13.attn.attention.k_proj.weight', 'transformer.h.17.attn.attention.bias', 'transformer.h.9.ln_2.bias', 'transformer.h.9.attn.attention.masked_bias', 'transformer.h.14.attn.attention.k_proj.weight', 'transformer.h.16.attn.attention.k_proj.weight', 'transformer.h.25.attn.attention.v_proj.weight', 'transformer.h.12.attn.attention.out_proj.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.7.attn.attention.out_proj.weight', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.27.attn.attention.out_proj.bias', 'transformer.h.16.attn.attention.masked_bias', 'transformer.h.28.attn.attention.out_proj.weight', 'transformer.h.18.attn.attention.out_proj.weight', 'transformer.h.1.attn.attention.k_proj.weight', 'transformer.h.13.mlp.c_fc.weight', 'transformer.h.30.ln_1.bias', 'transformer.h.8.ln_1.bias', 'transformer.h.16.attn.attention.v_proj.weight', 'transformer.h.22.ln_1.bias', 'transformer.h.4.attn.attention.q_proj.weight', 'transformer.h.31.attn.attention.q_proj.weight', 'transformer.h.10.attn.attention.masked_bias', 'transformer.h.21.mlp.c_fc.bias', 'transformer.h.1.attn.attention.out_proj.bias', 'transformer.wte.weight', 'transformer.h.19.ln_2.bias', 'transformer.h.6.attn.attention.out_proj.bias', 'transformer.h.30.attn.attention.v_proj.weight', 'transformer.h.25.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.12.mlp.c_fc.weight', 'transformer.h.28.mlp.c_proj.bias', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.23.attn.attention.v_proj.weight', 'transformer.h.14.mlp.c_proj.bias', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.30.attn.attention.out_proj.bias', 'transformer.h.29.attn.attention.q_proj.weight', 'transformer.h.11.attn.attention.v_proj.weight', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.22.ln_1.weight', 'transformer.h.14.attn.attention.out_proj.weight', 'transformer.h.18.mlp.c_fc.weight', 'transformer.h.20.ln_2.bias', 'transformer.h.16.ln_1.bias', 'transformer.h.21.attn.attention.out_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.18.ln_1.bias', 'transformer.h.18.mlp.c_fc.bias', 'transformer.h.6.ln_2.bias', 'transformer.h.16.ln_2.bias', 'transformer.h.28.ln_1.weight', 'transformer.h.24.ln_1.weight', 'transformer.h.15.attn.attention.out_proj.weight', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.9.attn.attention.out_proj.bias', 'transformer.h.29.attn.attention.masked_bias', 'transformer.h.17.ln_1.bias', 'transformer.h.18.attn.attention.k_proj.weight', 'transformer.h.24.attn.attention.masked_bias', 'transformer.h.29.attn.attention.out_proj.weight', 'transformer.h.17.attn.attention.out_proj.weight', 'transformer.h.25.ln_2.weight', 'transformer.h.15.mlp.c_fc.bias', 'transformer.h.19.ln_2.weight', 'transformer.h.20.ln_1.weight', 'transformer.h.11.attn.attention.bias', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.16.attn.attention.q_proj.weight', 'transformer.h.23.attn.attention.bias', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.13.attn.attention.masked_bias', 'transformer.h.10.ln_1.bias', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.27.ln_2.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.19.ln_1.bias', 'transformer.h.27.ln_2.bias', 'transformer.h.29.attn.attention.k_proj.weight', 'transformer.h.14.attn.attention.q_proj.weight', 'transformer.h.24.attn.attention.out_proj.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.11.ln_1.weight', 'transformer.h.23.mlp.c_fc.weight', 'transformer.h.22.attn.attention.q_proj.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.21.attn.attention.out_proj.weight', 'transformer.h.4.ln_1.weight', 'transformer.h.6.attn.attention.bias', 'transformer.h.15.attn.attention.bias', 'transformer.h.19.mlp.c_fc.bias', 'transformer.h.21.mlp.c_proj.bias', 'transformer.h.23.ln_1.weight', 'transformer.h.16.attn.attention.out_proj.weight', 'transformer.h.23.ln_1.bias', 'transformer.h.11.attn.attention.out_proj.weight', 'transformer.h.31.attn.attention.bias', 'transformer.h.12.attn.attention.q_proj.weight', 'transformer.h.15.attn.attention.out_proj.bias', 'transformer.h.17.ln_2.weight', 'transformer.h.18.attn.attention.masked_bias', 'transformer.h.13.ln_2.weight', 'transformer.h.3.attn.attention.k_proj.weight', 'transformer.h.9.ln_1.weight', 'transformer.h.17.attn.attention.k_proj.weight', 'transformer.h.10.attn.attention.bias', 'transformer.h.4.attn.attention.v_proj.weight', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.30.attn.attention.q_proj.weight', 'transformer.h.2.attn.attention.out_proj.bias', 'transformer.h.15.mlp.c_fc.weight', 'transformer.h.3.attn.attention.masked_bias', 'transformer.h.8.attn.attention.k_proj.weight', 'transformer.h.8.attn.attention.q_proj.weight', 'transformer.h.26.attn.attention.v_proj.weight', 'transformer.h.11.attn.attention.out_proj.bias', 'transformer.h.20.attn.attention.masked_bias', 'transformer.h.1.ln_2.bias', 'transformer.h.25.ln_1.weight', 'transformer.h.31.ln_2.bias', 'transformer.h.12.ln_1.bias', 'transformer.h.13.attn.attention.v_proj.weight', 'transformer.h.15.attn.attention.v_proj.weight', 'transformer.h.23.attn.attention.masked_bias', 'transformer.h.30.mlp.c_fc.bias', 'transformer.h.0.ln_1.weight', 'transformer.h.19.ln_1.weight', 'transformer.h.19.attn.attention.out_proj.bias', 'transformer.h.31.ln_2.weight', 'transformer.h.17.attn.attention.v_proj.weight', 'transformer.h.29.ln_2.bias', 'transformer.h.1.ln_1.bias', 'transformer.h.24.mlp.c_proj.weight', 'transformer.h.17.ln_1.weight', 'transformer.h.12.attn.attention.bias', 'transformer.h.0.attn.attention.out_proj.bias', 'transformer.h.23.mlp.c_proj.bias', 'transformer.h.25.attn.attention.masked_bias', 'transformer.h.5.attn.attention.q_proj.weight', 'transformer.h.0.attn.attention.bias', 'transformer.ln_f.bias', 'transformer.h.15.ln_2.weight', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.31.attn.attention.masked_bias', 'transformer.h.14.ln_1.bias', 'transformer.h.20.ln_2.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.9.attn.attention.k_proj.weight', 'transformer.h.4.attn.attention.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.26.ln_1.bias', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.22.attn.attention.masked_bias', 'transformer.h.15.ln_1.bias', 'transformer.h.12.mlp.c_fc.bias', 'transformer.h.8.attn.attention.bias', 'transformer.h.29.mlp.c_proj.weight', 'transformer.h.20.attn.attention.out_proj.bias', 'transformer.h.19.attn.attention.q_proj.weight', 'transformer.h.29.mlp.c_fc.weight', 'transformer.h.2.attn.attention.bias', 'transformer.h.24.attn.attention.v_proj.weight', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.30.mlp.c_proj.weight', 'transformer.h.8.attn.attention.out_proj.weight', 'transformer.h.27.ln_1.bias', 'transformer.h.29.mlp.c_proj.bias', 'transformer.h.19.attn.attention.bias', 'transformer.h.21.mlp.c_proj.weight', 'transformer.h.15.ln_1.weight', 'transformer.h.2.attn.attention.k_proj.weight', 'transformer.h.17.attn.attention.q_proj.weight', 'transformer.h.1.attn.attention.out_proj.weight', 'transformer.h.20.attn.attention.out_proj.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.8.ln_1.weight', 'transformer.h.27.attn.attention.q_proj.weight', 'transformer.h.28.attn.attention.bias', 'transformer.h.17.ln_2.bias', 'transformer.h.28.ln_2.bias', 'transformer.ln_f.weight', 'transformer.h.31.ln_1.weight', 'transformer.h.18.attn.attention.v_proj.weight', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.26.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.6.attn.attention.q_proj.weight', 'transformer.h.12.attn.attention.v_proj.weight', 'transformer.h.5.attn.attention.out_proj.bias', 'transformer.h.14.mlp.c_fc.weight', 'transformer.h.26.attn.attention.out_proj.weight', 'transformer.h.2.attn.attention.q_proj.weight', 'transformer.h.21.attn.attention.bias', 'transformer.h.8.ln_2.bias', 'transformer.h.20.attn.attention.q_proj.weight', 'transformer.h.13.attn.attention.q_proj.weight', 'transformer.h.10.ln_1.weight', 'transformer.h.5.attn.attention.bias', 'transformer.h.1.attn.attention.q_proj.weight', 'transformer.h.7.attn.attention.k_proj.weight', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.28.attn.attention.q_proj.weight', 'transformer.h.31.mlp.c_proj.weight', 'transformer.h.14.ln_2.bias', 'transformer.h.9.attn.attention.bias', 'transformer.h.31.attn.attention.k_proj.weight', 'transformer.h.13.ln_1.weight', 'transformer.h.20.attn.attention.bias', 'transformer.h.13.ln_2.bias', 'transformer.h.3.attn.attention.out_proj.weight', 'transformer.h.29.attn.attention.bias', 'transformer.h.7.ln_1.bias', 'transformer.h.14.attn.attention.out_proj.bias', 'transformer.h.18.attn.attention.q_proj.weight', 'transformer.h.16.mlp.c_fc.bias', 'transformer.h.29.mlp.c_fc.bias', 'transformer.h.2.attn.attention.masked_bias', 'transformer.h.23.ln_2.weight', 'transformer.h.31.ln_1.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.26.attn.attention.k_proj.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.20.attn.attention.k_proj.weight', 'transformer.h.3.ln_1.weight', 'transformer.h.3.attn.attention.v_proj.weight', 'transformer.h.27.mlp.c_fc.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.31.attn.attention.out_proj.weight', 'transformer.h.10.attn.attention.k_proj.weight', 'transformer.h.6.attn.attention.k_proj.weight', 'transformer.h.23.mlp.c_proj.weight', 'transformer.h.29.ln_1.bias', 'transformer.h.19.attn.attention.v_proj.weight', 'transformer.h.16.attn.attention.out_proj.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.14.ln_2.weight', 'transformer.h.24.attn.attention.out_proj.weight', 'transformer.h.9.mlp.c_fc.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2022-11-18 16:01:57,285][datasets.builder][WARNING] - Using custom data configuration ViktorThink--mountain_combined_813306-6918b9ea07482433
[2022-11-18 16:01:57,360][datasets.builder][WARNING] - Found cached dataset csv (/home/paperspace/.cache/huggingface/datasets/ViktorThink___csv/ViktorThink--mountain_combined_813306-6918b9ea07482433/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
  0%|          | 0/2 [00:00<?, ?it/s] 50%|     | 1/2 [00:00<00:00,  5.88it/s]100%|| 2/2 [00:00<00:00, 11.17it/s]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 1/814 [00:02<34:22,  2.54s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:04<31:40,  2.34s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:06<30:37,  2.27s/ba]Running tokenizer on dataset:   0%|          | 4/814 [00:09<29:44,  2.20s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:11<29:02,  2.15s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:13<28:10,  2.09s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:15<27:55,  2.08s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:17<27:29,  2.05s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:19<26:59,  2.01s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:20<26:32,  1.98s/ba]Running tokenizer on dataset:   1%|         | 11/814 [00:22<26:32,  1.98s/ba]Running tokenizer on dataset:   1%|         | 12/814 [00:24<26:23,  1.97s/ba]Running tokenizer on dataset:   2%|         | 13/814 [00:26<26:14,  1.97s/ba]Running tokenizer on dataset:   2%|         | 14/814 [00:28<26:09,  1.96s/ba]Running tokenizer on dataset:   2%|         | 15/814 [00:30<25:57,  1.95s/ba]Running tokenizer on dataset:   2%|         | 16/814 [00:32<25:42,  1.93s/ba]Running tokenizer on dataset:   2%|         | 17/814 [00:34<25:27,  1.92s/ba]Running tokenizer on dataset:   2%|         | 18/814 [00:36<25:14,  1.90s/ba]Running tokenizer on dataset:   2%|         | 19/814 [00:38<25:07,  1.90s/ba]Running tokenizer on dataset:   2%|         | 20/814 [00:40<25:06,  1.90s/ba]Running tokenizer on dataset:   3%|         | 21/814 [00:42<25:05,  1.90s/ba]Running tokenizer on dataset:   3%|         | 22/814 [00:43<24:53,  1.89s/ba]Running tokenizer on dataset:   3%|         | 23/814 [00:45<24:44,  1.88s/ba]Running tokenizer on dataset:   3%|         | 24/814 [00:47<24:38,  1.87s/ba]Running tokenizer on dataset:   3%|         | 25/814 [00:49<24:39,  1.88s/ba]Running tokenizer on dataset:   3%|         | 26/814 [00:51<25:50,  1.97s/ba]Running tokenizer on dataset:   3%|         | 27/814 [00:54<27:34,  2.10s/ba]Running tokenizer on dataset:   3%|         | 28/814 [00:56<28:10,  2.15s/ba]Running tokenizer on dataset:   4%|         | 29/814 [00:58<27:08,  2.08s/ba]Running tokenizer on dataset:   4%|         | 30/814 [01:00<26:20,  2.02s/ba]Running tokenizer on dataset:   4%|         | 31/814 [01:01<25:32,  1.96s/ba]Running tokenizer on dataset:   4%|         | 32/814 [01:03<25:18,  1.94s/ba]Running tokenizer on dataset:   4%|         | 33/814 [01:05<25:02,  1.92s/ba]Running tokenizer on dataset:   4%|         | 34/814 [01:07<24:31,  1.89s/ba]Running tokenizer on dataset:   4%|         | 35/814 [01:09<24:10,  1.86s/ba]Running tokenizer on dataset:   4%|         | 36/814 [01:11<23:50,  1.84s/ba]Running tokenizer on dataset:   5%|         | 37/814 [01:12<23:37,  1.82s/ba]Running tokenizer on dataset:   5%|         | 38/814 [01:14<23:19,  1.80s/ba]Running tokenizer on dataset:   5%|         | 39/814 [01:16<23:34,  1.83s/ba]Running tokenizer on dataset:   5%|         | 40/814 [01:18<23:32,  1.83s/ba]Running tokenizer on dataset:   5%|         | 41/814 [01:20<23:39,  1.84s/ba]Running tokenizer on dataset:   5%|         | 42/814 [01:22<23:43,  1.84s/ba]Running tokenizer on dataset:   5%|         | 43/814 [01:23<23:33,  1.83s/ba]Running tokenizer on dataset:   5%|         | 44/814 [01:25<23:48,  1.86s/ba]Running tokenizer on dataset:   6%|         | 45/814 [01:27<23:41,  1.85s/ba]Running tokenizer on dataset:   6%|         | 46/814 [01:29<23:26,  1.83s/ba]Running tokenizer on dataset:   6%|         | 47/814 [01:31<23:19,  1.82s/ba]Running tokenizer on dataset:   6%|         | 48/814 [01:32<23:03,  1.81s/ba]Running tokenizer on dataset:   6%|         | 49/814 [01:34<23:04,  1.81s/ba]Running tokenizer on dataset:   6%|         | 50/814 [01:36<23:04,  1.81s/ba]Running tokenizer on dataset:   6%|         | 51/814 [01:38<22:53,  1.80s/ba]Running tokenizer on dataset:   6%|         | 52/814 [01:40<23:00,  1.81s/ba]Running tokenizer on dataset:   7%|         | 53/814 [01:42<22:53,  1.81s/ba]Running tokenizer on dataset:   7%|         | 54/814 [01:43<22:50,  1.80s/ba]Running tokenizer on dataset:   7%|         | 55/814 [01:45<23:05,  1.82s/ba]Running tokenizer on dataset:   7%|         | 56/814 [01:47<23:00,  1.82s/ba]Running tokenizer on dataset:   7%|         | 57/814 [01:49<23:12,  1.84s/ba]Running tokenizer on dataset:   7%|         | 58/814 [01:51<22:56,  1.82s/ba]Running tokenizer on dataset:   7%|         | 59/814 [01:52<22:47,  1.81s/ba]Running tokenizer on dataset:   7%|         | 60/814 [01:54<22:35,  1.80s/ba]Running tokenizer on dataset:   7%|         | 61/814 [01:56<22:35,  1.80s/ba]Running tokenizer on dataset:   8%|         | 62/814 [01:58<22:40,  1.81s/ba]Running tokenizer on dataset:   8%|         | 63/814 [02:00<22:36,  1.81s/ba]Running tokenizer on dataset:   8%|         | 64/814 [02:01<22:23,  1.79s/ba]Running tokenizer on dataset:   8%|         | 65/814 [02:03<22:33,  1.81s/ba]Running tokenizer on dataset:   8%|         | 66/814 [02:05<22:31,  1.81s/ba]Running tokenizer on dataset:   8%|         | 67/814 [02:07<22:15,  1.79s/ba]Running tokenizer on dataset:   8%|         | 68/814 [02:09<22:09,  1.78s/ba]Running tokenizer on dataset:   8%|         | 69/814 [02:10<22:00,  1.77s/ba]Running tokenizer on dataset:   9%|         | 70/814 [02:12<21:57,  1.77s/ba]Running tokenizer on dataset:   9%|         | 71/814 [02:14<21:49,  1.76s/ba]Running tokenizer on dataset:   9%|         | 72/814 [02:16<23:57,  1.94s/ba]Running tokenizer on dataset:   9%|         | 73/814 [02:18<23:16,  1.88s/ba]Running tokenizer on dataset:   9%|         | 74/814 [02:20<22:47,  1.85s/ba]Running tokenizer on dataset:   9%|         | 75/814 [02:21<22:27,  1.82s/ba]Running tokenizer on dataset:   9%|         | 76/814 [02:23<22:52,  1.86s/ba]Running tokenizer on dataset:   9%|         | 77/814 [02:25<22:28,  1.83s/ba]Running tokenizer on dataset:  10%|         | 78/814 [02:27<22:20,  1.82s/ba]Running tokenizer on dataset:  10%|         | 79/814 [02:29<22:02,  1.80s/ba]Running tokenizer on dataset:  10%|         | 79/814 [02:30<23:16,  1.90s/ba]
 Traceback (most recent call last) 
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/datasets/arrow_dataset.py:2982 in _map_single                         
                                                                              
   2979                      range(*(slice(i, i + batch_size).indices( 
   2980                   )  # Something simpler?                       
   2981                   try:                                          
  2982                      batch = apply_function_on_filtered_inputs 
   2983                         batch,                                
   2984                         indices,                              
   2985                         check_same_num_examples=len(input_dat 
                                                                              
  locals  
  apply_function_on_filtered_inputs = <function                             
                                      Dataset._map_single.<locals>.apply_  
                                      at 0x7f467d7d7820>                    
                              batch = {                                     
                                         'train': [                        
                                            'upon better and\\nnobler     
                                      views; and advise your elder          
                                      sisters, when they perceive'+1575,    
                                            "log time reviewing U.S.      
                                      Army training films from the Vietnam  
                                      era. That's the mil"+1355,            
                                            'the speculative              
                                      philosophers. For example, the great  
                                      mathematician Euler, who do'+1567,    
                                            'the bedchamber. A short      
                                      while later he confided in one of     
                                      his servants, secretly'+1331,         
                                            'the familiar bond valuation  
                                      equation. Assuming semiannual coupon  
                                      payments, the e'+1402,                
                                            '$X$ associated with          
                                      $U\\\\bar{U}$ and $\\\\bar{D}{D}$     
                                      since this would drop the             
                                      poss'+1860,                           
                                            'parking lot                  
                                      dings.\\"\\n\\n\\"When these little   
                                      charges blow, they\'ll leave M16      
                                      impa'+1470,                           
                                            'above from Helms, \\"The     
                                      Indians,\\" pp. 3745. \\n | Bruhns,  
                                      _Ancient South Americ'+1388,          
                                            'get some sleep, so I         
                                      removed the light bulb and stored it  
                                      in the pocket of the C'+1301,         
                                            'set of ADE20K in Table       
                                      \\\\[tab:baseline\\\\]. All our       
                                      results except the last-row o'+1732,  
                                            ... +990                      
                                         ],                                
                                         'validation': [                   
                                            "given we can't stop people   
                                      signing up again with a new           
                                      disposable email address)"+1984,      
                                            'I\'m just repeating\'        
                                      stuff.\\" \\"Did I hear you say       
                                      you\'re looking for an                
                                      apartmen'+1451,                       
                                            'a model for belief. In M.    
                                      Vargas \\u0026 G. Yaffe (Eds.),       
                                      Rational and social age'+1793,        
                                            'away.\\"\\n\\n\\"Somehow, I  
                                      think she knows where he is,\\"       
                                      Virginia said, thoughtful'+1451,      
                                            'plane the limits of          
                                      validity of our model.\\n\\n![(Color  
                                      online) [*Characterizatio'+2041,      
                                            "son for fighting\\nagainst   
                                      the king and the mother country. The  
                                      old lady's face w"+1653,              
                                            'again.\\" \\"We\'re gonna    
                                      have to make the cut now.\\"          
                                      \\"Sharon?\\" \\"can you hear         
                                      me'+1554,                             
                                            'even have more commissions   
                                      such as yours.\\"\\n\\nThat was a     
                                      not-so-veiled referenc'+1491,         
                                            'stealth technology we were   
                                      never able to break.\\" \\"So how     
                                      come all of a sudden '+1534,          
                                            'create\\na small example     
                                      service.\\nI want to focus on two     
                                      major requirements.\\nPe'+1838,       
                                            ... +990                      
                                         ]                                 
                                      }                                     
                         batch_size = 1000                                  
                            batched = True                                  
                         buf_writer = None                                  
                    cache_file_name = '/home/paperspace/.cache/huggingfac  
                         cache_only = False                                 
                               desc = 'Running tokenizer on dataset'        
                   disable_nullable = False                                 
                       disable_tqdm = False                                 
                    drop_last_batch = False                                 
                           features = None                                  
                          fn_kwargs = {}                                    
                           function = <function                             
                                      preprocess.<locals>.tokenize_fn at    
                                      0x7f45bc6e3e50>                       
                                  i = 79000                                 
                            indices = [                                     
                                         79000,                            
                                         79001,                            
                                         79002,                            
                                         79003,                            
                                         79004,                            
                                         79005,                            
                                         79006,                            
                                         79007,                            
                                         79008,                            
                                         79009,                            
                                         ... +990                          
                                      ]                                     
             init_buffer_and_writer = <function                             
                                      Dataset._map_single.<locals>.init_b  
                                      at 0x7f45bc6c0550>                    
                      input_columns = None                                  
                      input_dataset = Dataset({                             
                                         features: ['train',               
                                      'validation'],                        
                                         num_rows: 813306                  
                                      })                                    
                     keep_in_memory = False                                 
               load_from_cache_file = True                                  
                    new_fingerprint = '4608445b9d629a4f'                    
                           num_rows = 813306                                
           NumExamplesMismatchError = <class                                
                                      'datasets.arrow_dataset.Dataset._ma  
                             offset = 0                                     
                               pbar = <tqdm.asyncio.tqdm_asyncio object at  
                                      0x7f467de30a30>                       
                          pbar_desc = 'Running tokenizer on dataset'        
                      pbar_iterable = <zip object at 0x7f467820e4c0>        
                         pbar_total = 814                                   
                          pbar_unit = 'ba'                                  
                               rank = None                                  
                     remove_columns = None                                  
                               self = Dataset({                             
                                         features: ['train',               
                                      'validation'],                        
                                         num_rows: 813306                  
                                      })                                    
                              stack = <contextlib.ExitStack object at       
                                      0x7f467de301f0>                       
                           tmp_file = <tempfile._TemporaryFileWrapper       
                                      object at 0x7f467de12220>             
                        update_data = True                                  
           validate_function_output = <function                             
                                      Dataset._map_single.<locals>.valida  
                                      at 0x7f45bc6e3dc0>                    
                       with_indices = False                                 
                          with_rank = False                                 
                             writer = <datasets.arrow_writer.ArrowWriter    
                                      object at 0x7f467ddb13d0>             
                  writer_batch_size = 1000                                  
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/datasets/arrow_dataset.py:2865 in apply_function_on_filtered_inputs   
                                                                              
   2862             additional_args += (effective_indices,)               
   2863          if with_rank:                                             
   2864             additional_args += (rank,)                            
  2865          processed_inputs = function(*fn_args, *additional_args, * 
   2866          if update_data is None:                                   
   2867             # Check if the function returns updated examples      
   2868             update_data = isinstance(processed_inputs, (Mapping,  
                                                                              
  locals  
           additional_args = ()                                             
   check_same_num_examples = False                                          
         effective_indices = [                                              
                                79000,                                     
                                79001,                                     
                                79002,                                     
                                79003,                                     
                                79004,                                     
                                79005,                                     
                                79006,                                     
                                79007,                                     
                                79008,                                     
                                79009,                                     
                                ... +990                                   
                             ]                                              
                   fn_args = [                                              
                                {                                          
                                   'train': [                             
                                      'upon better and\\nnobler views;   
                             and advise your elder sisters, when they       
                             perceive'+1575,                                
                                      "log time reviewing U.S. Army      
                             training films from the Vietnam era. That's    
                             the mil"+1355,                                 
                                      'the speculative philosophers.     
                             For example, the great mathematician Euler,    
                             who do'+1567,                                  
                                      'the bedchamber. A short while     
                             later he confided in one of his servants,      
                             secretly'+1331,                                
                                      'the familiar bond valuation       
                             equation. Assuming semiannual coupon           
                             payments, the e'+1402,                         
                                      '$X$ associated with               
                             $U\\\\bar{U}$ and $\\\\bar{D}{D}$ since this   
                             would drop the poss'+1860,                     
                                      'parking lot                       
                             dings.\\"\\n\\n\\"When these little charges    
                             blow, they\'ll leave M16 impa'+1470,           
                                      'above from Helms, \\"The          
                             Indians,\\" pp. 3745. \\n | Bruhns, _Ancient  
                             South Americ'+1388,                            
                                      'get some sleep, so I removed the  
                             light bulb and stored it in the pocket of the  
                             C'+1301,                                       
                                      'set of ADE20K in Table            
                             \\\\[tab:baseline\\\\]. All our results        
                             except the last-row o'+1732,                   
                                      ... +990                           
                                   ],                                     
                                   'validation': [                        
                                      "given we can't stop people        
                             signing up again with a new disposable email   
                             address)"+1984,                                
                                      'I\'m just repeating\' stuff.\\"   
                             \\"Did I hear you say you\'re looking for an   
                             apartmen'+1451,                                
                                      'a model for belief. In M. Vargas  
                             \\u0026 G. Yaffe (Eds.), Rational and social   
                             age'+1793,                                     
                                      'away.\\"\\n\\n\\"Somehow, I       
                             think she knows where he is,\\" Virginia       
                             said, thoughtful'+1451,                        
                                      'plane the limits of validity of   
                             our model.\\n\\n![(Color online)               
                             [*Characterizatio'+2041,                       
                                      "son for fighting\\nagainst the    
                             king and the mother country. The old lady's    
                             face w"+1653,                                  
                                      'again.\\" \\"We\'re gonna have    
                             to make the cut now.\\" \\"Sharon?\\" \\"can   
                             you hear me'+1554,                             
                                      'even have more commissions such   
                             as yours.\\"\\n\\nThat was a not-so-veiled     
                             referenc'+1491,                                
                                      'stealth technology we were never  
                             able to break.\\" \\"So how come all of a      
                             sudden '+1534,                                 
                                      'create\\na small example          
                             service.\\nI want to focus on two major        
                             requirements.\\nPe'+1838,                      
                                      ... +990                           
                                   ]                                      
                                }                                          
                             ]                                              
                 fn_kwargs = {}                                             
                  function = <function preprocess.<locals>.tokenize_fn at   
                             0x7f45bc6e3e50>                                
                   indices = [                                              
                                79000,                                     
                                79001,                                     
                                79002,                                     
                                79003,                                     
                                79004,                                     
                                79005,                                     
                                79006,                                     
                                79007,                                     
                                79008,                                     
                                79009,                                     
                                ... +990                                   
                             ]                                              
             input_columns = None                                           
                    inputs = {                                              
                                'train': [                                 
                                   'upon better and\\nnobler views; and   
                             advise your elder sisters, when they           
                             perceive'+1575,                                
                                   "log time reviewing U.S. Army          
                             training films from the Vietnam era. That's    
                             the mil"+1355,                                 
                                   'the speculative philosophers. For     
                             example, the great mathematician Euler, who    
                             do'+1567,                                      
                                   'the bedchamber. A short while later   
                             he confided in one of his servants,            
                             secretly'+1331,                                
                                   'the familiar bond valuation           
                             equation. Assuming semiannual coupon           
                             payments, the e'+1402,                         
                                   '$X$ associated with $U\\\\bar{U}$     
                             and $\\\\bar{D}{D}$ since this would drop the  
                             poss'+1860,                                    
                                   'parking lot dings.\\"\\n\\n\\"When    
                             these little charges blow, they\'ll leave M16  
                             impa'+1470,                                    
                                   'above from Helms, \\"The Indians,\\"  
                             pp. 3745. \\n | Bruhns, _Ancient South        
                             Americ'+1388,                                  
                                   'get some sleep, so I removed the      
                             light bulb and stored it in the pocket of the  
                             C'+1301,                                       
                                   'set of ADE20K in Table                
                             \\\\[tab:baseline\\\\]. All our results        
                             except the last-row o'+1732,                   
                                   ... +990                               
                                ],                                         
                                'validation': [                            
                                   "given we can't stop people signing    
                             up again with a new disposable email           
                             address)"+1984,                                
                                   'I\'m just repeating\' stuff.\\"       
                             \\"Did I hear you say you\'re looking for an   
                             apartmen'+1451,                                
                                   'a model for belief. In M. Vargas      
                             \\u0026 G. Yaffe (Eds.), Rational and social   
                             age'+1793,                                     
                                   'away.\\"\\n\\n\\"Somehow, I think     
                             she knows where he is,\\" Virginia said,       
                             thoughtful'+1451,                              
                                   'plane the limits of validity of our   
                             model.\\n\\n![(Color online)                   
                             [*Characterizatio'+2041,                       
                                   "son for fighting\\nagainst the king   
                             and the mother country. The old lady's face    
                             w"+1653,                                       
                                   'again.\\" \\"We\'re gonna have to     
                             make the cut now.\\" \\"Sharon?\\" \\"can you  
                             hear me'+1554,                                 
                                   'even have more commissions such as    
                             yours.\\"\\n\\nThat was a not-so-veiled        
                             referenc'+1491,                                
                                   'stealth technology we were never      
                             able to break.\\" \\"So how come all of a      
                             sudden '+1534,                                 
                                   'create\\na small example              
                             service.\\nI want to focus on two major        
                             requirements.\\nPe'+1838,                      
                                   ... +990                               
                                ]                                          
                             }                                              
  NumExamplesMismatchError = <class                                         
                             'datasets.arrow_dataset.Dataset._map_single.  
                    offset = 0                                              
                      rank = None                                           
            remove_columns = None                                           
                      self = Dataset({                                      
                                features: ['train', 'validation'],         
                                num_rows: 813306                           
                             })                                             
               update_data = True                                           
  validate_function_output = <function                                      
                             Dataset._map_single.<locals>.validate_functi  
                             at 0x7f45bc6e3dc0>                             
              with_indices = False                                          
                 with_rank = False                                          
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/datasets/arrow_dataset.py:2545 in decorated                           
                                                                              
   2542                Example(item, features=self.features) if not batc 
   2543             )                                                     
   2544             # Use the LazyDict internally, while mapping the func 
  2545             result = f(decorated_item, *args, **kwargs)           
   2546             # Return a standard dict                              
   2547             return result.data if isinstance(result, LazyDict) el 
   2548                                                                       
                                                                              
  locals  
            args = ()                                                       
         batched = True                                                     
  decorated_item = {                                                        
                      'train': [                                           
                         'upon better and\\nnobler views; and advise      
                   your elder sisters, when they perceive'+1575,            
                         "log time reviewing U.S. Army training films     
                   from the Vietnam era. That's the mil"+1355,              
                         'the speculative philosophers. For example, the  
                   great mathematician Euler, who do'+1567,                 
                         'the bedchamber. A short while later he          
                   confided in one of his servants, secretly'+1331,         
                         'the familiar bond valuation equation. Assuming  
                   semiannual coupon payments, the e'+1402,                 
                         '$X$ associated with $U\\\\bar{U}$ and           
                   $\\\\bar{D}{D}$ since this would drop the poss'+1860,    
                         'parking lot dings.\\"\\n\\n\\"When these        
                   little charges blow, they\'ll leave M16 impa'+1470,      
                         'above from Helms, \\"The Indians,\\" pp.        
                   3745. \\n | Bruhns, _Ancient South Americ'+1388,        
                         'get some sleep, so I removed the light bulb     
                   and stored it in the pocket of the C'+1301,              
                         'set of ADE20K in Table \\\\[tab:baseline\\\\].  
                   All our results except the last-row o'+1732,             
                         ... +990                                         
                      ],                                                   
                      'validation': [                                      
                         "given we can't stop people signing up again     
                   with a new disposable email address)"+1984,              
                         'I\'m just repeating\' stuff.\\" \\"Did I hear   
                   you say you\'re looking for an apartmen'+1451,           
                         'a model for belief. In M. Vargas \\u0026 G.     
                   Yaffe (Eds.), Rational and social age'+1793,             
                         'away.\\"\\n\\n\\"Somehow, I think she knows     
                   where he is,\\" Virginia said, thoughtful'+1451,         
                         'plane the limits of validity of our             
                   model.\\n\\n![(Color online) [*Characterizatio'+2041,    
                         "son for fighting\\nagainst the king and the     
                   mother country. The old lady's face w"+1653,             
                         'again.\\" \\"We\'re gonna have to make the cut  
                   now.\\" \\"Sharon?\\" \\"can you hear me'+1554,          
                         'even have more commissions such as              
                   yours.\\"\\n\\nThat was a not-so-veiled referenc'+1491,  
                         'stealth technology we were never able to        
                   break.\\" \\"So how come all of a sudden '+1534,         
                         'create\\na small example service.\\nI want to   
                   focus on two major requirements.\\nPe'+1838,             
                         ... +990                                         
                      ]                                                    
                   }                                                        
               f = <function preprocess.<locals>.tokenize_fn at             
                   0x7f4678211670>                                          
            item = {                                                        
                      'train': [                                           
                         'upon better and\\nnobler views; and advise      
                   your elder sisters, when they perceive'+1575,            
                         "log time reviewing U.S. Army training films     
                   from the Vietnam era. That's the mil"+1355,              
                         'the speculative philosophers. For example, the  
                   great mathematician Euler, who do'+1567,                 
                         'the bedchamber. A short while later he          
                   confided in one of his servants, secretly'+1331,         
                         'the familiar bond valuation equation. Assuming  
                   semiannual coupon payments, the e'+1402,                 
                         '$X$ associated with $U\\\\bar{U}$ and           
                   $\\\\bar{D}{D}$ since this would drop the poss'+1860,    
                         'parking lot dings.\\"\\n\\n\\"When these        
                   little charges blow, they\'ll leave M16 impa'+1470,      
                         'above from Helms, \\"The Indians,\\" pp.        
                   3745. \\n | Bruhns, _Ancient South Americ'+1388,        
                         'get some sleep, so I removed the light bulb     
                   and stored it in the pocket of the C'+1301,              
                         'set of ADE20K in Table \\\\[tab:baseline\\\\].  
                   All our results except the last-row o'+1732,             
                         ... +990                                         
                      ],                                                   
                      'validation': [                                      
                         "given we can't stop people signing up again     
                   with a new disposable email address)"+1984,              
                         'I\'m just repeating\' stuff.\\" \\"Did I hear   
                   you say you\'re looking for an apartmen'+1451,           
                         'a model for belief. In M. Vargas \\u0026 G.     
                   Yaffe (Eds.), Rational and social age'+1793,             
                         'away.\\"\\n\\n\\"Somehow, I think she knows     
                   where he is,\\" Virginia said, thoughtful'+1451,         
                         'plane the limits of validity of our             
                   model.\\n\\n![(Color online) [*Characterizatio'+2041,    
                         "son for fighting\\nagainst the king and the     
                   mother country. The old lady's face w"+1653,             
                         'again.\\" \\"We\'re gonna have to make the cut  
                   now.\\" \\"Sharon?\\" \\"can you hear me'+1554,          
                         'even have more commissions such as              
                   yours.\\"\\n\\nThat was a not-so-veiled referenc'+1491,  
                         'stealth technology we were never able to        
                   break.\\" \\"So how come all of a sudden '+1534,         
                         'create\\na small example service.\\nI want to   
                   focus on two major requirements.\\nPe'+1838,             
                         ... +990                                         
                      ]                                                    
                   }                                                        
          kwargs = {}                                                       
            self = Dataset({                                                
                      features: ['train', 'validation'],                   
                      num_rows: 813306                                     
                   })                                                       
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/finetune_using_clm_wandb.p 
 y:204 in tokenize_fn                                                         
                                                                              
   201       return result                                                  
   202                                                                       
   203    def tokenize_fn(examples):                                         
  204       result = tokenizer(                                            
   205          examples[text_column_name],                                
   206          padding=pad,                                               
   207          truncation=True,                                           
                                                                              
  locals  
               cfg = {'output_dir': 'tuned-model', 'bittensor':             
                     {'network': 'nobunaga'}, 'dataset': {'name':           
                     'ViktorThink/mountain_combined_813306',                
                     'config_name': None, 'num_batches': 5000,              
                     'block_size': 256, 'overwrite_cache': False,           
                     'keep_linebreaks': True, 'concatenate_raw': False,     
                     'load_tokenized_data': False}, 'model': {'name':       
                     'facebook/opt-2.7b', 'config_name': None},             
                     'tokenizer': {'name': None, 'use_fast': True,          
                     'preprocessing_num_workers': None, 'pad_token':        
                     '[PAD]'}, 'training': {'seed': 17,                     
                     'val_split_percent': 20, 'train_batch_size': 32,       
                     'eval_batch_size': 16, 'learning_rate': 3e-06,         
                     'weight_decay': 0.05, 'num_epochs': 4,                 
                     'max_train_steps': None,                               
                     'gradient_accumulation_steps': 2, 'lr_scheduler':      
                     'constant', 'lr_warmup_steps': 5, 'eval_every': 250,   
                     'max_eval_steps': 500, 'checkpoint':                   
                     {'resume_from_checkpoint': 0, 'every_n_steps':         
                     None}}, 'tracking': {'enabled': True, 'report_to':     
                     'all'}, 'testing': {'enabled': False}}                 
          examples = {                                                      
                        'train': [                                         
                           'upon better and\\nnobler views; and advise    
                     your elder sisters, when they perceive'+1575,          
                           "log time reviewing U.S. Army training films   
                     from the Vietnam era. That's the mil"+1355,            
                           'the speculative philosophers. For example,    
                     the great mathematician Euler, who do'+1567,           
                           'the bedchamber. A short while later he        
                     confided in one of his servants, secretly'+1331,       
                           'the familiar bond valuation equation.         
                     Assuming semiannual coupon payments, the e'+1402,      
                           '$X$ associated with $U\\\\bar{U}$ and         
                     $\\\\bar{D}{D}$ since this would drop the poss'+1860,  
                           'parking lot dings.\\"\\n\\n\\"When these      
                     little charges blow, they\'ll leave M16 impa'+1470,    
                           'above from Helms, \\"The Indians,\\" pp.      
                     3745. \\n | Bruhns, _Ancient South Americ'+1388,      
                           'get some sleep, so I removed the light bulb   
                     and stored it in the pocket of the C'+1301,            
                           'set of ADE20K in Table                        
                     \\\\[tab:baseline\\\\]. All our results except the     
                     last-row o'+1732,                                      
                           ... +990                                       
                        ],                                                 
                        'validation': [                                    
                           "given we can't stop people signing up again   
                     with a new disposable email address)"+1984,            
                           'I\'m just repeating\' stuff.\\" \\"Did I      
                     hear you say you\'re looking for an apartmen'+1451,    
                           'a model for belief. In M. Vargas \\u0026 G.   
                     Yaffe (Eds.), Rational and social age'+1793,           
                           'away.\\"\\n\\n\\"Somehow, I think she knows   
                     where he is,\\" Virginia said, thoughtful'+1451,       
                           'plane the limits of validity of our           
                     model.\\n\\n![(Color online) [*Characterizatio'+2041,  
                           "son for fighting\\nagainst the king and the   
                     mother country. The old lady's face w"+1653,           
                           'again.\\" \\"We\'re gonna have to make the    
                     cut now.\\" \\"Sharon?\\" \\"can you hear me'+1554,    
                           'even have more commissions such as            
                     yours.\\"\\n\\nThat was a not-so-veiled                
                     referenc'+1491,                                        
                           'stealth technology we were never able to      
                     break.\\" \\"So how come all of a sudden '+1534,       
                           'create\\na small example service.\\nI want    
                     to focus on two major requirements.\\nPe'+1838,        
                           ... +990                                       
                        ]                                                  
                     }                                                      
               pad = 'max_length'                                           
  text_column_name = 'train'                                                
         tokenizer = PreTrainedTokenizer(name_or_path='facebook/opt-2.7b',  
                     vocab_size=50265,                                      
                     model_max_len=1000000000000000019884624838656,         
                     is_fast=False, padding_side='right',                   
                     truncation_side='right', special_tokens={'bos_token':  
                     AddedToken("</s>", rstrip=False, lstrip=False,         
                     single_word=False, normalized=True), 'eos_token':      
                     AddedToken("</s>", rstrip=False, lstrip=False,         
                     single_word=False, normalized=True), 'unk_token':      
                     AddedToken("</s>", rstrip=False, lstrip=False,         
                     single_word=False, normalized=True), 'pad_token':      
                     AddedToken("<pad>", rstrip=False, lstrip=False,        
                     single_word=False, normalized=True)})                  
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/transformers/tokenization_utils_base.py:2488 in __call__              
                                                                              
   2485          # input mode in this case.                                
   2486          if not self._in_target_context_manager:                   
   2487             self._switch_to_input_mode()                          
  2488          encodings = self._call_one(text=text, text_pair=text_pair 
   2489       if text_target is not None:                                   
   2490          self._switch_to_target_mode()                             
   2491          target_encodings = self._call_one(text=text_target, text_ 
                                                                              
  locals  
          add_special_tokens = True                                         
                  all_kwargs = {                                            
                                  'add_special_tokens': True,              
                                  'padding': 'max_length',                 
                                  'truncation': True,                      
                                  'max_length': 256,                       
                                  'stride': 0,                             
                                  'is_split_into_words': False,            
                                  'pad_to_multiple_of': None,              
                                  'return_tensors': None,                  
                                  'return_token_type_ids': None,           
                                  'return_attention_mask': None,           
                                  ... +5                                   
                               }                                            
         is_split_into_words = False                                        
                      kwargs = {}                                           
                  max_length = 256                                          
          pad_to_multiple_of = None                                         
                     padding = 'max_length'                                 
       return_attention_mask = None                                         
               return_length = False                                        
      return_offsets_mapping = False                                        
   return_overflowing_tokens = False                                        
  return_special_tokens_mask = False                                        
              return_tensors = None                                         
       return_token_type_ids = None                                         
                        self = PreTrainedTokenizer(name_or_path='facebook  
                               vocab_size=50265,                            
                               model_max_len=1000000000000000019884624838  
                               is_fast=False, padding_side='right',         
                               truncation_side='right',                     
                               special_tokens={'bos_token':                 
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'eos_token':               
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'unk_token':               
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'pad_token':               
                               AddedToken("<pad>", rstrip=False,            
                               lstrip=False, single_word=False,             
                               normalized=True)})                           
                      stride = 0                                            
                        text = [                                            
                                  'upon better and\\nnobler views; and     
                               advise your elder sisters, when they         
                               perceive'+1575,                              
                                  "log time reviewing U.S. Army training   
                               films from the Vietnam era. That's the       
                               mil"+1355,                                   
                                  'the speculative philosophers. For       
                               example, the great mathematician Euler, who  
                               do'+1567,                                    
                                  'the bedchamber. A short while later he  
                               confided in one of his servants,             
                               secretly'+1331,                              
                                  'the familiar bond valuation equation.   
                               Assuming semiannual coupon payments, the     
                               e'+1402,                                     
                                  '$X$ associated with $U\\\\bar{U}$ and   
                               $\\\\bar{D}{D}$ since this would drop the    
                               poss'+1860,                                  
                                  'parking lot dings.\\"\\n\\n\\"When      
                               these little charges blow, they\'ll leave    
                               M16 impa'+1470,                              
                                  'above from Helms, \\"The Indians,\\"    
                               pp. 3745. \\n | Bruhns, _Ancient South      
                               Americ'+1388,                                
                                  'get some sleep, so I removed the light  
                               bulb and stored it in the pocket of the      
                               C'+1301,                                     
                                  'set of ADE20K in Table                  
                               \\\\[tab:baseline\\\\]. All our results      
                               except the last-row o'+1732,                 
                                  ... +990                                 
                               ]                                            
                   text_pair = None                                         
            text_pair_target = None                                         
                 text_target = None                                         
                  truncation = True                                         
                     verbose = True                                         
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/transformers/tokenization_utils_base.py:2574 in _call_one             
                                                                              
   2571                f" {len(text_pair)}."                             
   2572             )                                                     
   2573          batch_text_or_text_pairs = list(zip(text, text_pair)) if  
  2574          return self.batch_encode_plus(                            
   2575             batch_text_or_text_pairs=batch_text_or_text_pairs,    
   2576             add_special_tokens=add_special_tokens,                
   2577             padding=padding,                                      
                                                                              
  locals  
        _is_valid_text_input = <function                                    
                               PreTrainedTokenizerBase._call_one.<locals>  
                               at 0x7f459958b9d0>                           
          add_special_tokens = True                                         
    batch_text_or_text_pairs = [                                            
                                  'upon better and\\nnobler views; and     
                               advise your elder sisters, when they         
                               perceive'+1575,                              
                                  "log time reviewing U.S. Army training   
                               films from the Vietnam era. That's the       
                               mil"+1355,                                   
                                  'the speculative philosophers. For       
                               example, the great mathematician Euler, who  
                               do'+1567,                                    
                                  'the bedchamber. A short while later he  
                               confided in one of his servants,             
                               secretly'+1331,                              
                                  'the familiar bond valuation equation.   
                               Assuming semiannual coupon payments, the     
                               e'+1402,                                     
                                  '$X$ associated with $U\\\\bar{U}$ and   
                               $\\\\bar{D}{D}$ since this would drop the    
                               poss'+1860,                                  
                                  'parking lot dings.\\"\\n\\n\\"When      
                               these little charges blow, they\'ll leave    
                               M16 impa'+1470,                              
                                  'above from Helms, \\"The Indians,\\"    
                               pp. 3745. \\n | Bruhns, _Ancient South      
                               Americ'+1388,                                
                                  'get some sleep, so I removed the light  
                               bulb and stored it in the pocket of the      
                               C'+1301,                                     
                                  'set of ADE20K in Table                  
                               \\\\[tab:baseline\\\\]. All our results      
                               except the last-row o'+1732,                 
                                  ... +990                                 
                               ]                                            
                  is_batched = True                                         
         is_split_into_words = False                                        
                      kwargs = {}                                           
                  max_length = 256                                          
          pad_to_multiple_of = None                                         
                     padding = 'max_length'                                 
       return_attention_mask = None                                         
               return_length = False                                        
      return_offsets_mapping = False                                        
   return_overflowing_tokens = False                                        
  return_special_tokens_mask = False                                        
              return_tensors = None                                         
       return_token_type_ids = None                                         
                        self = PreTrainedTokenizer(name_or_path='facebook  
                               vocab_size=50265,                            
                               model_max_len=1000000000000000019884624838  
                               is_fast=False, padding_side='right',         
                               truncation_side='right',                     
                               special_tokens={'bos_token':                 
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'eos_token':               
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'unk_token':               
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'pad_token':               
                               AddedToken("<pad>", rstrip=False,            
                               lstrip=False, single_word=False,             
                               normalized=True)})                           
                      stride = 0                                            
                        text = [                                            
                                  'upon better and\\nnobler views; and     
                               advise your elder sisters, when they         
                               perceive'+1575,                              
                                  "log time reviewing U.S. Army training   
                               films from the Vietnam era. That's the       
                               mil"+1355,                                   
                                  'the speculative philosophers. For       
                               example, the great mathematician Euler, who  
                               do'+1567,                                    
                                  'the bedchamber. A short while later he  
                               confided in one of his servants,             
                               secretly'+1331,                              
                                  'the familiar bond valuation equation.   
                               Assuming semiannual coupon payments, the     
                               e'+1402,                                     
                                  '$X$ associated with $U\\\\bar{U}$ and   
                               $\\\\bar{D}{D}$ since this would drop the    
                               poss'+1860,                                  
                                  'parking lot dings.\\"\\n\\n\\"When      
                               these little charges blow, they\'ll leave    
                               M16 impa'+1470,                              
                                  'above from Helms, \\"The Indians,\\"    
                               pp. 3745. \\n | Bruhns, _Ancient South      
                               Americ'+1388,                                
                                  'get some sleep, so I removed the light  
                               bulb and stored it in the pocket of the      
                               C'+1301,                                     
                                  'set of ADE20K in Table                  
                               \\\\[tab:baseline\\\\]. All our results      
                               except the last-row o'+1732,                 
                                  ... +990                                 
                               ]                                            
                   text_pair = None                                         
                  truncation = True                                         
                     verbose = True                                         
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/transformers/tokenization_utils_base.py:2765 in batch_encode_plus     
                                                                              
   2762          **kwargs,                                                 
   2763       )                                                             
   2764                                                                     
  2765       return self._batch_encode_plus(                               
   2766          batch_text_or_text_pairs=batch_text_or_text_pairs,        
   2767          add_special_tokens=add_special_tokens,                    
   2768          padding_strategy=padding_strategy,                        
                                                                              
  locals  
          add_special_tokens = True                                         
    batch_text_or_text_pairs = [                                            
                                  'upon better and\\nnobler views; and     
                               advise your elder sisters, when they         
                               perceive'+1575,                              
                                  "log time reviewing U.S. Army training   
                               films from the Vietnam era. That's the       
                               mil"+1355,                                   
                                  'the speculative philosophers. For       
                               example, the great mathematician Euler, who  
                               do'+1567,                                    
                                  'the bedchamber. A short while later he  
                               confided in one of his servants,             
                               secretly'+1331,                              
                                  'the familiar bond valuation equation.   
                               Assuming semiannual coupon payments, the     
                               e'+1402,                                     
                                  '$X$ associated with $U\\\\bar{U}$ and   
                               $\\\\bar{D}{D}$ since this would drop the    
                               poss'+1860,                                  
                                  'parking lot dings.\\"\\n\\n\\"When      
                               these little charges blow, they\'ll leave    
                               M16 impa'+1470,                              
                                  'above from Helms, \\"The Indians,\\"    
                               pp. 3745. \\n | Bruhns, _Ancient South      
                               Americ'+1388,                                
                                  'get some sleep, so I removed the light  
                               bulb and stored it in the pocket of the      
                               C'+1301,                                     
                                  'set of ADE20K in Table                  
                               \\\\[tab:baseline\\\\]. All our results      
                               except the last-row o'+1732,                 
                                  ... +990                                 
                               ]                                            
         is_split_into_words = False                                        
                      kwargs = {}                                           
                  max_length = 256                                          
          pad_to_multiple_of = None                                         
                     padding = 'max_length'                                 
            padding_strategy = <PaddingStrategy.MAX_LENGTH: 'max_length'>   
       return_attention_mask = None                                         
               return_length = False                                        
      return_offsets_mapping = False                                        
   return_overflowing_tokens = False                                        
  return_special_tokens_mask = False                                        
              return_tensors = None                                         
       return_token_type_ids = None                                         
                        self = PreTrainedTokenizer(name_or_path='facebook  
                               vocab_size=50265,                            
                               model_max_len=1000000000000000019884624838  
                               is_fast=False, padding_side='right',         
                               truncation_side='right',                     
                               special_tokens={'bos_token':                 
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'eos_token':               
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'unk_token':               
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'pad_token':               
                               AddedToken("<pad>", rstrip=False,            
                               lstrip=False, single_word=False,             
                               normalized=True)})                           
                      stride = 0                                            
                  truncation = True                                         
         truncation_strategy = <TruncationStrategy.LONGEST_FIRST:           
                               'longest_first'>                             
                     verbose = True                                         
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/transformers/tokenization_utils.py:733 in _batch_encode_plus          
                                                                              
   730          else:                                                      
   731             ids, pair_ids = ids_or_pair_ids                        
   732                                                                     
  733          first_ids = get_input_ids(ids)                             
   734          second_ids = get_input_ids(pair_ids) if pair_ids is not No 
   735          input_ids.append((first_ids, second_ids))                  
   736                                                                        
                                                                              
  locals  
          add_special_tokens = True                                         
    batch_text_or_text_pairs = [                                            
                                  'upon better and\\nnobler views; and     
                               advise your elder sisters, when they         
                               perceive'+1575,                              
                                  "log time reviewing U.S. Army training   
                               films from the Vietnam era. That's the       
                               mil"+1355,                                   
                                  'the speculative philosophers. For       
                               example, the great mathematician Euler, who  
                               do'+1567,                                    
                                  'the bedchamber. A short while later he  
                               confided in one of his servants,             
                               secretly'+1331,                              
                                  'the familiar bond valuation equation.   
                               Assuming semiannual coupon payments, the     
                               e'+1402,                                     
                                  '$X$ associated with $U\\\\bar{U}$ and   
                               $\\\\bar{D}{D}$ since this would drop the    
                               poss'+1860,                                  
                                  'parking lot dings.\\"\\n\\n\\"When      
                               these little charges blow, they\'ll leave    
                               M16 impa'+1470,                              
                                  'above from Helms, \\"The Indians,\\"    
                               pp. 3745. \\n | Bruhns, _Ancient South      
                               Americ'+1388,                                
                                  'get some sleep, so I removed the light  
                               bulb and stored it in the pocket of the      
                               C'+1301,                                     
                                  'set of ADE20K in Table                  
                               \\\\[tab:baseline\\\\]. All our results      
                               except the last-row o'+1732,                 
                                  ... +990                                 
                               ]                                            
                   first_ids = [                                            
                                  9226,                                    
                                  169,                                     
                                  13,                                      
                                  47,                                      
                                  4,                                       
                                  3676,                                    
                                  3809,                                    
                                  7575,                                    
                                  5,                                       
                                  507,                                     
                                  ... +326                                 
                               ]                                            
               get_input_ids = <function                                    
                               PreTrainedTokenizer._batch_encode_plus.<lo  
                               at 0x7f459958bb80>                           
                         ids = 'Calibur. The anklebiter ignored him and     
                               kept furiously digging. Calibur took a       
                               k'+1342                                      
             ids_or_pair_ids = 'Calibur. The anklebiter ignored him and     
                               kept furiously digging. Calibur took a       
                               k'+1342                                      
                   input_ids = [                                            
                                  (                                        
                                     [                                    
                                        32630,                           
                                        357,                             
                                        8,                               
                                        37457,                           
                                        15688,                           
                                        2413,                            
                                        1371,                            
                                        2728,                            
                                        131,                             
                                        8,                               
                                        ... +412                         
                                     ],                                   
                                     None                                 
                                  ),                                       
                                  (                                        
                                     [                                    
                                        12376,                           
                                        86,                              
                                        9311,                            
                                        121,                             
                                        4,                               
                                        104,                             
                                        4,                               
                                        2938,                            
                                        1058,                            
                                        3541,                            
                                        ... +327                         
                                     ],                                   
                                     None                                 
                                  ),                                       
                                  (                                        
                                     [                                    
                                        627,                             
                                        21779,                           
                                        44267,                           
                                        4,                               
                                        286,                             
                                        1246,                            
                                        6,                               
                                        5,                               
                                        372,                             
                                        43027,                           
                                        ... +315                         
                                     ],                                   
                                     None                                 
                                  ),                                       
                                  (                                        
                                     [                                    
                                        627,                             
                                        3267,                            
                                        611,                             
                                        19383,                           
                                        4,                               
                                        83,                              
                                        765,                             
                                        150,                             
                                        423,                             
                                        37,                              
                                        ... +326                         
                                     ],                                   
                                     None                                 
                                  ),                                       
                                  (                                        
                                     [                                    
                                        627,                             
                                        2950,                            
                                        2175,                            
                                        7440,                            
                                        19587,                           
                                        4,                               
                                        29175,                           
                                        9031,                            
                                        30265,                           
                                        5564,                            
                                        ... +324                         
                                     ],                                   
                                     None                                 
                                  ),                                       
                                  (                                        
                                     [                                    
                                        1629,                            
                                        1000,                            
                                        1629,                            
                                        3059,                            
                                        19,                              
                                        68,                              
                                        791,                             
                                        48669,                           
                                        4901,                            
                                        45152,                           
                                        ... +516                         
                                     ],                                   
                                     None                                 
                                  ),                                       
                                  (                                        
                                     [                                    
                                        15129,                           
                                        154,                             
                                        319,                             
                                        385,                             
                                        1033,                            
                                        4,                               
                                        48110,                           
                                        37457,                           
                                        282,                             
                                        37457,                           
                                        ... +423                         
                                     ],                                   
                                     None                                 
                                  ),                                       
                                  (                                        
                                     [                                    
                                        23444,                           
                                        31,                              
                                        6851,                            
                                        4339,                            
                                        6,                               
                                        48298,                           
                                        133,                             
                                        6739,                            
                                        6,                               
                                        48110,                           
                                        ... +469                         
                                     ],                                   
                                     None                                 
                                  ),                                       
                                  (                                        
                                     [                                    
                                        6460,                            
                                        103,                             
                                        3581,                            
                                        6,                               
                                        98,                              
                                        38,                              
                                        2928,                            
                                        5,                               
                                        1109,                            
                                        32384,                           
                                        ... +302                         
                                     ],                                   
                                     None                                 
                                  ),                                       
                                  (                                        
                                     [                                    
                                        8738,                            
                                        9,                               
                                        4516,                            
                                        717,                             
                                        844,                             
                                        530,                             
                                        11,                              
                                        9513,                            
                                        49309,                           
                                        10975,                           
                                        ... +449                         
                                     ],                                   
                                     None                                 
                                  ),                                       
                                  ... +480                                 
                               ]                                            
         is_split_into_words = False                                        
                      kwargs = {}                                           
                  max_length = 256                                          
          pad_to_multiple_of = None                                         
            padding_strategy = <PaddingStrategy.MAX_LENGTH: 'max_length'>   
                    pair_ids = None                                         
       return_attention_mask = None                                         
               return_length = False                                        
      return_offsets_mapping = False                                        
   return_overflowing_tokens = False                                        
  return_special_tokens_mask = False                                        
              return_tensors = None                                         
       return_token_type_ids = None                                         
                  second_ids = None                                         
                        self = PreTrainedTokenizer(name_or_path='facebook  
                               vocab_size=50265,                            
                               model_max_len=1000000000000000019884624838  
                               is_fast=False, padding_side='right',         
                               truncation_side='right',                     
                               special_tokens={'bos_token':                 
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'eos_token':               
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'unk_token':               
                               AddedToken("</s>", rstrip=False,             
                               lstrip=False, single_word=False,             
                               normalized=True), 'pad_token':               
                               AddedToken("<pad>", rstrip=False,            
                               lstrip=False, single_word=False,             
                               normalized=True)})                           
                      stride = 0                                            
         truncation_strategy = <TruncationStrategy.LONGEST_FIRST:           
                               'longest_first'>                             
                     verbose = True                                         
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/transformers/tokenization_utils.py:701 in get_input_ids               
                                                                              
   698       def get_input_ids(text):                                       
   699          if isinstance(text, str):                                  
   700             tokens = self.tokenize(text, **kwargs)                 
  701             return self.convert_tokens_to_ids(tokens)              
   702          elif isinstance(text, (list, tuple)) and len(text) > 0 and 
   703             if is_split_into_words:                                
   704                tokens = list(                                     
                                                                              
  locals  
  is_split_into_words = False                                               
               kwargs = {}                                                  
                 self = PreTrainedTokenizer(name_or_path='facebook/opt-2.  
                        vocab_size=50265,                                   
                        model_max_len=1000000000000000019884624838656,      
                        is_fast=False, padding_side='right',                
                        truncation_side='right',                            
                        special_tokens={'bos_token': AddedToken("</s>",     
                        rstrip=False, lstrip=False, single_word=False,      
                        normalized=True), 'eos_token': AddedToken("</s>",   
                        rstrip=False, lstrip=False, single_word=False,      
                        normalized=True), 'unk_token': AddedToken("</s>",   
                        rstrip=False, lstrip=False, single_word=False,      
                        normalized=True), 'pad_token': AddedToken("<pad>",  
                        rstrip=False, lstrip=False, single_word=False,      
                        normalized=True)})                                  
                 text = 'Calibur. The anklebiter ignored him and kept       
                        furiously digging. Calibur took a k'+1342           
               tokens = [                                                   
                           'Cal',                                          
                           'ibur',                                         
                           '.',                                            
                           'The',                                         
                           'ankle',                                       
                           'bit',                                          
                           'er',                                           
                           'ignored',                                     
                           'him',                                         
                           'and',                                         
                           ... +331                                        
                        ]                                                   
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/transformers/tokenization_utils.py:579 in convert_tokens_to_ids       
                                                                              
   576                                                                      
   577       ids = []                                                       
   578       for token in tokens:                                           
  579          ids.append(self._convert_token_to_id_with_added_voc(token) 
   580       return ids                                                     
   581                                                                       
   582    def _convert_token_to_id_with_added_voc(self, token):              
                                                                              
  locals  
     ids = [15117, 28959, 4, 20, 7451, 5881, 254, 8266, 123, 8, ... +6]     
    self = PreTrainedTokenizer(name_or_path='facebook/opt-2.7b',            
           vocab_size=50265,                                                
           model_max_len=1000000000000000019884624838656, is_fast=False,    
           padding_side='right', truncation_side='right',                   
           special_tokens={'bos_token': AddedToken("</s>", rstrip=False,    
           lstrip=False, single_word=False, normalized=True), 'eos_token':  
           AddedToken("</s>", rstrip=False, lstrip=False,                   
           single_word=False, normalized=True), 'unk_token':                
           AddedToken("</s>", rstrip=False, lstrip=False,                   
           single_word=False, normalized=True), 'pad_token':                
           AddedToken("<pad>", rstrip=False, lstrip=False,                  
           single_word=False, normalized=True)})                            
   token = 'took'                                                          
  tokens = [                                                                
              'Cal',                                                       
              'ibur',                                                      
              '.',                                                         
              'The',                                                      
              'ankle',                                                    
              'bit',                                                       
              'er',                                                        
              'ignored',                                                  
              'him',                                                      
              'and',                                                      
              ... +331                                                     
           ]                                                                
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/transformers/tokenization_utils.py:588 in                             
 _convert_token_to_id_with_added_voc                                          
                                                                              
   585                                                                      
   586       if token in self.added_tokens_encoder:                         
   587          return self.added_tokens_encoder[token]                    
  588       return self._convert_token_to_id(token)                        
   589                                                                       
   590    def _convert_token_to_id(self, token):                             
   591       raise NotImplementedError                                      
                                                                              
  locals  
   self = PreTrainedTokenizer(name_or_path='facebook/opt-2.7b',             
          vocab_size=50265, model_max_len=1000000000000000019884624838656,  
          is_fast=False, padding_side='right', truncation_side='right',     
          special_tokens={'bos_token': AddedToken("</s>", rstrip=False,     
          lstrip=False, single_word=False, normalized=True), 'eos_token':   
          AddedToken("</s>", rstrip=False, lstrip=False,                    
          single_word=False, normalized=True), 'unk_token':                 
          AddedToken("</s>", rstrip=False, lstrip=False,                    
          single_word=False, normalized=True), 'pad_token':                 
          AddedToken("<pad>", rstrip=False, lstrip=False,                   
          single_word=False, normalized=True)})                             
  token = 'took'                                                           
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/transformers/models/gpt2/tokenization_gpt2.py:308 in                  
 _convert_token_to_id                                                         
                                                                              
   305                                                                       
   306    def _convert_token_to_id(self, token):                             
   307       """Converts a token (str) in an id using the vocab."""         
  308       return self.encoder.get(token, self.encoder.get(self.unk_token 
   309                                                                       
   310    def _convert_id_to_token(self, index):                             
   311       """Converts an index (integer) in a token (str) using the voca 
                                                                              
  locals  
   self = PreTrainedTokenizer(name_or_path='facebook/opt-2.7b',             
          vocab_size=50265, model_max_len=1000000000000000019884624838656,  
          is_fast=False, padding_side='right', truncation_side='right',     
          special_tokens={'bos_token': AddedToken("</s>", rstrip=False,     
          lstrip=False, single_word=False, normalized=True), 'eos_token':   
          AddedToken("</s>", rstrip=False, lstrip=False,                    
          single_word=False, normalized=True), 'unk_token':                 
          AddedToken("</s>", rstrip=False, lstrip=False,                    
          single_word=False, normalized=True), 'pad_token':                 
          AddedToken("<pad>", rstrip=False, lstrip=False,                   
          single_word=False, normalized=True)})                             
  token = 'took'                                                           
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/transformers/tokenization_utils_base.py:988 in unk_token              
                                                                              
    985          return None                                               
    986       return str(self._eos_token)                                   
    987                                                                      
   988    @property                                                         
    989    def unk_token(self) -> str:                                       
    990       """                                                           
    991       `str`: Unknown token. Log an error if used while not having b 
                                                                              
  locals  
  self = PreTrainedTokenizer(name_or_path='facebook/opt-2.7b',              
         vocab_size=50265, model_max_len=1000000000000000019884624838656,   
         is_fast=False, padding_side='right', truncation_side='right',      
         special_tokens={'bos_token': AddedToken("</s>", rstrip=False,      
         lstrip=False, single_word=False, normalized=True), 'eos_token':    
         AddedToken("</s>", rstrip=False, lstrip=False, single_word=False,  
         normalized=True), 'unk_token': AddedToken("</s>", rstrip=False,    
         lstrip=False, single_word=False, normalized=True), 'pad_token':    
         AddedToken("<pad>", rstrip=False, lstrip=False,                    
         single_word=False, normalized=True)})                              
  

KeyboardInterrupt

During handling of the above exception, another exception occurred:

 Traceback (most recent call last) 
 /home/paperspace/Documents/Repos/clm_model_tuning/finetune_using_clm_wandb.p 
 y:599 in <module>                                                            
                                                                              
   596                                                                        
   597                                                                        
   598 if __name__ == "__main__":                                             
  599    main()                                                             
                                                                              
  locals  
              __annotations__ = {}                                          
                 __builtins__ = <module 'builtins' (built-in)>              
                   __cached__ = None                                        
                      __doc__ = '\nFine-tuning the library models for       
                                causal language modeling (GPT, GPT-2,       
                                CTRL, '+208                                 
                     __file__ = 'finetune_using_clm_wandb.py'               
                   __loader__ = <_frozen_importlib_external.SourceFileLoa  
                                object at 0x7f46d89524c0>                   
                     __name__ = '__main__'                                  
                  __package__ = None                                        
                     __spec__ = None                                        
                  Accelerator = <class                                      
                                'accelerate.accelerator.Accelerator'>       
                   AutoConfig = <class                                      
                                'transformers.models.auto.configuration_a  
                    AutoModel = <class                                      
                                'transformers.models.auto.modeling_auto.A  
         AutoModelForCausalLM = <class                                      
                                'transformers.models.auto.modeling_auto.A  
                AutoTokenizer = <class                                      
                                'transformers.models.auto.tokenization_au  
                    bittensor = <module 'bittensor' from                    
                                '/home/paperspace/Documents/Repos/clm_mod  
                        chain = <class 'itertools.chain'>                   
  check_cfg_and_load_defaults = <function check_cfg_and_load_defaults at    
                                0x7f46d890e310>                             
           create_accelerator = <function create_accelerator at             
                                0x7f4680748f70>                             
             create_optimizer = <function create_optimizer at               
                                0x7f46807530d0>                             
                   DataLoader = <class                                      
                                'torch.utils.data.dataloader.DataLoader'>   
                      Dataset = <class 'datasets.arrow_dataset.Dataset'>    
                  DatasetDict = <class                                      
                                'datasets.dataset_dict.DatasetDict'>        
                     datasets = <module 'datasets' from                     
                                '/home/paperspace/Documents/Repos/clm_mod  
        default_data_collator = <function default_data_collator at          
                                0x7f469c066700>                             
                   DictConfig = <class 'omegaconf.dictconfig.DictConfig'>   
              DistributedType = <enum 'DistributedType'>                    
                   get_logger = <function get_logger at 0x7f46ab7781f0>     
                get_scheduler = <function get_scheduler at 0x7f469c0328b0>  
              HF_access_token = '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'     
                        hydra = <module 'hydra' from                        
                                '/home/paperspace/Documents/Repos/clm_mod  
                 load_dataset = <function load_dataset at 0x7f46bed87790>   
     load_model_and_tokenizer = <function load_model_and_tokenizer at       
                                0x7f4680753040>                             
          load_preloaded_data = <function load_preloaded_data at            
                                0x7f4680753280>                             
            load_raw_datasets = <function load_raw_datasets at              
                                0x7f4680748ee0>                             
                      logging = <module 'logging' from                      
                                '/usr/lib/python3.8/logging/__init__.py'>   
                         main = <function main at 0x7f4680753430>           
                         math = <module 'math' (built-in)>                  
                           np = <module 'numpy' from                        
                                '/home/paperspace/Documents/Repos/clm_mod  
                    OmegaConf = <class 'omegaconf.omegaconf.OmegaConf'>     
                           os = <module 'os' from                           
                                '/usr/lib/python3.8/os.py'>                 
                       pickle = <module 'pickle' from                       
                                '/usr/lib/python3.8/pickle.py'>             
                   preprocess = <function preprocess at 0x7f4680753160>     
                       random = <module 'random' from                       
                                '/usr/lib/python3.8/random.py'>             
      save_tokenized_datasets = <function save_tokenized_datasets at        
                                0x7f46807531f0>                             
                     set_seed = <function set_seed at 0x7f46a897cd30>       
                   test_model = False                                       
                         time = <module 'time' (built-in)>                  
                        torch = <module 'torch' from                        
                                '/home/paperspace/Documents/Repos/clm_mod  
                         tqdm = <class 'tqdm.asyncio.tqdm_asyncio'>         
                 transformers = <module 'transformers' from                 
                                '/home/paperspace/Documents/Repos/clm_mod  
                        wandb = <module 'wandb' from                        
                                '/home/paperspace/Documents/Repos/clm_mod  
                    WANDB_KEY = 'c0d007cc7a7f9e6db9b2d3d4d37f17f1b0202276'  
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/hydra/main.py:90 in decorated_main                                    
                                                                              
    87             else:                                                  
    88                # no return value from run_hydra() as it may somet 
    89                # multiple times (--multirun)                      
   90                _run_hydra(                                        
    91                   args=args,                                     
    92                   args_parser=args_parser,                       
    93                   task_function=task_function,                   
                                                                              
  locals  
             args = Namespace(cfg=None, config_dir=None, config_name=None,  
                    config_path=None, experimental_rerun=None, help=False,  
                    hydra_help=False, info=None, multirun=False,            
                    overrides=['model.name=facebook/opt-2.7b',              
                    'training.eval_every=250',                              
                    'training.train_batch_size=32',                         
                    'training.weight_decay=0.05',                           
                    'training.eval_batch_size=16',                          
                    'training.learning_rate=0.000003',                      
                    'training.val_split_percent=20',                        
                    'training.num_epochs=4', 'training.lr_warmup_steps=5',  
                    'training.gradient_accumulation_steps=2',               
                    'dataset.name=ViktorThink/mountain_combined_813306',    
                    'dataset.num_batches=5000', 'hydra.mode=RUN'],          
                    package=None, resolve=False, run=True,                  
                    shell_completion=False)                                 
      args_parser = ArgumentParser(prog='finetune_using_clm_wandb.py',      
                    usage=None, description='Hydra',                        
                    formatter_class=<class 'argparse.HelpFormatter'>,       
                    conflict_handler='error', add_help=False)               
  cfg_passthrough = None                                                    
      config_name = 'config'                                                
      config_path = 'conf'                                                  
    task_function = <function main at 0x7f46807533a0>                       
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/hydra/_internal/utils.py:389 in _run_hydra                            
                                                                              
   386                                                                      
   387       if args.run or args.multirun:                                  
   388          run_mode = hydra.get_mode(config_name=config_name, overrid 
  389          _run_app(                                                  
   390             run=args.run,                                          
   391             multirun=args.multirun,                                
   392             mode=run_mode,                                         
                                                                              
  locals  
        add_conf_dir = <function _run_hydra.<locals>.add_conf_dir at        
                       0x7f46807534c0>                                      
                args = Namespace(cfg=None, config_dir=None,                 
                       config_name=None, config_path=None,                  
                       experimental_rerun=None, help=False,                 
                       hydra_help=False, info=None, multirun=False,         
                       overrides=['model.name=facebook/opt-2.7b',           
                       'training.eval_every=250',                           
                       'training.train_batch_size=32',                      
                       'training.weight_decay=0.05',                        
                       'training.eval_batch_size=16',                       
                       'training.learning_rate=0.000003',                   
                       'training.val_split_percent=20',                     
                       'training.num_epochs=4',                             
                       'training.lr_warmup_steps=5',                        
                       'training.gradient_accumulation_steps=2',            
                       'dataset.name=ViktorThink/mountain_combined_813306  
                       'dataset.num_batches=5000', 'hydra.mode=RUN'],       
                       package=None, resolve=False, run=True,               
                       shell_completion=False)                              
         args_parser = ArgumentParser(prog='finetune_using_clm_wandb.py',   
                       usage=None, description='Hydra',                     
                       formatter_class=<class 'argparse.HelpFormatter'>,    
                       conflict_handler='error', add_help=False)            
  caller_stack_depth = 2                                                    
        calling_file = 'finetune_using_clm_wandb.py'                        
      calling_module = None                                                 
         config_name = 'config'                                             
         config_path = 'conf'                                               
         GlobalHydra = <class 'hydra.core.global_hydra.GlobalHydra'>        
        has_show_cfg = False                                                
               Hydra = <class 'hydra._internal.hydra.Hydra'>                
               hydra = <hydra._internal.hydra.Hydra object at               
                       0x7f4680759fa0>                                      
        num_commands = 0                                                    
           overrides = [                                                    
                          'model.name=facebook/opt-2.7b',                  
                          'training.eval_every=250',                       
                          'training.train_batch_size=32',                  
                          'training.weight_decay=0.05',                    
                          'training.eval_batch_size=16',                   
                          'training.learning_rate=0.000003',               
                          'training.val_split_percent=20',                 
                          'training.num_epochs=4',                         
                          'training.lr_warmup_steps=5',                    
                          'training.gradient_accumulation_steps=2',        
                          ... +3                                           
                       ]                                                    
            run_mode = None                                                 
         search_path = <hydra._internal.config_search_path_impl.ConfigSea  
                       object at 0x7f4680755bb0>                            
       task_function = <function main at 0x7f46807533a0>                    
           task_name = 'finetune_using_clm_wandb'                           
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/hydra/_internal/utils.py:452 in _run_app                              
                                                                              
   449          overrides.extend(["hydra.mode=MULTIRUN"])                  
   450                                                                       
   451    if mode == RunMode.RUN:                                            
  452       run_and_report(                                                
   453          lambda: hydra.run(                                         
   454             config_name=config_name,                               
   455             task_function=task_function,                           
                                                                              
  locals    
    config_name = 'config'                                                  
          hydra = <hydra._internal.hydra.Hydra object at 0x7f4680759fa0>    
           mode = <RunMode.RUN: 1>                                          
       multirun = False                                                     
      overrides = [                                                         
                     'model.name=facebook/opt-2.7b',                       
                     'training.eval_every=250',                            
                     'training.train_batch_size=32',                       
                     'training.weight_decay=0.05',                         
                     'training.eval_batch_size=16',                        
                     'training.learning_rate=0.000003',                    
                     'training.val_split_percent=20',                      
                     'training.num_epochs=4',                              
                     'training.lr_warmup_steps=5',                         
                     'training.gradient_accumulation_steps=2',             
                     ... +3                                                
                  ]                                                         
            run = True                                                      
  task_function = <function main at 0x7f46807533a0>                         
    
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/hydra/_internal/utils.py:213 in run_and_report                        
                                                                              
   210                                                                        
   211 def run_and_report(func: Any) -> Any:                                  
   212    try:                                                               
  213       return func()                                                  
   214    except Exception as ex:                                            
   215       if _is_env_set("HYDRA_FULL_ERROR") or is_under_debugger():     
   216          raise ex                                                   
                                                                              
  locals            
  func = <function _run_app.<locals>.<lambda> at 0x7f46806b2790>            
            
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/hydra/_internal/utils.py:453 in <lambda>                              
                                                                              
   450                                                                       
   451    if mode == RunMode.RUN:                                            
   452       run_and_report(                                                
  453          lambda: hydra.run(                                         
   454             config_name=config_name,                               
   455             task_function=task_function,                           
   456             overrides=overrides,                                   
                                                                              
  locals    
    config_name = 'config'                                                  
          hydra = <hydra._internal.hydra.Hydra object at 0x7f4680759fa0>    
      overrides = [                                                         
                     'model.name=facebook/opt-2.7b',                       
                     'training.eval_every=250',                            
                     'training.train_batch_size=32',                       
                     'training.weight_decay=0.05',                         
                     'training.eval_batch_size=16',                        
                     'training.learning_rate=0.000003',                    
                     'training.val_split_percent=20',                      
                     'training.num_epochs=4',                              
                     'training.lr_warmup_steps=5',                         
                     'training.gradient_accumulation_steps=2',             
                     ... +3                                                
                  ]                                                         
  task_function = <function main at 0x7f46807533a0>                         
    
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/hydra/_internal/hydra.py:119 in run                                   
                                                                              
   116       callbacks = Callbacks(cfg)                                     
   117       callbacks.on_run_start(config=cfg, config_name=config_name)    
   118                                                                      
  119       ret = run_job(                                                 
   120          hydra_context=HydraContext(                                
   121             config_loader=self.config_loader, callbacks=callbacks  
   122          ),                                                         
                                                                              
  locals  
               callbacks = <hydra._internal.callbacks.Callbacks object at   
                           0x7f46b4846d90>                                  
                     cfg = {'hydra': {'run': {'dir':                        
                           'outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}'},      
                           'sweep': {'dir':                                 
                           'multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}',      
                           'subdir': '${hydra.job.num}'}, 'launcher':       
                           {'_target_':                                     
                           'hydra._internal.core_plugins.basic_launcher.B  
                           'sweeper': {'_target_':                          
                           'hydra._internal.core_plugins.basic_sweeper.Ba  
                           'max_batch_size': None, 'params': None},         
                           'help': {'app_name': '${hydra.job.name}',        
                           'header': '${hydra.help.app_name} is powered by  
                           Hydra.\n', 'footer': 'Powered by Hydra           
                           (https://hydra.cc)\nUse --hydra-help to view     
                           Hydra specific help\n', 'template':              
                           '${hydra.help.header}\n== Configuration groups   
                           ==\nCompose your configuration from those        
                           groups                                           
                           (group=option)\n\n$APP_CONFIG_GROUPS\n\n==       
                           Config ==\nOverride anything in the config       
                           (foo.bar=value)\n\n$CONFIG\n\n${hydra.help.foo  
                           'hydra_help': {'template': "Hydra                
                           (${hydra.runtime.version})\nSee                  
                           https://hydra.cc for more info.\n\n== Flags      
                           ==\n$FLAGS_HELP\n\n== Configuration groups       
                           ==\nCompose your configuration from those        
                           groups (For example, append                      
                           hydra/job_logging=disabled to command            
                           line)\n\n$HYDRA_CONFIG_GROUPS\n\nUse '--cfg      
                           hydra' to Show the Hydra config.\n",             
                           'hydra_help': '???'}, 'hydra_logging':           
                           {'version': 1, 'formatters': {'simple':          
                           {'format': '[%(asctime)s][HYDRA]                 
                           %(message)s'}}, 'handlers': {'console':          
                           {'class': 'logging.StreamHandler', 'formatter':  
                           'simple', 'stream': 'ext://sys.stdout'}},        
                           'root': {'level': 'INFO', 'handlers':            
                           ['console']}, 'loggers': {'logging_example':     
                           {'level': 'DEBUG'}},                             
                           'disable_existing_loggers': False},              
                           'job_logging': {'version': 1, 'formatters':      
                           {'simple': {'format':                            
                           '[%(asctime)s][%(name)s][%(levelname)s] -        
                           %(message)s'}}, 'handlers': {'console':          
                           {'class': 'logging.StreamHandler', 'formatter':  
                           'simple', 'stream': 'ext://sys.stdout'},         
                           'file': {'class': 'logging.FileHandler',         
                           'formatter': 'simple', 'filename':               
                           '${hydra.runtime.output_dir}/${hydra.job.name}  
                           'root': {'level': 'INFO', 'handlers':            
                           ['console', 'file']},                            
                           'disable_existing_loggers': False}, 'env': {},   
                           'mode': <RunMode.RUN: 1>, 'searchpath': [],      
                           'callbacks': {}, 'output_subdir': '.hydra',      
                           'overrides': {'hydra': ['hydra.mode=RUN'],       
                           'task': ['model.name=facebook/opt-2.7b',         
                           'training.eval_every=250',                       
                           'training.train_batch_size=32',                  
                           'training.weight_decay=0.05',                    
                           'training.eval_batch_size=16',                   
                           'training.learning_rate=0.000003',               
                           'training.val_split_percent=20',                 
                           'training.num_epochs=4',                         
                           'training.lr_warmup_steps=5',                    
                           'training.gradient_accumulation_steps=2',        
                           'dataset.name=ViktorThink/mountain_combined_81  
                           'dataset.num_batches=5000']}, 'job': {'name':    
                           'finetune_using_clm_wandb', 'chdir': None,       
                           'override_dirname':                              
                           'dataset.name=ViktorThink/mountain_combined_81  
                           'id': '???', 'num': '???', 'config_name':        
                           'config', 'env_set': {}, 'env_copy': [],         
                           'config': {'override_dirname': {'kv_sep': '=',   
                           'item_sep': ',', 'exclude_keys': []}}},          
                           'runtime': {'version': '1.2.0', 'version_base':  
                           '1.2', 'cwd':                                    
                           '/home/paperspace/Documents/Repos/clm_model_tu  
                           'config_sources': [{'path': 'hydra.conf',        
                           'schema': 'pkg', 'provider': 'hydra'}, {'path':  
                           '/home/paperspace/Documents/Repos/clm_model_tu  
                           'schema': 'file', 'provider': 'main'}, {'path':  
                           '', 'schema': 'structured', 'provider':          
                           'schema'}], 'output_dir':                        
                           '/home/paperspace/Documents/Repos/clm_model_tu  
                           'choices': {'hydra/env': 'default',              
                           'hydra/callbacks': None, 'hydra/job_logging':    
                           'default', 'hydra/hydra_logging': 'default',     
                           'hydra/hydra_help': 'default', 'hydra/help':     
                           'default', 'hydra/sweeper': 'basic',             
                           'hydra/launcher': 'basic', 'hydra/output':       
                           'default'}}, 'verbose': False}, 'output_dir':    
                           'tuned-model', 'bittensor': {'network':          
                           'nobunaga'}, 'dataset': {'name':                 
                           'ViktorThink/mountain_combined_813306',          
                           'config_name': None, 'num_batches': 5000,        
                           'block_size': None, 'overwrite_cache': False,    
                           'keep_linebreaks': True, 'concatenate_raw':      
                           False, 'load_tokenized_data': False}, 'model':   
                           {'name': 'facebook/opt-2.7b', 'config_name':     
                           None}, 'tokenizer': {'name': None, 'use_fast':   
                           True, 'preprocessing_num_workers': None,         
                           'pad_token': '[PAD]'}, 'training': {'seed': 17,  
                           'val_split_percent': 20, 'train_batch_size':     
                           32, 'eval_batch_size': 16, 'learning_rate':      
                           3e-06, 'weight_decay': 0.05, 'num_epochs': 4,    
                           'max_train_steps': None,                         
                           'gradient_accumulation_steps': 2,                
                           'lr_scheduler': 'constant', 'lr_warmup_steps':   
                           5, 'eval_every': 250, 'max_eval_steps': 500,     
                           'checkpoint': {'resume_from_checkpoint': 0,      
                           'every_n_steps': None}}, 'tracking':             
                           {'enabled': True, 'report_to': 'all'},           
                           'testing': {'enabled': False}}                   
             config_name = 'config'                                         
               overrides = [                                                
                              'model.name=facebook/opt-2.7b',              
                              'training.eval_every=250',                   
                              'training.train_batch_size=32',              
                              'training.weight_decay=0.05',                
                              'training.eval_batch_size=16',               
                              'training.learning_rate=0.000003',           
                              'training.val_split_percent=20',             
                              'training.num_epochs=4',                     
                              'training.lr_warmup_steps=5',                
                              'training.gradient_accumulation_steps=2',    
                              ... +3                                       
                           ]                                                
                    self = <hydra._internal.hydra.Hydra object at           
                           0x7f4680759fa0>                                  
           task_function = <function main at 0x7f46807533a0>                
  with_log_configuration = True                                             
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/hydra/core/utils.py:186 in run_job                                    
                                                                              
   183       with env_override(hydra_cfg.hydra.job.env_set):                
   184          callbacks.on_job_start(config=config)                      
   185          try:                                                       
  186             ret.return_value = task_function(task_cfg)             
   187             ret.status = JobStatus.COMPLETED                       
   188          except Exception as e:                                     
   189             ret.return_value = e                                   
                                                                              
  locals  
             _chdir = False                                                 
          callbacks = <hydra._internal.callbacks.Callbacks object at        
                      0x7f46b4846d90>                                       
             config = {'hydra': {'run': {'dir':                             
                      'outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}'}, 'sweep':  
                      {'dir': 'multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}',   
                      'subdir': '${hydra.job.num}'}, 'launcher':            
                      {'_target_':                                          
                      'hydra._internal.core_plugins.basic_launcher.BasicL  
                      'sweeper': {'_target_':                               
                      'hydra._internal.core_plugins.basic_sweeper.BasicSw  
                      'max_batch_size': None, 'params': None}, 'help':      
                      {'app_name': '${hydra.job.name}', 'header':           
                      '${hydra.help.app_name} is powered by Hydra.\n',      
                      'footer': 'Powered by Hydra (https://hydra.cc)\nUse   
                      --hydra-help to view Hydra specific help\n',          
                      'template': '${hydra.help.header}\n== Configuration   
                      groups ==\nCompose your configuration from those      
                      groups (group=option)\n\n$APP_CONFIG_GROUPS\n\n==     
                      Config ==\nOverride anything in the config            
                      (foo.bar=value)\n\n$CONFIG\n\n${hydra.help.footer}\  
                      'hydra_help': {'template': "Hydra                     
                      (${hydra.runtime.version})\nSee https://hydra.cc for  
                      more info.\n\n== Flags ==\n$FLAGS_HELP\n\n==          
                      Configuration groups ==\nCompose your configuration   
                      from those groups (For example, append                
                      hydra/job_logging=disabled to command                 
                      line)\n\n$HYDRA_CONFIG_GROUPS\n\nUse '--cfg hydra'    
                      to Show the Hydra config.\n", 'hydra_help': '???'},   
                      'hydra_logging': {'version': 1, 'formatters':         
                      {'simple': {'format': '[%(asctime)s][HYDRA]           
                      %(message)s'}}, 'handlers': {'console': {'class':     
                      'logging.StreamHandler', 'formatter': 'simple',       
                      'stream': 'ext://sys.stdout'}}, 'root': {'level':     
                      'INFO', 'handlers': ['console']}, 'loggers':          
                      {'logging_example': {'level': 'DEBUG'}},              
                      'disable_existing_loggers': False}, 'job_logging':    
                      {'version': 1, 'formatters': {'simple': {'format':    
                      '[%(asctime)s][%(name)s][%(levelname)s] -             
                      %(message)s'}}, 'handlers': {'console': {'class':     
                      'logging.StreamHandler', 'formatter': 'simple',       
                      'stream': 'ext://sys.stdout'}, 'file': {'class':      
                      'logging.FileHandler', 'formatter': 'simple',         
                      'filename':                                           
                      '${hydra.runtime.output_dir}/${hydra.job.name}.log'  
                      'root': {'level': 'INFO', 'handlers': ['console',     
                      'file']}, 'disable_existing_loggers': False}, 'env':  
                      {}, 'mode': <RunMode.RUN: 1>, 'searchpath': [],       
                      'callbacks': {}, 'output_subdir': '.hydra',           
                      'overrides': {'hydra': ['hydra.mode=RUN'], 'task':    
                      ['model.name=facebook/opt-2.7b',                      
                      'training.eval_every=250',                            
                      'training.train_batch_size=32',                       
                      'training.weight_decay=0.05',                         
                      'training.eval_batch_size=16',                        
                      'training.learning_rate=0.000003',                    
                      'training.val_split_percent=20',                      
                      'training.num_epochs=4',                              
                      'training.lr_warmup_steps=5',                         
                      'training.gradient_accumulation_steps=2',             
                      'dataset.name=ViktorThink/mountain_combined_813306',  
                      'dataset.num_batches=5000']}, 'job': {'name':         
                      'finetune_using_clm_wandb', 'chdir': None,            
                      'override_dirname':                                   
                      'dataset.name=ViktorThink/mountain_combined_813306,  
                      'id': '???', 'num': '???', 'config_name': 'config',   
                      'env_set': {}, 'env_copy': [], 'config':              
                      {'override_dirname': {'kv_sep': '=', 'item_sep':      
                      ',', 'exclude_keys': []}}}, 'runtime': {'version':    
                      '1.2.0', 'version_base': '1.2', 'cwd':                
                      '/home/paperspace/Documents/Repos/clm_model_tuning',  
                      'config_sources': [{'path': 'hydra.conf', 'schema':   
                      'pkg', 'provider': 'hydra'}, {'path':                 
                      '/home/paperspace/Documents/Repos/clm_model_tuning/  
                      'schema': 'file', 'provider': 'main'}, {'path': '',   
                      'schema': 'structured', 'provider': 'schema'}],       
                      'output_dir':                                         
                      '/home/paperspace/Documents/Repos/clm_model_tuning/  
                      'choices': {'hydra/env': 'default',                   
                      'hydra/callbacks': None, 'hydra/job_logging':         
                      'default', 'hydra/hydra_logging': 'default',          
                      'hydra/hydra_help': 'default', 'hydra/help':          
                      'default', 'hydra/sweeper': 'basic',                  
                      'hydra/launcher': 'basic', 'hydra/output':            
                      'default'}}, 'verbose': False}, 'output_dir':         
                      'tuned-model', 'bittensor': {'network': 'nobunaga'},  
                      'dataset': {'name':                                   
                      'ViktorThink/mountain_combined_813306',               
                      'config_name': None, 'num_batches': 5000,             
                      'block_size': None, 'overwrite_cache': False,         
                      'keep_linebreaks': True, 'concatenate_raw': False,    
                      'load_tokenized_data': False}, 'model': {'name':      
                      'facebook/opt-2.7b', 'config_name': None},            
                      'tokenizer': {'name': None, 'use_fast': True,         
                      'preprocessing_num_workers': None, 'pad_token':       
                      '[PAD]'}, 'training': {'seed': 17,                    
                      'val_split_percent': 20, 'train_batch_size': 32,      
                      'eval_batch_size': 16, 'learning_rate': 3e-06,        
                      'weight_decay': 0.05, 'num_epochs': 4,                
                      'max_train_steps': None,                              
                      'gradient_accumulation_steps': 2, 'lr_scheduler':     
                      'constant', 'lr_warmup_steps': 5, 'eval_every': 250,  
                      'max_eval_steps': 500, 'checkpoint':                  
                      {'resume_from_checkpoint': 0, 'every_n_steps':        
                      None}}, 'tracking': {'enabled': True, 'report_to':    
                      'all'}, 'testing': {'enabled': False}}                
  configure_logging = True                                                  
          hydra_cfg = {'hydra': {'run': {'dir':                             
                      'outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}'}, 'sweep':  
                      {'dir': 'multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}',   
                      'subdir': '${hydra.job.num}'}, 'launcher':            
                      {'_target_':                                          
                      'hydra._internal.core_plugins.basic_launcher.BasicL  
                      'sweeper': {'_target_':                               
                      'hydra._internal.core_plugins.basic_sweeper.BasicSw  
                      'max_batch_size': None, 'params': None}, 'help':      
                      {'app_name': '${hydra.job.name}', 'header':           
                      '${hydra.help.app_name} is powered by Hydra.\n',      
                      'footer': 'Powered by Hydra (https://hydra.cc)\nUse   
                      --hydra-help to view Hydra specific help\n',          
                      'template': '${hydra.help.header}\n== Configuration   
                      groups ==\nCompose your configuration from those      
                      groups (group=option)\n\n$APP_CONFIG_GROUPS\n\n==     
                      Config ==\nOverride anything in the config            
                      (foo.bar=value)\n\n$CONFIG\n\n${hydra.help.footer}\  
                      'hydra_help': {'template': "Hydra                     
                      (${hydra.runtime.version})\nSee https://hydra.cc for  
                      more info.\n\n== Flags ==\n$FLAGS_HELP\n\n==          
                      Configuration groups ==\nCompose your configuration   
                      from those groups (For example, append                
                      hydra/job_logging=disabled to command                 
                      line)\n\n$HYDRA_CONFIG_GROUPS\n\nUse '--cfg hydra'    
                      to Show the Hydra config.\n", 'hydra_help': '???'},   
                      'hydra_logging': {'version': 1, 'formatters':         
                      {'simple': {'format': '[%(asctime)s][HYDRA]           
                      %(message)s'}}, 'handlers': {'console': {'class':     
                      'logging.StreamHandler', 'formatter': 'simple',       
                      'stream': 'ext://sys.stdout'}}, 'root': {'level':     
                      'INFO', 'handlers': ['console']}, 'loggers':          
                      {'logging_example': {'level': 'DEBUG'}},              
                      'disable_existing_loggers': False}, 'job_logging':    
                      {'version': 1, 'formatters': {'simple': {'format':    
                      '[%(asctime)s][%(name)s][%(levelname)s] -             
                      %(message)s'}}, 'handlers': {'console': {'class':     
                      'logging.StreamHandler', 'formatter': 'simple',       
                      'stream': 'ext://sys.stdout'}, 'file': {'class':      
                      'logging.FileHandler', 'formatter': 'simple',         
                      'filename':                                           
                      '${hydra.runtime.output_dir}/${hydra.job.name}.log'  
                      'root': {'level': 'INFO', 'handlers': ['console',     
                      'file']}, 'disable_existing_loggers': False}, 'env':  
                      {}, 'mode': <RunMode.RUN: 1>, 'searchpath': [],       
                      'callbacks': {}, 'output_subdir': '.hydra',           
                      'overrides': {'hydra': ['hydra.mode=RUN'], 'task':    
                      ['model.name=facebook/opt-2.7b',                      
                      'training.eval_every=250',                            
                      'training.train_batch_size=32',                       
                      'training.weight_decay=0.05',                         
                      'training.eval_batch_size=16',                        
                      'training.learning_rate=0.000003',                    
                      'training.val_split_percent=20',                      
                      'training.num_epochs=4',                              
                      'training.lr_warmup_steps=5',                         
                      'training.gradient_accumulation_steps=2',             
                      'dataset.name=ViktorThink/mountain_combined_813306',  
                      'dataset.num_batches=5000']}, 'job': {'name':         
                      'finetune_using_clm_wandb', 'chdir': None,            
                      'override_dirname':                                   
                      'dataset.name=ViktorThink/mountain_combined_813306,  
                      'id': '???', 'num': '???', 'config_name': 'config',   
                      'env_set': {}, 'env_copy': [], 'config':              
                      {'override_dirname': {'kv_sep': '=', 'item_sep':      
                      ',', 'exclude_keys': []}}}, 'runtime': {'version':    
                      '1.2.0', 'version_base': '1.2', 'cwd':                
                      '/home/paperspace/Documents/Repos/clm_model_tuning',  
                      'config_sources': [{'path': 'hydra.conf', 'schema':   
                      'pkg', 'provider': 'hydra'}, {'path':                 
                      '/home/paperspace/Documents/Repos/clm_model_tuning/  
                      'schema': 'file', 'provider': 'main'}, {'path': '',   
                      'schema': 'structured', 'provider': 'schema'}],       
                      'output_dir':                                         
                      '/home/paperspace/Documents/Repos/clm_model_tuning/  
                      'choices': {'hydra/env': 'default',                   
                      'hydra/callbacks': None, 'hydra/job_logging':         
                      'default', 'hydra/hydra_logging': 'default',          
                      'hydra/hydra_help': 'default', 'hydra/help':          
                      'default', 'hydra/sweeper': 'basic',                  
                      'hydra/launcher': 'basic', 'hydra/output':            
                      'default'}}, 'verbose': False}}                       
      hydra_context = HydraContext(                                         
                                                                           
                      config_loader=<hydra._internal.config_loader_impl.C  
                      object at 0x7f4680755f70>,                            
                         callbacks=<hydra._internal.callbacks.Callbacks    
                      object at 0x7f46b4846d90>                             
                      )                                                     
       hydra_output = PosixPath('/home/paperspace/Documents/Repos/clm_mod  
        job_dir_key = 'hydra.run.dir'                                       
     job_subdir_key = None                                                  
            old_cwd = '/home/paperspace/Documents/Repos/clm_model_tuning'   
     orig_hydra_cfg = None                                                  
         output_dir = 'outputs/2022-11-18/16-01-29'                         
          overrides = [                                                     
                         'model.name=facebook/opt-2.7b',                   
                         'training.eval_every=250',                        
                         'training.train_batch_size=32',                   
                         'training.weight_decay=0.05',                     
                         'training.eval_batch_size=16',                    
                         'training.learning_rate=0.000003',                
                         'training.val_split_percent=20',                  
                         'training.num_epochs=4',                          
                         'training.lr_warmup_steps=5',                     
                         'training.gradient_accumulation_steps=2',         
                         ... +2                                            
                      ]                                                     
                ret = JobReturn(                                            
                         overrides=[                                       
                            'model.name=facebook/opt-2.7b',               
                            'training.eval_every=250',                    
                            'training.train_batch_size=32',               
                            'training.weight_decay=0.05',                 
                            'training.eval_batch_size=16',                
                            'training.learning_rate=0.000003',            
                            'training.val_split_percent=20',              
                            'training.num_epochs=4',                      
                            'training.lr_warmup_steps=5',                 
                            'training.gradient_accumulation_steps=2',     
                            ... +2                                        
                         ],                                                
                         cfg={'output_dir': 'tuned-model', 'bittensor':    
                      {'network': 'nobunaga'}, 'dataset': {'name':          
                      'ViktorThink/mountain_combined_813306',               
                      'config_name': None, 'num_batches': 5000,             
                      'block_size': 256, 'overwrite_cache': False,          
                      'keep_linebreaks': True, 'concatenate_raw': False,    
                      'load_tokenized_data': False}, 'model': {'name':      
                      'facebook/opt-2.7b', 'config_name': None},            
                      'tokenizer': {'name': None, 'use_fast': True,         
                      'preprocessing_num_workers': None, 'pad_token':       
                      '[PAD]'}, 'training': {'seed': 17,                    
                      'val_split_percent': 20, 'train_batch_size': 32,      
                      'eval_batch_size': 16, 'learning_rate': 3e-06,        
                      'weight_decay': 0.05, 'num_epochs': 4,                
                      'max_train_steps': None,                              
                      'gradient_accumulation_steps': 2, 'lr_scheduler':     
                      'constant', 'lr_warmup_steps': 5, 'eval_every': 250,  
                      'max_eval_steps': 500, 'checkpoint':                  
                      {'resume_from_checkpoint': 0, 'every_n_steps':        
                      None}}, 'tracking': {'enabled': True, 'report_to':    
                      'all'}, 'testing': {'enabled': False}},               
                         hydra_cfg={'hydra': {'run': {'dir':               
                      'outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}'}, 'sweep':  
                      {'dir': 'multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}',   
                      'subdir': '${hydra.job.num}'}, 'launcher':            
                      {'_target_':                                          
                      'hydra._internal.core_plugins.basic_launcher.BasicL  
                      'sweeper': {'_target_':                               
                      'hydra._internal.core_plugins.basic_sweeper.BasicSw  
                      'max_batch_size': None, 'params': None}, 'help':      
                      {'app_name': '${hydra.job.name}', 'header':           
                      '${hydra.help.app_name} is powered by Hydra.\n',      
                      'footer': 'Powered by Hydra (https://hydra.cc)\nUse   
                      --hydra-help to view Hydra specific help\n',          
                      'template': '${hydra.help.header}\n== Configuration   
                      groups ==\nCompose your configuration from those      
                      groups (group=option)\n\n$APP_CONFIG_GROUPS\n\n==     
                      Config ==\nOverride anything in the config            
                      (foo.bar=value)\n\n$CONFIG\n\n${hydra.help.footer}\  
                      'hydra_help': {'template': "Hydra                     
                      (${hydra.runtime.version})\nSee https://hydra.cc for  
                      more info.\n\n== Flags ==\n$FLAGS_HELP\n\n==          
                      Configuration groups ==\nCompose your configuration   
                      from those groups (For example, append                
                      hydra/job_logging=disabled to command                 
                      line)\n\n$HYDRA_CONFIG_GROUPS\n\nUse '--cfg hydra'    
                      to Show the Hydra config.\n", 'hydra_help': '???'},   
                      'hydra_logging': {'version': 1, 'formatters':         
                      {'simple': {'format': '[%(asctime)s][HYDRA]           
                      %(message)s'}}, 'handlers': {'console': {'class':     
                      'logging.StreamHandler', 'formatter': 'simple',       
                      'stream': 'ext://sys.stdout'}}, 'root': {'level':     
                      'INFO', 'handlers': ['console']}, 'loggers':          
                      {'logging_example': {'level': 'DEBUG'}},              
                      'disable_existing_loggers': False}, 'job_logging':    
                      {'version': 1, 'formatters': {'simple': {'format':    
                      '[%(asctime)s][%(name)s][%(levelname)s] -             
                      %(message)s'}}, 'handlers': {'console': {'class':     
                      'logging.StreamHandler', 'formatter': 'simple',       
                      'stream': 'ext://sys.stdout'}, 'file': {'class':      
                      'logging.FileHandler', 'formatter': 'simple',         
                      'filename':                                           
                      '${hydra.runtime.output_dir}/${hydra.job.name}.log'  
                      'root': {'level': 'INFO', 'handlers': ['console',     
                      'file']}, 'disable_existing_loggers': False}, 'env':  
                      {}, 'mode': <RunMode.RUN: 1>, 'searchpath': [],       
                      'callbacks': {}, 'output_subdir': '.hydra',           
                      'overrides': {'hydra': ['hydra.mode=RUN'], 'task':    
                      ['model.name=facebook/opt-2.7b',                      
                      'training.eval_every=250',                            
                      'training.train_batch_size=32',                       
                      'training.weight_decay=0.05',                         
                      'training.eval_batch_size=16',                        
                      'training.learning_rate=0.000003',                    
                      'training.val_split_percent=20',                      
                      'training.num_epochs=4',                              
                      'training.lr_warmup_steps=5',                         
                      'training.gradient_accumulation_steps=2',             
                      'dataset.name=ViktorThink/mountain_combined_813306',  
                      'dataset.num_batches=5000']}, 'job': {'name':         
                      'finetune_using_clm_wandb', 'chdir': None,            
                      'override_dirname':                                   
                      'dataset.name=ViktorThink/mountain_combined_813306,  
                      'id': '???', 'num': '???', 'config_name': 'config',   
                      'env_set': {}, 'env_copy': [], 'config':              
                      {'override_dirname': {'kv_sep': '=', 'item_sep':      
                      ',', 'exclude_keys': []}}}, 'runtime': {'version':    
                      '1.2.0', 'version_base': '1.2', 'cwd':                
                      '/home/paperspace/Documents/Repos/clm_model_tuning',  
                      'config_sources': [{'path': 'hydra.conf', 'schema':   
                      'pkg', 'provider': 'hydra'}, {'path':                 
                      '/home/paperspace/Documents/Repos/clm_model_tuning/  
                      'schema': 'file', 'provider': 'main'}, {'path': '',   
                      'schema': 'structured', 'provider': 'schema'}],       
                      'output_dir':                                         
                      '/home/paperspace/Documents/Repos/clm_model_tuning/  
                      'choices': {'hydra/env': 'default',                   
                      'hydra/callbacks': None, 'hydra/job_logging':         
                      'default', 'hydra/hydra_logging': 'default',          
                      'hydra/hydra_help': 'default', 'hydra/help':          
                      'default', 'hydra/sweeper': 'basic',                  
                      'hydra/launcher': 'basic', 'hydra/output':            
                      'default'}}, 'verbose': False}},                      
                                                                           
                      working_dir='/home/paperspace/Documents/Repos/clm_m  
                         task_name=None,                                   
                         status=<JobStatus.UNKNOWN: 0>,                    
                         _return_value=None                                
                      )                                                     
           task_cfg = {'output_dir': 'tuned-model', 'bittensor':            
                      {'network': 'nobunaga'}, 'dataset': {'name':          
                      'ViktorThink/mountain_combined_813306',               
                      'config_name': None, 'num_batches': 5000,             
                      'block_size': 256, 'overwrite_cache': False,          
                      'keep_linebreaks': True, 'concatenate_raw': False,    
                      'load_tokenized_data': False}, 'model': {'name':      
                      'facebook/opt-2.7b', 'config_name': None},            
                      'tokenizer': {'name': None, 'use_fast': True,         
                      'preprocessing_num_workers': None, 'pad_token':       
                      '[PAD]'}, 'training': {'seed': 17,                    
                      'val_split_percent': 20, 'train_batch_size': 32,      
                      'eval_batch_size': 16, 'learning_rate': 3e-06,        
                      'weight_decay': 0.05, 'num_epochs': 4,                
                      'max_train_steps': None,                              
                      'gradient_accumulation_steps': 2, 'lr_scheduler':     
                      'constant', 'lr_warmup_steps': 5, 'eval_every': 250,  
                      'max_eval_steps': 500, 'checkpoint':                  
                      {'resume_from_checkpoint': 0, 'every_n_steps':        
                      None}}, 'tracking': {'enabled': True, 'report_to':    
                      'all'}, 'testing': {'enabled': False}}                
      task_function = <function main at 0x7f46807533a0>                     
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/finetune_using_clm_wandb.p 
 y:304 in main                                                                
                                                                              
   301    else:                                                              
   302       raw_datasets = load_raw_datasets(cfg)                          
   303                                                                      
  304       tokenized_datasets = preprocess(cfg, accelerator, tokenizer, r 
   305       if "train" not in tokenized_datasets.column_names:             
   306          tokenized_datasets = tokenized_datasets.train_test_split(  
   307             test_size=cfg.training.val_split_percent / 100,        
                                                                              
  locals  
   accelerator = <accelerate.accelerator.Accelerator object at              
                 0x7f4680635700>                                            
           cfg = {'output_dir': 'tuned-model', 'bittensor': {'network':     
                 'nobunaga'}, 'dataset': {'name':                           
                 'ViktorThink/mountain_combined_813306', 'config_name':     
                 None, 'num_batches': 5000, 'block_size': 256,              
                 'overwrite_cache': False, 'keep_linebreaks': True,         
                 'concatenate_raw': False, 'load_tokenized_data': False},   
                 'model': {'name': 'facebook/opt-2.7b', 'config_name':      
                 None}, 'tokenizer': {'name': None, 'use_fast': True,       
                 'preprocessing_num_workers': None, 'pad_token': '[PAD]'},  
                 'training': {'seed': 17, 'val_split_percent': 20,          
                 'train_batch_size': 32, 'eval_batch_size': 16,             
                 'learning_rate': 3e-06, 'weight_decay': 0.05,              
                 'num_epochs': 4, 'max_train_steps': None,                  
                 'gradient_accumulation_steps': 2, 'lr_scheduler':          
                 'constant', 'lr_warmup_steps': 5, 'eval_every': 250,       
                 'max_eval_steps': 500, 'checkpoint':                       
                 {'resume_from_checkpoint': 0, 'every_n_steps': None}},     
                 'tracking': {'enabled': True, 'report_to': 'all'},         
                 'testing': {'enabled': False}}                             
        logger = <MultiProcessAdapter __main__ (INFO)>                      
  lr_scheduler = <torch.optim.lr_scheduler.LambdaLR object at               
                 0x7f467aebf640>                                            
         model = GPTNeoForCausalLM(                                         
                   (transformer): GPTNeoModel(                              
                    (wte): Embedding(50265, 2560)                          
                    (wpe): Embedding(2048, 2560)                           
                    (drop): Dropout(p=0.0, inplace=False)                  
                    (h): ModuleList(                                       
                      (0): GPTNeoBlock(                                    
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (1): GPTNeoBlock(                                    
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (2): GPTNeoBlock(                                    
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (3): GPTNeoBlock(                                    
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (4): GPTNeoBlock(                                    
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (5): GPTNeoBlock(                                    
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (6): GPTNeoBlock(                                    
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (7): GPTNeoBlock(                                    
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (8): GPTNeoBlock(                                    
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (9): GPTNeoBlock(                                    
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (10): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (11): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (12): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (13): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (14): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (15): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (16): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (17): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (18): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (19): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (20): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (21): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (22): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (23): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (24): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (25): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (26): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (27): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (28): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (29): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (30): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                      (31): GPTNeoBlock(                                   
                       (ln_1): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (attn): GPTNeoAttention(                           
                         (attention): GPTNeoSelfAttention(                
                          (attn_dropout): Dropout(p=0.0, inplace=False)  
                          (resid_dropout): Dropout(p=0.0,                
                 inplace=False)                                             
                          (k_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (v_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (q_proj): Linear(in_features=2560,             
                 out_features=2560, bias=False)                             
                          (out_proj): Linear(in_features=2560,           
                 out_features=2560, bias=True)                              
                         )                                                
                       )                                                  
                       (ln_2): LayerNorm((2560,), eps=1e-05,              
                 elementwise_affine=True)                                   
                       (mlp): GPTNeoMLP(                                  
                         (c_fc): Linear(in_features=2560,                 
                 out_features=10240, bias=True)                             
                         (c_proj): Linear(in_features=10240,              
                 out_features=2560, bias=True)                              
                         (act): NewGELUActivation()                       
                         (dropout): Dropout(p=0.0, inplace=False)         
                       )                                                  
                      )                                                    
                    )                                                      
                    (ln_f): LayerNorm((2560,), eps=1e-05,                  
                 elementwise_affine=True)                                   
                   )                                                        
                   (lm_head): Linear(in_features=2560, out_features=50265,  
                 bias=False)                                                
                 )                                                          
     optimizer = AdamW (                                                    
                 Parameter Group 0                                          
                    amsgrad: False                                         
                    betas: (0.9, 0.999)                                    
                    capturable: False                                      
                    eps: 1e-08                                             
                    foreach: None                                          
                    initial_lr: 3e-06                                      
                    lr: 3e-06                                              
                    maximize: False                                        
                    weight_decay: 0.05                                     
                                                                            
                 Parameter Group 1                                          
                    amsgrad: False                                         
                    betas: (0.9, 0.999)                                    
                    capturable: False                                      
                    eps: 1e-08                                             
                    foreach: None                                          
                    initial_lr: 3e-06                                      
                    lr: 3e-06                                              
                    maximize: False                                        
                    weight_decay: 0.0                                      
                 )                                                          
  raw_datasets = DatasetDict({                                              
                    train: Dataset({                                       
                       features: ['train', 'validation'],                 
                       num_rows: 813306                                   
                    })                                                     
                    validation: Dataset({                                  
                       features: ['train', 'validation'],                 
                       num_rows: 813306                                   
                    })                                                     
                 })                                                         
     tokenizer = PreTrainedTokenizer(name_or_path='facebook/opt-2.7b',      
                 vocab_size=50265,                                          
                 model_max_len=1000000000000000019884624838656,             
                 is_fast=False, padding_side='right',                       
                 truncation_side='right', special_tokens={'bos_token':      
                 AddedToken("</s>", rstrip=False, lstrip=False,             
                 single_word=False, normalized=True), 'eos_token':          
                 AddedToken("</s>", rstrip=False, lstrip=False,             
                 single_word=False, normalized=True), 'unk_token':          
                 AddedToken("</s>", rstrip=False, lstrip=False,             
                 single_word=False, normalized=True), 'pad_token':          
                 AddedToken("<pad>", rstrip=False, lstrip=False,            
                 single_word=False, normalized=True)})                      
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/finetune_using_clm_wandb.p 
 y:215 in preprocess                                                          
                                                                              
   212                                                                       
   213    with accelerator.main_process_first():                             
   214                                                                      
  215       tokenized_datasets = raw_datasets.map(                         
   216          tokenize_fn,                                               
   217          batched=True,                                              
   218          num_proc=cfg.tokenizer.preprocessing_num_workers,          
                                                                              
  locals  
       accelerator = <accelerate.accelerator.Accelerator object at          
                     0x7f4680635700>                                        
               cfg = {'output_dir': 'tuned-model', 'bittensor':             
                     {'network': 'nobunaga'}, 'dataset': {'name':           
                     'ViktorThink/mountain_combined_813306',                
                     'config_name': None, 'num_batches': 5000,              
                     'block_size': 256, 'overwrite_cache': False,           
                     'keep_linebreaks': True, 'concatenate_raw': False,     
                     'load_tokenized_data': False}, 'model': {'name':       
                     'facebook/opt-2.7b', 'config_name': None},             
                     'tokenizer': {'name': None, 'use_fast': True,          
                     'preprocessing_num_workers': None, 'pad_token':        
                     '[PAD]'}, 'training': {'seed': 17,                     
                     'val_split_percent': 20, 'train_batch_size': 32,       
                     'eval_batch_size': 16, 'learning_rate': 3e-06,         
                     'weight_decay': 0.05, 'num_epochs': 4,                 
                     'max_train_steps': None,                               
                     'gradient_accumulation_steps': 2, 'lr_scheduler':      
                     'constant', 'lr_warmup_steps': 5, 'eval_every': 250,   
                     'max_eval_steps': 500, 'checkpoint':                   
                     {'resume_from_checkpoint': 0, 'every_n_steps':         
                     None}}, 'tracking': {'enabled': True, 'report_to':     
                     'all'}, 'testing': {'enabled': False}}                 
      column_names = {                                                      
                        'train': ['train', 'validation'],                  
                        'validation': ['train', 'validation']              
                     }                                                      
       group_texts = <function preprocess.<locals>.group_texts at           
                     0x7f46782113a0>                                        
               pad = 'max_length'                                           
      raw_datasets = DatasetDict({                                          
                        train: Dataset({                                   
                           features: ['train', 'validation'],             
                           num_rows: 813306                               
                        })                                                 
                        validation: Dataset({                              
                           features: ['train', 'validation'],             
                           num_rows: 813306                               
                        })                                                 
                     })                                                     
  text_column_name = 'train'                                                
       tokenize_fn = <function preprocess.<locals>.tokenize_fn at           
                     0x7f4678211670>                                        
         tokenizer = PreTrainedTokenizer(name_or_path='facebook/opt-2.7b',  
                     vocab_size=50265,                                      
                     model_max_len=1000000000000000019884624838656,         
                     is_fast=False, padding_side='right',                   
                     truncation_side='right', special_tokens={'bos_token':  
                     AddedToken("</s>", rstrip=False, lstrip=False,         
                     single_word=False, normalized=True), 'eos_token':      
                     AddedToken("</s>", rstrip=False, lstrip=False,         
                     single_word=False, normalized=True), 'unk_token':      
                     AddedToken("</s>", rstrip=False, lstrip=False,         
                     single_word=False, normalized=True), 'pad_token':      
                     AddedToken("<pad>", rstrip=False, lstrip=False,        
                     single_word=False, normalized=True)})                  
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/datasets/dataset_dict.py:777 in map                                   
                                                                              
    774       if cache_file_names is None:                                  
    775          cache_file_names = {k: None for k in self}                
    776       return DatasetDict(                                           
   777          {                                                         
    778             k: dataset.map(                                       
    779                function=function,                                
    780                with_indices=with_indices,                        
                                                                              
  locals  
            batch_size = 1000                                               
               batched = True                                               
      cache_file_names = {'train': None, 'validation': None}                
                  desc = 'Running tokenizer on dataset'                     
      disable_nullable = False                                              
       drop_last_batch = False                                              
              features = None                                               
             fn_kwargs = None                                               
              function = <function preprocess.<locals>.tokenize_fn at       
                         0x7f4678211670>                                    
         input_columns = None                                               
        keep_in_memory = False                                              
  load_from_cache_file = True                                               
              num_proc = None                                               
        remove_columns = None                                               
                  self = DatasetDict({                                      
                            train: Dataset({                               
                               features: ['train', 'validation'],         
                               num_rows: 813306                           
                            })                                             
                            validation: Dataset({                          
                               features: ['train', 'validation'],         
                               num_rows: 813306                           
                            })                                             
                         })                                                 
          with_indices = False                                              
             with_rank = False                                              
     writer_batch_size = 1000                                               
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/datasets/dataset_dict.py:778 in <dictcomp>                            
                                                                              
    775          cache_file_names = {k: None for k in self}                
    776       return DatasetDict(                                           
    777          {                                                         
   778             k: dataset.map(                                       
    779                function=function,                                
    780                with_indices=with_indices,                        
    781                with_rank=with_rank,                              
                                                                              
  locals  
                    .0 = <dict_itemiterator object at 0x7f467ad4ad60>       
            batch_size = 1000                                               
               batched = True                                               
      cache_file_names = {'train': None, 'validation': None}                
               dataset = Dataset({                                          
                            features: ['train', 'validation'],             
                            num_rows: 813306                               
                         })                                                 
                  desc = 'Running tokenizer on dataset'                     
      disable_nullable = False                                              
       drop_last_batch = False                                              
              features = None                                               
             fn_kwargs = None                                               
              function = <function preprocess.<locals>.tokenize_fn at       
                         0x7f4678211670>                                    
         input_columns = None                                               
                     k = 'train'                                            
        keep_in_memory = False                                              
  load_from_cache_file = True                                               
              num_proc = None                                               
        remove_columns = None                                               
          with_indices = False                                              
             with_rank = False                                              
     writer_batch_size = 1000                                               
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/datasets/arrow_dataset.py:2585 in map                                 
                                                                              
   2582       disable_tqdm = not logging.is_progress_bar_enabled()          
   2583                                                                     
   2584       if num_proc is None or num_proc == 1:                         
  2585          return self._map_single(                                  
   2586             function=function,                                    
   2587             with_indices=with_indices,                            
   2588             with_rank=with_rank,                                  
                                                                              
  locals  
            batch_size = 1000                                               
               batched = True                                               
       cache_file_name = None                                               
              decorate = <function Dataset.map.<locals>.decorate at         
                         0x7f45bc6e3ee0>                                    
                  desc = 'Running tokenizer on dataset'                     
      disable_nullable = False                                              
          disable_tqdm = False                                              
       drop_last_batch = False                                              
              features = None                                               
             fn_kwargs = {}                                                 
              function = <function preprocess.<locals>.tokenize_fn at       
                         0x7f45bc6e3e50>                                    
         input_columns = None                                               
        keep_in_memory = False                                              
  load_from_cache_file = True                                               
       new_fingerprint = None                                               
              num_proc = None                                               
        remove_columns = None                                               
                  self = Dataset({                                          
                            features: ['train', 'validation'],             
                            num_rows: 813306                               
                         })                                                 
       suffix_template = '_{rank:05d}_of_{num_proc:05d}'                    
          with_indices = False                                              
             with_rank = False                                              
     writer_batch_size = 1000                                               
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/datasets/arrow_dataset.py:585 in wrapper                              
                                                                              
    582       else:                                                         
    583          self: "Dataset" = kwargs.pop("self")                      
    584       # apply actual function                                       
   585       out: Union["Dataset", "DatasetDict"] = func(self, *args, **kw 
    586       datasets: List["Dataset"] = list(out.values()) if isinstance( 
    587       for dataset in datasets:                                      
    588          # Remove task templates if a column mapping of the templa 
                                                                              
  locals  
    args = ()                                                               
    func = <function Dataset._map_single at 0x7f46c90be8b0>                 
  kwargs = {                                                                
              'function': <function preprocess.<locals>.tokenize_fn at     
           0x7f45bc6e3e50>,                                                 
              'with_indices': False,                                       
              'with_rank': False,                                          
              'input_columns': None,                                       
              'batched': True,                                             
              'batch_size': 1000,                                          
              'drop_last_batch': False,                                    
              'remove_columns': None,                                      
              'keep_in_memory': False,                                     
              'load_from_cache_file': True,                                
              ... +8                                                       
           }                                                                
    self = Dataset({                                                        
              features: ['train', 'validation'],                           
              num_rows: 813306                                             
           })                                                               
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/datasets/arrow_dataset.py:552 in wrapper                              
                                                                              
    549          "output_all_columns": self._output_all_columns,           
    550       }                                                             
    551       # apply actual function                                       
   552       out: Union["Dataset", "DatasetDict"] = func(self, *args, **kw 
    553       datasets: List["Dataset"] = list(out.values()) if isinstance( 
    554       # re-apply format to the output                               
    555       for dataset in datasets:                                      
                                                                              
  locals  
                 args = ()                                                  
                 func = <function Dataset._map_single at 0x7f46c90be9d0>    
               kwargs = {                                                   
                           'function': <function                           
                        preprocess.<locals>.tokenize_fn at                  
                        0x7f45bc6e3e50>,                                    
                           'with_indices': False,                          
                           'with_rank': False,                             
                           'input_columns': None,                          
                           'batched': True,                                
                           'batch_size': 1000,                             
                           'drop_last_batch': False,                       
                           'remove_columns': None,                         
                           'keep_in_memory': False,                        
                           'load_from_cache_file': True,                   
                           ... +8                                          
                        }                                                   
                 self = Dataset({                                           
                           features: ['train', 'validation'],              
                           num_rows: 813306                                
                        })                                                  
          self_format = {                                                   
                           'type': None,                                   
                           'format_kwargs': {},                            
                           'columns': None,                                
                           'output_all_columns': False                     
                        }                                                   
  unformatted_columns = {'validation', 'train'}                             
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/datasets/fingerprint.py:480 in wrapper                                
                                                                              
   477                                                                     
   478          # Call actual function                                     
   479                                                                     
  480          out = func(self, *args, **kwargs)                          
   481                                                                     
   482          # Update fingerprint of in-place transforms + update in-pl 
   483                                                                        
                                                                              
  locals  
                    args = ()                                               
           default_value = False                                            
          default_values = {                                                
                              'function': None,                            
                              'with_indices': False,                       
                              'with_rank': False,                          
                              'input_columns': None,                       
                              'batched': False,                            
                              'batch_size': 1000,                          
                              'drop_last_batch': False,                    
                              'remove_columns': None,                      
                              'keep_in_memory': False,                     
                              'load_from_cache_file': None,                
                              ... +11                                      
                           }                                                
         default_varname = 'cache_only'                                     
        fingerprint_name = 'new_fingerprint'                                
       fingerprint_names = ['new_fingerprint']                              
                    func = <function Dataset._map_single at                 
                           0x7f46c90be940>                                  
           ignore_kwargs = [                                                
                              'load_from_cache_file',                      
                              'cache_file_name',                           
                              'disable_tqdm',                              
                              'desc',                                      
                              'cache_only'                                 
                           ]                                                
                 inplace = False                                            
                  kwargs = {                                                
                              'function': <function                        
                           preprocess.<locals>.tokenize_fn at               
                           0x7f45bc6e3e50>,                                 
                              'with_indices': False,                       
                              'with_rank': False,                          
                              'input_columns': None,                       
                              'batched': True,                             
                              'batch_size': 1000,                          
                              'drop_last_batch': False,                    
                              'remove_columns': None,                      
                              'keep_in_memory': False,                     
                              'load_from_cache_file': True,                
                              ... +8                                       
                           }                                                
  kwargs_for_fingerprint = {                                                
                              'function': <function                        
                           preprocess.<locals>.tokenize_fn at               
                           0x7f45bc6e3e50>,                                 
                              'batched': True,                             
                              'fn_kwargs': {},                             
                              'fingerprint_name': 'new_fingerprint'        
                           }                                                
                  params = [                                                
                              'function',                                  
                              'with_indices',                              
                              'with_rank',                                 
                              'input_columns',                             
                              'batched',                                   
                              'batch_size',                                
                              'drop_last_batch',                           
                              'remove_columns',                            
                              'keep_in_memory',                            
                              'load_from_cache_file',                      
                              ... +11                                      
                           ]                                                
     randomized_function = False                                            
                    self = Dataset({                                        
                              features: ['train', 'validation'],           
                              num_rows: 813306                             
                           })                                               
               transform = 'datasets.arrow_dataset.Dataset._map_single'     
              use_kwargs = None                                             
  
                                                                              
 /home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-pa 
 ckages/datasets/arrow_dataset.py:3009 in _map_single                         
                                                                              
   3006                if tmp_file is not None:                          
   3007                   tmp_file.close()                              
   3008                   if os.path.exists(tmp_file.name):             
  3009                      os.remove(tmp_file.name)                  
   3010             raise                                                 
   3011                                                                     
   3012       if update_data and tmp_file is not None:                      
                                                                              
  locals  
  apply_function_on_filtered_inputs = <function                             
                                      Dataset._map_single.<locals>.apply_  
                                      at 0x7f467d7d7820>                    
                              batch = {                                     
                                         'train': [                        
                                            'upon better and\\nnobler     
                                      views; and advise your elder          
                                      sisters, when they perceive'+1575,    
                                            "log time reviewing U.S.      
                                      Army training films from the Vietnam  
                                      era. That's the mil"+1355,            
                                            'the speculative              
                                      philosophers. For example, the great  
                                      mathematician Euler, who do'+1567,    
                                            'the bedchamber. A short      
                                      while later he confided in one of     
                                      his servants, secretly'+1331,         
                                            'the familiar bond valuation  
                                      equation. Assuming semiannual coupon  
                                      payments, the e'+1402,                
                                            '$X$ associated with          
                                      $U\\\\bar{U}$ and $\\\\bar{D}{D}$     
                                      since this would drop the             
                                      poss'+1860,                           
                                            'parking lot                  
                                      dings.\\"\\n\\n\\"When these little   
                                      charges blow, they\'ll leave M16      
                                      impa'+1470,                           
                                            'above from Helms, \\"The     
                                      Indians,\\" pp. 3745. \\n | Bruhns,  
                                      _Ancient South Americ'+1388,          
                                            'get some sleep, so I         
                                      removed the light bulb and stored it  
                                      in the pocket of the C'+1301,         
                                            'set of ADE20K in Table       
                                      \\\\[tab:baseline\\\\]. All our       
                                      results except the last-row o'+1732,  
                                            ... +990                      
                                         ],                                
                                         'validation': [                   
                                            "given we can't stop people   
                                      signing up again with a new           
                                      disposable email address)"+1984,      
                                            'I\'m just repeating\'        
                                      stuff.\\" \\"Did I hear you say       
                                      you\'re looking for an                
                                      apartmen'+1451,                       
                                            'a model for belief. In M.    
                                      Vargas \\u0026 G. Yaffe (Eds.),       
                                      Rational and social age'+1793,        
                                            'away.\\"\\n\\n\\"Somehow, I  
                                      think she knows where he is,\\"       
                                      Virginia said, thoughtful'+1451,      
                                            'plane the limits of          
                                      validity of our model.\\n\\n![(Color  
                                      online) [*Characterizatio'+2041,      
                                            "son for fighting\\nagainst   
                                      the king and the mother country. The  
                                      old lady's face w"+1653,              
                                            'again.\\" \\"We\'re gonna    
                                      have to make the cut now.\\"          
                                      \\"Sharon?\\" \\"can you hear         
                                      me'+1554,                             
                                            'even have more commissions   
                                      such as yours.\\"\\n\\nThat was a     
                                      not-so-veiled referenc'+1491,         
                                            'stealth technology we were   
                                      never able to break.\\" \\"So how     
                                      come all of a sudden '+1534,          
                                            'create\\na small example     
                                      service.\\nI want to focus on two     
                                      major requirements.\\nPe'+1838,       
                                            ... +990                      
                                         ]                                 
                                      }                                     
                         batch_size = 1000                                  
                            batched = True                                  
                         buf_writer = None                                  
                    cache_file_name = '/home/paperspace/.cache/huggingfac  
                         cache_only = False                                 
                               desc = 'Running tokenizer on dataset'        
                   disable_nullable = False                                 
                       disable_tqdm = False                                 
                    drop_last_batch = False                                 
                           features = None                                  
                          fn_kwargs = {}                                    
                           function = <function                             
                                      preprocess.<locals>.tokenize_fn at    
                                      0x7f45bc6e3e50>                       
                                  i = 79000                                 
                            indices = [                                     
                                         79000,                            
                                         79001,                            
                                         79002,                            
                                         79003,                            
                                         79004,                            
                                         79005,                            
                                         79006,                            
                                         79007,                            
                                         79008,                            
                                         79009,                            
                                         ... +990                          
                                      ]                                     
             init_buffer_and_writer = <function                             
                                      Dataset._map_single.<locals>.init_b  
                                      at 0x7f45bc6c0550>                    
                      input_columns = None                                  
                      input_dataset = Dataset({                             
                                         features: ['train',               
                                      'validation'],                        
                                         num_rows: 813306                  
                                      })                                    
                     keep_in_memory = False                                 
               load_from_cache_file = True                                  
                    new_fingerprint = '4608445b9d629a4f'                    
                           num_rows = 813306                                
           NumExamplesMismatchError = <class                                
                                      'datasets.arrow_dataset.Dataset._ma  
                             offset = 0                                     
                               pbar = <tqdm.asyncio.tqdm_asyncio object at  
                                      0x7f467de30a30>                       
                          pbar_desc = 'Running tokenizer on dataset'        
                      pbar_iterable = <zip object at 0x7f467820e4c0>        
                         pbar_total = 814                                   
                          pbar_unit = 'ba'                                  
                               rank = None                                  
                     remove_columns = None                                  
                               self = Dataset({                             
                                         features: ['train',               
                                      'validation'],                        
                                         num_rows: 813306                  
                                      })                                    
                              stack = <contextlib.ExitStack object at       
                                      0x7f467de301f0>                       
                           tmp_file = <tempfile._TemporaryFileWrapper       
                                      object at 0x7f467de12220>             
                        update_data = True                                  
           validate_function_output = <function                             
                                      Dataset._map_single.<locals>.valida  
                                      at 0x7f45bc6e3dc0>                    
                       with_indices = False                                 
                          with_rank = False                                 
                             writer = <datasets.arrow_writer.ArrowWriter    
                                      object at 0x7f467ddb13d0>             
                  writer_batch_size = 1000                                  
  

KeyboardInterrupt
[2022-11-18 16:04:42,455][__main__][INFO] - Setting random seed to 17
[2022-11-18 16:04:42,456][__main__][INFO] - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Mixed precision type: no

[2022-11-18 16:04:42,459][__main__][INFO] - output_dir: tuned-model
bittensor:
  network: nobunaga
dataset:
  name: ViktorThink/mountain_combined_813306
  config_name: null
  num_batches: 10
  block_size: 256
  overwrite_cache: false
  keep_linebreaks: true
  concatenate_raw: false
  load_tokenized_data: false
model:
  name: facebook/opt-2.7b
  config_name: null
tokenizer:
  name: null
  use_fast: true
  preprocessing_num_workers: null
  pad_token: '[PAD]'
training:
  seed: 17
  val_split_percent: 20
  train_batch_size: 32
  eval_batch_size: 16
  learning_rate: 3.0e-06
  weight_decay: 0.05
  num_epochs: 4
  max_train_steps: null
  gradient_accumulation_steps: 2
  lr_scheduler: constant
  lr_warmup_steps: 5
  eval_every: 250
  max_eval_steps: 500
  checkpoint:
    resume_from_checkpoint: 0
    every_n_steps: null
tracking:
  enabled: true
  report_to: all
testing:
  enabled: false

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--EleutherAI--gpt-neo-2.7B/snapshots/51568a6e0ae813a3f2a9da558ab7beac5e3acc24/config.json
Model config GPTNeoConfig {
  "_name_or_path": "EleutherAI/gpt-neo-2.7B",
  "activation_function": "gelu_new",
  "architectures": [
    "GPTNeoForCausalLM"
  ],
  "attention_dropout": 0,
  "attention_layers": [
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local"
  ],
  "attention_types": [
    [
      [
        "global",
        "local"
      ],
      16
    ]
  ],
  "bos_token_id": 50256,
  "embed_dropout": 0,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "hidden_size": 2560,
  "initializer_range": 0.02,
  "intermediate_size": null,
  "layer_norm_epsilon": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neo",
  "num_heads": 20,
  "num_layers": 32,
  "resid_dropout": 0,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50,
      "temperature": 0.9
    }
  },
  "tokenizer_class": "GPT2Tokenizer",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50257,
  "window_size": 256
}

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading file vocab.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/vocab.json
loading file merges.txt from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/merges.txt
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/tokenizer_config.json
loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading weights file flax_model.msgpack from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Loading Flax weights from /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Some weights of the Flax model were not used when initializing the PyTorch model GPTNeoForCausalLM: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.18.fc1.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.bias']
- This IS expected if you are initializing GPTNeoForCausalLM from a Flax model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a FlaxBertForPreTraining model).
- This IS NOT expected if you are initializing GPTNeoForCausalLM from a Flax model that you expect to be exactly identical (e.g. initializing a BertForSequenceClassification model from a FlaxBertForSequenceClassification model).
Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['transformer.h.8.attn.attention.out_proj.weight', 'transformer.h.1.attn.attention.k_proj.weight', 'transformer.h.25.attn.attention.out_proj.bias', 'transformer.h.8.ln_2.bias', 'transformer.h.1.attn.attention.v_proj.weight', 'transformer.h.0.attn.attention.masked_bias', 'transformer.h.14.ln_2.bias', 'transformer.h.11.ln_2.weight', 'transformer.h.26.attn.attention.out_proj.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.10.attn.attention.k_proj.weight', 'transformer.h.14.ln_1.weight', 'transformer.h.22.mlp.c_fc.weight', 'transformer.h.31.attn.attention.out_proj.weight', 'transformer.h.15.mlp.c_fc.weight', 'transformer.h.8.attn.attention.k_proj.weight', 'transformer.h.5.attn.attention.v_proj.weight', 'transformer.h.20.mlp.c_fc.bias', 'transformer.h.15.ln_2.bias', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.14.attn.attention.bias', 'transformer.h.13.ln_1.weight', 'transformer.h.28.attn.attention.k_proj.weight', 'transformer.h.9.ln_2.weight', 'transformer.h.13.ln_1.bias', 'transformer.h.30.attn.attention.k_proj.weight', 'transformer.wpe.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.12.attn.attention.bias', 'transformer.h.30.attn.attention.q_proj.weight', 'transformer.h.25.mlp.c_proj.bias', 'transformer.h.10.attn.attention.bias', 'transformer.h.13.attn.attention.out_proj.bias', 'transformer.h.6.attn.attention.q_proj.weight', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.5.attn.attention.out_proj.bias', 'transformer.h.22.attn.attention.masked_bias', 'transformer.h.28.mlp.c_proj.weight', 'transformer.h.16.attn.attention.bias', 'transformer.h.15.ln_1.bias', 'transformer.h.21.mlp.c_fc.bias', 'transformer.h.5.attn.attention.out_proj.weight', 'transformer.h.10.ln_2.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.28.attn.attention.out_proj.weight', 'transformer.h.10.attn.attention.v_proj.weight', 'transformer.h.20.mlp.c_fc.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.24.ln_1.bias', 'transformer.h.20.attn.attention.v_proj.weight', 'transformer.h.6.ln_1.weight', 'transformer.h.5.attn.attention.k_proj.weight', 'transformer.h.12.mlp.c_fc.weight', 'transformer.h.0.attn.attention.q_proj.weight', 'transformer.h.17.attn.attention.masked_bias', 'transformer.h.28.mlp.c_fc.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.11.ln_2.bias', 'transformer.h.19.attn.attention.k_proj.weight', 'transformer.h.14.mlp.c_proj.bias', 'transformer.h.17.ln_2.bias', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.29.attn.attention.bias', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.16.attn.attention.v_proj.weight', 'transformer.h.28.ln_1.bias', 'transformer.h.16.attn.attention.masked_bias', 'transformer.h.12.attn.attention.out_proj.bias', 'transformer.h.26.attn.attention.k_proj.weight', 'transformer.h.19.attn.attention.q_proj.weight', 'transformer.h.12.mlp.c_fc.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.26.mlp.c_proj.bias', 'transformer.h.8.ln_2.weight', 'transformer.h.12.attn.attention.v_proj.weight', 'transformer.h.29.ln_2.bias', 'transformer.h.8.attn.attention.q_proj.weight', 'transformer.h.30.attn.attention.masked_bias', 'transformer.h.30.attn.attention.bias', 'transformer.h.22.ln_1.bias', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.10.attn.attention.q_proj.weight', 'transformer.h.23.attn.attention.out_proj.bias', 'transformer.h.29.attn.attention.out_proj.weight', 'transformer.h.22.attn.attention.bias', 'transformer.h.30.ln_1.weight', 'transformer.h.8.attn.attention.v_proj.weight', 'transformer.h.9.attn.attention.out_proj.bias', 'transformer.h.31.attn.attention.masked_bias', 'transformer.h.20.ln_1.bias', 'transformer.h.7.ln_1.bias', 'transformer.h.25.mlp.c_fc.weight', 'transformer.h.20.mlp.c_proj.bias', 'transformer.h.30.attn.attention.v_proj.weight', 'transformer.h.29.ln_1.bias', 'transformer.h.23.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.25.attn.attention.q_proj.weight', 'transformer.h.10.ln_1.weight', 'transformer.h.24.attn.attention.q_proj.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.18.mlp.c_proj.weight', 'transformer.h.7.ln_1.weight', 'transformer.h.31.attn.attention.bias', 'transformer.h.18.mlp.c_proj.bias', 'transformer.h.30.mlp.c_fc.weight', 'transformer.h.22.ln_2.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.17.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.out_proj.weight', 'transformer.h.8.attn.attention.bias', 'transformer.h.19.attn.attention.bias', 'transformer.h.14.attn.attention.v_proj.weight', 'transformer.h.23.attn.attention.v_proj.weight', 'transformer.h.27.attn.attention.q_proj.weight', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.22.mlp.c_proj.bias', 'transformer.h.15.attn.attention.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.18.mlp.c_fc.bias', 'transformer.h.29.ln_2.weight', 'transformer.h.20.attn.attention.q_proj.weight', 'transformer.h.29.mlp.c_fc.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.18.attn.attention.masked_bias', 'transformer.h.9.attn.attention.masked_bias', 'transformer.h.11.attn.attention.out_proj.bias', 'transformer.h.23.ln_1.bias', 'transformer.h.4.attn.attention.q_proj.weight', 'transformer.h.19.ln_1.weight', 'transformer.h.9.ln_1.weight', 'transformer.h.29.attn.attention.q_proj.weight', 'transformer.h.13.ln_2.bias', 'transformer.h.3.attn.attention.k_proj.weight', 'transformer.h.20.ln_1.weight', 'transformer.h.7.attn.attention.out_proj.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.0.attn.attention.v_proj.weight', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.19.ln_2.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.17.ln_1.weight', 'transformer.h.13.mlp.c_fc.bias', 'transformer.h.6.attn.attention.out_proj.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.0.attn.attention.out_proj.bias', 'transformer.h.16.attn.attention.out_proj.bias', 'transformer.h.7.attn.attention.bias', 'transformer.h.11.attn.attention.k_proj.weight', 'transformer.h.15.mlp.c_fc.bias', 'transformer.h.25.ln_1.weight', 'transformer.h.22.attn.attention.out_proj.weight', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.27.ln_2.weight', 'transformer.h.19.mlp.c_proj.weight', 'transformer.h.12.attn.attention.k_proj.weight', 'transformer.h.23.mlp.c_proj.bias', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.21.attn.attention.out_proj.bias', 'transformer.h.24.attn.attention.out_proj.bias', 'transformer.h.13.attn.attention.out_proj.weight', 'transformer.h.24.mlp.c_proj.weight', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.23.mlp.c_proj.weight', 'transformer.h.27.mlp.c_proj.bias', 'transformer.h.19.mlp.c_proj.bias', 'transformer.h.19.attn.attention.out_proj.bias', 'transformer.h.5.attn.attention.masked_bias', 'transformer.h.24.mlp.c_fc.weight', 'transformer.h.21.attn.attention.out_proj.weight', 'transformer.h.20.attn.attention.masked_bias', 'transformer.h.25.ln_2.weight', 'transformer.h.2.attn.attention.k_proj.weight', 'transformer.h.7.attn.attention.k_proj.weight', 'transformer.h.27.attn.attention.bias', 'transformer.h.11.attn.attention.v_proj.weight', 'transformer.h.26.mlp.c_proj.weight', 'transformer.h.15.ln_2.weight', 'transformer.h.25.mlp.c_fc.bias', 'transformer.h.26.attn.attention.bias', 'transformer.h.12.ln_1.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.14.attn.attention.k_proj.weight', 'transformer.h.25.attn.attention.v_proj.weight', 'transformer.h.4.attn.attention.out_proj.weight', 'transformer.h.23.attn.attention.out_proj.weight', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.16.mlp.c_fc.weight', 'transformer.h.4.ln_2.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.25.mlp.c_proj.weight', 'transformer.h.3.attn.attention.masked_bias', 'transformer.h.1.attn.attention.q_proj.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.18.attn.attention.out_proj.bias', 'transformer.h.27.attn.attention.out_proj.weight', 'transformer.h.29.attn.attention.v_proj.weight', 'transformer.h.25.attn.attention.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.20.ln_2.bias', 'transformer.h.23.attn.attention.masked_bias', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.9.attn.attention.bias', 'transformer.h.26.attn.attention.v_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.4.ln_1.bias', 'transformer.h.27.attn.attention.out_proj.bias', 'transformer.h.28.mlp.c_proj.bias', 'transformer.h.31.mlp.c_proj.bias', 'transformer.h.30.mlp.c_fc.bias', 'transformer.h.11.attn.attention.bias', 'transformer.h.12.ln_2.bias', 'transformer.h.22.mlp.c_proj.weight', 'transformer.ln_f.bias', 'transformer.h.2.ln_2.bias', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.22.attn.attention.q_proj.weight', 'transformer.h.2.attn.attention.out_proj.weight', 'transformer.h.19.attn.attention.out_proj.weight', 'transformer.h.31.attn.attention.k_proj.weight', 'transformer.h.13.mlp.c_fc.weight', 'transformer.h.28.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.27.attn.attention.k_proj.weight', 'transformer.h.23.ln_2.bias', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.28.attn.attention.bias', 'transformer.h.24.attn.attention.k_proj.weight', 'transformer.h.29.mlp.c_proj.bias', 'transformer.h.18.mlp.c_fc.weight', 'transformer.h.3.attn.attention.out_proj.weight', 'transformer.h.1.attn.attention.masked_bias', 'transformer.h.16.attn.attention.out_proj.weight', 'transformer.h.17.attn.attention.q_proj.weight', 'transformer.h.14.attn.attention.out_proj.bias', 'transformer.h.12.attn.attention.q_proj.weight', 'transformer.h.22.attn.attention.v_proj.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.4.attn.attention.masked_bias', 'transformer.h.25.ln_2.bias', 'transformer.h.18.ln_1.weight', 'transformer.h.20.attn.attention.out_proj.weight', 'transformer.h.4.attn.attention.out_proj.bias', 'transformer.h.9.ln_2.bias', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.14.mlp.c_fc.bias', 'transformer.h.15.attn.attention.masked_bias', 'transformer.h.23.attn.attention.k_proj.weight', 'transformer.h.22.ln_1.weight', 'transformer.h.31.mlp.c_fc.weight', 'transformer.h.4.attn.attention.v_proj.weight', 'transformer.h.20.attn.attention.bias', 'transformer.h.6.attn.attention.out_proj.weight', 'transformer.h.29.attn.attention.out_proj.bias', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.21.attn.attention.q_proj.weight', 'transformer.h.3.ln_2.weight', 'transformer.h.3.attn.attention.bias', 'transformer.h.26.attn.attention.q_proj.weight', 'transformer.h.28.mlp.c_fc.bias', 'transformer.h.19.attn.attention.v_proj.weight', 'transformer.h.6.attn.attention.v_proj.weight', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.16.ln_1.weight', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.31.ln_2.bias', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.29.mlp.c_proj.weight', 'transformer.h.30.ln_2.bias', 'transformer.h.9.attn.attention.q_proj.weight', 'transformer.h.1.attn.attention.out_proj.bias', 'transformer.h.20.mlp.c_proj.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.28.ln_2.weight', 'transformer.h.22.ln_2.weight', 'transformer.h.0.attn.attention.k_proj.weight', 'transformer.h.16.ln_2.weight', 'transformer.h.19.mlp.c_fc.weight', 'transformer.h.19.ln_1.bias', 'transformer.h.26.ln_1.weight', 'transformer.h.11.ln_1.weight', 'transformer.h.18.attn.attention.k_proj.weight', 'transformer.h.31.ln_1.weight', 'transformer.h.14.attn.attention.out_proj.weight', 'transformer.h.12.ln_2.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.16.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.out_proj.bias', 'transformer.h.24.ln_2.bias', 'transformer.h.4.attn.attention.k_proj.weight', 'transformer.h.26.ln_2.bias', 'transformer.h.7.attn.attention.out_proj.bias', 'transformer.h.27.attn.attention.masked_bias', 'transformer.h.29.ln_1.weight', 'transformer.h.29.mlp.c_fc.bias', 'transformer.h.15.ln_1.weight', 'transformer.h.24.mlp.c_proj.bias', 'transformer.h.27.attn.attention.v_proj.weight', 'transformer.h.16.ln_1.bias', 'transformer.h.21.attn.attention.k_proj.weight', 'transformer.h.22.attn.attention.k_proj.weight', 'transformer.h.14.ln_2.weight', 'transformer.h.17.attn.attention.bias', 'transformer.h.21.attn.attention.masked_bias', 'transformer.h.28.attn.attention.v_proj.weight', 'transformer.h.27.mlp.c_proj.weight', 'transformer.h.15.attn.attention.q_proj.weight', 'transformer.h.7.attn.attention.q_proj.weight', 'transformer.h.7.ln_2.weight', 'transformer.h.24.ln_2.weight', 'transformer.h.2.ln_2.weight', 'transformer.h.24.attn.attention.bias', 'transformer.h.2.ln_1.bias', 'transformer.h.23.mlp.c_fc.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.17.ln_1.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.18.attn.attention.bias', 'lm_head.weight', 'transformer.h.21.mlp.c_proj.bias', 'transformer.h.18.attn.attention.v_proj.weight', 'transformer.h.14.mlp.c_fc.weight', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.30.ln_2.weight', 'transformer.h.17.ln_2.weight', 'transformer.h.4.ln_1.weight', 'transformer.h.19.mlp.c_fc.bias', 'transformer.h.10.ln_1.bias', 'transformer.h.24.attn.attention.v_proj.weight', 'transformer.h.2.attn.attention.q_proj.weight', 'transformer.h.24.attn.attention.out_proj.weight', 'transformer.h.23.ln_1.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.11.attn.attention.masked_bias', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.8.attn.attention.masked_bias', 'transformer.h.0.attn.attention.out_proj.weight', 'transformer.h.12.attn.attention.out_proj.weight', 'transformer.h.20.ln_2.weight', 'transformer.h.27.ln_1.bias', 'transformer.h.10.attn.attention.masked_bias', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.17.mlp.c_fc.bias', 'transformer.h.2.attn.attention.out_proj.bias', 'transformer.h.8.mlp.c_proj.bias', 'transformer.wte.weight', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.11.attn.attention.q_proj.weight', 'transformer.h.25.ln_1.bias', 'transformer.h.4.attn.attention.bias', 'transformer.h.22.attn.attention.out_proj.bias', 'transformer.h.6.attn.attention.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.21.ln_1.bias', 'transformer.h.1.attn.attention.out_proj.weight', 'transformer.h.30.mlp.c_proj.weight', 'transformer.h.6.ln_2.weight', 'transformer.h.17.mlp.c_fc.weight', 'transformer.h.17.attn.attention.out_proj.bias', 'transformer.h.26.ln_2.weight', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.26.attn.attention.masked_bias', 'transformer.h.16.attn.attention.q_proj.weight', 'transformer.h.21.mlp.c_proj.weight', 'transformer.h.15.attn.attention.out_proj.bias', 'transformer.h.13.attn.attention.bias', 'transformer.h.13.attn.attention.v_proj.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.28.attn.attention.out_proj.bias', 'transformer.h.28.attn.attention.masked_bias', 'transformer.h.9.attn.attention.out_proj.weight', 'transformer.h.9.attn.attention.k_proj.weight', 'transformer.h.26.mlp.c_fc.weight', 'transformer.h.21.mlp.c_fc.weight', 'transformer.h.20.attn.attention.out_proj.bias', 'transformer.h.18.attn.attention.q_proj.weight', 'transformer.h.24.ln_1.weight', 'transformer.h.7.attn.attention.masked_bias', 'transformer.h.25.attn.attention.out_proj.weight', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.5.ln_1.weight', 'transformer.h.2.ln_1.weight', 'transformer.h.10.attn.attention.out_proj.weight', 'transformer.h.22.mlp.c_fc.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.26.mlp.c_fc.bias', 'transformer.h.27.mlp.c_fc.bias', 'transformer.h.23.attn.attention.bias', 'transformer.h.11.ln_1.bias', 'transformer.h.18.ln_2.weight', 'transformer.h.31.ln_1.bias', 'transformer.h.11.attn.attention.out_proj.weight', 'transformer.h.27.ln_2.bias', 'transformer.h.2.attn.attention.v_proj.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.25.attn.attention.k_proj.weight', 'transformer.h.8.attn.attention.out_proj.bias', 'transformer.h.5.attn.attention.q_proj.weight', 'transformer.h.19.ln_2.bias', 'transformer.h.6.attn.attention.k_proj.weight', 'transformer.h.6.attn.attention.masked_bias', 'transformer.ln_f.weight', 'transformer.h.13.attn.attention.k_proj.weight', 'transformer.h.25.attn.attention.masked_bias', 'transformer.h.9.attn.attention.v_proj.weight', 'transformer.h.3.attn.attention.q_proj.weight', 'transformer.h.12.attn.attention.masked_bias', 'transformer.h.31.attn.attention.q_proj.weight', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.29.attn.attention.k_proj.weight', 'transformer.h.30.mlp.c_proj.bias', 'transformer.h.13.attn.attention.q_proj.weight', 'transformer.h.12.ln_1.weight', 'transformer.h.31.mlp.c_proj.weight', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.26.attn.attention.out_proj.weight', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.31.attn.attention.out_proj.bias', 'transformer.h.5.attn.attention.bias', 'transformer.h.1.attn.attention.bias', 'transformer.h.17.attn.attention.out_proj.weight', 'transformer.h.28.attn.attention.q_proj.weight', 'transformer.h.3.attn.attention.v_proj.weight', 'transformer.h.8.ln_1.weight', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.21.attn.attention.bias', 'transformer.h.0.attn.attention.bias', 'transformer.h.24.mlp.c_fc.bias', 'transformer.h.6.ln_1.bias', 'transformer.h.21.ln_1.weight', 'transformer.h.2.attn.attention.bias', 'transformer.h.10.ln_2.bias', 'transformer.h.31.attn.attention.v_proj.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.24.attn.attention.masked_bias', 'transformer.h.4.ln_2.bias', 'transformer.h.18.attn.attention.out_proj.weight', 'transformer.h.21.ln_2.weight', 'transformer.h.30.ln_1.bias', 'transformer.h.23.attn.attention.q_proj.weight', 'transformer.h.15.attn.attention.v_proj.weight', 'transformer.h.3.attn.attention.out_proj.bias', 'transformer.h.15.attn.attention.k_proj.weight', 'transformer.h.21.attn.attention.v_proj.weight', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.29.attn.attention.masked_bias', 'transformer.h.0.ln_1.weight', 'transformer.h.15.attn.attention.out_proj.weight', 'transformer.h.13.attn.attention.masked_bias', 'transformer.h.10.attn.attention.out_proj.bias', 'transformer.h.7.attn.attention.v_proj.weight', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.2.attn.attention.masked_bias', 'transformer.h.23.ln_2.weight', 'transformer.h.26.ln_1.bias', 'transformer.h.16.ln_2.bias', 'transformer.h.17.attn.attention.v_proj.weight', 'transformer.h.21.ln_2.bias', 'transformer.h.16.mlp.c_fc.bias', 'transformer.h.14.ln_1.bias', 'transformer.h.14.attn.attention.masked_bias', 'transformer.h.28.ln_2.bias', 'transformer.h.31.ln_2.weight', 'transformer.h.31.mlp.c_fc.bias', 'transformer.h.13.ln_2.weight', 'transformer.h.14.attn.attention.q_proj.weight', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.18.ln_1.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.18.ln_2.bias', 'transformer.h.27.mlp.c_fc.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.19.attn.attention.masked_bias', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.27.ln_1.weight', 'transformer.h.20.attn.attention.k_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2022-11-18 16:05:13,199][datasets.builder][WARNING] - Using custom data configuration ViktorThink--mountain_combined_813306-6918b9ea07482433
[2022-11-18 16:05:13,324][datasets.builder][WARNING] - Found cached dataset csv (/home/paperspace/.cache/huggingface/datasets/ViktorThink___csv/ViktorThink--mountain_combined_813306-6918b9ea07482433/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
  0%|          | 0/2 [00:00<?, ?it/s] 50%|     | 1/2 [00:00<00:00,  5.43it/s]100%|| 2/2 [00:00<00:00, 10.22it/s]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 1/814 [00:03<46:55,  3.46s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:06<43:45,  3.23s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:09<41:58,  3.11s/ba]Running tokenizer on dataset:   0%|          | 4/814 [00:12<40:32,  3.00s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:15<39:52,  2.96s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:17<38:31,  2.86s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:20<37:59,  2.82s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:23<37:22,  2.78s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:25<36:37,  2.73s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:28<35:58,  2.69s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:30<40:14,  3.00s/ba]
Error in sys.excepthook:
Traceback (most recent call last):
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1694, in print
    extend(render(renderable, render_options))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/constrain.py", line 29, in __rich_console__
    yield from console.render(self.renderable, child_options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/panel.py", line 220, in __rich_console__
    lines = console.render_lines(renderable, child_options, style=style)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 511, in __rich_console__
    yield from self._render(console, render_options, widths)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 824, in _render
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/panel.py", line 220, in __rich_console__
    lines = console.render_lines(renderable, child_options, style=style)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 511, in __rich_console__
    yield from self._render(console, render_options, widths)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 824, in _render
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/pretty.py", line 342, in __rich_console__
    pretty_text = Text.from_ansi(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/text.py", line 313, in from_ansi
    result = joiner.join(line for line in decoder.decode(text))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/text.py", line 752, in join
    def iter_text() -> Iterable["Text"]:
  File "/usr/lib/python3.8/typing.py", line 258, in inner
    return cached(*args, **kwds)
  File "/usr/lib/python3.8/typing.py", line 723, in __hash__
    return hash((self.__origin__, self.__args__))
KeyboardInterrupt

Original exception was:
Traceback (most recent call last):
  File "finetune_using_clm_wandb.py", line 599, in <module>
    main()
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "finetune_using_clm_wandb.py", line 304, in main
    tokenized_datasets = preprocess(cfg, accelerator, tokenizer, raw_datasets)
  File "finetune_using_clm_wandb.py", line 215, in preprocess
    tokenized_datasets = raw_datasets.map(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/dataset_dict.py", line 777, in map
    {
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/dataset_dict.py", line 778, in <dictcomp>
    k: dataset.map(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2585, in map
    return self._map_single(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 585, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 552, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/fingerprint.py", line 480, in wrapper
    out = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2982, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2865, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2545, in decorated
    result = f(decorated_item, *args, **kwargs)
  File "finetune_using_clm_wandb.py", line 204, in tokenize_fn
    result = tokenizer(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2488, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2574, in _call_one
    return self.batch_encode_plus(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2765, in batch_encode_plus
    return self._batch_encode_plus(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 733, in _batch_encode_plus
    first_ids = get_input_ids(ids)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 701, in get_input_ids
    return self.convert_tokens_to_ids(tokens)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 579, in convert_tokens_to_ids
    ids.append(self._convert_token_to_id_with_added_voc(token))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 588, in _convert_token_to_id_with_added_voc
    return self._convert_token_to_id(token)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/models/gpt2/tokenization_gpt2.py", line 308, in _convert_token_to_id
    return self.encoder.get(token, self.encoder.get(self.unk_token))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 988, in unk_token
    @property
KeyboardInterrupt
[2022-11-18 16:05:55,852][__main__][INFO] - Setting random seed to 17
[2022-11-18 16:05:55,853][__main__][INFO] - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Mixed precision type: no

[2022-11-18 16:05:55,855][__main__][INFO] - output_dir: tuned-model
bittensor:
  network: nobunaga
dataset:
  name: ViktorThink/mountain_combined_813306
  config_name: null
  num_batches: 10
  block_size: 256
  overwrite_cache: false
  keep_linebreaks: true
  concatenate_raw: false
  load_tokenized_data: false
model:
  name: facebook/opt-2.7b
  config_name: null
tokenizer:
  name: null
  use_fast: true
  preprocessing_num_workers: null
  pad_token: '[PAD]'
training:
  seed: 17
  val_split_percent: 20
  train_batch_size: 32
  eval_batch_size: 16
  learning_rate: 3.0e-06
  weight_decay: 0.05
  num_epochs: 4
  max_train_steps: null
  gradient_accumulation_steps: 2
  lr_scheduler: constant
  lr_warmup_steps: 5
  eval_every: 250
  max_eval_steps: 500
  checkpoint:
    resume_from_checkpoint: 0
    every_n_steps: null
tracking:
  enabled: true
  report_to: all
testing:
  enabled: false

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--EleutherAI--gpt-neo-2.7B/snapshots/51568a6e0ae813a3f2a9da558ab7beac5e3acc24/config.json
Model config GPTNeoConfig {
  "_name_or_path": "EleutherAI/gpt-neo-2.7B",
  "activation_function": "gelu_new",
  "architectures": [
    "GPTNeoForCausalLM"
  ],
  "attention_dropout": 0,
  "attention_layers": [
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local"
  ],
  "attention_types": [
    [
      [
        "global",
        "local"
      ],
      16
    ]
  ],
  "bos_token_id": 50256,
  "embed_dropout": 0,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "hidden_size": 2560,
  "initializer_range": 0.02,
  "intermediate_size": null,
  "layer_norm_epsilon": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neo",
  "num_heads": 20,
  "num_layers": 32,
  "resid_dropout": 0,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50,
      "temperature": 0.9
    }
  },
  "tokenizer_class": "GPT2Tokenizer",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50257,
  "window_size": 256
}

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading file vocab.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/vocab.json
loading file merges.txt from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/merges.txt
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/tokenizer_config.json
loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading weights file flax_model.msgpack from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Loading Flax weights from /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Some weights of the Flax model were not used when initializing the PyTorch model GPTNeoForCausalLM: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.18.fc1.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.bias']
- This IS expected if you are initializing GPTNeoForCausalLM from a Flax model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a FlaxBertForPreTraining model).
- This IS NOT expected if you are initializing GPTNeoForCausalLM from a Flax model that you expect to be exactly identical (e.g. initializing a BertForSequenceClassification model from a FlaxBertForSequenceClassification model).
Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['transformer.h.17.attn.attention.q_proj.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.9.attn.attention.q_proj.weight', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.22.attn.attention.k_proj.weight', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.19.attn.attention.v_proj.weight', 'transformer.h.22.ln_1.weight', 'transformer.h.23.attn.attention.k_proj.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.9.attn.attention.bias', 'transformer.h.19.ln_1.weight', 'transformer.h.21.attn.attention.k_proj.weight', 'transformer.h.21.mlp.c_proj.bias', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.15.mlp.c_fc.weight', 'transformer.h.19.mlp.c_fc.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.21.attn.attention.v_proj.weight', 'transformer.h.16.mlp.c_fc.bias', 'transformer.h.18.ln_2.weight', 'transformer.h.0.attn.attention.v_proj.weight', 'transformer.h.15.attn.attention.bias', 'transformer.h.9.ln_2.bias', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.25.attn.attention.out_proj.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.10.ln_2.weight', 'transformer.h.16.attn.attention.v_proj.weight', 'transformer.h.26.ln_1.weight', 'transformer.h.15.ln_1.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.31.attn.attention.masked_bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.1.attn.attention.out_proj.weight', 'transformer.h.25.ln_1.weight', 'transformer.h.29.ln_1.weight', 'transformer.h.25.attn.attention.bias', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.2.ln_1.bias', 'transformer.h.22.ln_2.bias', 'transformer.h.14.attn.attention.q_proj.weight', 'transformer.h.5.attn.attention.k_proj.weight', 'transformer.h.1.attn.attention.v_proj.weight', 'transformer.h.9.attn.attention.v_proj.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.2.attn.attention.q_proj.weight', 'transformer.h.14.ln_2.weight', 'transformer.h.8.ln_2.weight', 'transformer.h.1.attn.attention.bias', 'transformer.h.3.attn.attention.out_proj.weight', 'transformer.h.0.attn.attention.k_proj.weight', 'transformer.h.21.mlp.c_fc.bias', 'transformer.h.25.mlp.c_fc.bias', 'transformer.h.0.attn.attention.q_proj.weight', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.25.attn.attention.out_proj.weight', 'transformer.h.9.ln_2.weight', 'transformer.h.17.ln_2.bias', 'transformer.h.22.attn.attention.masked_bias', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.8.ln_1.bias', 'transformer.h.24.ln_2.weight', 'transformer.h.12.attn.attention.masked_bias', 'transformer.h.19.attn.attention.out_proj.bias', 'transformer.h.23.mlp.c_proj.weight', 'transformer.h.25.ln_2.weight', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.16.attn.attention.bias', 'transformer.h.26.attn.attention.masked_bias', 'transformer.h.1.ln_1.bias', 'transformer.h.8.attn.attention.v_proj.weight', 'transformer.h.0.attn.attention.out_proj.bias', 'transformer.h.20.attn.attention.k_proj.weight', 'transformer.h.31.attn.attention.k_proj.weight', 'transformer.h.9.attn.attention.k_proj.weight', 'transformer.ln_f.bias', 'transformer.h.19.mlp.c_proj.bias', 'transformer.h.14.ln_1.bias', 'transformer.h.30.attn.attention.out_proj.weight', 'transformer.h.22.attn.attention.v_proj.weight', 'transformer.h.27.attn.attention.q_proj.weight', 'transformer.h.11.ln_2.weight', 'transformer.h.31.attn.attention.v_proj.weight', 'transformer.h.8.attn.attention.bias', 'transformer.h.0.ln_2.bias', 'transformer.h.6.attn.attention.out_proj.bias', 'transformer.h.17.ln_1.weight', 'transformer.h.19.mlp.c_fc.bias', 'transformer.h.26.attn.attention.k_proj.weight', 'transformer.h.29.ln_2.weight', 'transformer.h.6.attn.attention.q_proj.weight', 'transformer.h.5.attn.attention.v_proj.weight', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.23.ln_1.weight', 'transformer.h.19.ln_2.weight', 'transformer.h.17.attn.attention.masked_bias', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.17.attn.attention.k_proj.weight', 'transformer.h.9.ln_1.weight', 'transformer.h.6.attn.attention.masked_bias', 'transformer.h.28.attn.attention.k_proj.weight', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.18.mlp.c_fc.bias', 'transformer.h.15.mlp.c_fc.bias', 'transformer.h.23.attn.attention.masked_bias', 'transformer.h.4.attn.attention.out_proj.bias', 'transformer.h.29.mlp.c_proj.weight', 'transformer.h.20.ln_2.weight', 'transformer.h.11.attn.attention.out_proj.bias', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.23.mlp.c_proj.bias', 'transformer.h.31.attn.attention.out_proj.bias', 'transformer.h.25.mlp.c_fc.weight', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.7.attn.attention.k_proj.weight', 'transformer.h.17.attn.attention.out_proj.bias', 'transformer.h.20.attn.attention.out_proj.weight', 'transformer.h.23.mlp.c_fc.weight', 'transformer.h.29.attn.attention.bias', 'transformer.h.29.attn.attention.k_proj.weight', 'transformer.h.17.attn.attention.out_proj.weight', 'transformer.h.30.ln_2.weight', 'transformer.h.3.attn.attention.bias', 'transformer.h.2.ln_2.bias', 'transformer.h.11.ln_2.bias', 'transformer.h.27.ln_2.weight', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.22.attn.attention.out_proj.weight', 'transformer.h.26.attn.attention.v_proj.weight', 'transformer.h.1.attn.attention.q_proj.weight', 'transformer.h.30.mlp.c_fc.bias', 'transformer.h.24.attn.attention.out_proj.weight', 'transformer.h.11.attn.attention.masked_bias', 'transformer.h.22.ln_1.bias', 'transformer.h.16.attn.attention.out_proj.bias', 'transformer.h.31.attn.attention.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.31.ln_1.bias', 'transformer.h.26.attn.attention.bias', 'transformer.h.13.ln_2.bias', 'transformer.h.24.ln_1.weight', 'transformer.h.6.attn.attention.v_proj.weight', 'transformer.h.12.ln_2.weight', 'transformer.h.13.mlp.c_fc.weight', 'transformer.h.16.mlp.c_fc.weight', 'transformer.h.26.mlp.c_proj.bias', 'transformer.h.1.ln_2.bias', 'transformer.h.15.attn.attention.out_proj.weight', 'transformer.h.20.attn.attention.q_proj.weight', 'transformer.h.23.attn.attention.q_proj.weight', 'transformer.h.12.attn.attention.out_proj.weight', 'transformer.h.25.attn.attention.v_proj.weight', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.wte.weight', 'transformer.h.7.attn.attention.out_proj.bias', 'transformer.h.12.ln_2.bias', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.4.ln_1.weight', 'transformer.h.13.attn.attention.masked_bias', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.2.attn.attention.bias', 'transformer.h.19.mlp.c_proj.weight', 'transformer.h.15.ln_2.bias', 'transformer.h.14.attn.attention.out_proj.bias', 'transformer.h.24.attn.attention.q_proj.weight', 'transformer.h.11.attn.attention.bias', 'transformer.h.5.attn.attention.out_proj.weight', 'transformer.h.16.attn.attention.q_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.18.attn.attention.v_proj.weight', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.4.attn.attention.masked_bias', 'transformer.h.27.mlp.c_fc.weight', 'transformer.h.28.attn.attention.out_proj.bias', 'transformer.h.22.attn.attention.out_proj.bias', 'transformer.h.21.mlp.c_fc.weight', 'transformer.h.14.mlp.c_fc.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.23.mlp.c_fc.bias', 'transformer.h.20.attn.attention.masked_bias', 'transformer.h.24.attn.attention.v_proj.weight', 'transformer.h.0.ln_2.weight', 'transformer.h.4.ln_2.weight', 'transformer.h.14.ln_2.bias', 'transformer.h.10.attn.attention.k_proj.weight', 'transformer.h.2.ln_1.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.6.attn.attention.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.24.mlp.c_fc.weight', 'transformer.h.30.mlp.c_proj.bias', 'transformer.h.18.attn.attention.k_proj.weight', 'transformer.h.23.attn.attention.out_proj.bias', 'transformer.h.31.attn.attention.out_proj.weight', 'transformer.h.23.attn.attention.v_proj.weight', 'transformer.h.10.ln_1.weight', 'transformer.h.8.attn.attention.k_proj.weight', 'transformer.h.18.attn.attention.bias', 'transformer.h.25.ln_1.bias', 'transformer.h.27.attn.attention.out_proj.bias', 'transformer.h.13.attn.attention.out_proj.weight', 'transformer.h.27.attn.attention.masked_bias', 'transformer.h.13.mlp.c_fc.bias', 'transformer.h.18.ln_2.bias', 'transformer.h.18.attn.attention.out_proj.bias', 'transformer.h.31.mlp.c_proj.weight', 'transformer.h.5.ln_1.weight', 'transformer.h.2.mlp.c_fc.weight', 'transformer.wpe.weight', 'transformer.h.28.ln_2.weight', 'transformer.h.13.attn.attention.bias', 'transformer.h.24.attn.attention.masked_bias', 'transformer.h.17.mlp.c_fc.bias', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.7.attn.attention.out_proj.weight', 'transformer.h.9.attn.attention.masked_bias', 'transformer.h.17.mlp.c_fc.weight', 'transformer.h.20.mlp.c_proj.bias', 'transformer.h.7.attn.attention.q_proj.weight', 'transformer.h.29.attn.attention.masked_bias', 'transformer.h.8.attn.attention.out_proj.bias', 'transformer.h.29.mlp.c_fc.bias', 'transformer.h.29.attn.attention.q_proj.weight', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.17.attn.attention.bias', 'transformer.h.0.attn.attention.masked_bias', 'transformer.h.13.attn.attention.v_proj.weight', 'transformer.h.15.attn.attention.v_proj.weight', 'transformer.h.4.attn.attention.v_proj.weight', 'transformer.h.12.mlp.c_fc.bias', 'transformer.h.10.ln_2.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.10.attn.attention.out_proj.bias', 'transformer.h.26.ln_2.weight', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.20.attn.attention.out_proj.bias', 'transformer.h.20.mlp.c_fc.weight', 'transformer.h.13.attn.attention.out_proj.bias', 'transformer.h.13.ln_1.bias', 'transformer.h.22.attn.attention.q_proj.weight', 'transformer.h.5.attn.attention.q_proj.weight', 'transformer.h.3.attn.attention.k_proj.weight', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.14.mlp.c_fc.bias', 'transformer.h.11.attn.attention.out_proj.weight', 'transformer.h.11.ln_1.weight', 'transformer.h.20.mlp.c_fc.bias', 'transformer.h.20.attn.attention.v_proj.weight', 'transformer.h.27.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.masked_bias', 'transformer.h.31.ln_2.bias', 'transformer.h.0.attn.attention.out_proj.weight', 'transformer.h.2.attn.attention.masked_bias', 'transformer.h.28.attn.attention.bias', 'transformer.h.3.ln_2.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.10.attn.attention.masked_bias', 'transformer.h.29.ln_2.bias', 'transformer.h.23.attn.attention.out_proj.weight', 'transformer.h.10.attn.attention.v_proj.weight', 'transformer.h.3.ln_2.weight', 'transformer.h.4.attn.attention.out_proj.weight', 'transformer.h.4.attn.attention.q_proj.weight', 'transformer.h.29.mlp.c_fc.weight', 'transformer.h.18.mlp.c_fc.weight', 'transformer.h.24.ln_1.bias', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.27.attn.attention.out_proj.weight', 'transformer.h.18.mlp.c_proj.weight', 'transformer.h.17.ln_1.bias', 'transformer.h.19.attn.attention.k_proj.weight', 'transformer.h.15.ln_1.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.12.attn.attention.k_proj.weight', 'transformer.h.14.mlp.c_proj.bias', 'transformer.h.29.mlp.c_proj.bias', 'transformer.h.28.attn.attention.v_proj.weight', 'transformer.h.5.attn.attention.out_proj.bias', 'transformer.h.10.attn.attention.q_proj.weight', 'transformer.h.23.ln_2.bias', 'transformer.h.20.ln_1.weight', 'transformer.h.30.ln_2.bias', 'transformer.h.6.ln_1.bias', 'transformer.h.18.ln_1.bias', 'transformer.h.21.mlp.c_proj.weight', 'transformer.h.28.mlp.c_fc.bias', 'transformer.h.16.ln_1.bias', 'transformer.h.29.attn.attention.out_proj.weight', 'transformer.h.21.ln_2.bias', 'transformer.ln_f.weight', 'transformer.h.15.attn.attention.q_proj.weight', 'transformer.h.5.attn.attention.bias', 'transformer.h.0.ln_1.bias', 'transformer.h.7.attn.attention.bias', 'transformer.h.21.attn.attention.out_proj.weight', 'transformer.h.19.attn.attention.q_proj.weight', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.28.attn.attention.q_proj.weight', 'transformer.h.27.attn.attention.bias', 'transformer.h.30.attn.attention.bias', 'transformer.h.16.ln_1.weight', 'transformer.h.31.ln_2.weight', 'transformer.h.8.attn.attention.masked_bias', 'transformer.h.12.attn.attention.out_proj.bias', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.24.attn.attention.bias', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.23.attn.attention.bias', 'transformer.h.0.attn.attention.bias', 'transformer.h.8.attn.attention.q_proj.weight', 'transformer.h.28.mlp.c_fc.weight', 'transformer.h.28.ln_1.weight', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.22.mlp.c_fc.weight', 'transformer.h.17.ln_2.weight', 'transformer.h.28.mlp.c_proj.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.11.attn.attention.v_proj.weight', 'transformer.h.21.ln_1.weight', 'transformer.h.19.ln_1.bias', 'transformer.h.2.attn.attention.k_proj.weight', 'transformer.h.6.attn.attention.k_proj.weight', 'transformer.h.2.attn.attention.out_proj.bias', 'transformer.h.4.attn.attention.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.3.attn.attention.q_proj.weight', 'transformer.h.15.ln_2.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.14.attn.attention.v_proj.weight', 'transformer.h.31.mlp.c_fc.bias', 'transformer.h.27.ln_1.weight', 'transformer.h.23.ln_1.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.2.attn.attention.v_proj.weight', 'transformer.h.6.attn.attention.out_proj.weight', 'transformer.h.29.ln_1.bias', 'transformer.h.3.attn.attention.out_proj.bias', 'transformer.h.13.ln_2.weight', 'transformer.h.19.ln_2.bias', 'transformer.h.28.mlp.c_proj.weight', 'transformer.h.21.ln_2.weight', 'transformer.h.26.ln_1.bias', 'transformer.h.14.attn.attention.k_proj.weight', 'transformer.h.27.mlp.c_proj.weight', 'lm_head.weight', 'transformer.h.13.attn.attention.q_proj.weight', 'transformer.h.30.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.27.mlp.c_fc.bias', 'transformer.h.7.attn.attention.v_proj.weight', 'transformer.h.16.ln_2.weight', 'transformer.h.6.ln_1.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.14.ln_1.weight', 'transformer.h.30.mlp.c_proj.weight', 'transformer.h.12.mlp.c_fc.weight', 'transformer.h.8.ln_1.weight', 'transformer.h.1.ln_2.weight', 'transformer.h.2.ln_2.weight', 'transformer.h.13.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.k_proj.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.22.ln_2.weight', 'transformer.h.16.ln_2.bias', 'transformer.h.26.attn.attention.out_proj.weight', 'transformer.h.28.ln_1.bias', 'transformer.h.27.ln_2.bias', 'transformer.h.9.attn.attention.out_proj.bias', 'transformer.h.28.attn.attention.masked_bias', 'transformer.h.30.attn.attention.v_proj.weight', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.20.ln_1.bias', 'transformer.h.10.attn.attention.out_proj.weight', 'transformer.h.31.ln_1.weight', 'transformer.h.6.ln_2.weight', 'transformer.h.25.mlp.c_proj.weight', 'transformer.h.25.attn.attention.masked_bias', 'transformer.h.30.ln_1.weight', 'transformer.h.8.attn.attention.out_proj.weight', 'transformer.h.30.attn.attention.q_proj.weight', 'transformer.h.4.attn.attention.k_proj.weight', 'transformer.h.24.ln_2.bias', 'transformer.h.30.ln_1.bias', 'transformer.h.21.attn.attention.bias', 'transformer.h.24.mlp.c_proj.weight', 'transformer.h.25.mlp.c_proj.bias', 'transformer.h.6.ln_2.bias', 'transformer.h.18.attn.attention.out_proj.weight', 'transformer.h.29.attn.attention.out_proj.bias', 'transformer.h.31.attn.attention.q_proj.weight', 'transformer.h.19.attn.attention.masked_bias', 'transformer.h.21.attn.attention.q_proj.weight', 'transformer.h.3.attn.attention.v_proj.weight', 'transformer.h.22.mlp.c_proj.bias', 'transformer.h.29.attn.attention.v_proj.weight', 'transformer.h.22.attn.attention.bias', 'transformer.h.18.attn.attention.q_proj.weight', 'transformer.h.10.attn.attention.bias', 'transformer.h.18.ln_1.weight', 'transformer.h.9.attn.attention.out_proj.weight', 'transformer.h.15.attn.attention.masked_bias', 'transformer.h.4.ln_1.bias', 'transformer.h.30.attn.attention.out_proj.bias', 'transformer.h.27.ln_1.bias', 'transformer.h.5.attn.attention.masked_bias', 'transformer.h.12.attn.attention.q_proj.weight', 'transformer.h.13.ln_1.weight', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.18.attn.attention.masked_bias', 'transformer.h.7.ln_1.bias', 'transformer.h.2.attn.attention.out_proj.weight', 'transformer.h.21.attn.attention.masked_bias', 'transformer.h.16.attn.attention.masked_bias', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.19.attn.attention.out_proj.weight', 'transformer.h.1.attn.attention.out_proj.bias', 'transformer.h.15.attn.attention.out_proj.bias', 'transformer.h.25.attn.attention.k_proj.weight', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.26.mlp.c_fc.bias', 'transformer.h.28.ln_2.bias', 'transformer.h.31.mlp.c_proj.bias', 'transformer.h.24.attn.attention.k_proj.weight', 'transformer.h.23.ln_2.weight', 'transformer.h.31.mlp.c_fc.weight', 'transformer.h.26.mlp.c_fc.weight', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.3.attn.attention.masked_bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.7.ln_2.bias', 'transformer.h.12.attn.attention.v_proj.weight', 'transformer.h.12.attn.attention.bias', 'transformer.h.26.ln_2.bias', 'transformer.h.27.mlp.c_proj.bias', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.14.attn.attention.out_proj.weight', 'transformer.h.26.mlp.c_proj.weight', 'transformer.h.11.attn.attention.q_proj.weight', 'transformer.h.12.ln_1.bias', 'transformer.h.16.attn.attention.k_proj.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.16.attn.attention.out_proj.weight', 'transformer.h.1.attn.attention.masked_bias', 'transformer.h.17.attn.attention.v_proj.weight', 'transformer.h.24.mlp.c_fc.bias', 'transformer.h.26.attn.attention.q_proj.weight', 'transformer.h.24.mlp.c_proj.bias', 'transformer.h.12.ln_1.weight', 'transformer.h.15.attn.attention.k_proj.weight', 'transformer.h.14.attn.attention.bias', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.28.attn.attention.out_proj.weight', 'transformer.h.22.mlp.c_fc.bias', 'transformer.h.22.mlp.c_proj.weight', 'transformer.h.21.attn.attention.out_proj.bias', 'transformer.h.7.attn.attention.masked_bias', 'transformer.h.18.mlp.c_proj.bias', 'transformer.h.24.attn.attention.out_proj.bias', 'transformer.h.27.attn.attention.v_proj.weight', 'transformer.h.20.attn.attention.bias', 'transformer.h.26.attn.attention.out_proj.bias', 'transformer.h.4.ln_2.bias', 'transformer.h.19.attn.attention.bias', 'transformer.h.1.attn.attention.k_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.21.ln_1.bias', 'transformer.h.25.attn.attention.q_proj.weight', 'transformer.h.25.ln_2.bias', 'transformer.h.14.attn.attention.masked_bias', 'transformer.h.20.ln_2.bias', 'transformer.h.20.mlp.c_proj.weight', 'transformer.h.11.attn.attention.k_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2022-11-18 16:06:29,167][datasets.builder][WARNING] - Using custom data configuration ViktorThink--mountain_combined_813306-6918b9ea07482433
[2022-11-18 16:06:29,264][datasets.builder][WARNING] - Found cached dataset csv (/home/paperspace/.cache/huggingface/datasets/ViktorThink___csv/ViktorThink--mountain_combined_813306-6918b9ea07482433/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
  0%|          | 0/2 [00:00<?, ?it/s] 50%|     | 1/2 [00:00<00:00,  5.42it/s]100%|| 2/2 [00:00<00:00, 10.21it/s]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 1/814 [00:02<34:49,  2.57s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:04<32:05,  2.37s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:07<30:58,  2.29s/ba]Running tokenizer on dataset:   0%|          | 4/814 [00:09<29:58,  2.22s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:11<29:15,  2.17s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:13<28:21,  2.11s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:15<28:04,  2.09s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:17<27:40,  2.06s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:19<27:11,  2.03s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:21<26:45,  2.00s/ba]Running tokenizer on dataset:   1%|         | 11/814 [00:23<26:44,  2.00s/ba]Running tokenizer on dataset:   1%|         | 12/814 [00:25<26:33,  1.99s/ba]Running tokenizer on dataset:   2%|         | 13/814 [00:27<26:28,  1.98s/ba]Running tokenizer on dataset:   2%|         | 14/814 [00:29<26:22,  1.98s/ba]Running tokenizer on dataset:   2%|         | 15/814 [00:30<26:14,  1.97s/ba]Running tokenizer on dataset:   2%|         | 16/814 [00:32<25:59,  1.95s/ba]Running tokenizer on dataset:   2%|         | 17/814 [00:34<25:43,  1.94s/ba]Running tokenizer on dataset:   2%|         | 18/814 [00:36<25:32,  1.92s/ba]Running tokenizer on dataset:   2%|         | 19/814 [00:38<25:20,  1.91s/ba]Running tokenizer on dataset:   2%|         | 20/814 [00:40<25:22,  1.92s/ba]Running tokenizer on dataset:   3%|         | 21/814 [00:42<25:19,  1.92s/ba]Running tokenizer on dataset:   3%|         | 22/814 [00:44<25:03,  1.90s/ba]Running tokenizer on dataset:   3%|         | 23/814 [00:46<24:50,  1.88s/ba]Running tokenizer on dataset:   3%|         | 24/814 [00:47<24:45,  1.88s/ba]Running tokenizer on dataset:   3%|         | 25/814 [00:49<24:43,  1.88s/ba]Running tokenizer on dataset:   3%|         | 26/814 [00:51<24:35,  1.87s/ba]Running tokenizer on dataset:   3%|         | 27/814 [00:53<24:18,  1.85s/ba]Running tokenizer on dataset:   3%|         | 28/814 [00:55<24:23,  1.86s/ba]Running tokenizer on dataset:   4%|         | 29/814 [00:57<24:30,  1.87s/ba]Running tokenizer on dataset:   4%|         | 30/814 [00:59<24:29,  1.87s/ba]Running tokenizer on dataset:   4%|         | 31/814 [01:01<24:18,  1.86s/ba]Running tokenizer on dataset:   4%|         | 32/814 [01:02<24:30,  1.88s/ba]Running tokenizer on dataset:   4%|         | 33/814 [01:04<24:23,  1.87s/ba]Running tokenizer on dataset:   4%|         | 34/814 [01:06<24:05,  1.85s/ba]Running tokenizer on dataset:   4%|         | 35/814 [01:08<23:55,  1.84s/ba]Running tokenizer on dataset:   4%|         | 36/814 [01:10<23:38,  1.82s/ba]Running tokenizer on dataset:   5%|         | 37/814 [01:11<23:31,  1.82s/ba]Running tokenizer on dataset:   5%|         | 38/814 [01:13<23:17,  1.80s/ba]Running tokenizer on dataset:   5%|         | 39/814 [01:15<23:34,  1.83s/ba]Running tokenizer on dataset:   5%|         | 40/814 [01:17<23:34,  1.83s/ba]Running tokenizer on dataset:   5%|         | 41/814 [01:19<23:33,  1.83s/ba]Running tokenizer on dataset:   5%|         | 42/814 [01:21<23:33,  1.83s/ba]Running tokenizer on dataset:   5%|         | 43/814 [01:22<23:27,  1.83s/ba]Running tokenizer on dataset:   5%|         | 44/814 [01:24<23:43,  1.85s/ba]Running tokenizer on dataset:   6%|         | 45/814 [01:26<23:34,  1.84s/ba]Running tokenizer on dataset:   6%|         | 46/814 [01:28<23:22,  1.83s/ba]Running tokenizer on dataset:   6%|         | 47/814 [01:30<23:12,  1.81s/ba]Running tokenizer on dataset:   6%|         | 48/814 [01:32<22:57,  1.80s/ba]Running tokenizer on dataset:   6%|         | 49/814 [01:33<23:00,  1.80s/ba]Running tokenizer on dataset:   6%|         | 50/814 [01:35<22:56,  1.80s/ba]Running tokenizer on dataset:   6%|         | 51/814 [01:37<22:45,  1.79s/ba]Running tokenizer on dataset:   6%|         | 52/814 [01:39<22:54,  1.80s/ba]Running tokenizer on dataset:   7%|         | 53/814 [01:41<22:49,  1.80s/ba]Running tokenizer on dataset:   7%|         | 54/814 [01:42<23:01,  1.82s/ba]Running tokenizer on dataset:   7%|         | 55/814 [01:44<23:02,  1.82s/ba]Running tokenizer on dataset:   7%|         | 56/814 [01:46<22:59,  1.82s/ba]Running tokenizer on dataset:   7%|         | 57/814 [01:48<23:15,  1.84s/ba]Running tokenizer on dataset:   7%|         | 58/814 [01:50<22:59,  1.82s/ba]Running tokenizer on dataset:   7%|         | 59/814 [01:51<22:49,  1.81s/ba]Running tokenizer on dataset:   7%|         | 60/814 [01:53<22:40,  1.80s/ba]Running tokenizer on dataset:   7%|         | 61/814 [01:55<22:38,  1.80s/ba]Running tokenizer on dataset:   8%|         | 62/814 [01:57<22:38,  1.81s/ba]Running tokenizer on dataset:   8%|         | 63/814 [01:59<22:29,  1.80s/ba]Running tokenizer on dataset:   8%|         | 64/814 [02:00<22:20,  1.79s/ba]Running tokenizer on dataset:   8%|         | 65/814 [02:02<22:28,  1.80s/ba]Running tokenizer on dataset:   8%|         | 66/814 [02:04<22:33,  1.81s/ba]Running tokenizer on dataset:   8%|         | 67/814 [02:06<22:17,  1.79s/ba]Running tokenizer on dataset:   8%|         | 68/814 [02:08<22:10,  1.78s/ba]Running tokenizer on dataset:   8%|         | 69/814 [02:09<22:05,  1.78s/ba]Running tokenizer on dataset:   9%|         | 70/814 [02:11<21:59,  1.77s/ba]Running tokenizer on dataset:   9%|         | 71/814 [02:13<21:52,  1.77s/ba]Running tokenizer on dataset:   9%|         | 72/814 [02:15<24:00,  1.94s/ba]Running tokenizer on dataset:   9%|         | 73/814 [02:17<23:21,  1.89s/ba]Running tokenizer on dataset:   9%|         | 74/814 [02:19<22:47,  1.85s/ba]Running tokenizer on dataset:   9%|         | 75/814 [02:21<22:26,  1.82s/ba]Running tokenizer on dataset:   9%|         | 76/814 [02:22<22:52,  1.86s/ba]Running tokenizer on dataset:   9%|         | 77/814 [02:24<22:30,  1.83s/ba]Running tokenizer on dataset:  10%|         | 78/814 [02:26<22:20,  1.82s/ba]Running tokenizer on dataset:  10%|         | 79/814 [02:28<22:03,  1.80s/ba]Running tokenizer on dataset:  10%|         | 79/814 [02:29<23:13,  1.90s/ba]
Error in sys.excepthook:
Traceback (most recent call last):
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1694, in print
    extend(render(renderable, render_options))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/constrain.py", line 29, in __rich_console__
    yield from console.render(self.renderable, child_options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/panel.py", line 220, in __rich_console__
    lines = console.render_lines(renderable, child_options, style=style)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 511, in __rich_console__
    yield from self._render(console, render_options, widths)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 824, in _render
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/panel.py", line 220, in __rich_console__
    lines = console.render_lines(renderable, child_options, style=style)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 511, in __rich_console__
    yield from self._render(console, render_options, widths)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 824, in _render
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/pretty.py", line 350, in __rich_console__
    self.highlighter(pretty_text)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/highlighter.py", line 38, in __call__
    self.highlight(highlight_text)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/highlighter.py", line 77, in highlight
    highlight_regex(re_highlight, style_prefix=self.base_style)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/text.py", line 579, in highlight_regex
    for match in re.finditer(re_highlight, plain):
KeyboardInterrupt

Original exception was:
Traceback (most recent call last):
  File "finetune_using_clm_wandb.py", line 599, in <module>
    main()
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "finetune_using_clm_wandb.py", line 304, in main
    tokenized_datasets = preprocess(cfg, accelerator, tokenizer, raw_datasets)
  File "finetune_using_clm_wandb.py", line 215, in preprocess
    tokenized_datasets = raw_datasets.map(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/dataset_dict.py", line 777, in map
    {
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/dataset_dict.py", line 778, in <dictcomp>
    k: dataset.map(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2585, in map
    return self._map_single(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 585, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 552, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/fingerprint.py", line 480, in wrapper
    out = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2982, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2865, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2545, in decorated
    result = f(decorated_item, *args, **kwargs)
  File "finetune_using_clm_wandb.py", line 204, in tokenize_fn
    result = tokenizer(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2488, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2574, in _call_one
    return self.batch_encode_plus(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2765, in batch_encode_plus
    return self._batch_encode_plus(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 733, in _batch_encode_plus
    first_ids = get_input_ids(ids)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 700, in get_input_ids
    tokens = self.tokenize(text, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 547, in tokenize
    tokenized_text.extend(self._tokenize(token))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/models/gpt2/tokenization_gpt2.py", line 303, in _tokenize
    bpe_tokens.extend(bpe_token for bpe_token in self.bpe(token).split(" "))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/models/gpt2/tokenization_gpt2.py", line 210, in bpe
    if token in self.cache:
KeyboardInterrupt
[2022-11-18 16:09:15,017][__main__][INFO] - Setting random seed to 17
[2022-11-18 16:09:15,018][__main__][INFO] - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Mixed precision type: no

[2022-11-18 16:09:15,022][__main__][INFO] - output_dir: tuned-model
bittensor:
  network: nobunaga
dataset:
  name: ViktorThink/mountain_combined_813306
  config_name: null
  num_batches: 2
  block_size: 256
  overwrite_cache: true
  keep_linebreaks: true
  concatenate_raw: false
  load_tokenized_data: false
model:
  name: facebook/opt-2.7b
  config_name: null
tokenizer:
  name: null
  use_fast: true
  preprocessing_num_workers: null
  pad_token: '[PAD]'
training:
  seed: 17
  val_split_percent: 20
  train_batch_size: 32
  eval_batch_size: 16
  learning_rate: 3.0e-06
  weight_decay: 0.05
  num_epochs: 4
  max_train_steps: null
  gradient_accumulation_steps: 2
  lr_scheduler: constant
  lr_warmup_steps: 5
  eval_every: 250
  max_eval_steps: 500
  checkpoint:
    resume_from_checkpoint: 0
    every_n_steps: null
tracking:
  enabled: true
  report_to: all
testing:
  enabled: false

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--EleutherAI--gpt-neo-2.7B/snapshots/51568a6e0ae813a3f2a9da558ab7beac5e3acc24/config.json
Model config GPTNeoConfig {
  "_name_or_path": "EleutherAI/gpt-neo-2.7B",
  "activation_function": "gelu_new",
  "architectures": [
    "GPTNeoForCausalLM"
  ],
  "attention_dropout": 0,
  "attention_layers": [
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local"
  ],
  "attention_types": [
    [
      [
        "global",
        "local"
      ],
      16
    ]
  ],
  "bos_token_id": 50256,
  "embed_dropout": 0,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "hidden_size": 2560,
  "initializer_range": 0.02,
  "intermediate_size": null,
  "layer_norm_epsilon": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neo",
  "num_heads": 20,
  "num_layers": 32,
  "resid_dropout": 0,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50,
      "temperature": 0.9
    }
  },
  "tokenizer_class": "GPT2Tokenizer",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50257,
  "window_size": 256
}

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading file vocab.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/vocab.json
loading file merges.txt from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/merges.txt
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/tokenizer_config.json
loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading weights file flax_model.msgpack from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Loading Flax weights from /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Some weights of the Flax model were not used when initializing the PyTorch model GPTNeoForCausalLM: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.18.fc1.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.bias']
- This IS expected if you are initializing GPTNeoForCausalLM from a Flax model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a FlaxBertForPreTraining model).
- This IS NOT expected if you are initializing GPTNeoForCausalLM from a Flax model that you expect to be exactly identical (e.g. initializing a BertForSequenceClassification model from a FlaxBertForSequenceClassification model).
Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['transformer.h.28.ln_1.weight', 'transformer.h.24.attn.attention.bias', 'transformer.h.1.attn.attention.k_proj.weight', 'transformer.h.31.attn.attention.out_proj.weight', 'transformer.h.10.ln_2.weight', 'transformer.h.25.ln_2.bias', 'transformer.h.1.attn.attention.out_proj.bias', 'transformer.h.11.attn.attention.bias', 'transformer.h.29.ln_1.bias', 'transformer.h.2.attn.attention.k_proj.weight', 'transformer.h.31.attn.attention.q_proj.weight', 'transformer.h.30.ln_1.weight', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.10.ln_2.bias', 'transformer.h.23.attn.attention.bias', 'transformer.h.18.attn.attention.out_proj.weight', 'transformer.h.16.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.5.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.19.attn.attention.v_proj.weight', 'transformer.h.11.ln_1.weight', 'transformer.h.3.attn.attention.out_proj.weight', 'transformer.h.13.attn.attention.masked_bias', 'transformer.h.9.ln_1.weight', 'transformer.h.14.mlp.c_fc.weight', 'transformer.h.4.attn.attention.out_proj.bias', 'transformer.h.0.attn.attention.v_proj.weight', 'transformer.h.28.attn.attention.v_proj.weight', 'transformer.h.15.mlp.c_fc.bias', 'transformer.h.24.ln_2.bias', 'transformer.h.17.mlp.c_fc.weight', 'transformer.h.19.attn.attention.q_proj.weight', 'transformer.h.12.ln_1.weight', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.10.attn.attention.out_proj.weight', 'transformer.h.0.attn.attention.out_proj.weight', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.30.attn.attention.q_proj.weight', 'transformer.h.28.attn.attention.out_proj.bias', 'transformer.h.1.attn.attention.out_proj.weight', 'transformer.h.22.ln_2.weight', 'transformer.h.29.attn.attention.out_proj.weight', 'transformer.h.19.ln_2.weight', 'transformer.h.24.mlp.c_proj.bias', 'transformer.h.26.ln_1.weight', 'transformer.h.25.attn.attention.k_proj.weight', 'transformer.h.5.ln_2.weight', 'transformer.h.9.attn.attention.k_proj.weight', 'transformer.h.23.ln_1.bias', 'transformer.h.21.attn.attention.v_proj.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.16.attn.attention.v_proj.weight', 'transformer.h.2.attn.attention.bias', 'transformer.h.12.attn.attention.out_proj.bias', 'transformer.h.19.ln_1.bias', 'transformer.h.11.attn.attention.v_proj.weight', 'transformer.h.9.attn.attention.q_proj.weight', 'transformer.h.25.attn.attention.out_proj.bias', 'transformer.h.26.ln_2.bias', 'transformer.h.21.mlp.c_fc.weight', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.9.attn.attention.bias', 'transformer.h.8.attn.attention.out_proj.bias', 'transformer.h.23.ln_2.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.7.ln_1.bias', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.10.attn.attention.masked_bias', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.25.attn.attention.q_proj.weight', 'transformer.h.7.attn.attention.v_proj.weight', 'transformer.h.2.attn.attention.out_proj.bias', 'transformer.h.2.attn.attention.out_proj.weight', 'transformer.h.28.mlp.c_proj.bias', 'transformer.h.23.attn.attention.q_proj.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.5.attn.attention.k_proj.weight', 'transformer.wpe.weight', 'transformer.h.25.mlp.c_proj.weight', 'transformer.h.1.attn.attention.q_proj.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.15.attn.attention.bias', 'transformer.h.5.attn.attention.bias', 'transformer.h.6.ln_2.bias', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.12.attn.attention.bias', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.27.attn.attention.out_proj.weight', 'transformer.h.16.attn.attention.bias', 'transformer.h.24.ln_2.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.22.mlp.c_fc.bias', 'transformer.h.21.attn.attention.out_proj.bias', 'transformer.h.24.attn.attention.v_proj.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.12.ln_2.weight', 'transformer.h.22.attn.attention.v_proj.weight', 'transformer.h.7.attn.attention.out_proj.bias', 'transformer.h.26.ln_1.bias', 'transformer.h.31.ln_2.bias', 'transformer.h.4.attn.attention.k_proj.weight', 'transformer.h.1.attn.attention.bias', 'transformer.h.26.attn.attention.out_proj.bias', 'transformer.h.18.attn.attention.out_proj.bias', 'transformer.h.27.mlp.c_proj.weight', 'transformer.h.5.attn.attention.out_proj.bias', 'transformer.h.14.ln_1.weight', 'transformer.h.24.ln_1.weight', 'transformer.h.13.attn.attention.q_proj.weight', 'transformer.h.29.ln_2.bias', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.28.attn.attention.out_proj.weight', 'transformer.h.12.mlp.c_fc.bias', 'transformer.h.18.attn.attention.k_proj.weight', 'transformer.h.3.ln_1.weight', 'transformer.h.29.mlp.c_fc.bias', 'lm_head.weight', 'transformer.h.24.attn.attention.masked_bias', 'transformer.h.20.ln_1.weight', 'transformer.h.24.mlp.c_fc.bias', 'transformer.h.31.attn.attention.v_proj.weight', 'transformer.h.8.attn.attention.v_proj.weight', 'transformer.h.15.ln_2.weight', 'transformer.h.23.ln_2.bias', 'transformer.h.29.mlp.c_proj.bias', 'transformer.h.31.ln_1.bias', 'transformer.h.20.attn.attention.masked_bias', 'transformer.h.2.attn.attention.masked_bias', 'transformer.h.21.ln_1.weight', 'transformer.h.20.attn.attention.v_proj.weight', 'transformer.h.9.ln_2.weight', 'transformer.h.21.ln_2.weight', 'transformer.h.27.attn.attention.v_proj.weight', 'transformer.h.21.mlp.c_proj.weight', 'transformer.h.30.mlp.c_proj.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.15.attn.attention.k_proj.weight', 'transformer.h.16.ln_1.weight', 'transformer.h.27.attn.attention.out_proj.bias', 'transformer.h.18.attn.attention.bias', 'transformer.h.4.ln_2.bias', 'transformer.h.31.attn.attention.k_proj.weight', 'transformer.h.29.attn.attention.masked_bias', 'transformer.h.24.attn.attention.out_proj.bias', 'transformer.h.30.attn.attention.v_proj.weight', 'transformer.h.29.mlp.c_proj.weight', 'transformer.h.19.attn.attention.out_proj.bias', 'transformer.h.31.attn.attention.masked_bias', 'transformer.h.8.attn.attention.masked_bias', 'transformer.h.19.ln_2.bias', 'transformer.h.22.attn.attention.k_proj.weight', 'transformer.h.23.attn.attention.masked_bias', 'transformer.h.20.attn.attention.out_proj.weight', 'transformer.h.23.attn.attention.out_proj.bias', 'transformer.h.22.ln_2.bias', 'transformer.h.21.attn.attention.q_proj.weight', 'transformer.h.23.mlp.c_fc.bias', 'transformer.h.5.ln_1.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.17.attn.attention.masked_bias', 'transformer.h.3.ln_1.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.12.mlp.c_fc.weight', 'transformer.h.21.ln_2.bias', 'transformer.h.13.ln_1.weight', 'transformer.h.27.mlp.c_fc.weight', 'transformer.h.17.ln_1.weight', 'transformer.h.3.attn.attention.masked_bias', 'transformer.h.28.attn.attention.q_proj.weight', 'transformer.h.12.attn.attention.out_proj.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.7.attn.attention.out_proj.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.11.ln_1.bias', 'transformer.h.25.attn.attention.masked_bias', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.7.ln_2.bias', 'transformer.h.18.ln_2.bias', 'transformer.h.19.attn.attention.masked_bias', 'transformer.h.16.mlp.c_fc.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.4.attn.attention.out_proj.weight', 'transformer.h.18.ln_1.weight', 'transformer.h.14.attn.attention.k_proj.weight', 'transformer.h.22.ln_1.weight', 'transformer.h.26.mlp.c_proj.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.8.attn.attention.k_proj.weight', 'transformer.h.27.attn.attention.q_proj.weight', 'transformer.h.8.attn.attention.q_proj.weight', 'transformer.h.30.ln_2.weight', 'transformer.h.28.attn.attention.k_proj.weight', 'transformer.h.14.attn.attention.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.14.attn.attention.masked_bias', 'transformer.h.25.attn.attention.v_proj.weight', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.18.mlp.c_proj.weight', 'transformer.h.3.attn.attention.v_proj.weight', 'transformer.h.8.ln_1.weight', 'transformer.h.7.ln_1.weight', 'transformer.h.8.attn.attention.bias', 'transformer.h.0.attn.attention.k_proj.weight', 'transformer.h.22.mlp.c_fc.weight', 'transformer.h.22.mlp.c_proj.weight', 'transformer.h.13.mlp.c_fc.bias', 'transformer.h.11.attn.attention.k_proj.weight', 'transformer.h.17.attn.attention.q_proj.weight', 'transformer.h.14.ln_1.bias', 'transformer.h.20.mlp.c_proj.weight', 'transformer.h.30.mlp.c_fc.weight', 'transformer.h.30.ln_2.bias', 'transformer.h.15.attn.attention.masked_bias', 'transformer.h.31.ln_1.weight', 'transformer.h.21.attn.attention.masked_bias', 'transformer.h.2.attn.attention.q_proj.weight', 'transformer.h.8.attn.attention.out_proj.weight', 'transformer.h.10.attn.attention.out_proj.bias', 'transformer.h.16.ln_2.bias', 'transformer.h.19.mlp.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.23.mlp.c_fc.weight', 'transformer.h.15.attn.attention.out_proj.bias', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.24.attn.attention.q_proj.weight', 'transformer.h.23.mlp.c_proj.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.31.mlp.c_fc.bias', 'transformer.h.13.mlp.c_fc.weight', 'transformer.h.20.ln_1.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.24.attn.attention.k_proj.weight', 'transformer.h.13.ln_1.bias', 'transformer.h.15.attn.attention.q_proj.weight', 'transformer.h.18.attn.attention.masked_bias', 'transformer.h.6.attn.attention.v_proj.weight', 'transformer.h.19.mlp.c_proj.weight', 'transformer.h.30.mlp.c_proj.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.0.attn.attention.q_proj.weight', 'transformer.h.17.ln_2.weight', 'transformer.h.26.attn.attention.k_proj.weight', 'transformer.h.6.attn.attention.out_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.31.mlp.c_fc.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.31.mlp.c_proj.bias', 'transformer.h.22.attn.attention.bias', 'transformer.h.20.attn.attention.out_proj.bias', 'transformer.h.16.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.bias', 'transformer.h.27.mlp.c_proj.bias', 'transformer.h.25.ln_2.weight', 'transformer.h.23.ln_1.weight', 'transformer.h.18.mlp.c_fc.bias', 'transformer.h.23.attn.attention.out_proj.weight', 'transformer.h.14.ln_2.weight', 'transformer.h.14.attn.attention.out_proj.weight', 'transformer.h.12.attn.attention.k_proj.weight', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.15.attn.attention.out_proj.weight', 'transformer.h.17.ln_2.bias', 'transformer.h.29.attn.attention.q_proj.weight', 'transformer.h.9.attn.attention.out_proj.bias', 'transformer.h.27.ln_1.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.25.ln_1.weight', 'transformer.h.27.attn.attention.k_proj.weight', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.6.attn.attention.out_proj.weight', 'transformer.h.26.mlp.c_fc.weight', 'transformer.h.15.ln_2.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.28.attn.attention.bias', 'transformer.h.1.ln_1.bias', 'transformer.h.6.attn.attention.k_proj.weight', 'transformer.h.13.attn.attention.k_proj.weight', 'transformer.h.2.attn.attention.v_proj.weight', 'transformer.h.26.attn.attention.out_proj.weight', 'transformer.h.5.attn.attention.q_proj.weight', 'transformer.ln_f.weight', 'transformer.h.28.ln_2.weight', 'transformer.h.12.ln_1.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.11.attn.attention.out_proj.bias', 'transformer.h.28.ln_1.bias', 'transformer.h.6.attn.attention.q_proj.weight', 'transformer.h.0.attn.attention.masked_bias', 'transformer.h.19.mlp.c_fc.weight', 'transformer.h.27.ln_2.bias', 'transformer.h.10.attn.attention.k_proj.weight', 'transformer.h.29.mlp.c_fc.weight', 'transformer.h.27.attn.attention.bias', 'transformer.h.29.ln_2.weight', 'transformer.h.31.ln_2.weight', 'transformer.h.3.attn.attention.out_proj.bias', 'transformer.h.10.attn.attention.v_proj.weight', 'transformer.h.3.attn.attention.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.13.attn.attention.bias', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.26.mlp.c_proj.weight', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.4.attn.attention.v_proj.weight', 'transformer.h.0.attn.attention.bias', 'transformer.h.9.attn.attention.masked_bias', 'transformer.h.20.ln_2.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.21.attn.attention.out_proj.weight', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.20.mlp.c_proj.bias', 'transformer.h.17.attn.attention.out_proj.weight', 'transformer.h.4.attn.attention.q_proj.weight', 'transformer.h.5.attn.attention.masked_bias', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.30.attn.attention.masked_bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.25.attn.attention.bias', 'transformer.h.8.ln_2.bias', 'transformer.h.28.ln_2.bias', 'transformer.h.21.mlp.c_proj.bias', 'transformer.h.26.mlp.c_fc.bias', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.25.mlp.c_proj.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.8.ln_2.weight', 'transformer.h.26.attn.attention.v_proj.weight', 'transformer.h.7.attn.attention.masked_bias', 'transformer.h.18.attn.attention.v_proj.weight', 'transformer.h.24.attn.attention.out_proj.weight', 'transformer.h.15.ln_1.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.21.attn.attention.bias', 'transformer.h.15.ln_1.weight', 'transformer.h.21.mlp.c_fc.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.17.ln_1.bias', 'transformer.h.11.attn.attention.q_proj.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.11.attn.attention.out_proj.weight', 'transformer.h.22.attn.attention.masked_bias', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.13.attn.attention.out_proj.bias', 'transformer.h.29.attn.attention.k_proj.weight', 'transformer.h.18.ln_2.weight', 'transformer.h.7.attn.attention.k_proj.weight', 'transformer.h.19.mlp.c_fc.bias', 'transformer.h.20.attn.attention.k_proj.weight', 'transformer.h.12.attn.attention.q_proj.weight', 'transformer.h.18.attn.attention.q_proj.weight', 'transformer.h.25.attn.attention.out_proj.weight', 'transformer.h.14.attn.attention.out_proj.bias', 'transformer.h.11.attn.attention.masked_bias', 'transformer.h.14.mlp.c_proj.bias', 'transformer.h.12.attn.attention.v_proj.weight', 'transformer.h.13.ln_2.bias', 'transformer.h.17.attn.attention.k_proj.weight', 'transformer.h.27.attn.attention.masked_bias', 'transformer.h.17.attn.attention.bias', 'transformer.h.24.ln_1.bias', 'transformer.h.9.attn.attention.v_proj.weight', 'transformer.h.31.attn.attention.bias', 'transformer.h.19.attn.attention.k_proj.weight', 'transformer.h.29.attn.attention.out_proj.bias', 'transformer.h.25.mlp.c_fc.bias', 'transformer.h.21.ln_1.bias', 'transformer.h.3.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.out_proj.weight', 'transformer.h.11.ln_2.weight', 'transformer.h.5.attn.attention.v_proj.weight', 'transformer.h.24.mlp.c_proj.weight', 'transformer.h.16.attn.attention.out_proj.weight', 'transformer.h.7.attn.attention.bias', 'transformer.h.26.ln_2.weight', 'transformer.h.12.ln_2.bias', 'transformer.h.20.ln_2.weight', 'transformer.h.30.ln_1.bias', 'transformer.h.30.mlp.c_fc.bias', 'transformer.h.9.attn.attention.out_proj.weight', 'transformer.h.2.ln_2.weight', 'transformer.h.10.attn.attention.bias', 'transformer.h.28.mlp.c_proj.weight', 'transformer.h.16.attn.attention.q_proj.weight', 'transformer.h.23.attn.attention.k_proj.weight', 'transformer.h.22.mlp.c_proj.bias', 'transformer.h.27.ln_2.weight', 'transformer.h.5.attn.attention.out_proj.weight', 'transformer.h.18.ln_1.bias', 'transformer.h.20.mlp.c_fc.bias', 'transformer.h.26.attn.attention.masked_bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.0.attn.attention.out_proj.bias', 'transformer.h.1.ln_2.bias', 'transformer.h.22.ln_1.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.14.attn.attention.q_proj.weight', 'transformer.h.23.attn.attention.v_proj.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.14.ln_2.bias', 'transformer.h.22.attn.attention.q_proj.weight', 'transformer.h.25.ln_1.bias', 'transformer.h.22.attn.attention.out_proj.bias', 'transformer.h.3.attn.attention.q_proj.weight', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.19.attn.attention.bias', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.20.mlp.c_fc.weight', 'transformer.h.30.attn.attention.out_proj.bias', 'transformer.h.19.attn.attention.out_proj.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.4.ln_1.weight', 'transformer.h.29.attn.attention.v_proj.weight', 'transformer.h.29.ln_1.weight', 'transformer.h.24.mlp.c_fc.weight', 'transformer.h.30.attn.attention.k_proj.weight', 'transformer.h.15.mlp.c_fc.weight', 'transformer.h.23.mlp.c_proj.bias', 'transformer.h.12.attn.attention.masked_bias', 'transformer.h.27.mlp.c_fc.bias', 'transformer.h.17.mlp.c_fc.bias', 'transformer.h.26.attn.attention.bias', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.20.attn.attention.bias', 'transformer.wte.weight', 'transformer.h.20.attn.attention.q_proj.weight', 'transformer.h.13.ln_2.weight', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.17.attn.attention.out_proj.bias', 'transformer.h.21.attn.attention.k_proj.weight', 'transformer.h.26.attn.attention.q_proj.weight', 'transformer.h.31.mlp.c_proj.weight', 'transformer.h.16.attn.attention.masked_bias', 'transformer.h.10.ln_1.weight', 'transformer.h.6.attn.attention.bias', 'transformer.h.14.mlp.c_fc.bias', 'transformer.h.29.attn.attention.bias', 'transformer.h.6.ln_1.weight', 'transformer.h.7.ln_2.weight', 'transformer.h.25.mlp.c_fc.weight', 'transformer.h.18.mlp.c_fc.weight', 'transformer.h.28.attn.attention.masked_bias', 'transformer.h.9.ln_2.bias', 'transformer.h.13.attn.attention.v_proj.weight', 'transformer.h.22.attn.attention.out_proj.weight', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.7.attn.attention.q_proj.weight', 'transformer.h.6.attn.attention.masked_bias', 'transformer.ln_f.bias', 'transformer.h.10.ln_1.bias', 'transformer.h.1.attn.attention.masked_bias', 'transformer.h.14.attn.attention.v_proj.weight', 'transformer.h.18.mlp.c_proj.bias', 'transformer.h.28.mlp.c_fc.bias', 'transformer.h.16.attn.attention.out_proj.bias', 'transformer.h.2.ln_2.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.16.ln_1.bias', 'transformer.h.17.attn.attention.v_proj.weight', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.16.ln_2.weight', 'transformer.h.15.attn.attention.v_proj.weight', 'transformer.h.31.attn.attention.out_proj.bias', 'transformer.h.4.attn.attention.bias', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.10.attn.attention.q_proj.weight', 'transformer.h.27.ln_1.bias', 'transformer.h.4.attn.attention.masked_bias', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.19.ln_1.weight', 'transformer.h.28.mlp.c_fc.weight', 'transformer.h.1.attn.attention.v_proj.weight', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.13.attn.attention.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2022-11-18 16:09:47,220][datasets.builder][WARNING] - Using custom data configuration ViktorThink--mountain_combined_813306-6918b9ea07482433
[2022-11-18 16:09:47,312][datasets.builder][WARNING] - Found cached dataset csv (/home/paperspace/.cache/huggingface/datasets/ViktorThink___csv/ViktorThink--mountain_combined_813306-6918b9ea07482433/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
  0%|          | 0/2 [00:00<?, ?it/s] 50%|     | 1/2 [00:00<00:00,  5.95it/s]100%|| 2/2 [00:00<00:00, 11.29it/s]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 1/814 [00:02<35:05,  2.59s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:04<32:31,  2.40s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:07<31:10,  2.31s/ba]Running tokenizer on dataset:   0%|          | 4/814 [00:09<30:08,  2.23s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:11<29:27,  2.18s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:13<28:36,  2.12s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:15<28:15,  2.10s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:17<27:47,  2.07s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:19<27:19,  2.04s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:21<26:49,  2.00s/ba]Running tokenizer on dataset:   1%|         | 11/814 [00:23<26:50,  2.01s/ba]Running tokenizer on dataset:   1%|         | 12/814 [00:25<26:41,  2.00s/ba]Running tokenizer on dataset:   2%|         | 13/814 [00:27<26:32,  1.99s/ba]Running tokenizer on dataset:   2%|         | 14/814 [00:29<26:25,  1.98s/ba]Running tokenizer on dataset:   2%|         | 15/814 [00:31<26:10,  1.97s/ba]Running tokenizer on dataset:   2%|         | 16/814 [00:32<25:56,  1.95s/ba]Running tokenizer on dataset:   2%|         | 17/814 [00:34<25:43,  1.94s/ba]Running tokenizer on dataset:   2%|         | 18/814 [00:36<25:28,  1.92s/ba]Running tokenizer on dataset:   2%|         | 19/814 [00:38<25:22,  1.91s/ba]Running tokenizer on dataset:   2%|         | 20/814 [00:41<27:43,  2.10s/ba]Running tokenizer on dataset:   3%|         | 21/814 [00:43<29:31,  2.23s/ba]Running tokenizer on dataset:   3%|         | 22/814 [00:46<30:25,  2.31s/ba]Running tokenizer on dataset:   3%|         | 23/814 [00:48<31:08,  2.36s/ba]Running tokenizer on dataset:   3%|         | 24/814 [00:51<31:39,  2.40s/ba]Running tokenizer on dataset:   3%|         | 25/814 [00:53<32:08,  2.44s/ba]Running tokenizer on dataset:   3%|         | 26/814 [00:56<32:14,  2.45s/ba]Running tokenizer on dataset:   3%|         | 27/814 [00:58<32:09,  2.45s/ba]Running tokenizer on dataset:   3%|         | 28/814 [01:01<32:25,  2.48s/ba]Running tokenizer on dataset:   4%|         | 29/814 [01:03<32:44,  2.50s/ba]Running tokenizer on dataset:   4%|         | 30/814 [01:06<32:42,  2.50s/ba]Running tokenizer on dataset:   4%|         | 31/814 [01:08<32:30,  2.49s/ba]Running tokenizer on dataset:   4%|         | 32/814 [01:11<32:37,  2.50s/ba]Running tokenizer on dataset:   4%|         | 33/814 [01:13<30:05,  2.31s/ba]Running tokenizer on dataset:   4%|         | 34/814 [01:14<28:07,  2.16s/ba]Running tokenizer on dataset:   4%|         | 35/814 [01:16<26:44,  2.06s/ba]Running tokenizer on dataset:   4%|         | 36/814 [01:18<25:38,  1.98s/ba]Running tokenizer on dataset:   5%|         | 37/814 [01:20<24:56,  1.93s/ba]Running tokenizer on dataset:   5%|         | 38/814 [01:22<24:16,  1.88s/ba]Running tokenizer on dataset:   5%|         | 39/814 [01:24<24:18,  1.88s/ba]Running tokenizer on dataset:   5%|         | 40/814 [01:25<24:03,  1.86s/ba]Running tokenizer on dataset:   5%|         | 41/814 [01:27<23:57,  1.86s/ba]Running tokenizer on dataset:   5%|         | 42/814 [01:29<23:50,  1.85s/ba]Running tokenizer on dataset:   5%|         | 43/814 [01:31<23:42,  1.84s/ba]Running tokenizer on dataset:   5%|         | 44/814 [01:33<23:54,  1.86s/ba]Running tokenizer on dataset:   6%|         | 45/814 [01:35<23:48,  1.86s/ba]Running tokenizer on dataset:   6%|         | 46/814 [01:36<23:28,  1.83s/ba]Running tokenizer on dataset:   6%|         | 47/814 [01:38<23:19,  1.83s/ba]Running tokenizer on dataset:   6%|         | 48/814 [01:40<23:03,  1.81s/ba]Running tokenizer on dataset:   6%|         | 49/814 [01:42<23:04,  1.81s/ba]Running tokenizer on dataset:   6%|         | 50/814 [01:44<22:59,  1.81s/ba]Running tokenizer on dataset:   6%|         | 51/814 [01:45<22:47,  1.79s/ba]Running tokenizer on dataset:   6%|         | 52/814 [01:47<22:54,  1.80s/ba]Running tokenizer on dataset:   7%|         | 53/814 [01:49<22:50,  1.80s/ba]Running tokenizer on dataset:   7%|         | 54/814 [01:51<22:47,  1.80s/ba]Running tokenizer on dataset:   7%|         | 55/814 [01:53<23:02,  1.82s/ba]Running tokenizer on dataset:   7%|         | 56/814 [01:54<22:58,  1.82s/ba]Running tokenizer on dataset:   7%|         | 57/814 [01:56<23:14,  1.84s/ba]Running tokenizer on dataset:   7%|         | 58/814 [01:58<22:57,  1.82s/ba]Running tokenizer on dataset:   7%|         | 59/814 [02:00<22:50,  1.82s/ba]Running tokenizer on dataset:   7%|         | 60/814 [02:02<22:39,  1.80s/ba]Running tokenizer on dataset:   7%|         | 61/814 [02:03<22:36,  1.80s/ba]Running tokenizer on dataset:   8%|         | 62/814 [02:05<22:39,  1.81s/ba]Running tokenizer on dataset:   8%|         | 63/814 [02:07<22:30,  1.80s/ba]Running tokenizer on dataset:   8%|         | 64/814 [02:09<22:22,  1.79s/ba]Running tokenizer on dataset:   8%|         | 65/814 [02:11<22:32,  1.81s/ba]Running tokenizer on dataset:   8%|         | 66/814 [02:13<22:31,  1.81s/ba]Running tokenizer on dataset:   8%|         | 67/814 [02:14<22:20,  1.79s/ba]Running tokenizer on dataset:   8%|         | 68/814 [02:16<22:12,  1.79s/ba]Running tokenizer on dataset:   8%|         | 69/814 [02:18<22:04,  1.78s/ba]Running tokenizer on dataset:   9%|         | 70/814 [02:20<22:00,  1.77s/ba]Running tokenizer on dataset:   9%|         | 71/814 [02:21<21:55,  1.77s/ba]Running tokenizer on dataset:   9%|         | 72/814 [02:24<24:01,  1.94s/ba]Running tokenizer on dataset:   9%|         | 73/814 [02:25<23:23,  1.89s/ba]Running tokenizer on dataset:   9%|         | 74/814 [02:27<22:51,  1.85s/ba]Running tokenizer on dataset:   9%|         | 75/814 [02:29<22:32,  1.83s/ba]Running tokenizer on dataset:   9%|         | 76/814 [02:31<23:05,  1.88s/ba]Running tokenizer on dataset:   9%|         | 77/814 [02:33<22:40,  1.85s/ba]Running tokenizer on dataset:  10%|         | 78/814 [02:35<22:28,  1.83s/ba]Running tokenizer on dataset:  10%|         | 79/814 [02:36<22:11,  1.81s/ba]Running tokenizer on dataset:  10%|         | 80/814 [02:38<22:04,  1.80s/ba]Running tokenizer on dataset:  10%|         | 81/814 [02:40<22:04,  1.81s/ba]Running tokenizer on dataset:  10%|         | 82/814 [02:42<22:03,  1.81s/ba]Running tokenizer on dataset:  10%|         | 83/814 [02:44<21:57,  1.80s/ba]Running tokenizer on dataset:  10%|         | 84/814 [02:45<21:51,  1.80s/ba]Running tokenizer on dataset:  10%|         | 85/814 [02:47<21:43,  1.79s/ba]Running tokenizer on dataset:  11%|         | 86/814 [02:49<21:32,  1.78s/ba]Running tokenizer on dataset:  11%|         | 87/814 [02:51<21:32,  1.78s/ba]Running tokenizer on dataset:  11%|         | 88/814 [02:52<21:29,  1.78s/ba]Running tokenizer on dataset:  11%|         | 89/814 [02:54<21:33,  1.78s/ba]Running tokenizer on dataset:  11%|         | 90/814 [02:56<21:29,  1.78s/ba]Running tokenizer on dataset:  11%|         | 91/814 [02:58<21:26,  1.78s/ba]Running tokenizer on dataset:  11%|        | 92/814 [02:59<21:12,  1.76s/ba]Running tokenizer on dataset:  11%|        | 93/814 [03:01<21:17,  1.77s/ba]Running tokenizer on dataset:  12%|        | 94/814 [03:03<21:10,  1.76s/ba]Running tokenizer on dataset:  12%|        | 95/814 [03:05<21:00,  1.75s/ba]Running tokenizer on dataset:  12%|        | 96/814 [03:07<21:09,  1.77s/ba]Running tokenizer on dataset:  12%|        | 97/814 [03:08<21:09,  1.77s/ba]Running tokenizer on dataset:  12%|        | 98/814 [03:10<21:07,  1.77s/ba]Running tokenizer on dataset:  12%|        | 99/814 [03:12<21:10,  1.78s/ba]Running tokenizer on dataset:  12%|        | 100/814 [03:14<21:02,  1.77s/ba]Running tokenizer on dataset:  12%|        | 101/814 [03:15<20:56,  1.76s/ba]Running tokenizer on dataset:  13%|        | 102/814 [03:17<20:52,  1.76s/ba]Running tokenizer on dataset:  13%|        | 103/814 [03:19<20:56,  1.77s/ba]Running tokenizer on dataset:  13%|        | 104/814 [03:21<20:48,  1.76s/ba]Running tokenizer on dataset:  13%|        | 105/814 [03:22<20:45,  1.76s/ba]Running tokenizer on dataset:  13%|        | 106/814 [03:24<20:46,  1.76s/ba]Running tokenizer on dataset:  13%|        | 107/814 [03:26<20:48,  1.77s/ba]Running tokenizer on dataset:  13%|        | 108/814 [03:28<20:51,  1.77s/ba]Running tokenizer on dataset:  13%|        | 109/814 [03:29<20:50,  1.77s/ba]Running tokenizer on dataset:  14%|        | 110/814 [03:31<20:41,  1.76s/ba]Running tokenizer on dataset:  14%|        | 111/814 [03:33<20:38,  1.76s/ba]Running tokenizer on dataset:  14%|        | 112/814 [03:35<20:35,  1.76s/ba]Running tokenizer on dataset:  14%|        | 113/814 [03:36<20:31,  1.76s/ba]Running tokenizer on dataset:  14%|        | 114/814 [03:38<20:34,  1.76s/ba]Running tokenizer on dataset:  14%|        | 115/814 [03:40<20:39,  1.77s/ba]Running tokenizer on dataset:  14%|        | 116/814 [03:42<20:33,  1.77s/ba]Running tokenizer on dataset:  14%|        | 117/814 [03:44<20:31,  1.77s/ba]Running tokenizer on dataset:  14%|        | 118/814 [03:45<20:39,  1.78s/ba]Running tokenizer on dataset:  15%|        | 119/814 [03:47<20:18,  1.75s/ba]Running tokenizer on dataset:  15%|        | 120/814 [03:49<20:08,  1.74s/ba]Running tokenizer on dataset:  15%|        | 121/814 [03:51<20:22,  1.76s/ba]Running tokenizer on dataset:  15%|        | 122/814 [03:52<20:16,  1.76s/ba]Running tokenizer on dataset:  15%|        | 123/814 [03:54<20:09,  1.75s/ba]Running tokenizer on dataset:  15%|        | 124/814 [03:56<20:08,  1.75s/ba]Running tokenizer on dataset:  15%|        | 125/814 [03:58<20:06,  1.75s/ba]Running tokenizer on dataset:  15%|        | 126/814 [03:59<20:11,  1.76s/ba]Running tokenizer on dataset:  16%|        | 127/814 [04:01<20:11,  1.76s/ba]Running tokenizer on dataset:  16%|        | 128/814 [04:03<19:56,  1.74s/ba]Running tokenizer on dataset:  16%|        | 129/814 [04:05<20:03,  1.76s/ba]Running tokenizer on dataset:  16%|        | 130/814 [04:06<19:48,  1.74s/ba]Running tokenizer on dataset:  16%|        | 131/814 [04:08<19:51,  1.74s/ba]Running tokenizer on dataset:  16%|        | 132/814 [04:10<19:41,  1.73s/ba]Running tokenizer on dataset:  16%|        | 133/814 [04:12<19:43,  1.74s/ba]Running tokenizer on dataset:  16%|        | 134/814 [04:13<19:35,  1.73s/ba]Running tokenizer on dataset:  17%|        | 135/814 [04:15<19:34,  1.73s/ba]Running tokenizer on dataset:  17%|        | 136/814 [04:17<19:32,  1.73s/ba]Running tokenizer on dataset:  17%|        | 137/814 [04:18<19:33,  1.73s/ba]Running tokenizer on dataset:  17%|        | 138/814 [04:20<19:45,  1.75s/ba]Running tokenizer on dataset:  17%|        | 139/814 [04:22<19:36,  1.74s/ba]Running tokenizer on dataset:  17%|        | 140/814 [04:24<19:28,  1.73s/ba]Running tokenizer on dataset:  17%|        | 141/814 [04:25<19:24,  1.73s/ba]Running tokenizer on dataset:  17%|        | 142/814 [04:27<19:32,  1.75s/ba]Running tokenizer on dataset:  18%|        | 143/814 [04:29<19:26,  1.74s/ba]Running tokenizer on dataset:  18%|        | 144/814 [04:31<19:25,  1.74s/ba]Running tokenizer on dataset:  18%|        | 145/814 [04:32<19:22,  1.74s/ba]Running tokenizer on dataset:  18%|        | 146/814 [04:34<19:10,  1.72s/ba]Running tokenizer on dataset:  18%|        | 147/814 [04:36<19:21,  1.74s/ba]Running tokenizer on dataset:  18%|        | 148/814 [04:38<19:21,  1.74s/ba]Running tokenizer on dataset:  18%|        | 149/814 [04:39<19:04,  1.72s/ba]Running tokenizer on dataset:  18%|        | 150/814 [04:41<18:59,  1.72s/ba]Running tokenizer on dataset:  19%|        | 151/814 [04:43<18:52,  1.71s/ba]Running tokenizer on dataset:  19%|        | 152/814 [04:44<18:49,  1.71s/ba]Running tokenizer on dataset:  19%|        | 153/814 [04:46<18:59,  1.72s/ba]Running tokenizer on dataset:  19%|        | 154/814 [04:48<19:01,  1.73s/ba]Running tokenizer on dataset:  19%|        | 155/814 [04:50<18:56,  1.72s/ba]Running tokenizer on dataset:  19%|        | 156/814 [04:51<18:58,  1.73s/ba]Running tokenizer on dataset:  19%|        | 157/814 [04:53<19:31,  1.78s/ba]Running tokenizer on dataset:  19%|        | 158/814 [04:55<19:14,  1.76s/ba]Running tokenizer on dataset:  20%|        | 159/814 [04:57<19:04,  1.75s/ba]Running tokenizer on dataset:  20%|        | 160/814 [04:58<18:58,  1.74s/ba]Running tokenizer on dataset:  20%|        | 161/814 [05:00<18:49,  1.73s/ba]Running tokenizer on dataset:  20%|        | 162/814 [05:02<18:49,  1.73s/ba]Running tokenizer on dataset:  20%|        | 163/814 [05:04<18:45,  1.73s/ba]Running tokenizer on dataset:  20%|        | 164/814 [05:05<18:51,  1.74s/ba]Running tokenizer on dataset:  20%|        | 165/814 [05:07<18:56,  1.75s/ba]Running tokenizer on dataset:  20%|        | 166/814 [05:09<18:56,  1.75s/ba]Running tokenizer on dataset:  21%|        | 167/814 [05:11<18:46,  1.74s/ba]Running tokenizer on dataset:  21%|        | 168/814 [05:12<18:36,  1.73s/ba]Running tokenizer on dataset:  21%|        | 169/814 [05:14<18:33,  1.73s/ba]Running tokenizer on dataset:  21%|        | 170/814 [05:16<18:28,  1.72s/ba]Running tokenizer on dataset:  21%|        | 171/814 [05:17<18:27,  1.72s/ba]Running tokenizer on dataset:  21%|        | 172/814 [05:19<18:43,  1.75s/ba]Running tokenizer on dataset:  21%|       | 173/814 [05:21<18:56,  1.77s/ba]Running tokenizer on dataset:  21%|       | 174/814 [05:23<18:45,  1.76s/ba]Running tokenizer on dataset:  21%|       | 175/814 [05:24<18:34,  1.74s/ba]Running tokenizer on dataset:  22%|       | 176/814 [05:26<18:29,  1.74s/ba]Running tokenizer on dataset:  22%|       | 177/814 [05:28<18:29,  1.74s/ba]Running tokenizer on dataset:  22%|       | 178/814 [05:30<18:36,  1.75s/ba]Running tokenizer on dataset:  22%|       | 179/814 [05:32<18:34,  1.76s/ba]Running tokenizer on dataset:  22%|       | 180/814 [05:33<18:38,  1.76s/ba]Running tokenizer on dataset:  22%|       | 181/814 [05:35<18:33,  1.76s/ba]Running tokenizer on dataset:  22%|       | 182/814 [05:37<18:32,  1.76s/ba]Running tokenizer on dataset:  22%|       | 183/814 [05:39<18:32,  1.76s/ba]Running tokenizer on dataset:  23%|       | 184/814 [05:40<18:23,  1.75s/ba]Running tokenizer on dataset:  23%|       | 185/814 [05:42<18:19,  1.75s/ba]Running tokenizer on dataset:  23%|       | 186/814 [05:44<18:17,  1.75s/ba]Running tokenizer on dataset:  23%|       | 187/814 [05:46<18:10,  1.74s/ba]Running tokenizer on dataset:  23%|       | 188/814 [05:47<18:05,  1.73s/ba]Running tokenizer on dataset:  23%|       | 189/814 [05:49<18:02,  1.73s/ba]Running tokenizer on dataset:  23%|       | 190/814 [05:51<18:01,  1.73s/ba]Running tokenizer on dataset:  23%|       | 191/814 [05:53<18:12,  1.75s/ba]Running tokenizer on dataset:  24%|       | 192/814 [05:54<18:08,  1.75s/ba]Running tokenizer on dataset:  24%|       | 193/814 [05:56<18:10,  1.76s/ba]Running tokenizer on dataset:  24%|       | 194/814 [05:58<18:04,  1.75s/ba]Running tokenizer on dataset:  24%|       | 195/814 [06:00<18:05,  1.75s/ba]Running tokenizer on dataset:  24%|       | 196/814 [06:01<18:01,  1.75s/ba]Running tokenizer on dataset:  24%|       | 197/814 [06:03<17:58,  1.75s/ba]Running tokenizer on dataset:  24%|       | 198/814 [06:05<18:04,  1.76s/ba]Running tokenizer on dataset:  24%|       | 199/814 [06:07<17:55,  1.75s/ba]Running tokenizer on dataset:  25%|       | 200/814 [06:08<17:47,  1.74s/ba]Running tokenizer on dataset:  25%|       | 201/814 [06:10<17:44,  1.74s/ba]Running tokenizer on dataset:  25%|       | 202/814 [06:12<17:45,  1.74s/ba]Running tokenizer on dataset:  25%|       | 203/814 [06:13<17:43,  1.74s/ba]Running tokenizer on dataset:  25%|       | 204/814 [06:15<17:44,  1.75s/ba]Running tokenizer on dataset:  25%|       | 205/814 [06:17<17:36,  1.74s/ba]Running tokenizer on dataset:  25%|       | 206/814 [06:19<17:38,  1.74s/ba]Running tokenizer on dataset:  25%|       | 207/814 [06:20<17:41,  1.75s/ba]Running tokenizer on dataset:  26%|       | 208/814 [06:22<17:37,  1.74s/ba]Running tokenizer on dataset:  26%|       | 209/814 [06:24<17:35,  1.74s/ba]Running tokenizer on dataset:  26%|       | 210/814 [06:26<17:35,  1.75s/ba]Running tokenizer on dataset:  26%|       | 211/814 [06:27<17:33,  1.75s/ba]Running tokenizer on dataset:  26%|       | 211/814 [06:28<18:31,  1.84s/ba]
Error in sys.excepthook:
Traceback (most recent call last):
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1694, in print
    extend(render(renderable, render_options))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/constrain.py", line 29, in __rich_console__
    yield from console.render(self.renderable, child_options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/panel.py", line 220, in __rich_console__
    lines = console.render_lines(renderable, child_options, style=style)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 511, in __rich_console__
    yield from self._render(console, render_options, widths)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 824, in _render
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/syntax.py", line 609, in __rich_console__
    segments = Segments(self._get_syntax(console, options))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 668, in __init__
    self.segments = list(segments)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/syntax.py", line 637, in _get_syntax
    text = self.highlight(processed_code, self.line_range)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/syntax.py", line 509, in highlight
    text.append_tokens(tokens_to_spans())
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/text.py", line 999, in append_tokens
    offset += len(content)
KeyboardInterrupt

Original exception was:
Traceback (most recent call last):
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2982, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2865, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2545, in decorated
    result = f(decorated_item, *args, **kwargs)
  File "finetune_using_clm_wandb.py", line 204, in tokenize_fn
    result = tokenizer(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2488, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2574, in _call_one
    return self.batch_encode_plus(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2765, in batch_encode_plus
    return self._batch_encode_plus(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 733, in _batch_encode_plus
    first_ids = get_input_ids(ids)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 700, in get_input_ids
    tokens = self.tokenize(text, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 547, in tokenize
    tokenized_text.extend(self._tokenize(token))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/models/gpt2/tokenization_gpt2.py", line 299, in _tokenize
    for token in re.findall(self.pat, text):
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/regex/regex.py", line 338, in findall
    return pat.findall(string, pos, endpos, overlapped, concurrent, timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "finetune_using_clm_wandb.py", line 599, in <module>
    main()
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "finetune_using_clm_wandb.py", line 304, in main
    tokenized_datasets = preprocess(cfg, accelerator, tokenizer, raw_datasets)
  File "finetune_using_clm_wandb.py", line 215, in preprocess
    tokenized_datasets = raw_datasets.map(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/dataset_dict.py", line 777, in map
    {
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/dataset_dict.py", line 778, in <dictcomp>
    k: dataset.map(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2585, in map
    return self._map_single(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 585, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 552, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/fingerprint.py", line 480, in wrapper
    out = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 3009, in _map_single
    os.remove(tmp_file.name)
KeyboardInterrupt
[2022-11-18 16:16:26,906][__main__][INFO] - Setting random seed to 17
[2022-11-18 16:16:26,907][__main__][INFO] - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Mixed precision type: no

[2022-11-18 16:16:26,909][__main__][INFO] - output_dir: tuned-model
bittensor:
  network: nobunaga
dataset:
  name: ViktorThink/mountain_combined_813306
  config_name: null
  num_batches: 2
  block_size: 256
  overwrite_cache: false
  keep_linebreaks: true
  concatenate_raw: false
  load_tokenized_data: false
model:
  name: facebook/opt-2.7b
  config_name: null
tokenizer:
  name: null
  use_fast: true
  preprocessing_num_workers: 12
  pad_token: '[PAD]'
training:
  seed: 17
  val_split_percent: 20
  train_batch_size: 32
  eval_batch_size: 16
  learning_rate: 3.0e-06
  weight_decay: 0.05
  num_epochs: 4
  max_train_steps: null
  gradient_accumulation_steps: 2
  lr_scheduler: constant
  lr_warmup_steps: 5
  eval_every: 250
  max_eval_steps: 500
  checkpoint:
    resume_from_checkpoint: 0
    every_n_steps: null
tracking:
  enabled: true
  report_to: all
testing:
  enabled: false

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--EleutherAI--gpt-neo-2.7B/snapshots/51568a6e0ae813a3f2a9da558ab7beac5e3acc24/config.json
Model config GPTNeoConfig {
  "_name_or_path": "EleutherAI/gpt-neo-2.7B",
  "activation_function": "gelu_new",
  "architectures": [
    "GPTNeoForCausalLM"
  ],
  "attention_dropout": 0,
  "attention_layers": [
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local"
  ],
  "attention_types": [
    [
      [
        "global",
        "local"
      ],
      16
    ]
  ],
  "bos_token_id": 50256,
  "embed_dropout": 0,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "hidden_size": 2560,
  "initializer_range": 0.02,
  "intermediate_size": null,
  "layer_norm_epsilon": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neo",
  "num_heads": 20,
  "num_layers": 32,
  "resid_dropout": 0,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50,
      "temperature": 0.9
    }
  },
  "tokenizer_class": "GPT2Tokenizer",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50257,
  "window_size": 256
}

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading file vocab.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/vocab.json
loading file merges.txt from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/merges.txt
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/tokenizer_config.json
loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading weights file flax_model.msgpack from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Loading Flax weights from /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Some weights of the Flax model were not used when initializing the PyTorch model GPTNeoForCausalLM: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.18.fc1.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.bias']
- This IS expected if you are initializing GPTNeoForCausalLM from a Flax model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a FlaxBertForPreTraining model).
- This IS NOT expected if you are initializing GPTNeoForCausalLM from a Flax model that you expect to be exactly identical (e.g. initializing a BertForSequenceClassification model from a FlaxBertForSequenceClassification model).
Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['transformer.h.10.ln_2.bias', 'transformer.h.31.attn.attention.bias', 'transformer.h.20.ln_1.weight', 'transformer.h.6.ln_2.weight', 'transformer.h.30.ln_2.bias', 'transformer.h.16.attn.attention.out_proj.weight', 'transformer.h.14.mlp.c_proj.bias', 'transformer.h.29.ln_2.weight', 'transformer.h.17.attn.attention.bias', 'transformer.h.2.ln_1.bias', 'transformer.h.6.ln_2.bias', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.2.attn.attention.masked_bias', 'transformer.h.2.attn.attention.k_proj.weight', 'transformer.h.4.attn.attention.bias', 'transformer.h.18.ln_2.bias', 'transformer.h.29.attn.attention.masked_bias', 'transformer.h.25.attn.attention.q_proj.weight', 'transformer.h.12.attn.attention.v_proj.weight', 'transformer.h.18.attn.attention.v_proj.weight', 'transformer.h.1.attn.attention.bias', 'transformer.h.8.ln_1.bias', 'transformer.h.15.mlp.c_fc.weight', 'transformer.h.27.ln_2.weight', 'transformer.h.31.attn.attention.masked_bias', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.21.attn.attention.v_proj.weight', 'transformer.h.27.ln_2.bias', 'transformer.h.19.ln_2.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.23.ln_2.weight', 'transformer.h.18.attn.attention.bias', 'transformer.h.19.mlp.c_proj.weight', 'transformer.h.19.ln_2.weight', 'transformer.h.18.mlp.c_fc.weight', 'transformer.h.24.ln_1.weight', 'transformer.h.6.ln_1.weight', 'transformer.h.17.attn.attention.out_proj.bias', 'transformer.h.13.mlp.c_fc.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.7.attn.attention.out_proj.bias', 'transformer.h.18.attn.attention.out_proj.bias', 'transformer.h.19.mlp.c_fc.weight', 'transformer.h.27.attn.attention.k_proj.weight', 'transformer.h.31.ln_2.bias', 'transformer.h.11.attn.attention.masked_bias', 'transformer.h.1.attn.attention.out_proj.bias', 'transformer.h.9.ln_2.weight', 'transformer.h.7.ln_1.weight', 'transformer.h.26.attn.attention.k_proj.weight', 'transformer.h.26.mlp.c_fc.bias', 'transformer.h.24.ln_1.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.9.attn.attention.bias', 'transformer.h.7.attn.attention.bias', 'transformer.h.17.ln_1.bias', 'transformer.h.4.ln_1.bias', 'transformer.h.10.attn.attention.k_proj.weight', 'transformer.h.24.attn.attention.k_proj.weight', 'transformer.h.8.attn.attention.v_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.27.attn.attention.out_proj.bias', 'transformer.h.31.attn.attention.k_proj.weight', 'transformer.h.8.attn.attention.q_proj.weight', 'transformer.h.19.attn.attention.out_proj.bias', 'transformer.h.13.ln_2.weight', 'transformer.h.0.attn.attention.out_proj.bias', 'transformer.h.3.attn.attention.bias', 'transformer.h.28.attn.attention.out_proj.bias', 'transformer.h.30.ln_1.weight', 'transformer.h.14.ln_1.weight', 'transformer.h.1.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.out_proj.weight', 'transformer.h.15.attn.attention.v_proj.weight', 'transformer.h.19.attn.attention.q_proj.weight', 'transformer.h.0.attn.attention.q_proj.weight', 'transformer.h.0.attn.attention.bias', 'transformer.h.15.attn.attention.k_proj.weight', 'transformer.h.28.ln_2.weight', 'transformer.h.14.attn.attention.k_proj.weight', 'transformer.h.27.mlp.c_fc.bias', 'transformer.ln_f.weight', 'transformer.h.15.attn.attention.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.17.attn.attention.out_proj.weight', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.30.mlp.c_proj.weight', 'transformer.h.22.attn.attention.q_proj.weight', 'transformer.h.24.mlp.c_proj.weight', 'transformer.h.20.mlp.c_proj.bias', 'transformer.h.14.ln_2.weight', 'transformer.h.20.attn.attention.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.29.mlp.c_proj.weight', 'transformer.h.14.attn.attention.q_proj.weight', 'transformer.h.21.ln_2.bias', 'transformer.h.25.attn.attention.out_proj.weight', 'transformer.h.17.ln_2.weight', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.5.ln_1.weight', 'transformer.h.25.attn.attention.k_proj.weight', 'transformer.h.23.attn.attention.out_proj.weight', 'transformer.h.9.attn.attention.q_proj.weight', 'transformer.h.7.attn.attention.out_proj.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.9.attn.attention.out_proj.bias', 'transformer.h.31.attn.attention.q_proj.weight', 'transformer.h.19.mlp.c_proj.bias', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.24.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.24.mlp.c_fc.bias', 'transformer.h.16.ln_1.weight', 'transformer.h.5.attn.attention.out_proj.bias', 'transformer.h.25.ln_2.bias', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.15.mlp.c_fc.bias', 'transformer.h.8.ln_2.bias', 'transformer.h.16.attn.attention.masked_bias', 'transformer.h.23.ln_1.bias', 'transformer.h.13.mlp.c_fc.weight', 'transformer.h.5.attn.attention.k_proj.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.13.ln_1.bias', 'transformer.h.21.ln_1.bias', 'transformer.h.0.ln_1.weight', 'transformer.h.10.attn.attention.out_proj.bias', 'transformer.h.27.ln_1.weight', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.5.attn.attention.masked_bias', 'transformer.h.17.mlp.c_fc.weight', 'transformer.h.28.ln_1.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.30.attn.attention.out_proj.bias', 'transformer.h.13.attn.attention.bias', 'transformer.h.3.ln_1.bias', 'transformer.h.11.ln_1.bias', 'transformer.h.3.attn.attention.out_proj.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.23.attn.attention.q_proj.weight', 'transformer.h.23.ln_2.bias', 'transformer.h.16.attn.attention.v_proj.weight', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.26.mlp.c_proj.bias', 'transformer.h.27.attn.attention.masked_bias', 'transformer.h.10.ln_2.weight', 'transformer.h.1.attn.attention.v_proj.weight', 'transformer.h.28.mlp.c_fc.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.11.attn.attention.k_proj.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.14.mlp.c_fc.bias', 'transformer.h.12.attn.attention.masked_bias', 'transformer.h.0.ln_2.bias', 'transformer.h.22.ln_2.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.4.attn.attention.v_proj.weight', 'transformer.h.13.ln_2.bias', 'transformer.h.6.ln_1.bias', 'transformer.h.15.ln_1.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.23.mlp.c_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.18.ln_2.weight', 'transformer.h.30.attn.attention.v_proj.weight', 'transformer.h.14.ln_1.bias', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.14.ln_2.bias', 'transformer.h.30.attn.attention.masked_bias', 'transformer.h.0.attn.attention.k_proj.weight', 'transformer.h.12.ln_2.weight', 'transformer.h.21.attn.attention.out_proj.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.25.ln_1.bias', 'transformer.h.22.attn.attention.bias', 'transformer.h.8.attn.attention.bias', 'transformer.h.1.ln_1.bias', 'transformer.h.15.attn.attention.q_proj.weight', 'transformer.h.8.ln_2.weight', 'transformer.h.1.ln_1.weight', 'transformer.h.4.attn.attention.q_proj.weight', 'transformer.h.15.attn.attention.masked_bias', 'transformer.ln_f.bias', 'transformer.h.19.mlp.c_fc.bias', 'transformer.h.28.attn.attention.masked_bias', 'transformer.h.22.mlp.c_proj.bias', 'transformer.h.15.ln_2.weight', 'transformer.h.29.attn.attention.q_proj.weight', 'transformer.h.5.ln_2.weight', 'transformer.h.31.mlp.c_fc.bias', 'transformer.h.14.attn.attention.v_proj.weight', 'transformer.h.20.mlp.c_fc.bias', 'transformer.h.13.attn.attention.k_proj.weight', 'transformer.h.26.ln_1.bias', 'transformer.h.31.mlp.c_fc.weight', 'transformer.h.31.mlp.c_proj.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.5.attn.attention.out_proj.weight', 'transformer.h.6.attn.attention.v_proj.weight', 'transformer.h.18.ln_1.bias', 'transformer.h.20.ln_2.weight', 'transformer.h.21.attn.attention.q_proj.weight', 'transformer.h.6.attn.attention.bias', 'transformer.h.27.mlp.c_proj.bias', 'transformer.h.21.ln_2.weight', 'transformer.h.3.attn.attention.k_proj.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.23.mlp.c_proj.bias', 'transformer.h.0.attn.attention.out_proj.weight', 'transformer.h.11.attn.attention.bias', 'transformer.h.13.attn.attention.v_proj.weight', 'transformer.h.19.attn.attention.masked_bias', 'transformer.h.31.attn.attention.v_proj.weight', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.11.attn.attention.q_proj.weight', 'transformer.h.18.attn.attention.masked_bias', 'transformer.h.24.ln_2.weight', 'transformer.h.27.attn.attention.q_proj.weight', 'transformer.h.27.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.30.ln_1.bias', 'transformer.h.24.attn.attention.out_proj.weight', 'transformer.h.10.attn.attention.masked_bias', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.17.ln_2.bias', 'transformer.h.28.attn.attention.out_proj.weight', 'transformer.h.31.ln_2.weight', 'transformer.h.3.attn.attention.masked_bias', 'transformer.h.16.ln_2.bias', 'transformer.h.28.ln_1.weight', 'transformer.h.22.attn.attention.k_proj.weight', 'transformer.h.0.attn.attention.masked_bias', 'transformer.h.2.attn.attention.out_proj.bias', 'transformer.h.13.ln_1.weight', 'transformer.h.19.ln_1.bias', 'transformer.h.6.attn.attention.out_proj.bias', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.2.attn.attention.bias', 'transformer.h.26.attn.attention.q_proj.weight', 'transformer.h.29.ln_1.weight', 'transformer.h.15.ln_1.bias', 'transformer.h.18.mlp.c_fc.bias', 'transformer.h.22.attn.attention.masked_bias', 'transformer.h.30.mlp.c_fc.weight', 'transformer.h.8.attn.attention.k_proj.weight', 'transformer.h.26.ln_2.bias', 'transformer.h.7.ln_1.bias', 'transformer.h.25.mlp.c_fc.weight', 'transformer.h.25.mlp.c_fc.bias', 'transformer.h.22.mlp.c_proj.weight', 'transformer.h.20.attn.attention.masked_bias', 'transformer.h.29.ln_2.bias', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.12.attn.attention.out_proj.weight', 'transformer.h.7.attn.attention.masked_bias', 'transformer.h.31.mlp.c_proj.weight', 'transformer.h.26.ln_1.weight', 'transformer.h.12.attn.attention.bias', 'transformer.h.25.attn.attention.bias', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.16.mlp.c_fc.weight', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.29.attn.attention.bias', 'transformer.h.23.attn.attention.k_proj.weight', 'transformer.h.21.mlp.c_proj.bias', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.21.mlp.c_fc.weight', 'transformer.h.28.mlp.c_proj.weight', 'transformer.h.29.attn.attention.k_proj.weight', 'transformer.h.24.mlp.c_proj.bias', 'transformer.h.26.attn.attention.out_proj.weight', 'transformer.h.11.attn.attention.out_proj.weight', 'transformer.h.16.mlp.c_fc.bias', 'transformer.h.23.ln_1.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.26.attn.attention.v_proj.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.22.ln_1.weight', 'transformer.h.12.attn.attention.k_proj.weight', 'transformer.h.13.attn.attention.out_proj.weight', 'transformer.h.2.attn.attention.q_proj.weight', 'transformer.h.14.attn.attention.out_proj.bias', 'transformer.h.14.attn.attention.out_proj.weight', 'transformer.h.25.ln_1.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.29.mlp.c_proj.bias', 'transformer.h.30.attn.attention.q_proj.weight', 'transformer.h.21.ln_1.weight', 'transformer.h.29.ln_1.bias', 'transformer.h.9.attn.attention.out_proj.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.12.attn.attention.q_proj.weight', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.29.attn.attention.v_proj.weight', 'transformer.h.11.ln_2.weight', 'transformer.h.20.ln_2.bias', 'transformer.h.27.attn.attention.out_proj.weight', 'transformer.h.8.attn.attention.out_proj.weight', 'transformer.h.26.mlp.c_proj.weight', 'transformer.h.21.attn.attention.bias', 'transformer.h.15.attn.attention.out_proj.bias', 'transformer.h.24.attn.attention.q_proj.weight', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.31.attn.attention.out_proj.bias', 'transformer.h.2.ln_2.bias', 'transformer.h.20.attn.attention.v_proj.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.2.attn.attention.out_proj.weight', 'transformer.h.13.attn.attention.masked_bias', 'transformer.h.6.attn.attention.k_proj.weight', 'transformer.h.29.mlp.c_fc.weight', 'transformer.h.6.attn.attention.q_proj.weight', 'transformer.h.9.attn.attention.v_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.20.mlp.c_proj.weight', 'transformer.h.31.ln_1.bias', 'transformer.h.0.attn.attention.v_proj.weight', 'transformer.h.6.attn.attention.out_proj.weight', 'transformer.h.30.mlp.c_proj.bias', 'transformer.h.21.attn.attention.k_proj.weight', 'transformer.h.22.ln_2.weight', 'transformer.h.5.attn.attention.q_proj.weight', 'transformer.h.17.attn.attention.q_proj.weight', 'transformer.h.31.attn.attention.out_proj.weight', 'transformer.h.19.attn.attention.v_proj.weight', 'transformer.h.18.attn.attention.out_proj.weight', 'transformer.h.28.attn.attention.v_proj.weight', 'transformer.h.24.attn.attention.out_proj.bias', 'transformer.h.24.attn.attention.masked_bias', 'transformer.h.4.ln_1.weight', 'transformer.h.23.mlp.c_fc.bias', 'transformer.h.29.mlp.c_fc.bias', 'transformer.h.12.attn.attention.out_proj.bias', 'transformer.h.29.attn.attention.out_proj.weight', 'transformer.h.28.attn.attention.k_proj.weight', 'transformer.h.14.attn.attention.bias', 'transformer.h.14.attn.attention.masked_bias', 'transformer.h.16.ln_1.bias', 'transformer.h.20.attn.attention.out_proj.bias', 'transformer.h.12.mlp.c_fc.weight', 'transformer.h.20.attn.attention.q_proj.weight', 'transformer.h.10.attn.attention.v_proj.weight', 'transformer.h.20.mlp.c_fc.weight', 'transformer.h.17.attn.attention.v_proj.weight', 'transformer.h.25.mlp.c_proj.weight', 'transformer.h.7.attn.attention.v_proj.weight', 'transformer.h.28.mlp.c_proj.bias', 'transformer.h.31.ln_1.weight', 'transformer.h.17.attn.attention.k_proj.weight', 'transformer.h.22.attn.attention.out_proj.bias', 'transformer.h.12.ln_1.weight', 'transformer.h.26.attn.attention.bias', 'transformer.h.16.attn.attention.out_proj.bias', 'transformer.h.11.attn.attention.v_proj.weight', 'transformer.h.27.attn.attention.v_proj.weight', 'transformer.h.4.attn.attention.out_proj.bias', 'transformer.h.4.attn.attention.masked_bias', 'transformer.h.7.attn.attention.k_proj.weight', 'transformer.h.27.ln_1.bias', 'transformer.h.28.attn.attention.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.29.attn.attention.out_proj.bias', 'transformer.h.26.attn.attention.out_proj.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.15.attn.attention.out_proj.weight', 'transformer.h.21.mlp.c_proj.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.26.attn.attention.masked_bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.20.ln_1.bias', 'transformer.h.18.ln_1.weight', 'transformer.h.22.ln_1.bias', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.1.attn.attention.masked_bias', 'transformer.h.19.ln_1.weight', 'transformer.h.23.attn.attention.bias', 'transformer.h.3.attn.attention.out_proj.weight', 'transformer.h.24.attn.attention.bias', 'transformer.h.28.mlp.c_fc.weight', 'transformer.h.12.ln_1.bias', 'transformer.h.15.ln_2.bias', 'transformer.h.8.attn.attention.masked_bias', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.25.ln_2.weight', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.14.mlp.c_fc.weight', 'transformer.h.19.attn.attention.bias', 'transformer.h.25.attn.attention.masked_bias', 'transformer.h.1.attn.attention.out_proj.weight', 'transformer.h.24.attn.attention.v_proj.weight', 'transformer.h.18.mlp.c_proj.bias', 'transformer.h.22.mlp.c_fc.bias', 'transformer.h.10.attn.attention.q_proj.weight', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.20.attn.attention.k_proj.weight', 'transformer.h.23.attn.attention.masked_bias', 'transformer.h.22.mlp.c_fc.weight', 'transformer.h.13.attn.attention.q_proj.weight', 'transformer.h.16.attn.attention.q_proj.weight', 'transformer.h.5.attn.attention.bias', 'transformer.h.4.attn.attention.k_proj.weight', 'transformer.h.19.attn.attention.out_proj.weight', 'transformer.h.1.ln_2.weight', 'transformer.h.25.attn.attention.v_proj.weight', 'transformer.h.10.ln_1.weight', 'transformer.h.9.attn.attention.k_proj.weight', 'transformer.h.4.attn.attention.out_proj.weight', 'transformer.h.26.ln_2.weight', 'transformer.h.30.ln_2.weight', 'transformer.h.21.attn.attention.out_proj.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.21.attn.attention.masked_bias', 'transformer.h.30.mlp.c_fc.bias', 'transformer.h.16.attn.attention.bias', 'transformer.h.13.attn.attention.out_proj.bias', 'transformer.h.10.attn.attention.out_proj.weight', 'transformer.h.7.attn.attention.q_proj.weight', 'transformer.h.22.attn.attention.out_proj.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.18.attn.attention.k_proj.weight', 'transformer.h.16.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.bias', 'transformer.h.9.attn.attention.masked_bias', 'transformer.h.27.mlp.c_proj.weight', 'transformer.h.12.ln_2.bias', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.21.mlp.c_fc.bias', 'transformer.h.23.mlp.c_fc.weight', 'transformer.h.16.ln_2.weight', 'transformer.h.10.attn.attention.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.17.attn.attention.masked_bias', 'transformer.h.22.attn.attention.v_proj.weight', 'transformer.h.23.attn.attention.out_proj.bias', 'transformer.h.23.attn.attention.v_proj.weight', 'transformer.h.8.attn.attention.out_proj.bias', 'lm_head.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.1.attn.attention.q_proj.weight', 'transformer.h.18.attn.attention.q_proj.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.27.attn.attention.bias', 'transformer.h.17.mlp.c_fc.bias', 'transformer.h.25.mlp.c_proj.bias', 'transformer.h.11.ln_1.weight', 'transformer.h.3.attn.attention.q_proj.weight', 'transformer.h.20.attn.attention.out_proj.weight', 'transformer.h.6.attn.attention.masked_bias', 'transformer.h.19.attn.attention.k_proj.weight', 'transformer.h.11.attn.attention.out_proj.bias', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.30.attn.attention.k_proj.weight', 'transformer.h.28.attn.attention.q_proj.weight', 'transformer.wpe.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.2.attn.attention.v_proj.weight', 'transformer.h.2.ln_1.weight', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.28.ln_2.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.12.mlp.c_fc.bias', 'transformer.h.24.ln_2.bias', 'transformer.h.5.attn.attention.v_proj.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.8.ln_1.weight', 'transformer.h.3.attn.attention.v_proj.weight', 'transformer.wte.weight', 'transformer.h.25.attn.attention.out_proj.bias', 'transformer.h.26.mlp.c_fc.weight', 'transformer.h.18.mlp.c_proj.weight', 'transformer.h.17.ln_1.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2022-11-18 16:16:55,225][datasets.builder][WARNING] - Using custom data configuration ViktorThink--mountain_combined_813306-6918b9ea07482433
[2022-11-18 16:16:55,322][datasets.builder][WARNING] - Found cached dataset csv (/home/paperspace/.cache/huggingface/datasets/ViktorThink___csv/ViktorThink--mountain_combined_813306-6918b9ea07482433/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
  0%|          | 0/2 [00:00<?, ?it/s] 50%|     | 1/2 [00:00<00:00,  5.29it/s]100%|| 2/2 [00:00<00:00,  9.96it/s]
Running tokenizer on dataset #0:   0%|          | 0/68 [00:00<?, ?ba/s]
Running tokenizer on dataset #1:   0%|          | 0/68 [00:00<?, ?ba/s][A

Running tokenizer on dataset #2:   0%|          | 0/68 [00:00<?, ?ba/s][A[ARunning tokenizer on dataset #0:   1%|         | 1/68 [00:02<02:56,  2.63s/ba]


Running tokenizer on dataset #3:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A



Running tokenizer on dataset #4:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A
Running tokenizer on dataset #1:   1%|         | 1/68 [00:02<03:11,  2.86s/ba][A




Running tokenizer on dataset #5:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[ARunning tokenizer on dataset #0:   3%|         | 2/68 [00:04<02:41,  2.44s/ba]





Running tokenizer on dataset #6:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A

Running tokenizer on dataset #2:   1%|         | 1/68 [00:03<04:02,  3.62s/ba][A[A


Running tokenizer on dataset #3:   1%|         | 1/68 [00:03<03:32,  3.17s/ba][A[A[A






Running tokenizer on dataset #7:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A[A
Running tokenizer on dataset #1:   3%|         | 2/68 [00:05<03:15,  2.96s/ba][A



Running tokenizer on dataset #4:   1%|         | 1/68 [00:03<03:42,  3.32s/ba][A[A[A[A







Running tokenizer on dataset #8:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:   4%|         | 3/68 [00:07<02:34,  2.38s/ba]




Running tokenizer on dataset #5:   1%|         | 1/68 [00:02<03:18,  2.97s/ba][A[A[A[A[A





Running tokenizer on dataset #6:   1%|         | 1/68 [00:02<03:02,  2.73s/ba][A[A[A[A[A[A


Running tokenizer on dataset #3:   3%|         | 2/68 [00:05<02:56,  2.67s/ba][A[A[A








Running tokenizer on dataset #9:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:   3%|         | 2/68 [00:06<03:37,  3.29s/ba][A[A
Running tokenizer on dataset #1:   4%|         | 3/68 [00:08<02:54,  2.69s/ba][A









Running tokenizer on dataset #10:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:   1%|         | 1/68 [00:02<03:13,  2.89s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:   6%|         | 4/68 [00:09<02:28,  2.32s/ba]







Running tokenizer on dataset #8:   1%|         | 1/68 [00:02<03:01,  2.71s/ba][A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:   3%|         | 2/68 [00:06<03:31,  3.21s/ba][A[A[A[A










Running tokenizer on dataset #11:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:   3%|         | 2/68 [00:05<02:44,  2.49s/ba][A[A[A[A[A[A




Running tokenizer on dataset #5:   3%|         | 2/68 [00:06<03:22,  3.07s/ba][A[A[A[A[A


Running tokenizer on dataset #3:   4%|         | 3/68 [00:07<02:42,  2.49s/ba][A[A[A

Running tokenizer on dataset #2:   4%|         | 3/68 [00:09<03:23,  3.12s/ba][A[A
Running tokenizer on dataset #1:   6%|         | 4/68 [00:11<02:54,  2.73s/ba][A






Running tokenizer on dataset #7:   3%|         | 2/68 [00:05<02:50,  2.58s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:   1%|         | 1/68 [00:03<04:00,  3.59s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:   7%|         | 5/68 [00:12<02:36,  2.48s/ba]







Running tokenizer on dataset #8:   3%|         | 2/68 [00:05<02:44,  2.49s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:   4%|         | 3/68 [00:07<02:33,  2.36s/ba][A[A[A[A[A[A


Running tokenizer on dataset #3:   6%|         | 4/68 [00:09<02:31,  2.37s/ba][A[A[A



Running tokenizer on dataset #4:   4%|         | 3/68 [00:09<03:19,  3.08s/ba][A[A[A[A









Running tokenizer on dataset #10:   1%|         | 1/68 [00:03<04:02,  3.62s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:   4%|         | 3/68 [00:09<03:15,  3.01s/ba][A[A[A[A[A










Running tokenizer on dataset #11:   1%|         | 1/68 [00:03<03:58,  3.55s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:   7%|         | 5/68 [00:13<02:39,  2.53s/ba][A






Running tokenizer on dataset #7:   4%|         | 3/68 [00:07<02:38,  2.43s/ba][A[A[A[A[A[A[A

Running tokenizer on dataset #2:   6%|         | 4/68 [00:12<03:14,  3.04s/ba][A[A


Running tokenizer on dataset #3:   7%|         | 5/68 [00:12<02:23,  2.28s/ba][A[A[ARunning tokenizer on dataset #0:   9%|         | 6/68 [00:14<02:39,  2.57s/ba]







Running tokenizer on dataset #8:   4%|         | 3/68 [00:07<02:50,  2.63s/ba][A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:   3%|         | 2/68 [00:06<03:36,  3.29s/ba][A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:   6%|         | 4/68 [00:09<02:34,  2.42s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:   6%|         | 4/68 [00:12<03:10,  2.97s/ba][A[A[A[A









Running tokenizer on dataset #10:   3%|         | 2/68 [00:06<03:37,  3.29s/ba][A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:   9%|         | 6/68 [00:15<02:26,  2.37s/ba][A






Running tokenizer on dataset #7:   6%|         | 4/68 [00:09<02:29,  2.33s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:   6%|         | 4/68 [00:12<03:11,  2.99s/ba][A[A[A[A[A










Running tokenizer on dataset #11:   3%|         | 2/68 [00:06<03:34,  3.25s/ba][A[A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:   9%|         | 6/68 [00:14<02:17,  2.21s/ba][A[A[A

Running tokenizer on dataset #2:   7%|         | 5/68 [00:15<03:05,  2.95s/ba][A[ARunning tokenizer on dataset #0:  10%|         | 7/68 [00:17<02:41,  2.64s/ba]







Running tokenizer on dataset #8:   6%|         | 4/68 [00:10<02:54,  2.73s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:   7%|         | 5/68 [00:12<02:42,  2.57s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:  10%|         | 7/68 [00:17<02:18,  2.27s/ba][A








Running tokenizer on dataset #9:   4%|         | 3/68 [00:09<03:27,  3.19s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:   7%|         | 5/68 [00:11<02:23,  2.28s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:   7%|         | 5/68 [00:14<03:03,  2.91s/ba][A[A[A[A









Running tokenizer on dataset #10:   4%|         | 3/68 [00:09<03:24,  3.14s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  10%|         | 7/68 [00:16<02:12,  2.18s/ba][A[A[A




Running tokenizer on dataset #5:   7%|         | 5/68 [00:14<03:04,  2.92s/ba][A[A[A[A[A










Running tokenizer on dataset #11:   4%|         | 3/68 [00:09<03:22,  3.11s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:   9%|         | 6/68 [00:18<02:59,  2.89s/ba][A[A
Running tokenizer on dataset #1:  12%|        | 8/68 [00:19<02:13,  2.22s/ba][A






Running tokenizer on dataset #7:   9%|         | 6/68 [00:13<02:17,  2.21s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  12%|        | 8/68 [00:20<02:40,  2.68s/ba]





Running tokenizer on dataset #6:   9%|         | 6/68 [00:15<02:43,  2.63s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:   7%|         | 5/68 [00:13<02:52,  2.74s/ba][A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:   6%|         | 4/68 [00:12<03:17,  3.08s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  12%|        | 8/68 [00:18<02:07,  2.13s/ba][A[A[A



Running tokenizer on dataset #4:   9%|         | 6/68 [00:17<02:57,  2.86s/ba][A[A[A[A









Running tokenizer on dataset #10:   6%|         | 4/68 [00:12<03:12,  3.01s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:   9%|         | 6/68 [00:17<02:59,  2.89s/ba][A[A[A[A[A
Running tokenizer on dataset #1:  13%|        | 9/68 [00:21<02:08,  2.18s/ba][A






Running tokenizer on dataset #7:  10%|         | 7/68 [00:16<02:13,  2.20s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  13%|        | 9/68 [00:22<02:28,  2.52s/ba]










Running tokenizer on dataset #11:   6%|         | 4/68 [00:12<03:13,  3.03s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  10%|         | 7/68 [00:20<02:54,  2.86s/ba][A[A


Running tokenizer on dataset #3:  13%|        | 9/68 [00:20<02:03,  2.09s/ba][A[A[A







Running tokenizer on dataset #8:   9%|         | 6/68 [00:16<02:49,  2.74s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  10%|         | 7/68 [00:18<02:47,  2.74s/ba][A[A[A[A[A[A








Running tokenizer on dataset #9:   7%|         | 5/68 [00:15<03:08,  2.99s/ba][A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  10%|         | 7/68 [00:20<02:53,  2.84s/ba][A[A[A[A
Running tokenizer on dataset #1:  15%|        | 10/68 [00:23<02:04,  2.15s/ba][A









Running tokenizer on dataset #10:   7%|         | 5/68 [00:15<03:05,  2.95s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  15%|        | 10/68 [00:24<02:16,  2.36s/ba]






Running tokenizer on dataset #7:  12%|        | 8/68 [00:18<02:10,  2.18s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  10%|         | 7/68 [00:20<02:54,  2.85s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  15%|        | 10/68 [00:22<01:59,  2.07s/ba][A[A[A










Running tokenizer on dataset #11:   7%|         | 5/68 [00:15<03:05,  2.94s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  12%|        | 8/68 [00:23<02:48,  2.81s/ba][A[A







Running tokenizer on dataset #8:  10%|         | 7/68 [00:19<02:49,  2.78s/ba][A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  16%|        | 11/68 [00:25<02:00,  2.11s/ba][A





Running tokenizer on dataset #6:  12%|        | 8/68 [00:21<02:43,  2.73s/ba][A[A[A[A[A[A








Running tokenizer on dataset #9:   9%|         | 6/68 [00:18<03:01,  2.93s/ba][A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  12%|        | 8/68 [00:23<02:47,  2.79s/ba][A[A[A[ARunning tokenizer on dataset #0:  16%|        | 11/68 [00:26<02:09,  2.28s/ba]






Running tokenizer on dataset #7:  13%|        | 9/68 [00:20<02:07,  2.16s/ba][A[A[A[A[A[A[A


Running tokenizer on dataset #3:  16%|        | 11/68 [00:24<01:56,  2.04s/ba][A[A[A









Running tokenizer on dataset #10:   9%|         | 6/68 [00:18<02:58,  2.87s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  12%|        | 8/68 [00:23<02:49,  2.83s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  13%|        | 9/68 [00:26<02:44,  2.78s/ba][A[A










Running tokenizer on dataset #11:   9%|         | 6/68 [00:18<02:59,  2.90s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  18%|        | 12/68 [00:27<01:57,  2.09s/ba][ARunning tokenizer on dataset #0:  18%|        | 12/68 [00:28<02:03,  2.20s/ba]







Running tokenizer on dataset #8:  12%|        | 8/68 [00:21<02:45,  2.75s/ba][A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  15%|        | 10/68 [00:22<02:03,  2.14s/ba][A[A[A[A[A[A[A


Running tokenizer on dataset #3:  18%|        | 12/68 [00:26<01:53,  2.03s/ba][A[A[A





Running tokenizer on dataset #6:  13%|        | 9/68 [00:23<02:41,  2.74s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  13%|        | 9/68 [00:25<02:43,  2.76s/ba][A[A[A[A








Running tokenizer on dataset #9:  10%|         | 7/68 [00:21<02:55,  2.88s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  10%|         | 7/68 [00:20<02:53,  2.85s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  13%|        | 9/68 [00:25<02:44,  2.79s/ba][A[A[A[A[A
Running tokenizer on dataset #1:  19%|        | 13/68 [00:29<01:54,  2.08s/ba][A

Running tokenizer on dataset #2:  15%|        | 10/68 [00:28<02:38,  2.73s/ba][A[ARunning tokenizer on dataset #0:  19%|        | 13/68 [00:30<01:58,  2.15s/ba]


Running tokenizer on dataset #3:  19%|        | 13/68 [00:28<01:51,  2.02s/ba][A[A[A










Running tokenizer on dataset #11:  10%|         | 7/68 [00:20<02:56,  2.89s/ba][A[A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  16%|        | 11/68 [00:24<02:06,  2.22s/ba][A[A[A[A[A[A[A







Running tokenizer on dataset #8:  13%|        | 9/68 [00:24<02:41,  2.74s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  15%|        | 10/68 [00:26<02:36,  2.70s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  15%|        | 10/68 [00:28<02:38,  2.73s/ba][A[A[A[A








Running tokenizer on dataset #9:  12%|        | 8/68 [00:23<02:49,  2.83s/ba][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  21%|        | 14/68 [00:31<01:51,  2.06s/ba][A









Running tokenizer on dataset #10:  12%|        | 8/68 [00:23<02:48,  2.82s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  21%|        | 14/68 [00:32<01:54,  2.12s/ba]




Running tokenizer on dataset #5:  15%|        | 10/68 [00:28<02:39,  2.74s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  21%|        | 14/68 [00:30<01:49,  2.02s/ba][A[A[A

Running tokenizer on dataset #2:  16%|        | 11/68 [00:31<02:34,  2.71s/ba][A[A





Running tokenizer on dataset #6:  16%|        | 11/68 [00:28<02:22,  2.50s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  18%|        | 12/68 [00:27<02:08,  2.29s/ba][A[A[A[A[A[A[A










Running tokenizer on dataset #11:  12%|        | 8/68 [00:23<02:50,  2.84s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  15%|        | 10/68 [00:27<02:37,  2.71s/ba][A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  22%|       | 15/68 [00:33<01:48,  2.05s/ba][A



Running tokenizer on dataset #4:  16%|        | 11/68 [00:31<02:35,  2.73s/ba][A[A[A[A








Running tokenizer on dataset #9:  13%|        | 9/68 [00:26<02:44,  2.79s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  22%|       | 15/68 [00:34<01:50,  2.09s/ba]


Running tokenizer on dataset #3:  22%|       | 15/68 [00:32<01:46,  2.02s/ba][A[A[A









Running tokenizer on dataset #10:  13%|        | 9/68 [00:26<02:44,  2.79s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  16%|        | 11/68 [00:31<02:36,  2.74s/ba][A[A[A[A[A





Running tokenizer on dataset #6:  18%|        | 12/68 [00:30<02:11,  2.34s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  19%|        | 13/68 [00:29<02:01,  2.21s/ba][A[A[A[A[A[A[A

Running tokenizer on dataset #2:  18%|        | 12/68 [00:34<02:32,  2.73s/ba][A[A
Running tokenizer on dataset #1:  24%|       | 16/68 [00:35<01:45,  2.02s/ba][A










Running tokenizer on dataset #11:  13%|        | 9/68 [00:26<02:46,  2.81s/ba][A[A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  24%|       | 16/68 [00:36<01:47,  2.06s/ba]







Running tokenizer on dataset #8:  16%|        | 11/68 [00:29<02:32,  2.68s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  24%|       | 16/68 [00:34<01:44,  2.01s/ba][A[A[A



Running tokenizer on dataset #4:  18%|        | 12/68 [00:34<02:32,  2.72s/ba][A[A[A[A








Running tokenizer on dataset #9:  15%|        | 10/68 [00:29<02:39,  2.75s/ba][A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  19%|        | 13/68 [00:32<02:03,  2.25s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  21%|        | 14/68 [00:31<01:56,  2.16s/ba][A[A[A[A[A[A[A









Running tokenizer on dataset #10:  15%|        | 10/68 [00:28<02:38,  2.74s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  18%|        | 12/68 [00:33<02:31,  2.71s/ba][A[A[A[A[A
Running tokenizer on dataset #1:  25%|       | 17/68 [00:37<01:42,  2.01s/ba][A

Running tokenizer on dataset #2:  19%|        | 13/68 [00:36<02:28,  2.69s/ba][A[ARunning tokenizer on dataset #0:  25%|       | 17/68 [00:38<01:43,  2.04s/ba]


Running tokenizer on dataset #3:  25%|       | 17/68 [00:36<01:42,  2.00s/ba][A[A[A










Running tokenizer on dataset #11:  15%|        | 10/68 [00:29<02:40,  2.77s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  18%|        | 12/68 [00:32<02:29,  2.66s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  21%|        | 14/68 [00:34<01:57,  2.18s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  22%|       | 15/68 [00:33<01:51,  2.11s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  19%|        | 13/68 [00:36<02:28,  2.71s/ba][A[A[A[A








Running tokenizer on dataset #9:  16%|        | 11/68 [00:31<02:35,  2.74s/ba][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  26%|       | 18/68 [00:39<01:39,  2.00s/ba][A









Running tokenizer on dataset #10:  16%|        | 11/68 [00:31<02:34,  2.71s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  26%|       | 18/68 [00:40<01:40,  2.02s/ba]




Running tokenizer on dataset #5:  19%|        | 13/68 [00:36<02:26,  2.67s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  26%|       | 18/68 [00:38<01:39,  1.99s/ba][A[A[A

Running tokenizer on dataset #2:  21%|        | 14/68 [00:39<02:23,  2.65s/ba][A[A





Running tokenizer on dataset #6:  22%|       | 15/68 [00:36<01:53,  2.15s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  24%|       | 16/68 [00:35<01:48,  2.09s/ba][A[A[A[A[A[A[A










Running tokenizer on dataset #11:  16%|        | 11/68 [00:31<02:36,  2.75s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  19%|        | 13/68 [00:34<02:25,  2.65s/ba][A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  28%|       | 19/68 [00:41<01:37,  1.99s/ba][A



Running tokenizer on dataset #4:  21%|        | 14/68 [00:39<02:24,  2.67s/ba][A[A[A[ARunning tokenizer on dataset #0:  28%|       | 19/68 [00:42<01:38,  2.00s/ba]








Running tokenizer on dataset #9:  18%|        | 12/68 [00:34<02:32,  2.73s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  28%|       | 19/68 [00:40<01:36,  1.98s/ba][A[A[A









Running tokenizer on dataset #10:  18%|        | 12/68 [00:34<02:31,  2.70s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  21%|        | 14/68 [00:39<02:23,  2.66s/ba][A[A[A[A[A





Running tokenizer on dataset #6:  24%|       | 16/68 [00:38<01:49,  2.10s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  25%|       | 17/68 [00:37<01:45,  2.06s/ba][A[A[A[A[A[A[A

Running tokenizer on dataset #2:  22%|       | 15/68 [00:42<02:19,  2.64s/ba][A[A
Running tokenizer on dataset #1:  29%|       | 20/68 [00:43<01:34,  1.98s/ba][A










Running tokenizer on dataset #11:  18%|        | 12/68 [00:34<02:32,  2.72s/ba][A[A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  29%|       | 20/68 [00:44<01:35,  2.00s/ba]







Running tokenizer on dataset #8:  21%|        | 14/68 [00:37<02:22,  2.65s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  29%|       | 20/68 [00:42<01:34,  1.97s/ba][A[A[A



Running tokenizer on dataset #4:  22%|       | 15/68 [00:41<02:20,  2.65s/ba][A[A[A[A








Running tokenizer on dataset #9:  19%|        | 13/68 [00:37<02:28,  2.70s/ba][A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  25%|       | 17/68 [00:40<01:44,  2.06s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  26%|       | 18/68 [00:39<01:42,  2.04s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  22%|       | 15/68 [00:41<02:20,  2.65s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  19%|        | 13/68 [00:36<02:28,  2.70s/ba][A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  31%|       | 21/68 [00:45<01:32,  1.97s/ba][A

Running tokenizer on dataset #2:  24%|       | 16/68 [00:44<02:16,  2.63s/ba][A[ARunning tokenizer on dataset #0:  31%|       | 21/68 [00:46<01:33,  2.00s/ba]


Running tokenizer on dataset #3:  31%|       | 21/68 [00:44<01:33,  1.99s/ba][A[A[A










Running tokenizer on dataset #11:  19%|        | 13/68 [00:37<02:29,  2.71s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  22%|       | 15/68 [00:40<02:19,  2.64s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  26%|       | 18/68 [00:42<01:44,  2.09s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  28%|       | 19/68 [00:41<01:39,  2.04s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  24%|       | 16/68 [00:44<02:17,  2.65s/ba][A[A[A[A
Running tokenizer on dataset #1:  32%|      | 22/68 [00:47<01:30,  1.97s/ba][A








Running tokenizer on dataset #9:  21%|        | 14/68 [00:39<02:25,  2.70s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  32%|      | 22/68 [00:48<01:31,  1.98s/ba]









Running tokenizer on dataset #10:  21%|        | 14/68 [00:39<02:25,  2.70s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  24%|       | 16/68 [00:44<02:20,  2.71s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  32%|      | 22/68 [00:46<01:31,  1.99s/ba][A[A[A

Running tokenizer on dataset #2:  25%|       | 17/68 [00:47<02:13,  2.62s/ba][A[A






Running tokenizer on dataset #7:  29%|       | 20/68 [00:43<01:36,  2.01s/ba][A[A[A[A[A[A[A







Running tokenizer on dataset #8:  24%|       | 16/68 [00:42<02:16,  2.62s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  21%|        | 14/68 [00:39<02:25,  2.70s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  34%|      | 23/68 [00:49<01:28,  1.96s/ba][A



Running tokenizer on dataset #4:  25%|       | 17/68 [00:47<02:13,  2.63s/ba][A[A[A[A





Running tokenizer on dataset #6:  28%|       | 19/68 [00:45<01:50,  2.25s/ba][A[A[A[A[A[ARunning tokenizer on dataset #0:  34%|      | 23/68 [00:50<01:28,  1.96s/ba]








Running tokenizer on dataset #9:  22%|       | 15/68 [00:42<02:22,  2.68s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  34%|      | 23/68 [00:48<01:28,  1.97s/ba][A[A[A









Running tokenizer on dataset #10:  22%|       | 15/68 [00:42<02:21,  2.67s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  25%|       | 17/68 [00:47<02:16,  2.68s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  31%|       | 21/68 [00:45<01:33,  2.00s/ba][A[A[A[A[A[A[A

Running tokenizer on dataset #2:  26%|       | 18/68 [00:50<02:12,  2.64s/ba][A[A
Running tokenizer on dataset #1:  35%|      | 24/68 [00:51<01:25,  1.95s/ba][ARunning tokenizer on dataset #0:  35%|      | 24/68 [00:52<01:26,  1.96s/ba]







Running tokenizer on dataset #8:  25%|       | 17/68 [00:45<02:13,  2.62s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  22%|       | 15/68 [00:42<02:23,  2.70s/ba][A[A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  35%|      | 24/68 [00:50<01:26,  1.96s/ba][A[A[A





Running tokenizer on dataset #6:  29%|       | 20/68 [00:47<01:52,  2.35s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  26%|       | 18/68 [00:49<02:11,  2.63s/ba][A[A[A[A








Running tokenizer on dataset #9:  24%|       | 16/68 [00:45<02:19,  2.68s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  32%|      | 22/68 [00:47<01:31,  2.00s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  37%|      | 25/68 [00:53<01:23,  1.95s/ba][A









Running tokenizer on dataset #10:  24%|       | 16/68 [00:44<02:18,  2.66s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  26%|       | 18/68 [00:49<02:12,  2.64s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  28%|       | 19/68 [00:52<02:08,  2.62s/ba][A[ARunning tokenizer on dataset #0:  37%|      | 25/68 [00:54<01:24,  1.96s/ba]


Running tokenizer on dataset #3:  37%|      | 25/68 [00:51<01:23,  1.94s/ba][A[A[A







Running tokenizer on dataset #8:  26%|       | 18/68 [00:48<02:10,  2.60s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  24%|       | 16/68 [00:45<02:18,  2.67s/ba][A[A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  31%|       | 21/68 [00:50<01:53,  2.42s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  28%|       | 19/68 [00:52<02:07,  2.61s/ba][A[A[A[A






Running tokenizer on dataset #7:  34%|      | 23/68 [00:49<01:28,  1.97s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  38%|      | 26/68 [00:55<01:21,  1.94s/ba][A








Running tokenizer on dataset #9:  25%|       | 17/68 [00:47<02:15,  2.66s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  38%|      | 26/68 [00:56<01:21,  1.95s/ba]









Running tokenizer on dataset #10:  25%|       | 17/68 [00:47<02:14,  2.63s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  38%|      | 26/68 [00:53<01:21,  1.95s/ba][A[A[A




Running tokenizer on dataset #5:  28%|       | 19/68 [00:52<02:08,  2.63s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  29%|       | 20/68 [00:55<02:05,  2.61s/ba][A[A






Running tokenizer on dataset #7:  35%|      | 24/68 [00:51<01:26,  1.96s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  40%|      | 27/68 [00:57<01:18,  1.93s/ba][A







Running tokenizer on dataset #8:  28%|       | 19/68 [00:50<02:07,  2.61s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  25%|       | 17/68 [00:47<02:15,  2.66s/ba][A[A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  32%|      | 22/68 [00:53<01:53,  2.47s/ba][A[A[A[A[A[ARunning tokenizer on dataset #0:  40%|      | 27/68 [00:58<01:19,  1.94s/ba]



Running tokenizer on dataset #4:  29%|       | 20/68 [00:54<02:05,  2.62s/ba][A[A[A[A


Running tokenizer on dataset #3:  40%|      | 27/68 [00:55<01:19,  1.94s/ba][A[A[A








Running tokenizer on dataset #9:  26%|       | 18/68 [00:50<02:13,  2.67s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  26%|       | 18/68 [00:50<02:10,  2.61s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  29%|       | 20/68 [00:54<02:06,  2.63s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  37%|      | 25/68 [00:53<01:23,  1.94s/ba][A[A[A[A[A[A[A

Running tokenizer on dataset #2:  31%|       | 21/68 [00:57<02:02,  2.60s/ba][A[A
Running tokenizer on dataset #1:  41%|      | 28/68 [00:59<01:16,  1.92s/ba][ARunning tokenizer on dataset #0:  41%|      | 28/68 [01:00<01:17,  1.94s/ba]







Running tokenizer on dataset #8:  29%|       | 20/68 [00:53<02:05,  2.60s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  41%|      | 28/68 [00:57<01:17,  1.93s/ba][A[A[A










Running tokenizer on dataset #11:  26%|       | 18/68 [00:50<02:13,  2.67s/ba][A[A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  34%|      | 23/68 [00:55<01:52,  2.50s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  31%|       | 21/68 [00:57<02:02,  2.60s/ba][A[A[A[A








Running tokenizer on dataset #9:  28%|       | 19/68 [00:53<02:10,  2.66s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  38%|      | 26/68 [00:55<01:21,  1.94s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  43%|     | 29/68 [01:01<01:15,  1.93s/ba][A









Running tokenizer on dataset #10:  28%|       | 19/68 [00:52<02:07,  2.61s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  31%|       | 21/68 [00:57<02:02,  2.60s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  32%|      | 22/68 [01:00<01:58,  2.57s/ba][A[ARunning tokenizer on dataset #0:  43%|     | 29/68 [01:02<01:16,  1.95s/ba]


Running tokenizer on dataset #3:  43%|     | 29/68 [00:59<01:18,  2.02s/ba][A[A[A





Running tokenizer on dataset #6:  35%|      | 24/68 [00:57<01:42,  2.33s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  31%|       | 21/68 [00:55<02:02,  2.60s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  28%|       | 19/68 [00:53<02:10,  2.66s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  32%|      | 22/68 [01:00<01:59,  2.60s/ba][A[A[A[A






Running tokenizer on dataset #7:  40%|      | 27/68 [00:57<01:20,  1.96s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  44%|     | 30/68 [01:02<01:13,  1.93s/ba][A








Running tokenizer on dataset #9:  29%|       | 20/68 [00:55<01:59,  2.50s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  44%|     | 30/68 [01:04<01:14,  1.95s/ba]




Running tokenizer on dataset #5:  32%|      | 22/68 [01:00<01:57,  2.56s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  29%|       | 20/68 [00:55<02:05,  2.62s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  34%|      | 23/68 [01:02<01:55,  2.57s/ba][A[A





Running tokenizer on dataset #6:  37%|      | 25/68 [00:59<01:35,  2.21s/ba][A[A[A[A[A[A


Running tokenizer on dataset #3:  44%|     | 30/68 [01:02<01:22,  2.18s/ba][A[A[A






Running tokenizer on dataset #7:  41%|      | 28/68 [00:58<01:18,  1.95s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  46%|     | 31/68 [01:04<01:11,  1.93s/ba][A







Running tokenizer on dataset #8:  32%|      | 22/68 [00:58<01:59,  2.59s/ba][A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  31%|       | 21/68 [00:57<01:49,  2.34s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  29%|       | 20/68 [00:55<02:06,  2.64s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  34%|      | 23/68 [01:02<01:55,  2.57s/ba][A[A[A[ARunning tokenizer on dataset #0:  46%|     | 31/68 [01:06<01:11,  1.94s/ba]





Running tokenizer on dataset #6:  38%|      | 26/68 [01:01<01:30,  2.15s/ba][A[A[A[A[A[A




Running tokenizer on dataset #5:  34%|      | 23/68 [01:02<01:55,  2.56s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  31%|       | 21/68 [00:57<02:01,  2.59s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  35%|      | 24/68 [01:05<01:53,  2.57s/ba][A[A






Running tokenizer on dataset #7:  43%|     | 29/68 [01:00<01:15,  1.95s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  47%|     | 32/68 [01:06<01:09,  1.92s/ba][A







Running tokenizer on dataset #8:  34%|      | 23/68 [01:00<01:48,  2.41s/ba][A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  32%|      | 22/68 [00:59<01:42,  2.24s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  46%|     | 31/68 [01:05<01:24,  2.29s/ba][A[A[ARunning tokenizer on dataset #0:  47%|     | 32/68 [01:08<01:10,  1.96s/ba]










Running tokenizer on dataset #11:  31%|       | 21/68 [00:58<02:03,  2.63s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  35%|      | 24/68 [01:05<01:52,  2.56s/ba][A[A[A[A





Running tokenizer on dataset #6:  40%|      | 27/68 [01:03<01:24,  2.07s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  44%|     | 30/68 [01:02<01:14,  1.95s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  35%|      | 24/68 [01:05<01:51,  2.54s/ba][A[A[A[A[A
Running tokenizer on dataset #1:  49%|     | 33/68 [01:08<01:08,  1.96s/ba][A









Running tokenizer on dataset #10:  32%|      | 22/68 [01:00<01:57,  2.56s/ba][A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  34%|      | 23/68 [01:01<01:36,  2.14s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  35%|      | 24/68 [01:02<01:41,  2.30s/ba][A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  37%|      | 25/68 [01:07<01:50,  2.56s/ba][A[ARunning tokenizer on dataset #0:  49%|     | 33/68 [01:10<01:08,  1.96s/ba]


Running tokenizer on dataset #3:  47%|     | 32/68 [01:07<01:25,  2.36s/ba][A[A[A





Running tokenizer on dataset #6:  41%|      | 28/68 [01:05<01:20,  2.02s/ba][A[A[A[A[A[A










Running tokenizer on dataset #11:  32%|      | 22/68 [01:00<02:01,  2.64s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  37%|      | 25/68 [01:07<01:50,  2.57s/ba][A[A[A[A






Running tokenizer on dataset #7:  46%|     | 31/68 [01:04<01:12,  1.96s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  35%|      | 24/68 [01:03<01:31,  2.07s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  37%|      | 25/68 [01:04<01:34,  2.19s/ba][A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  50%|     | 34/68 [01:11<01:11,  2.09s/ba][A




Running tokenizer on dataset #5:  37%|      | 25/68 [01:07<01:48,  2.53s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  50%|     | 34/68 [01:12<01:05,  1.94s/ba]









Running tokenizer on dataset #10:  34%|      | 23/68 [01:02<01:56,  2.60s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  38%|      | 26/68 [01:10<01:47,  2.55s/ba][A[A





Running tokenizer on dataset #6:  43%|     | 29/68 [01:07<01:17,  1.99s/ba][A[A[A[A[A[A


Running tokenizer on dataset #3:  49%|     | 33/68 [01:10<01:24,  2.41s/ba][A[A[A






Running tokenizer on dataset #7:  47%|     | 32/68 [01:06<01:09,  1.94s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  37%|      | 25/68 [01:04<01:26,  2.01s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  38%|      | 26/68 [01:06<01:29,  2.13s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  34%|      | 23/68 [01:03<01:57,  2.61s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  38%|      | 26/68 [01:10<01:49,  2.60s/ba][A[A[A[ARunning tokenizer on dataset #0:  51%|    | 35/68 [01:14<01:03,  1.93s/ba]





Running tokenizer on dataset #6:  44%|     | 30/68 [01:09<01:14,  1.96s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:  51%|    | 35/68 [01:13<01:13,  2.22s/ba][A




Running tokenizer on dataset #5:  38%|      | 26/68 [01:10<01:46,  2.53s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  35%|      | 24/68 [01:05<01:53,  2.58s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  40%|      | 27/68 [01:13<01:44,  2.56s/ba][A[A






Running tokenizer on dataset #7:  49%|     | 33/68 [01:08<01:07,  1.94s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  38%|      | 26/68 [01:06<01:23,  1.99s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  50%|     | 34/68 [01:12<01:23,  2.46s/ba][A[A[A







Running tokenizer on dataset #8:  40%|      | 27/68 [01:08<01:25,  2.10s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  53%|    | 36/68 [01:15<01:01,  1.91s/ba]





Running tokenizer on dataset #6:  46%|     | 31/68 [01:10<01:11,  1.93s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  40%|      | 27/68 [01:12<01:45,  2.58s/ba][A[A[A[A
Running tokenizer on dataset #1:  53%|    | 36/68 [01:16<01:13,  2.29s/ba][A




Running tokenizer on dataset #5:  40%|      | 27/68 [01:12<01:45,  2.56s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  50%|     | 34/68 [01:10<01:05,  1.93s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  40%|      | 27/68 [01:08<01:21,  1.98s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  37%|      | 25/68 [01:08<01:51,  2.59s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  41%|      | 28/68 [01:15<01:42,  2.55s/ba][A[A







Running tokenizer on dataset #8:  41%|      | 28/68 [01:10<01:22,  2.06s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  35%|      | 24/68 [01:07<02:11,  2.99s/ba][A[A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  54%|    | 37/68 [01:17<00:59,  1.93s/ba]


Running tokenizer on dataset #3:  51%|    | 35/68 [01:15<01:21,  2.47s/ba][A[A[A





Running tokenizer on dataset #6:  47%|     | 32/68 [01:12<01:09,  1.94s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  41%|      | 28/68 [01:15<01:42,  2.57s/ba][A[A[A[A






Running tokenizer on dataset #7:  51%|    | 35/68 [01:12<01:04,  1.95s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  41%|      | 28/68 [01:10<01:19,  1.98s/ba][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  54%|    | 37/68 [01:18<01:12,  2.35s/ba][A







Running tokenizer on dataset #8:  43%|     | 29/68 [01:12<01:19,  2.04s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  56%|    | 38/68 [01:19<00:57,  1.91s/ba]




Running tokenizer on dataset #5:  41%|      | 28/68 [01:15<01:42,  2.56s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  38%|      | 26/68 [01:10<01:47,  2.57s/ba][A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  49%|     | 33/68 [01:14<01:07,  1.92s/ba][A[A[A[A[A[A










Running tokenizer on dataset #11:  37%|      | 25/68 [01:09<02:03,  2.86s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  43%|     | 29/68 [01:18<01:40,  2.59s/ba][A[A


Running tokenizer on dataset #3:  53%|    | 36/68 [01:17<01:19,  2.49s/ba][A[A[A






Running tokenizer on dataset #7:  53%|    | 36/68 [01:14<01:02,  1.95s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  43%|     | 29/68 [01:12<01:17,  1.98s/ba][A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  43%|     | 29/68 [01:18<01:39,  2.56s/ba][A[A[A[A







Running tokenizer on dataset #8:  44%|     | 30/68 [01:14<01:16,  2.02s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  57%|    | 39/68 [01:21<00:56,  1.93s/ba]
Running tokenizer on dataset #1:  56%|    | 38/68 [01:21<01:12,  2.40s/ba][A





Running tokenizer on dataset #6:  50%|     | 34/68 [01:16<01:05,  1.93s/ba][A[A[A[A[A[A




Running tokenizer on dataset #5:  43%|     | 29/68 [01:17<01:38,  2.53s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  40%|      | 27/68 [01:13<01:44,  2.55s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  38%|      | 26/68 [01:12<01:56,  2.77s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  44%|     | 30/68 [01:20<01:38,  2.59s/ba][A[A






Running tokenizer on dataset #7:  54%|    | 37/68 [01:16<01:00,  1.94s/ba][A[A[A[A[A[A[A


Running tokenizer on dataset #3:  54%|    | 37/68 [01:20<01:17,  2.50s/ba][A[A[A








Running tokenizer on dataset #9:  44%|     | 30/68 [01:14<01:14,  1.97s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  46%|     | 31/68 [01:16<01:14,  2.00s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  59%|    | 40/68 [01:23<00:54,  1.93s/ba]





Running tokenizer on dataset #6:  51%|    | 35/68 [01:18<01:03,  1.92s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  44%|     | 30/68 [01:20<01:36,  2.55s/ba][A[A[A[A
Running tokenizer on dataset #1:  57%|    | 39/68 [01:23<01:10,  2.42s/ba][A




Running tokenizer on dataset #5:  44%|     | 30/68 [01:20<01:35,  2.52s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  56%|    | 38/68 [01:18<00:58,  1.95s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  46%|     | 31/68 [01:16<01:11,  1.94s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  41%|      | 28/68 [01:15<01:42,  2.57s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  40%|      | 27/68 [01:14<01:50,  2.69s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  46%|     | 31/68 [01:23<01:35,  2.57s/ba][A[A







Running tokenizer on dataset #8:  47%|     | 32/68 [01:18<01:10,  1.97s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  56%|    | 38/68 [01:22<01:14,  2.49s/ba][A[A[ARunning tokenizer on dataset #0:  60%|    | 41/68 [01:25<00:52,  1.94s/ba]





Running tokenizer on dataset #6:  53%|    | 36/68 [01:20<01:00,  1.90s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  46%|     | 31/68 [01:22<01:32,  2.51s/ba][A[A[A[A






Running tokenizer on dataset #7:  57%|    | 39/68 [01:20<00:55,  1.93s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  59%|    | 40/68 [01:26<01:08,  2.44s/ba][A








Running tokenizer on dataset #9:  47%|     | 32/68 [01:18<01:09,  1.93s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  46%|     | 31/68 [01:22<01:33,  2.53s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  49%|     | 33/68 [01:20<01:08,  1.95s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  62%|   | 42/68 [01:27<00:50,  1.94s/ba]









Running tokenizer on dataset #10:  43%|     | 29/68 [01:18<01:40,  2.56s/ba][A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  54%|    | 37/68 [01:22<00:58,  1.89s/ba][A[A[A[A[A[A










Running tokenizer on dataset #11:  41%|      | 28/68 [01:17<01:46,  2.65s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  47%|     | 32/68 [01:25<01:31,  2.55s/ba][A[A


Running tokenizer on dataset #3:  57%|    | 39/68 [01:25<01:11,  2.46s/ba][A[A[A








Running tokenizer on dataset #9:  49%|     | 33/68 [01:20<01:06,  1.91s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  59%|    | 40/68 [01:22<00:54,  1.94s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  47%|     | 32/68 [01:25<01:31,  2.54s/ba][A[A[A[A







Running tokenizer on dataset #8:  50%|     | 34/68 [01:22<01:06,  1.97s/ba][A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  60%|    | 41/68 [01:28<01:06,  2.46s/ba][ARunning tokenizer on dataset #0:  63%|   | 43/68 [01:29<00:48,  1.94s/ba]





Running tokenizer on dataset #6:  56%|    | 38/68 [01:24<00:56,  1.88s/ba][A[A[A[A[A[A




Running tokenizer on dataset #5:  47%|     | 32/68 [01:25<01:30,  2.53s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  44%|     | 30/68 [01:20<01:37,  2.56s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  43%|     | 29/68 [01:20<01:42,  2.62s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  49%|     | 33/68 [01:28<01:29,  2.55s/ba][A[A


Running tokenizer on dataset #3:  59%|    | 40/68 [01:27<01:09,  2.49s/ba][A[A[A








Running tokenizer on dataset #9:  50%|     | 34/68 [01:22<01:04,  1.91s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  60%|    | 41/68 [01:24<00:52,  1.94s/ba][A[A[A[A[A[A[A







Running tokenizer on dataset #8:  51%|    | 35/68 [01:24<01:04,  1.97s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  57%|    | 39/68 [01:26<00:54,  1.88s/ba][A[A[A[A[A[ARunning tokenizer on dataset #0:  65%|   | 44/68 [01:31<00:47,  1.96s/ba]



Running tokenizer on dataset #4:  49%|     | 33/68 [01:28<01:28,  2.54s/ba][A[A[A[A
Running tokenizer on dataset #1:  62%|   | 42/68 [01:31<01:03,  2.46s/ba][A




Running tokenizer on dataset #5:  49%|     | 33/68 [01:27<01:27,  2.50s/ba][A[A[A[A[A








Running tokenizer on dataset #9:  51%|    | 35/68 [01:24<01:02,  1.90s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  46%|     | 31/68 [01:23<01:34,  2.55s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  62%|   | 42/68 [01:26<00:50,  1.94s/ba][A[A[A[A[A[A[A

Running tokenizer on dataset #2:  50%|     | 34/68 [01:30<01:25,  2.53s/ba][A[A


Running tokenizer on dataset #3:  60%|    | 41/68 [01:30<01:07,  2.49s/ba][A[A[A










Running tokenizer on dataset #11:  44%|     | 30/68 [01:22<01:39,  2.63s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  53%|    | 36/68 [01:25<01:02,  1.96s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  59%|    | 40/68 [01:27<00:52,  1.88s/ba][A[A[A[A[A[ARunning tokenizer on dataset #0:  66%|   | 45/68 [01:33<00:44,  1.95s/ba]



Running tokenizer on dataset #4:  50%|     | 34/68 [01:30<01:26,  2.54s/ba][A[A[A[A
Running tokenizer on dataset #1:  63%|   | 43/68 [01:33<01:01,  2.46s/ba][A








Running tokenizer on dataset #9:  53%|    | 36/68 [01:26<01:00,  1.90s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  63%|   | 43/68 [01:28<00:48,  1.95s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  50%|     | 34/68 [01:30<01:25,  2.51s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  54%|    | 37/68 [01:27<01:00,  1.95s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  60%|    | 41/68 [01:29<00:50,  1.88s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  47%|     | 32/68 [01:25<01:31,  2.55s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  51%|    | 35/68 [01:33<01:22,  2.51s/ba][A[ARunning tokenizer on dataset #0:  68%|   | 46/68 [01:35<00:42,  1.95s/ba]


Running tokenizer on dataset #3:  62%|   | 42/68 [01:32<01:04,  2.49s/ba][A[A[A










Running tokenizer on dataset #11:  46%|     | 31/68 [01:25<01:36,  2.62s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  54%|    | 37/68 [01:27<00:58,  1.89s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  65%|   | 44/68 [01:30<00:46,  1.94s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  51%|    | 35/68 [01:33<01:23,  2.53s/ba][A[A[A[A
Running tokenizer on dataset #1:  65%|   | 44/68 [01:36<00:59,  2.48s/ba][A





Running tokenizer on dataset #6:  62%|   | 42/68 [01:31<00:48,  1.87s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  56%|    | 38/68 [01:29<00:58,  1.95s/ba][A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  51%|    | 35/68 [01:32<01:22,  2.50s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  69%|   | 47/68 [01:37<00:40,  1.93s/ba]









Running tokenizer on dataset #10:  49%|     | 33/68 [01:28<01:28,  2.52s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  53%|    | 36/68 [01:35<01:20,  2.50s/ba][A[A


Running tokenizer on dataset #3:  63%|   | 43/68 [01:35<01:02,  2.49s/ba][A[A[A










Running tokenizer on dataset #11:  47%|     | 32/68 [01:27<01:33,  2.59s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  56%|    | 38/68 [01:29<00:56,  1.88s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  66%|   | 45/68 [01:32<00:44,  1.94s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  63%|   | 43/68 [01:33<00:47,  1.88s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  57%|    | 39/68 [01:31<00:56,  1.94s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  71%|   | 48/68 [01:39<00:38,  1.91s/ba]



Running tokenizer on dataset #4:  53%|    | 36/68 [01:35<01:20,  2.52s/ba][A[A[A[A
Running tokenizer on dataset #1:  66%|   | 45/68 [01:38<00:56,  2.46s/ba][A




Running tokenizer on dataset #5:  53%|    | 36/68 [01:35<01:20,  2.51s/ba][A[A[A[A[A








Running tokenizer on dataset #9:  57%|    | 39/68 [01:31<00:54,  1.89s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  50%|     | 34/68 [01:30<01:26,  2.54s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  68%|   | 46/68 [01:33<00:42,  1.92s/ba][A[A[A[A[A[A[A


Running tokenizer on dataset #3:  65%|   | 44/68 [01:37<00:59,  2.49s/ba][A[A[A

Running tokenizer on dataset #2:  54%|    | 37/68 [01:38<01:18,  2.55s/ba][A[A










Running tokenizer on dataset #11:  49%|     | 33/68 [01:30<01:30,  2.58s/ba][A[A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  65%|   | 44/68 [01:35<00:45,  1.88s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  59%|    | 40/68 [01:33<00:53,  1.93s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  72%|  | 49/68 [01:41<00:36,  1.91s/ba]



Running tokenizer on dataset #4:  54%|    | 37/68 [01:38<01:18,  2.52s/ba][A[A[A[A
Running tokenizer on dataset #1:  68%|   | 46/68 [01:41<00:54,  2.47s/ba][A








Running tokenizer on dataset #9:  59%|    | 40/68 [01:33<00:52,  1.89s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  54%|    | 37/68 [01:37<01:18,  2.52s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  69%|   | 47/68 [01:35<00:40,  1.92s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  66%|   | 45/68 [01:37<00:43,  1.88s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  51%|    | 35/68 [01:33<01:23,  2.52s/ba][A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  60%|    | 41/68 [01:35<00:51,  1.92s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  74%|  | 50/68 [01:42<00:34,  1.91s/ba]


Running tokenizer on dataset #3:  66%|   | 45/68 [01:40<00:57,  2.48s/ba][A[A[A

Running tokenizer on dataset #2:  56%|    | 38/68 [01:41<01:16,  2.55s/ba][A[A










Running tokenizer on dataset #11:  50%|     | 34/68 [01:32<01:27,  2.56s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  60%|    | 41/68 [01:35<00:51,  1.90s/ba][A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  56%|    | 38/68 [01:40<01:15,  2.51s/ba][A[A[A[A






Running tokenizer on dataset #7:  71%|   | 48/68 [01:37<00:38,  1.91s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  69%|   | 47/68 [01:43<00:52,  2.48s/ba][A





Running tokenizer on dataset #6:  68%|   | 46/68 [01:39<00:41,  1.87s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  62%|   | 42/68 [01:37<00:49,  1.92s/ba][A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  56%|    | 38/68 [01:40<01:15,  2.52s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  75%|  | 51/68 [01:44<00:32,  1.91s/ba]









Running tokenizer on dataset #10:  53%|    | 36/68 [01:35<01:20,  2.53s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  68%|   | 46/68 [01:42<00:54,  2.49s/ba][A[A[A

Running tokenizer on dataset #2:  57%|    | 39/68 [01:43<01:13,  2.54s/ba][A[A








Running tokenizer on dataset #9:  62%|   | 42/68 [01:37<00:49,  1.90s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  51%|    | 35/68 [01:35<01:26,  2.62s/ba][A[A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  72%|  | 49/68 [01:39<00:36,  1.91s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  69%|   | 47/68 [01:41<00:39,  1.88s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  57%|    | 39/68 [01:43<01:11,  2.48s/ba][A[A[A[A







Running tokenizer on dataset #8:  63%|   | 43/68 [01:39<00:48,  1.94s/ba][A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  71%|   | 48/68 [01:45<00:49,  2.48s/ba][ARunning tokenizer on dataset #0:  76%|  | 52/68 [01:46<00:30,  1.93s/ba]




Running tokenizer on dataset #5:  57%|    | 39/68 [01:42<01:12,  2.50s/ba][A[A[A[A[A








Running tokenizer on dataset #9:  63%|   | 43/68 [01:39<00:47,  1.90s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  54%|    | 37/68 [01:38<01:18,  2.53s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  69%|   | 47/68 [01:45<00:52,  2.50s/ba][A[A[A

Running tokenizer on dataset #2:  59%|    | 40/68 [01:46<01:10,  2.51s/ba][A[A






Running tokenizer on dataset #7:  74%|  | 50/68 [01:41<00:34,  1.90s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  71%|   | 48/68 [01:42<00:37,  1.88s/ba][A[A[A[A[A[A










Running tokenizer on dataset #11:  53%|    | 36/68 [01:38<01:23,  2.61s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  65%|   | 44/68 [01:41<00:46,  1.93s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  78%|  | 53/68 [01:48<00:28,  1.92s/ba]
Running tokenizer on dataset #1:  72%|  | 49/68 [01:48<00:47,  2.48s/ba][A



Running tokenizer on dataset #4:  59%|    | 40/68 [01:45<01:10,  2.53s/ba][A[A[A[A








Running tokenizer on dataset #9:  65%|   | 44/68 [01:41<00:45,  1.89s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  59%|    | 40/68 [01:45<01:09,  2.48s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  75%|  | 51/68 [01:43<00:32,  1.89s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  72%|  | 49/68 [01:44<00:35,  1.89s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  56%|    | 38/68 [01:40<01:15,  2.50s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  71%|   | 48/68 [01:47<00:50,  2.50s/ba][A[A[A

Running tokenizer on dataset #2:  60%|    | 41/68 [01:48<01:07,  2.51s/ba][A[A







Running tokenizer on dataset #8:  66%|   | 45/68 [01:43<00:44,  1.93s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  79%|  | 54/68 [01:50<00:26,  1.92s/ba]










Running tokenizer on dataset #11:  54%|    | 37/68 [01:40<01:20,  2.60s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  66%|   | 45/68 [01:43<00:43,  1.89s/ba][A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  60%|    | 41/68 [01:48<01:07,  2.50s/ba][A[A[A[A
Running tokenizer on dataset #1:  74%|  | 50/68 [01:51<00:45,  2.51s/ba][A






Running tokenizer on dataset #7:  76%|  | 52/68 [01:45<00:30,  1.91s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  74%|  | 50/68 [01:46<00:33,  1.88s/ba][A[A[A[A[A[A




Running tokenizer on dataset #5:  60%|    | 41/68 [01:47<01:07,  2.49s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  68%|   | 46/68 [01:45<00:42,  1.93s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  81%|  | 55/68 [01:52<00:24,  1.92s/ba]









Running tokenizer on dataset #10:  57%|    | 39/68 [01:43<01:13,  2.52s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  72%|  | 49/68 [01:50<00:47,  2.51s/ba][A[A[A

Running tokenizer on dataset #2:  62%|   | 42/68 [01:51<01:05,  2.52s/ba][A[A










Running tokenizer on dataset #11:  56%|    | 38/68 [01:43<01:17,  2.58s/ba][A[A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  78%|  | 53/68 [01:47<00:28,  1.92s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  75%|  | 51/68 [01:48<00:31,  1.85s/ba][A[A[A[A[A[A








Running tokenizer on dataset #9:  68%|   | 46/68 [01:45<00:46,  2.10s/ba][A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  62%|   | 42/68 [01:50<01:04,  2.49s/ba][A[A[A[A
Running tokenizer on dataset #1:  75%|  | 51/68 [01:53<00:42,  2.47s/ba][A







Running tokenizer on dataset #8:  69%|   | 47/68 [01:47<00:40,  1.92s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  82%| | 56/68 [01:54<00:23,  1.92s/ba]




Running tokenizer on dataset #5:  62%|   | 42/68 [01:50<01:04,  2.49s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  63%|   | 43/68 [01:53<01:00,  2.42s/ba][A[A









Running tokenizer on dataset #10:  59%|    | 40/68 [01:46<01:10,  2.51s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  74%|  | 50/68 [01:52<00:45,  2.51s/ba][A[A[A






Running tokenizer on dataset #7:  79%|  | 54/68 [01:49<00:26,  1.91s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  76%|  | 52/68 [01:50<00:29,  1.85s/ba][A[A[A[A[A[A










Running tokenizer on dataset #11:  57%|    | 39/68 [01:45<01:14,  2.59s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  69%|   | 47/68 [01:47<00:44,  2.12s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  71%|   | 48/68 [01:49<00:38,  1.93s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  84%| | 57/68 [01:56<00:21,  1.94s/ba]
Running tokenizer on dataset #1:  76%|  | 52/68 [01:55<00:39,  2.45s/ba][A



Running tokenizer on dataset #4:  63%|   | 43/68 [01:53<01:02,  2.50s/ba][A[A[A[A




Running tokenizer on dataset #5:  63%|   | 43/68 [01:52<01:01,  2.47s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  65%|   | 44/68 [01:55<00:54,  2.27s/ba][A[A






Running tokenizer on dataset #7:  81%|  | 55/68 [01:51<00:24,  1.91s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  78%|  | 53/68 [01:52<00:27,  1.86s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  60%|    | 41/68 [01:48<01:08,  2.52s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  75%|  | 51/68 [01:55<00:42,  2.51s/ba][A[A[A








Running tokenizer on dataset #9:  71%|   | 48/68 [01:49<00:40,  2.04s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  72%|  | 49/68 [01:51<00:36,  1.93s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  85%| | 58/68 [01:58<00:19,  1.93s/ba]










Running tokenizer on dataset #11:  59%|    | 40/68 [01:48<01:12,  2.58s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  78%|  | 53/68 [01:58<00:36,  2.46s/ba][A

Running tokenizer on dataset #2:  66%|   | 45/68 [01:57<00:50,  2.18s/ba][A[A



Running tokenizer on dataset #4:  65%|   | 44/68 [01:55<01:00,  2.50s/ba][A[A[A[A





Running tokenizer on dataset #6:  79%|  | 54/68 [01:54<00:26,  1.86s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  82%| | 56/68 [01:52<00:22,  1.91s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  65%|   | 44/68 [01:55<00:58,  2.45s/ba][A[A[A[A[A








Running tokenizer on dataset #9:  72%|  | 49/68 [01:51<00:37,  1.98s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  74%|  | 50/68 [01:52<00:34,  1.92s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  87%| | 59/68 [02:00<00:17,  1.92s/ba]









Running tokenizer on dataset #10:  62%|   | 42/68 [01:51<01:05,  2.53s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  76%|  | 52/68 [01:57<00:39,  2.49s/ba][A[A[A

Running tokenizer on dataset #2:  68%|   | 46/68 [01:59<00:46,  2.09s/ba][A[A










Running tokenizer on dataset #11:  60%|    | 41/68 [01:51<01:08,  2.55s/ba][A[A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  81%|  | 55/68 [01:55<00:24,  1.86s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  84%| | 57/68 [01:54<00:21,  1.93s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  79%|  | 54/68 [02:00<00:34,  2.45s/ba][A



Running tokenizer on dataset #4:  66%|   | 45/68 [01:58<00:57,  2.48s/ba][A[A[A[A








Running tokenizer on dataset #9:  74%|  | 50/68 [01:53<00:35,  1.95s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  66%|   | 45/68 [01:57<00:56,  2.45s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  75%|  | 51/68 [01:54<00:32,  1.92s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  88%| | 60/68 [02:02<00:15,  1.91s/ba]


Running tokenizer on dataset #3:  78%|  | 53/68 [01:59<00:36,  2.46s/ba][A[A[A









Running tokenizer on dataset #10:  63%|   | 43/68 [01:53<01:03,  2.53s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  69%|   | 47/68 [02:01<00:43,  2.05s/ba][A[A





Running tokenizer on dataset #6:  82%| | 56/68 [01:57<00:22,  1.89s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  85%| | 58/68 [01:56<00:19,  1.93s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  75%|  | 51/68 [01:55<00:32,  1.92s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  62%|   | 42/68 [01:53<01:05,  2.53s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  81%|  | 55/68 [02:03<00:31,  2.45s/ba][A







Running tokenizer on dataset #8:  76%|  | 52/68 [01:56<00:30,  1.93s/ba][A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  68%|   | 46/68 [02:00<00:54,  2.47s/ba][A[A[A[ARunning tokenizer on dataset #0:  90%| | 61/68 [02:04<00:13,  1.91s/ba]




Running tokenizer on dataset #5:  68%|   | 46/68 [02:00<00:54,  2.47s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  71%|   | 48/68 [02:02<00:40,  2.01s/ba][A[A





Running tokenizer on dataset #6:  84%| | 57/68 [01:59<00:20,  1.89s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  87%| | 59/68 [01:58<00:17,  1.91s/ba][A[A[A[A[A[A[A


Running tokenizer on dataset #3:  79%|  | 54/68 [02:02<00:34,  2.45s/ba][A[A[A









Running tokenizer on dataset #10:  65%|   | 44/68 [01:56<00:59,  2.50s/ba][A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  76%|  | 52/68 [01:57<00:30,  1.91s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  78%|  | 53/68 [01:58<00:28,  1.91s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  91%| | 62/68 [02:05<00:11,  1.92s/ba]










Running tokenizer on dataset #11:  63%|   | 43/68 [01:55<01:02,  2.52s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  82%| | 56/68 [02:05<00:29,  2.45s/ba][A



Running tokenizer on dataset #4:  69%|   | 47/68 [02:02<00:51,  2.46s/ba][A[A[A[A

Running tokenizer on dataset #2:  72%|  | 49/68 [02:04<00:37,  1.97s/ba][A[A




Running tokenizer on dataset #5:  69%|   | 47/68 [02:02<00:51,  2.47s/ba][A[A[A[A[A





Running tokenizer on dataset #6:  85%| | 58/68 [02:01<00:18,  1.89s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  88%| | 60/68 [02:00<00:15,  1.90s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  78%|  | 53/68 [01:59<00:28,  1.93s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  81%|  | 55/68 [02:04<00:31,  2.46s/ba][A[A[A







Running tokenizer on dataset #8:  79%|  | 54/68 [02:00<00:26,  1.90s/ba][A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  66%|   | 45/68 [01:58<00:57,  2.50s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  93%|| 63/68 [02:08<00:09,  1.96s/ba]

Running tokenizer on dataset #2:  74%|  | 50/68 [02:06<00:35,  1.95s/ba][A[A










Running tokenizer on dataset #11:  65%|   | 44/68 [01:58<01:00,  2.51s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  84%| | 57/68 [02:08<00:26,  2.45s/ba][A



Running tokenizer on dataset #4:  71%|   | 48/68 [02:05<00:49,  2.45s/ba][A[A[A[A





Running tokenizer on dataset #6:  87%| | 59/68 [02:03<00:16,  1.88s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  90%| | 61/68 [02:02<00:13,  1.91s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  79%|  | 54/68 [02:00<00:26,  1.90s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  71%|   | 48/68 [02:04<00:49,  2.47s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  81%|  | 55/68 [02:02<00:24,  1.90s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  82%| | 56/68 [02:07<00:29,  2.46s/ba][A[A[A









Running tokenizer on dataset #10:  68%|   | 46/68 [02:01<00:54,  2.48s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  94%|| 64/68 [02:10<00:08,  2.10s/ba]

Running tokenizer on dataset #2:  75%|  | 51/68 [02:08<00:32,  1.93s/ba][A[A





Running tokenizer on dataset #6:  88%| | 60/68 [02:05<00:15,  1.88s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  91%| | 62/68 [02:04<00:11,  1.89s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  81%|  | 55/68 [02:02<00:24,  1.88s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  66%|   | 45/68 [02:00<00:57,  2.51s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  72%|  | 49/68 [02:07<00:46,  2.43s/ba][A[A[A[A
Running tokenizer on dataset #1:  85%| | 58/68 [02:10<00:24,  2.45s/ba][A







Running tokenizer on dataset #8:  82%| | 56/68 [02:04<00:22,  1.90s/ba][A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  72%|  | 49/68 [02:07<00:46,  2.45s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  76%|  | 52/68 [02:10<00:30,  1.92s/ba][A[A


Running tokenizer on dataset #3:  84%| | 57/68 [02:09<00:27,  2.46s/ba][A[A[A





Running tokenizer on dataset #6:  90%| | 61/68 [02:07<00:13,  1.89s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  69%|   | 47/68 [02:03<00:52,  2.48s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  93%|| 63/68 [02:06<00:09,  1.91s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  96%|| 65/68 [02:13<00:06,  2.24s/ba]








Running tokenizer on dataset #9:  82%| | 56/68 [02:04<00:22,  1.87s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  84%| | 57/68 [02:06<00:21,  1.92s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  68%|   | 46/68 [02:03<00:54,  2.48s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  87%| | 59/68 [02:13<00:22,  2.46s/ba][A



Running tokenizer on dataset #4:  74%|  | 50/68 [02:10<00:43,  2.44s/ba][A[A[A[A




Running tokenizer on dataset #5:  74%|  | 50/68 [02:09<00:42,  2.36s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  78%|  | 53/68 [02:12<00:28,  1.90s/ba][A[A





Running tokenizer on dataset #6:  91%| | 62/68 [02:09<00:11,  1.86s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  94%|| 64/68 [02:08<00:07,  1.91s/ba][A[A[A[A[A[A[A


Running tokenizer on dataset #3:  85%| | 58/68 [02:12<00:24,  2.47s/ba][A[A[A









Running tokenizer on dataset #10:  71%|   | 48/68 [02:06<00:49,  2.49s/ba][A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  85%| | 58/68 [02:08<00:19,  1.92s/ba][A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  84%| | 57/68 [02:07<00:22,  2.06s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  97%|| 66/68 [02:15<00:04,  2.32s/ba]




Running tokenizer on dataset #5:  75%|  | 51/68 [02:11<00:37,  2.21s/ba][A[A[A[A[A
Running tokenizer on dataset #1:  88%| | 60/68 [02:15<00:19,  2.43s/ba][A










Running tokenizer on dataset #11:  69%|   | 47/68 [02:05<00:52,  2.48s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  79%|  | 54/68 [02:14<00:26,  1.90s/ba][A[A



Running tokenizer on dataset #4:  75%|  | 51/68 [02:12<00:41,  2.46s/ba][A[A[A[A





Running tokenizer on dataset #6:  93%|| 63/68 [02:11<00:09,  1.86s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  96%|| 65/68 [02:10<00:05,  1.91s/ba][A[A[A[A[A[A[A







Running tokenizer on dataset #8:  87%| | 59/68 [02:10<00:17,  1.91s/ba][A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  76%|  | 52/68 [02:13<00:33,  2.11s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  87%| | 59/68 [02:14<00:22,  2.49s/ba][A[A[A









Running tokenizer on dataset #10:  72%|  | 49/68 [02:08<00:47,  2.49s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  99%|| 67/68 [02:17<00:02,  2.35s/ba]








Running tokenizer on dataset #9:  85%| | 58/68 [02:09<00:21,  2.18s/ba][A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  81%|  | 55/68 [02:16<00:24,  1.91s/ba][A[A





Running tokenizer on dataset #6:  94%|| 64/68 [02:12<00:07,  1.87s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  97%|| 66/68 [02:11<00:03,  1.89s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  90%| | 61/68 [02:17<00:17,  2.44s/ba][A










Running tokenizer on dataset #11:  71%|   | 48/68 [02:08<00:49,  2.49s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  76%|  | 52/68 [02:15<00:39,  2.46s/ba][A[A[A[A







Running tokenizer on dataset #8:  88%| | 60/68 [02:11<00:15,  1.90s/ba][A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  78%|  | 53/68 [02:15<00:30,  2.04s/ba][A[A[A[A[ARunning tokenizer on dataset #0: 100%|| 68/68 [02:19<00:00,  2.21s/ba]Running tokenizer on dataset #0: 100%|| 68/68 [02:19<00:00,  2.06s/ba]

Running tokenizer on dataset #2:  82%| | 56/68 [02:18<00:22,  1.91s/ba][A[A





Running tokenizer on dataset #6:  96%|| 65/68 [02:14<00:05,  1.86s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  74%|  | 50/68 [02:10<00:44,  2.48s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  88%| | 60/68 [02:17<00:20,  2.50s/ba][A[A[A






Running tokenizer on dataset #7:  99%|| 67/68 [02:13<00:01,  1.89s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  87%| | 59/68 [02:12<00:20,  2.27s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  72%|  | 49/68 [02:10<00:44,  2.37s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  91%| | 62/68 [02:20<00:14,  2.43s/ba][A







Running tokenizer on dataset #8:  90%| | 61/68 [02:13<00:13,  1.90s/ba][A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  78%|  | 53/68 [02:17<00:36,  2.46s/ba][A[A[A[A




Running tokenizer on dataset #5:  79%|  | 54/68 [02:17<00:27,  1.99s/ba][A[A[A[A[A






Running tokenizer on dataset #7: 100%|| 68/68 [02:15<00:00,  1.76s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #7: 100%|| 68/68 [02:15<00:00,  1.99s/ba]

Running tokenizer on dataset #2:  84%| | 57/68 [02:19<00:20,  1.91s/ba][A[A





Running tokenizer on dataset #6:  97%|| 66/68 [02:16<00:03,  1.94s/ba][A[A[A[A[A[A


Running tokenizer on dataset #3:  90%| | 61/68 [02:19<00:17,  2.48s/ba][A[A[A









Running tokenizer on dataset #10:  75%|  | 51/68 [02:13<00:41,  2.47s/ba][A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  88%| | 60/68 [02:14<00:18,  2.33s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  91%| | 62/68 [02:15<00:11,  1.93s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  74%|  | 50/68 [02:12<00:43,  2.41s/ba][A[A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  81%|  | 55/68 [02:18<00:25,  1.97s/ba][A[A[A[A[A
Running tokenizer on dataset #1:  93%|| 63/68 [02:22<00:12,  2.44s/ba][A



Running tokenizer on dataset #4:  79%|  | 54/68 [02:20<00:34,  2.46s/ba][A[A[A[A

Running tokenizer on dataset #2:  85%| | 58/68 [02:21<00:19,  1.91s/ba][A[A





Running tokenizer on dataset #6:  99%|| 67/68 [02:19<00:02,  2.09s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  93%|| 63/68 [02:17<00:09,  1.93s/ba][A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  76%|  | 52/68 [02:15<00:39,  2.46s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  91%| | 62/68 [02:22<00:14,  2.48s/ba][A[A[A




Running tokenizer on dataset #5:  82%| | 56/68 [02:20<00:23,  1.93s/ba][A[A[A[A[A








Running tokenizer on dataset #9:  90%| | 61/68 [02:17<00:16,  2.38s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  75%|  | 51/68 [02:15<00:40,  2.40s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  87%| | 59/68 [02:23<00:17,  1.91s/ba][A[A
Running tokenizer on dataset #1:  94%|| 64/68 [02:25<00:09,  2.43s/ba][A



Running tokenizer on dataset #4:  81%|  | 55/68 [02:22<00:31,  2.45s/ba][A[A[A[A





Running tokenizer on dataset #6: 100%|| 68/68 [02:21<00:00,  2.03s/ba][A[A[A[A[A[ARunning tokenizer on dataset #6: 100%|| 68/68 [02:21<00:00,  2.08s/ba]







Running tokenizer on dataset #8:  94%|| 64/68 [02:19<00:07,  1.90s/ba][A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  84%| | 57/68 [02:22<00:20,  1.91s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  93%|| 63/68 [02:24<00:12,  2.41s/ba][A[A[A









Running tokenizer on dataset #10:  78%|  | 53/68 [02:18<00:36,  2.47s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  88%| | 60/68 [02:25<00:15,  1.91s/ba][A[A








Running tokenizer on dataset #9:  91%| | 62/68 [02:19<00:14,  2.41s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  76%|  | 52/68 [02:17<00:38,  2.42s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  96%|| 65/68 [02:27<00:07,  2.42s/ba][A



Running tokenizer on dataset #4:  82%| | 56/68 [02:24<00:29,  2.44s/ba][A[A[A[A







Running tokenizer on dataset #8:  96%|| 65/68 [02:21<00:05,  1.90s/ba][A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  85%| | 58/68 [02:24<00:18,  1.88s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  94%|| 64/68 [02:26<00:09,  2.25s/ba][A[A[A

Running tokenizer on dataset #2:  90%| | 61/68 [02:27<00:13,  1.88s/ba][A[A









Running tokenizer on dataset #10:  79%|  | 54/68 [02:20<00:34,  2.46s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  78%|  | 53/68 [02:20<00:36,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  97%|| 66/68 [02:29<00:04,  2.42s/ba][A








Running tokenizer on dataset #9:  93%|| 63/68 [02:22<00:12,  2.51s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  97%|| 66/68 [02:23<00:03,  1.90s/ba][A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  87%| | 59/68 [02:26<00:16,  1.89s/ba][A[A[A[A[A



Running tokenizer on dataset #4:  84%| | 57/68 [02:27<00:27,  2.46s/ba][A[A[A[A


Running tokenizer on dataset #3:  96%|| 65/68 [02:28<00:06,  2.13s/ba][A[A[A

Running tokenizer on dataset #2:  91%| | 62/68 [02:29<00:11,  1.89s/ba][A[A









Running tokenizer on dataset #10:  81%|  | 55/68 [02:23<00:32,  2.47s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  88%| | 60/68 [02:28<00:14,  1.87s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  99%|| 67/68 [02:25<00:01,  1.91s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  97%|| 66/68 [02:30<00:04,  2.04s/ba][A[A[A
Running tokenizer on dataset #1:  99%|| 67/68 [02:32<00:02,  2.39s/ba][A










Running tokenizer on dataset #11:  79%|  | 54/68 [02:22<00:34,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  94%|| 64/68 [02:24<00:09,  2.50s/ba][A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  93%|| 63/68 [02:31<00:09,  1.89s/ba][A[A



Running tokenizer on dataset #4:  85%| | 58/68 [02:29<00:24,  2.47s/ba][A[A[A[A







Running tokenizer on dataset #8: 100%|| 68/68 [02:26<00:00,  1.77s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #8: 100%|| 68/68 [02:26<00:00,  2.16s/ba]




Running tokenizer on dataset #5:  90%| | 61/68 [02:30<00:13,  1.87s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  99%|| 67/68 [02:31<00:01,  1.99s/ba][A[A[A
Running tokenizer on dataset #1: 100%|| 68/68 [02:34<00:00,  2.24s/ba][ARunning tokenizer on dataset #1: 100%|| 68/68 [02:34<00:00,  2.27s/ba]









Running tokenizer on dataset #10:  82%| | 56/68 [02:25<00:29,  2.45s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  94%|| 64/68 [02:33<00:07,  1.87s/ba][A[A










Running tokenizer on dataset #11:  81%|  | 55/68 [02:25<00:32,  2.46s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  96%|| 65/68 [02:27<00:07,  2.49s/ba][A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  87%| | 59/68 [02:32<00:22,  2.47s/ba][A[A[A[A


Running tokenizer on dataset #3: 100%|| 68/68 [02:33<00:00,  1.82s/ba][A[A[ARunning tokenizer on dataset #3: 100%|| 68/68 [02:33<00:00,  2.26s/ba]




Running tokenizer on dataset #5:  91%| | 62/68 [02:31<00:11,  1.84s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  96%|| 65/68 [02:35<00:05,  1.87s/ba][A[A









Running tokenizer on dataset #10:  84%| | 57/68 [02:28<00:26,  2.45s/ba][A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  97%|| 66/68 [02:29<00:04,  2.45s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  93%|| 63/68 [02:33<00:09,  1.83s/ba][A[A[A[A[A










Running tokenizer on dataset #11:  82%| | 56/68 [02:27<00:29,  2.49s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  88%| | 60/68 [02:34<00:19,  2.48s/ba][A[A[A[A

Running tokenizer on dataset #2:  97%|| 66/68 [02:36<00:03,  1.86s/ba][A[A




Running tokenizer on dataset #5:  94%|| 64/68 [02:35<00:07,  1.82s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  85%| | 58/68 [02:30<00:24,  2.46s/ba][A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  99%|| 67/68 [02:31<00:02,  2.44s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  84%| | 57/68 [02:30<00:27,  2.47s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  99%|| 67/68 [02:38<00:01,  1.86s/ba][A[A



Running tokenizer on dataset #4:  90%| | 61/68 [02:37<00:17,  2.47s/ba][A[A[A[A




Running tokenizer on dataset #5:  96%|| 65/68 [02:37<00:05,  1.82s/ba][A[A[A[A[A

Running tokenizer on dataset #2: 100%|| 68/68 [02:40<00:00,  1.73s/ba][A[ARunning tokenizer on dataset #2: 100%|| 68/68 [02:40<00:00,  2.36s/ba]








Running tokenizer on dataset #9: 100%|| 68/68 [02:33<00:00,  2.27s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #9: 100%|| 68/68 [02:33<00:00,  2.26s/ba]









Running tokenizer on dataset #10:  87%| | 59/68 [02:33<00:22,  2.45s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  85%| | 58/68 [02:32<00:24,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  91%| | 62/68 [02:39<00:14,  2.45s/ba][A[A[A[A




Running tokenizer on dataset #5:  97%|| 66/68 [02:39<00:03,  1.83s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  88%| | 60/68 [02:35<00:19,  2.42s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  99%|| 67/68 [02:40<00:01,  1.83s/ba][A[A[A[A[A










Running tokenizer on dataset #11:  87%| | 59/68 [02:35<00:22,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  93%|| 63/68 [02:42<00:12,  2.44s/ba][A[A[A[A




Running tokenizer on dataset #5: 100%|| 68/68 [02:42<00:00,  1.70s/ba][A[A[A[A[ARunning tokenizer on dataset #5: 100%|| 68/68 [02:42<00:00,  2.39s/ba]









Running tokenizer on dataset #10:  90%| | 61/68 [02:37<00:17,  2.46s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  88%| | 60/68 [02:37<00:19,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  94%|| 64/68 [02:44<00:09,  2.44s/ba][A[A[A[A









Running tokenizer on dataset #10:  91%| | 62/68 [02:40<00:14,  2.46s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  90%| | 61/68 [02:39<00:17,  2.44s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  96%|| 65/68 [02:47<00:07,  2.43s/ba][A[A[A[A









Running tokenizer on dataset #10:  93%|| 63/68 [02:42<00:12,  2.48s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  91%| | 62/68 [02:42<00:14,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  97%|| 66/68 [02:49<00:04,  2.43s/ba][A[A[A[A









Running tokenizer on dataset #10:  94%|| 64/68 [02:45<00:09,  2.46s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  93%|| 63/68 [02:44<00:12,  2.46s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  99%|| 67/68 [02:51<00:02,  2.42s/ba][A[A[A[A









Running tokenizer on dataset #10:  96%|| 65/68 [02:47<00:07,  2.47s/ba][A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4: 100%|| 68/68 [02:53<00:00,  2.23s/ba][A[A[A[ARunning tokenizer on dataset #4: 100%|| 68/68 [02:53<00:00,  2.55s/ba]










Running tokenizer on dataset #11:  94%|| 64/68 [02:47<00:09,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  97%|| 66/68 [02:50<00:04,  2.44s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  96%|| 65/68 [02:49<00:07,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  99%|| 67/68 [02:52<00:02,  2.42s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  97%|| 66/68 [02:52<00:04,  2.42s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10: 100%|| 68/68 [02:54<00:00,  2.25s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #10: 100%|| 68/68 [02:54<00:00,  2.56s/ba]










Running tokenizer on dataset #11:  99%|| 67/68 [02:54<00:02,  2.42s/ba][A[A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11: 100%|| 68/68 [02:56<00:00,  2.25s/ba][A[A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #11: 100%|| 68/68 [02:56<00:00,  2.59s/ba]










Running tokenizer on dataset #0:   0%|          | 0/68 [00:00<?, ?ba/s]
Running tokenizer on dataset #1:   0%|          | 0/68 [00:00<?, ?ba/s][A

Running tokenizer on dataset #2:   0%|          | 0/68 [00:00<?, ?ba/s][A[ARunning tokenizer on dataset #0:   1%|         | 1/68 [00:02<02:57,  2.65s/ba]


Running tokenizer on dataset #3:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A



Running tokenizer on dataset #4:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A
Running tokenizer on dataset #1:   1%|         | 1/68 [00:02<03:00,  2.69s/ba][A

Running tokenizer on dataset #2:   1%|         | 1/68 [00:02<03:02,  2.73s/ba][A[A




Running tokenizer on dataset #5:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[ARunning tokenizer on dataset #0:   3%|         | 2/68 [00:04<02:41,  2.45s/ba]





Running tokenizer on dataset #6:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A
Running tokenizer on dataset #1:   3%|         | 2/68 [00:04<02:42,  2.45s/ba][A



Running tokenizer on dataset #4:   1%|         | 1/68 [00:02<03:01,  2.70s/ba][A[A[A[A


Running tokenizer on dataset #3:   1%|         | 1/68 [00:03<04:08,  3.70s/ba][A[A[A






Running tokenizer on dataset #7:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A[A

Running tokenizer on dataset #2:   3%|         | 2/68 [00:05<02:44,  2.49s/ba][A[ARunning tokenizer on dataset #0:   4%|         | 3/68 [00:07<02:34,  2.38s/ba]







Running tokenizer on dataset #8:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:   1%|         | 1/68 [00:02<02:59,  2.68s/ba][A[A[A[A[A








Running tokenizer on dataset #9:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:   4%|         | 3/68 [00:07<02:31,  2.33s/ba][A





Running tokenizer on dataset #6:   1%|         | 1/68 [00:02<03:07,  2.80s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:   3%|         | 2/68 [00:05<02:44,  2.49s/ba][A[A[A[A

Running tokenizer on dataset #2:   4%|         | 3/68 [00:07<02:33,  2.36s/ba][A[A









Running tokenizer on dataset #10:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:   6%|         | 4/68 [00:09<02:30,  2.36s/ba]


Running tokenizer on dataset #3:   3%|         | 2/68 [00:06<03:42,  3.38s/ba][A[A[A




Running tokenizer on dataset #5:   3%|         | 2/68 [00:05<02:44,  2.50s/ba][A[A[A[A[A







Running tokenizer on dataset #8:   1%|         | 1/68 [00:02<02:58,  2.67s/ba][A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:   1%|         | 1/68 [00:03<03:59,  3.57s/ba][A[A[A[A[A[A[A










Running tokenizer on dataset #11:   0%|          | 0/68 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:   3%|         | 2/68 [00:05<02:48,  2.55s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:   4%|         | 3/68 [00:07<02:32,  2.35s/ba][A[A[A[A








Running tokenizer on dataset #9:   1%|         | 1/68 [00:02<03:03,  2.74s/ba][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:   6%|         | 4/68 [00:09<02:40,  2.51s/ba][A

Running tokenizer on dataset #2:   6%|         | 4/68 [00:09<02:27,  2.30s/ba][A[ARunning tokenizer on dataset #0:   7%|         | 5/68 [00:11<02:24,  2.29s/ba]




Running tokenizer on dataset #5:   4%|         | 3/68 [00:07<02:33,  2.37s/ba][A[A[A[A[A







Running tokenizer on dataset #8:   3%|         | 2/68 [00:04<02:41,  2.45s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:   4%|         | 3/68 [00:07<02:36,  2.41s/ba][A[A[A[A[A[A


Running tokenizer on dataset #3:   4%|         | 3/68 [00:09<03:30,  3.24s/ba][A[A[A



Running tokenizer on dataset #4:   6%|         | 4/68 [00:09<02:25,  2.28s/ba][A[A[A[A









Running tokenizer on dataset #10:   1%|         | 1/68 [00:03<04:01,  3.61s/ba][A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:   7%|         | 5/68 [00:12<02:29,  2.38s/ba][A








Running tokenizer on dataset #9:   3%|         | 2/68 [00:05<02:45,  2.50s/ba][A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:   7%|         | 5/68 [00:11<02:20,  2.23s/ba][A[A






Running tokenizer on dataset #7:   3%|         | 2/68 [00:06<03:38,  3.31s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:   9%|         | 6/68 [00:13<02:18,  2.23s/ba]










Running tokenizer on dataset #11:   1%|         | 1/68 [00:03<04:01,  3.60s/ba][A[A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:   6%|         | 4/68 [00:09<02:28,  2.32s/ba][A[A[A[A[A







Running tokenizer on dataset #8:   4%|         | 3/68 [00:07<02:33,  2.37s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:   6%|         | 4/68 [00:09<02:29,  2.34s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:   9%|         | 6/68 [00:14<02:21,  2.28s/ba][A



Running tokenizer on dataset #4:   7%|         | 5/68 [00:11<02:20,  2.23s/ba][A[A[A[A

Running tokenizer on dataset #2:   9%|         | 6/68 [00:13<02:15,  2.19s/ba][A[A








Running tokenizer on dataset #9:   4%|         | 3/68 [00:07<02:37,  2.43s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:   6%|         | 4/68 [00:12<03:20,  3.13s/ba][A[A[ARunning tokenizer on dataset #0:  10%|         | 7/68 [00:15<02:14,  2.20s/ba]









Running tokenizer on dataset #10:   3%|         | 2/68 [00:06<03:33,  3.24s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:   4%|         | 3/68 [00:09<03:24,  3.15s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:   7%|         | 5/68 [00:11<02:21,  2.24s/ba][A[A[A[A[A







Running tokenizer on dataset #8:   6%|         | 4/68 [00:09<02:26,  2.28s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:   3%|         | 2/68 [00:06<03:35,  3.27s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  10%|         | 7/68 [00:16<02:14,  2.21s/ba][A



Running tokenizer on dataset #4:   9%|         | 6/68 [00:13<02:16,  2.19s/ba][A[A[A[A





Running tokenizer on dataset #6:   7%|         | 5/68 [00:11<02:24,  2.29s/ba][A[A[A[A[A[A

Running tokenizer on dataset #2:  10%|         | 7/68 [00:15<02:11,  2.16s/ba][A[A








Running tokenizer on dataset #9:   6%|         | 4/68 [00:09<02:30,  2.35s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  12%|        | 8/68 [00:18<02:10,  2.17s/ba]









Running tokenizer on dataset #10:   4%|         | 3/68 [00:08<03:02,  2.80s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:   9%|         | 6/68 [00:13<02:16,  2.19s/ba][A[A[A[A[A


Running tokenizer on dataset #3:   7%|         | 5/68 [00:15<03:12,  3.05s/ba][A[A[A







Running tokenizer on dataset #8:   7%|         | 5/68 [00:11<02:19,  2.21s/ba][A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:   6%|         | 4/68 [00:12<03:14,  3.04s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  12%|        | 8/68 [00:18<02:10,  2.18s/ba][A



Running tokenizer on dataset #4:  10%|         | 7/68 [00:15<02:13,  2.19s/ba][A[A[A[A





Running tokenizer on dataset #6:   9%|         | 6/68 [00:13<02:18,  2.23s/ba][A[A[A[A[A[A

Running tokenizer on dataset #2:  12%|        | 8/68 [00:17<02:07,  2.12s/ba][A[A










Running tokenizer on dataset #11:   4%|         | 3/68 [00:09<03:23,  3.12s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:   7%|         | 5/68 [00:11<02:24,  2.29s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  13%|        | 9/68 [00:20<02:05,  2.13s/ba]




Running tokenizer on dataset #5:  10%|         | 7/68 [00:15<02:11,  2.16s/ba][A[A[A[A[A









Running tokenizer on dataset #10:   6%|         | 4/68 [00:11<02:52,  2.69s/ba][A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:   9%|         | 6/68 [00:13<02:13,  2.16s/ba][A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  13%|        | 9/68 [00:20<02:06,  2.15s/ba][A






Running tokenizer on dataset #7:   7%|         | 5/68 [00:14<02:52,  2.73s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  12%|        | 8/68 [00:17<02:08,  2.14s/ba][A[A[A[A

Running tokenizer on dataset #2:  13%|        | 9/68 [00:19<02:03,  2.10s/ba][A[A


Running tokenizer on dataset #3:   9%|         | 6/68 [00:18<03:05,  2.99s/ba][A[A[A





Running tokenizer on dataset #6:  10%|         | 7/68 [00:16<02:16,  2.23s/ba][A[A[A[A[A[A








Running tokenizer on dataset #9:   9%|         | 6/68 [00:13<02:18,  2.23s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  15%|        | 10/68 [00:22<02:01,  2.10s/ba]




Running tokenizer on dataset #5:  12%|        | 8/68 [00:17<02:08,  2.14s/ba][A[A[A[A[A










Running tokenizer on dataset #11:   6%|         | 4/68 [00:12<03:13,  3.03s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  10%|         | 7/68 [00:15<02:11,  2.16s/ba][A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  15%|        | 10/68 [00:22<02:02,  2.12s/ba][A






Running tokenizer on dataset #7:   9%|         | 6/68 [00:16<02:36,  2.52s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  13%|        | 9/68 [00:19<02:05,  2.12s/ba][A[A[A[A

Running tokenizer on dataset #2:  15%|        | 10/68 [00:21<01:59,  2.07s/ba][A[A









Running tokenizer on dataset #10:   7%|         | 5/68 [00:14<02:53,  2.75s/ba][A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  12%|        | 8/68 [00:18<02:16,  2.28s/ba][A[A[A[A[A[ARunning tokenizer on dataset #0:  16%|        | 11/68 [00:24<01:59,  2.10s/ba]








Running tokenizer on dataset #9:  10%|         | 7/68 [00:16<02:14,  2.20s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  10%|         | 7/68 [00:21<03:00,  2.96s/ba][A[A[A




Running tokenizer on dataset #5:  13%|        | 9/68 [00:19<02:04,  2.11s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  12%|        | 8/68 [00:17<02:06,  2.11s/ba][A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  16%|        | 11/68 [00:24<01:58,  2.09s/ba][A

Running tokenizer on dataset #2:  16%|        | 11/68 [00:23<01:56,  2.04s/ba][A[A










Running tokenizer on dataset #11:   7%|         | 5/68 [00:15<03:05,  2.94s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  15%|        | 10/68 [00:22<02:01,  2.10s/ba][A[A[A[A






Running tokenizer on dataset #7:  10%|         | 7/68 [00:18<02:26,  2.40s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  18%|        | 12/68 [00:26<01:56,  2.08s/ba]








Running tokenizer on dataset #9:  12%|        | 8/68 [00:18<02:09,  2.16s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:   9%|         | 6/68 [00:16<02:50,  2.75s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  15%|        | 10/68 [00:21<01:59,  2.07s/ba][A[A[A[A[A





Running tokenizer on dataset #6:  13%|        | 9/68 [00:21<02:23,  2.43s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  13%|        | 9/68 [00:19<02:03,  2.09s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  12%|        | 8/68 [00:24<02:54,  2.91s/ba][A[A[A
Running tokenizer on dataset #1:  18%|        | 12/68 [00:26<01:55,  2.07s/ba][A

Running tokenizer on dataset #2:  18%|        | 12/68 [00:25<01:55,  2.06s/ba][A[A



Running tokenizer on dataset #4:  16%|        | 11/68 [00:24<01:59,  2.10s/ba][A[A[A[A






Running tokenizer on dataset #7:  12%|        | 8/68 [00:21<02:19,  2.33s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  19%|        | 13/68 [00:28<01:54,  2.08s/ba]








Running tokenizer on dataset #9:  13%|        | 9/68 [00:20<02:05,  2.13s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:   9%|         | 6/68 [00:18<02:59,  2.90s/ba][A[A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  16%|        | 11/68 [00:23<01:57,  2.07s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  15%|        | 10/68 [00:21<01:59,  2.06s/ba][A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  10%|         | 7/68 [00:19<02:49,  2.77s/ba][A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  19%|        | 13/68 [00:28<01:52,  2.05s/ba][A





Running tokenizer on dataset #6:  15%|        | 10/68 [00:24<02:25,  2.51s/ba][A[A[A[A[A[A

Running tokenizer on dataset #2:  19%|        | 13/68 [00:27<01:51,  2.03s/ba][A[A



Running tokenizer on dataset #4:  18%|        | 12/68 [00:26<01:56,  2.08s/ba][A[A[A[A






Running tokenizer on dataset #7:  13%|        | 9/68 [00:23<02:13,  2.26s/ba][A[A[A[A[A[A[A


Running tokenizer on dataset #3:  13%|        | 9/68 [00:27<02:48,  2.86s/ba][A[A[ARunning tokenizer on dataset #0:  21%|        | 14/68 [00:30<01:51,  2.07s/ba]








Running tokenizer on dataset #9:  15%|        | 10/68 [00:22<02:01,  2.10s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  18%|        | 12/68 [00:25<01:54,  2.04s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  16%|        | 11/68 [00:23<01:55,  2.02s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  10%|         | 7/68 [00:20<02:55,  2.88s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  21%|        | 14/68 [00:30<01:50,  2.04s/ba][A

Running tokenizer on dataset #2:  21%|        | 14/68 [00:29<01:47,  2.00s/ba][A[A



Running tokenizer on dataset #4:  19%|        | 13/68 [00:28<01:53,  2.07s/ba][A[A[A[A









Running tokenizer on dataset #10:  12%|        | 8/68 [00:22<02:45,  2.76s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  15%|        | 10/68 [00:25<02:07,  2.20s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  16%|        | 11/68 [00:26<02:26,  2.57s/ba][A[A[A[A[A[ARunning tokenizer on dataset #0:  22%|       | 15/68 [00:32<01:48,  2.05s/ba]








Running tokenizer on dataset #9:  16%|        | 11/68 [00:24<01:58,  2.09s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  19%|        | 13/68 [00:27<01:50,  2.01s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  15%|        | 10/68 [00:29<02:43,  2.82s/ba][A[A[A







Running tokenizer on dataset #8:  18%|        | 12/68 [00:25<01:52,  2.01s/ba][A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  22%|       | 15/68 [00:31<01:45,  1.98s/ba][A[A
Running tokenizer on dataset #1:  22%|       | 15/68 [00:32<01:47,  2.04s/ba][A



Running tokenizer on dataset #4:  21%|        | 14/68 [00:30<01:50,  2.04s/ba][A[A[A[A










Running tokenizer on dataset #11:  12%|        | 8/68 [00:23<02:50,  2.84s/ba][A[A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  16%|        | 11/68 [00:27<02:01,  2.14s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  24%|       | 16/68 [00:34<01:45,  2.04s/ba]








Running tokenizer on dataset #9:  18%|        | 12/68 [00:26<01:56,  2.07s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  21%|        | 14/68 [00:29<01:48,  2.01s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  13%|        | 9/68 [00:25<02:42,  2.76s/ba][A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  18%|        | 12/68 [00:29<02:24,  2.59s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  19%|        | 13/68 [00:27<01:49,  2.00s/ba][A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  24%|       | 16/68 [00:33<01:42,  1.97s/ba][A[A
Running tokenizer on dataset #1:  24%|       | 16/68 [00:34<01:44,  2.01s/ba][A


Running tokenizer on dataset #3:  16%|        | 11/68 [00:32<02:38,  2.79s/ba][A[A[A



Running tokenizer on dataset #4:  22%|       | 15/68 [00:32<01:47,  2.03s/ba][A[A[A[A






Running tokenizer on dataset #7:  18%|        | 12/68 [00:29<01:57,  2.10s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  25%|       | 17/68 [00:36<01:43,  2.02s/ba]








Running tokenizer on dataset #9:  19%|        | 13/68 [00:28<01:52,  2.05s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  22%|       | 15/68 [00:31<01:44,  1.98s/ba][A[A[A[A[A










Running tokenizer on dataset #11:  13%|        | 9/68 [00:26<02:45,  2.80s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  21%|        | 14/68 [00:29<01:47,  1.99s/ba][A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  15%|        | 10/68 [00:27<02:37,  2.71s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  25%|       | 17/68 [00:35<01:40,  1.97s/ba][A[A
Running tokenizer on dataset #1:  25%|       | 17/68 [00:36<01:42,  2.01s/ba][A





Running tokenizer on dataset #6:  19%|        | 13/68 [00:32<02:24,  2.62s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  24%|       | 16/68 [00:34<01:45,  2.02s/ba][A[A[A[A






Running tokenizer on dataset #7:  19%|        | 13/68 [00:31<01:54,  2.08s/ba][A[A[A[A[A[A[A


Running tokenizer on dataset #3:  18%|        | 12/68 [00:35<02:35,  2.77s/ba][A[A[ARunning tokenizer on dataset #0:  26%|       | 18/68 [00:38<01:40,  2.01s/ba]








Running tokenizer on dataset #9:  21%|        | 14/68 [00:30<01:50,  2.05s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  24%|       | 16/68 [00:33<01:45,  2.03s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  22%|       | 15/68 [00:31<01:45,  1.98s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  15%|        | 10/68 [00:29<02:39,  2.76s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  26%|       | 18/68 [00:38<01:39,  1.99s/ba][A



Running tokenizer on dataset #4:  25%|       | 17/68 [00:36<01:42,  2.01s/ba][A[A[A[A

Running tokenizer on dataset #2:  26%|       | 18/68 [00:38<01:44,  2.10s/ba][A[A









Running tokenizer on dataset #10:  16%|        | 11/68 [00:30<02:33,  2.70s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  21%|        | 14/68 [00:33<01:51,  2.07s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  21%|        | 14/68 [00:34<02:22,  2.63s/ba][A[A[A[A[A[ARunning tokenizer on dataset #0:  28%|       | 19/68 [00:40<01:38,  2.00s/ba]








Running tokenizer on dataset #9:  22%|       | 15/68 [00:32<01:48,  2.04s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  25%|       | 17/68 [00:35<01:42,  2.01s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  24%|       | 16/68 [00:33<01:42,  1.97s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  19%|        | 13/68 [00:38<02:31,  2.75s/ba][A[A[A
Running tokenizer on dataset #1:  28%|       | 19/68 [00:40<01:37,  1.99s/ba][A



Running tokenizer on dataset #4:  26%|       | 18/68 [00:38<01:40,  2.01s/ba][A[A[A[A










Running tokenizer on dataset #11:  16%|        | 11/68 [00:31<02:35,  2.73s/ba][A[A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  22%|       | 15/68 [00:35<01:48,  2.05s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  29%|       | 20/68 [00:42<01:35,  2.00s/ba]

Running tokenizer on dataset #2:  28%|       | 19/68 [00:40<01:49,  2.24s/ba][A[A








Running tokenizer on dataset #9:  24%|       | 16/68 [00:34<01:46,  2.04s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  18%|        | 12/68 [00:33<02:30,  2.69s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  26%|       | 18/68 [00:37<01:39,  1.99s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  25%|       | 17/68 [00:35<01:40,  1.97s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  22%|       | 15/68 [00:37<02:20,  2.66s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:  29%|       | 20/68 [00:42<01:34,  1.98s/ba][A



Running tokenizer on dataset #4:  28%|       | 19/68 [00:40<01:37,  2.00s/ba][A[A[A[A


Running tokenizer on dataset #3:  21%|        | 14/68 [00:40<02:28,  2.76s/ba][A[A[A






Running tokenizer on dataset #7:  24%|       | 16/68 [00:37<01:46,  2.04s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  31%|       | 21/68 [00:44<01:33,  1.99s/ba]








Running tokenizer on dataset #9:  25%|       | 17/68 [00:36<01:43,  2.03s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  28%|       | 19/68 [00:39<01:37,  1.98s/ba][A[A[A[A[A










Running tokenizer on dataset #11:  18%|        | 12/68 [00:34<02:31,  2.70s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  26%|       | 18/68 [00:37<01:38,  1.96s/ba][A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  29%|       | 20/68 [00:43<01:52,  2.34s/ba][A[A









Running tokenizer on dataset #10:  19%|        | 13/68 [00:35<02:27,  2.69s/ba][A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  31%|       | 21/68 [00:44<01:32,  1.98s/ba][A





Running tokenizer on dataset #6:  24%|       | 16/68 [00:40<02:17,  2.65s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  29%|       | 20/68 [00:42<01:36,  2.00s/ba][A[A[A[A






Running tokenizer on dataset #7:  25%|       | 17/68 [00:39<01:44,  2.04s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  32%|      | 22/68 [00:46<01:30,  1.98s/ba]


Running tokenizer on dataset #3:  22%|       | 15/68 [00:43<02:26,  2.76s/ba][A[A[A




Running tokenizer on dataset #5:  29%|       | 20/68 [00:41<01:35,  1.99s/ba][A[A[A[A[A








Running tokenizer on dataset #9:  26%|       | 18/68 [00:38<01:41,  2.04s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  28%|       | 19/68 [00:39<01:36,  1.97s/ba][A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  32%|      | 22/68 [00:46<01:30,  1.97s/ba][A










Running tokenizer on dataset #11:  19%|        | 13/68 [00:37<02:28,  2.69s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  31%|       | 21/68 [00:45<01:53,  2.41s/ba][A[A



Running tokenizer on dataset #4:  31%|       | 21/68 [00:44<01:36,  2.06s/ba][A[A[A[A









Running tokenizer on dataset #10:  21%|        | 14/68 [00:38<02:25,  2.70s/ba][A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  25%|       | 17/68 [00:42<02:14,  2.64s/ba][A[A[A[A[A[ARunning tokenizer on dataset #0:  34%|      | 23/68 [00:48<01:28,  1.97s/ba]






Running tokenizer on dataset #7:  26%|       | 18/68 [00:41<01:42,  2.04s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  31%|       | 21/68 [00:43<01:32,  1.97s/ba][A[A[A[A[A








Running tokenizer on dataset #9:  28%|       | 19/68 [00:40<01:39,  2.03s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  29%|       | 20/68 [00:41<01:34,  1.97s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  24%|       | 16/68 [00:46<02:22,  2.75s/ba][A[A[A
Running tokenizer on dataset #1:  34%|      | 23/68 [00:48<01:28,  1.96s/ba][A










Running tokenizer on dataset #11:  21%|        | 14/68 [00:39<02:24,  2.68s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  32%|      | 22/68 [00:48<01:52,  2.44s/ba][A[ARunning tokenizer on dataset #0:  35%|      | 24/68 [00:50<01:26,  1.97s/ba]






Running tokenizer on dataset #7:  28%|       | 19/68 [00:43<01:39,  2.03s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  32%|      | 22/68 [00:45<01:29,  1.94s/ba][A[A[A[A[A



Running tokenizer on dataset #4:  32%|      | 22/68 [00:46<01:42,  2.22s/ba][A[A[A[A








Running tokenizer on dataset #9:  29%|       | 20/68 [00:42<01:36,  2.02s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  31%|       | 21/68 [00:43<01:31,  1.96s/ba][A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  22%|       | 15/68 [00:41<02:21,  2.68s/ba][A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  26%|       | 18/68 [00:45<02:10,  2.61s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:  35%|      | 24/68 [00:50<01:25,  1.94s/ba][A


Running tokenizer on dataset #3:  25%|       | 17/68 [00:48<02:19,  2.73s/ba][A[A[ARunning tokenizer on dataset #0:  37%|      | 25/68 [00:52<01:24,  1.97s/ba]






Running tokenizer on dataset #7:  29%|       | 20/68 [00:45<01:36,  2.00s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  34%|      | 23/68 [00:47<01:26,  1.93s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  32%|      | 22/68 [00:45<01:29,  1.95s/ba][A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  34%|      | 23/68 [00:50<01:51,  2.48s/ba][A[A








Running tokenizer on dataset #9:  31%|       | 21/68 [00:44<01:34,  2.01s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  22%|       | 15/68 [00:42<02:21,  2.68s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  37%|      | 25/68 [00:52<01:23,  1.94s/ba][A



Running tokenizer on dataset #4:  34%|      | 23/68 [00:49<01:44,  2.32s/ba][A[A[A[A









Running tokenizer on dataset #10:  24%|       | 16/68 [00:43<02:18,  2.66s/ba][A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  28%|       | 19/68 [00:47<02:08,  2.62s/ba][A[A[A[A[A[ARunning tokenizer on dataset #0:  38%|      | 26/68 [00:54<01:22,  1.96s/ba]






Running tokenizer on dataset #7:  31%|       | 21/68 [00:47<01:34,  2.00s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  35%|      | 24/68 [00:49<01:24,  1.91s/ba][A[A[A[A[A







Running tokenizer on dataset #8:  34%|      | 23/68 [00:47<01:27,  1.94s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  26%|       | 18/68 [00:51<02:15,  2.71s/ba][A[A[A








Running tokenizer on dataset #9:  32%|      | 22/68 [00:46<01:32,  2.02s/ba][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  38%|      | 26/68 [00:54<01:21,  1.93s/ba][A

Running tokenizer on dataset #2:  35%|      | 24/68 [00:53<01:50,  2.51s/ba][A[A










Running tokenizer on dataset #11:  24%|       | 16/68 [00:44<02:17,  2.65s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  35%|      | 24/68 [00:52<01:45,  2.39s/ba][A[A[A[A









Running tokenizer on dataset #10:  25%|       | 17/68 [00:46<02:14,  2.63s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  40%|      | 27/68 [00:56<01:19,  1.95s/ba]





Running tokenizer on dataset #6:  29%|       | 20/68 [00:50<02:05,  2.62s/ba][A[A[A[A[A[A




Running tokenizer on dataset #5:  37%|      | 25/68 [00:51<01:21,  1.91s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  32%|      | 22/68 [00:49<01:32,  2.00s/ba][A[A[A[A[A[A[A







Running tokenizer on dataset #8:  35%|      | 24/68 [00:49<01:25,  1.95s/ba][A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  34%|      | 23/68 [00:48<01:29,  1.99s/ba][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  40%|      | 27/68 [00:55<01:18,  1.92s/ba][A


Running tokenizer on dataset #3:  28%|       | 19/68 [00:54<02:11,  2.69s/ba][A[A[A

Running tokenizer on dataset #2:  37%|      | 25/68 [00:55<01:47,  2.51s/ba][A[A










Running tokenizer on dataset #11:  25%|       | 17/68 [00:47<02:14,  2.63s/ba][A[A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  41%|      | 28/68 [00:58<01:18,  1.96s/ba]




Running tokenizer on dataset #5:  38%|      | 26/68 [00:53<01:20,  1.91s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  34%|      | 23/68 [00:51<01:28,  1.97s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  37%|      | 25/68 [00:54<01:45,  2.45s/ba][A[A[A[A







Running tokenizer on dataset #8:  37%|      | 25/68 [00:51<01:22,  1.93s/ba][A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  26%|       | 18/68 [00:49<02:11,  2.62s/ba][A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  35%|      | 24/68 [00:50<01:27,  1.98s/ba][A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  31%|       | 21/68 [00:53<02:02,  2.61s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:  41%|      | 28/68 [00:57<01:16,  1.92s/ba][A


Running tokenizer on dataset #3:  29%|       | 20/68 [00:56<02:09,  2.69s/ba][A[A[ARunning tokenizer on dataset #0:  43%|     | 29/68 [01:00<01:16,  1.97s/ba]




Running tokenizer on dataset #5:  40%|      | 27/68 [00:55<01:18,  1.92s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  35%|      | 24/68 [00:53<01:26,  1.97s/ba][A[A[A[A[A[A[A

Running tokenizer on dataset #2:  38%|      | 26/68 [00:58<01:45,  2.51s/ba][A[A







Running tokenizer on dataset #8:  38%|      | 26/68 [00:52<01:21,  1.93s/ba][A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  37%|      | 25/68 [00:52<01:23,  1.95s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  26%|       | 18/68 [00:50<02:11,  2.63s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  43%|     | 29/68 [00:59<01:15,  1.93s/ba][A



Running tokenizer on dataset #4:  38%|      | 26/68 [00:57<01:45,  2.51s/ba][A[A[A[A









Running tokenizer on dataset #10:  28%|       | 19/68 [00:51<02:08,  2.62s/ba][A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  32%|      | 22/68 [00:55<02:00,  2.61s/ba][A[A[A[A[A[A




Running tokenizer on dataset #5:  41%|      | 28/68 [00:57<01:16,  1.92s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  44%|     | 30/68 [01:01<01:14,  1.97s/ba]






Running tokenizer on dataset #7:  37%|      | 25/68 [00:55<01:23,  1.94s/ba][A[A[A[A[A[A[A







Running tokenizer on dataset #8:  40%|      | 27/68 [00:54<01:19,  1.93s/ba][A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  38%|      | 26/68 [00:54<01:22,  1.96s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  31%|       | 21/68 [00:59<02:06,  2.70s/ba][A[A[A
Running tokenizer on dataset #1:  44%|     | 30/68 [01:01<01:13,  1.92s/ba][A

Running tokenizer on dataset #2:  40%|      | 27/68 [01:01<01:43,  2.52s/ba][A[A










Running tokenizer on dataset #11:  28%|       | 19/68 [00:52<02:08,  2.62s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  40%|      | 27/68 [00:59<01:43,  2.52s/ba][A[A[A[A




Running tokenizer on dataset #5:  43%|     | 29/68 [00:58<01:13,  1.90s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  29%|       | 20/68 [00:54<02:06,  2.63s/ba][A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  34%|      | 23/68 [00:58<01:57,  2.61s/ba][A[A[A[A[A[ARunning tokenizer on dataset #0:  46%|     | 31/68 [01:03<01:12,  1.95s/ba]






Running tokenizer on dataset #7:  38%|      | 26/68 [00:57<01:21,  1.94s/ba][A[A[A[A[A[A[A







Running tokenizer on dataset #8:  41%|      | 28/68 [00:56<01:17,  1.93s/ba][A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  40%|      | 27/68 [00:56<01:20,  1.96s/ba][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  46%|     | 31/68 [01:03<01:11,  1.93s/ba][A

Running tokenizer on dataset #2:  41%|      | 28/68 [01:03<01:40,  2.52s/ba][A[A


Running tokenizer on dataset #3:  32%|      | 22/68 [01:02<02:03,  2.69s/ba][A[A[A




Running tokenizer on dataset #5:  44%|     | 30/68 [01:00<01:12,  1.89s/ba][A[A[A[A[A










Running tokenizer on dataset #11:  29%|       | 20/68 [00:55<02:05,  2.61s/ba][A[A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  47%|     | 32/68 [01:05<01:10,  1.97s/ba]






Running tokenizer on dataset #7:  40%|      | 27/68 [00:59<01:19,  1.95s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  41%|      | 28/68 [01:02<01:40,  2.52s/ba][A[A[A[A







Running tokenizer on dataset #8:  43%|     | 29/68 [00:58<01:14,  1.92s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  35%|      | 24/68 [01:00<01:50,  2.51s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  31%|       | 21/68 [00:56<02:02,  2.60s/ba][A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  41%|      | 28/68 [00:58<01:18,  1.97s/ba][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  47%|     | 32/68 [01:05<01:09,  1.92s/ba][A




Running tokenizer on dataset #5:  46%|     | 31/68 [01:02<01:10,  1.90s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  43%|     | 29/68 [01:05<01:37,  2.49s/ba][A[ARunning tokenizer on dataset #0:  49%|     | 33/68 [01:07<01:08,  1.95s/ba]






Running tokenizer on dataset #7:  41%|      | 28/68 [01:01<01:17,  1.95s/ba][A[A[A[A[A[A[A


Running tokenizer on dataset #3:  34%|      | 23/68 [01:04<02:00,  2.68s/ba][A[A[A







Running tokenizer on dataset #8:  44%|     | 30/68 [01:00<01:12,  1.92s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  37%|      | 25/68 [01:02<01:40,  2.33s/ba][A[A[A[A[A[A










Running tokenizer on dataset #11:  31%|       | 21/68 [00:57<02:02,  2.60s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  49%|     | 33/68 [01:07<01:07,  1.92s/ba][A



Running tokenizer on dataset #4:  43%|     | 29/68 [01:04<01:38,  2.52s/ba][A[A[A[A








Running tokenizer on dataset #9:  43%|     | 29/68 [01:00<01:18,  2.01s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  32%|      | 22/68 [00:59<01:58,  2.57s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  47%|     | 32/68 [01:04<01:08,  1.90s/ba][A[A[A[A[A

Running tokenizer on dataset #2:  44%|     | 30/68 [01:07<01:28,  2.32s/ba][A[ARunning tokenizer on dataset #0:  50%|     | 34/68 [01:09<01:05,  1.93s/ba]






Running tokenizer on dataset #7:  43%|     | 29/68 [01:03<01:17,  1.98s/ba][A[A[A[A[A[A[A







Running tokenizer on dataset #8:  46%|     | 31/68 [01:02<01:10,  1.92s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  38%|      | 26/68 [01:04<01:33,  2.24s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:  50%|     | 34/68 [01:09<01:04,  1.91s/ba][A


Running tokenizer on dataset #3:  35%|      | 24/68 [01:07<01:54,  2.61s/ba][A[A[A



Running tokenizer on dataset #4:  44%|     | 30/68 [01:07<01:32,  2.44s/ba][A[A[A[A










Running tokenizer on dataset #11:  32%|      | 22/68 [01:00<01:59,  2.61s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  44%|     | 30/68 [01:02<01:22,  2.17s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  49%|     | 33/68 [01:06<01:06,  1.89s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  34%|      | 23/68 [01:02<01:56,  2.60s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  51%|    | 35/68 [01:11<01:03,  1.92s/ba]







Running tokenizer on dataset #8:  47%|     | 32/68 [01:04<01:08,  1.90s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  40%|      | 27/68 [01:06<01:27,  2.14s/ba][A[A[A[A[A[A

Running tokenizer on dataset #2:  46%|     | 31/68 [01:10<01:26,  2.33s/ba][A[A
Running tokenizer on dataset #1:  51%|    | 35/68 [01:11<01:03,  1.91s/ba][A


Running tokenizer on dataset #3:  37%|      | 25/68 [01:09<01:44,  2.42s/ba][A[A[A






Running tokenizer on dataset #7:  44%|     | 30/68 [01:05<01:22,  2.16s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  46%|     | 31/68 [01:09<01:26,  2.33s/ba][A[A[A[A




Running tokenizer on dataset #5:  50%|     | 34/68 [01:08<01:04,  1.89s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  53%|    | 36/68 [01:13<01:00,  1.91s/ba]










Running tokenizer on dataset #11:  34%|      | 23/68 [01:03<01:56,  2.59s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  46%|     | 31/68 [01:05<01:23,  2.27s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  49%|     | 33/68 [01:06<01:06,  1.89s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  41%|      | 28/68 [01:08<01:23,  2.08s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  35%|      | 24/68 [01:04<01:53,  2.58s/ba][A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  53%|    | 36/68 [01:13<01:00,  1.91s/ba][A


Running tokenizer on dataset #3:  38%|      | 26/68 [01:11<01:37,  2.31s/ba][A[A[A

Running tokenizer on dataset #2:  47%|     | 32/68 [01:12<01:25,  2.38s/ba][A[A






Running tokenizer on dataset #7:  46%|     | 31/68 [01:08<01:22,  2.22s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  51%|    | 35/68 [01:10<01:02,  1.89s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  54%|    | 37/68 [01:15<00:59,  1.90s/ba]



Running tokenizer on dataset #4:  47%|     | 32/68 [01:11<01:26,  2.40s/ba][A[A[A[A







Running tokenizer on dataset #8:  50%|     | 34/68 [01:08<01:05,  1.92s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  43%|     | 29/68 [01:10<01:19,  2.04s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:  54%|    | 37/68 [01:15<00:59,  1.91s/ba][A








Running tokenizer on dataset #9:  47%|     | 32/68 [01:07<01:24,  2.35s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  40%|      | 27/68 [01:13<01:31,  2.22s/ba][A[A[A









Running tokenizer on dataset #10:  37%|      | 25/68 [01:07<01:51,  2.58s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  47%|     | 32/68 [01:09<01:16,  2.13s/ba][A[A[A[A[A[A[A

Running tokenizer on dataset #2:  49%|     | 33/68 [01:15<01:24,  2.42s/ba][A[A




Running tokenizer on dataset #5:  53%|    | 36/68 [01:12<01:01,  1.91s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  56%|    | 38/68 [01:17<00:56,  1.89s/ba]










Running tokenizer on dataset #11:  35%|      | 24/68 [01:06<02:10,  2.96s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  51%|    | 35/68 [01:10<01:03,  1.92s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  44%|     | 30/68 [01:12<01:16,  2.00s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  49%|     | 33/68 [01:14<01:25,  2.45s/ba][A[A[A[A
Running tokenizer on dataset #1:  56%|    | 38/68 [01:16<00:57,  1.91s/ba][A


Running tokenizer on dataset #3:  41%|      | 28/68 [01:15<01:25,  2.15s/ba][A[A[A








Running tokenizer on dataset #9:  49%|     | 33/68 [01:10<01:23,  2.40s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  49%|     | 33/68 [01:11<01:12,  2.06s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  54%|    | 37/68 [01:14<00:59,  1.91s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  38%|      | 26/68 [01:09<01:47,  2.56s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  57%|    | 39/68 [01:19<00:55,  1.91s/ba]







Running tokenizer on dataset #8:  53%|    | 36/68 [01:12<01:01,  1.91s/ba][A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  50%|     | 34/68 [01:17<01:22,  2.44s/ba][A[A





Running tokenizer on dataset #6:  46%|     | 31/68 [01:14<01:12,  1.97s/ba][A[A[A[A[A[A










Running tokenizer on dataset #11:  37%|      | 25/68 [01:09<02:01,  2.83s/ba][A[A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  57%|    | 39/68 [01:18<00:55,  1.90s/ba][A


Running tokenizer on dataset #3:  43%|     | 29/68 [01:17<01:21,  2.09s/ba][A[A[A



Running tokenizer on dataset #4:  50%|     | 34/68 [01:16<01:23,  2.47s/ba][A[A[A[A






Running tokenizer on dataset #7:  50%|     | 34/68 [01:13<01:09,  2.03s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  56%|    | 38/68 [01:16<00:57,  1.92s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  59%|    | 40/68 [01:21<00:53,  1.91s/ba]








Running tokenizer on dataset #9:  50%|     | 34/68 [01:12<01:23,  2.44s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  54%|    | 37/68 [01:13<00:59,  1.91s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  47%|     | 32/68 [01:16<01:11,  1.97s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  40%|      | 27/68 [01:12<01:44,  2.55s/ba][A[A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  59%|    | 40/68 [01:20<00:53,  1.91s/ba][A

Running tokenizer on dataset #2:  51%|    | 35/68 [01:20<01:20,  2.45s/ba][A[A










Running tokenizer on dataset #11:  38%|      | 26/68 [01:11<01:53,  2.70s/ba][A[A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  44%|     | 30/68 [01:19<01:18,  2.07s/ba][A[A[A






Running tokenizer on dataset #7:  51%|    | 35/68 [01:15<01:06,  2.03s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  57%|    | 39/68 [01:17<00:55,  1.90s/ba][A[A[A[A[A



Running tokenizer on dataset #4:  51%|    | 35/68 [01:19<01:21,  2.48s/ba][A[A[A[ARunning tokenizer on dataset #0:  60%|    | 41/68 [01:23<00:51,  1.92s/ba]







Running tokenizer on dataset #8:  56%|    | 38/68 [01:15<00:57,  1.91s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  49%|     | 33/68 [01:17<01:08,  1.95s/ba][A[A[A[A[A[A








Running tokenizer on dataset #9:  51%|    | 35/68 [01:15<01:21,  2.46s/ba][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  60%|    | 41/68 [01:22<00:51,  1.92s/ba][A










Running tokenizer on dataset #11:  40%|      | 27/68 [01:13<01:40,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  41%|      | 28/68 [01:14<01:42,  2.57s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  46%|     | 31/68 [01:21<01:15,  2.04s/ba][A[A[A

Running tokenizer on dataset #2:  53%|    | 36/68 [01:22<01:18,  2.45s/ba][A[A






Running tokenizer on dataset #7:  53%|    | 36/68 [01:17<01:03,  1.99s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  59%|    | 40/68 [01:19<00:52,  1.89s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  62%|   | 42/68 [01:24<00:49,  1.92s/ba]







Running tokenizer on dataset #8:  57%|    | 39/68 [01:17<00:55,  1.90s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  50%|     | 34/68 [01:19<01:06,  1.95s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  53%|    | 36/68 [01:21<01:19,  2.49s/ba][A[A[A[A
Running tokenizer on dataset #1:  62%|   | 42/68 [01:24<00:49,  1.91s/ba][A










Running tokenizer on dataset #11:  41%|      | 28/68 [01:15<01:31,  2.30s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  53%|    | 36/68 [01:18<01:19,  2.48s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  47%|     | 32/68 [01:23<01:12,  2.02s/ba][A[A[A




Running tokenizer on dataset #5:  60%|    | 41/68 [01:21<00:51,  1.90s/ba][A[A[A[A[A









Running tokenizer on dataset #10:  43%|     | 29/68 [01:17<01:39,  2.56s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  63%|   | 43/68 [01:26<00:47,  1.91s/ba]






Running tokenizer on dataset #7:  54%|    | 37/68 [01:20<01:06,  2.14s/ba][A[A[A[A[A[A[A







Running tokenizer on dataset #8:  59%|    | 40/68 [01:19<00:52,  1.89s/ba][A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  54%|    | 37/68 [01:25<01:17,  2.50s/ba][A[A





Running tokenizer on dataset #6:  51%|    | 35/68 [01:21<01:03,  1.93s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:  63%|   | 43/68 [01:26<00:47,  1.90s/ba][A










Running tokenizer on dataset #11:  43%|     | 29/68 [01:17<01:25,  2.18s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  54%|    | 37/68 [01:24<01:17,  2.49s/ba][A[A[A[A


Running tokenizer on dataset #3:  49%|     | 33/68 [01:25<01:10,  2.00s/ba][A[A[A




Running tokenizer on dataset #5:  62%|   | 42/68 [01:23<00:49,  1.89s/ba][A[A[A[A[A








Running tokenizer on dataset #9:  54%|    | 37/68 [01:20<01:16,  2.48s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  65%|   | 44/68 [01:28<00:46,  1.92s/ba]







Running tokenizer on dataset #8:  60%|    | 41/68 [01:21<00:51,  1.89s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  53%|    | 36/68 [01:23<01:01,  1.91s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  44%|     | 30/68 [01:19<01:36,  2.55s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  56%|    | 38/68 [01:27<01:13,  2.44s/ba][A[A
Running tokenizer on dataset #1:  65%|   | 44/68 [01:28<00:45,  1.91s/ba][A






Running tokenizer on dataset #7:  56%|    | 38/68 [01:22<01:08,  2.27s/ba][A[A[A[A[A[A[A










Running tokenizer on dataset #11:  44%|     | 30/68 [01:19<01:20,  2.11s/ba][A[A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  63%|   | 43/68 [01:25<00:47,  1.88s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  50%|     | 34/68 [01:27<01:08,  2.01s/ba][A[A[A



Running tokenizer on dataset #4:  56%|    | 38/68 [01:26<01:14,  2.49s/ba][A[A[A[ARunning tokenizer on dataset #0:  66%|   | 45/68 [01:30<00:43,  1.91s/ba]







Running tokenizer on dataset #8:  62%|   | 42/68 [01:23<00:49,  1.89s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  54%|    | 37/68 [01:25<00:59,  1.91s/ba][A[A[A[A[A[A








Running tokenizer on dataset #9:  56%|    | 38/68 [01:22<01:14,  2.48s/ba][A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  57%|    | 39/68 [01:29<01:06,  2.28s/ba][A[A
Running tokenizer on dataset #1:  66%|   | 45/68 [01:30<00:43,  1.90s/ba][A






Running tokenizer on dataset #7:  57%|    | 39/68 [01:24<01:02,  2.15s/ba][A[A[A[A[A[A[A










Running tokenizer on dataset #11:  46%|     | 31/68 [01:21<01:16,  2.07s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  46%|     | 31/68 [01:22<01:34,  2.55s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  65%|   | 44/68 [01:27<00:44,  1.87s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  51%|    | 35/68 [01:29<01:05,  1.98s/ba][A[A[ARunning tokenizer on dataset #0:  68%|   | 46/68 [01:32<00:41,  1.89s/ba]







Running tokenizer on dataset #8:  63%|   | 43/68 [01:25<00:47,  1.92s/ba][A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  57%|    | 39/68 [01:29<01:11,  2.47s/ba][A[A[A[A





Running tokenizer on dataset #6:  56%|    | 38/68 [01:27<00:56,  1.90s/ba][A[A[A[A[A[A

Running tokenizer on dataset #2:  59%|    | 40/68 [01:31<01:00,  2.16s/ba][A[A
Running tokenizer on dataset #1:  68%|   | 46/68 [01:32<00:42,  1.91s/ba][A






Running tokenizer on dataset #7:  59%|    | 40/68 [01:26<00:58,  2.08s/ba][A[A[A[A[A[A[A








Running tokenizer on dataset #9:  57%|    | 39/68 [01:25<01:12,  2.50s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  47%|     | 32/68 [01:23<01:12,  2.02s/ba][A[A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  66%|   | 45/68 [01:29<00:43,  1.87s/ba][A[A[A[A[A


Running tokenizer on dataset #3:  53%|    | 36/68 [01:31<01:03,  1.98s/ba][A[A[ARunning tokenizer on dataset #0:  69%|   | 47/68 [01:34<00:39,  1.88s/ba]









Running tokenizer on dataset #10:  47%|     | 32/68 [01:24<01:31,  2.54s/ba][A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  65%|   | 44/68 [01:27<00:45,  1.91s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  57%|    | 39/68 [01:29<00:55,  1.90s/ba][A[A[A[A[A[A

Running tokenizer on dataset #2:  60%|    | 41/68 [01:33<00:56,  2.08s/ba][A[A
Running tokenizer on dataset #1:  69%|   | 47/68 [01:34<00:40,  1.92s/ba][A






Running tokenizer on dataset #7:  60%|    | 41/68 [01:28<00:54,  2.03s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  59%|    | 40/68 [01:31<01:09,  2.50s/ba][A[A[A[A










Running tokenizer on dataset #11:  49%|     | 33/68 [01:25<01:09,  2.00s/ba][A[A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  68%|   | 46/68 [01:31<00:41,  1.89s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  71%|   | 48/68 [01:36<00:37,  1.86s/ba]








Running tokenizer on dataset #9:  59%|    | 40/68 [01:28<01:10,  2.51s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  54%|    | 37/68 [01:33<01:01,  1.97s/ba][A[A[A







Running tokenizer on dataset #8:  66%|   | 45/68 [01:29<00:43,  1.91s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  59%|    | 40/68 [01:31<00:52,  1.89s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  49%|     | 33/68 [01:27<01:28,  2.52s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  62%|   | 42/68 [01:35<00:53,  2.04s/ba][A[A
Running tokenizer on dataset #1:  71%|   | 48/68 [01:36<00:38,  1.92s/ba][A






Running tokenizer on dataset #7:  62%|   | 42/68 [01:30<00:51,  2.00s/ba][A[A[A[A[A[A[A










Running tokenizer on dataset #11:  50%|     | 34/68 [01:27<01:06,  1.97s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  60%|    | 41/68 [01:34<01:06,  2.48s/ba][A[A[A[A




Running tokenizer on dataset #5:  69%|   | 47/68 [01:33<00:39,  1.90s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  72%|  | 49/68 [01:38<00:35,  1.86s/ba]


Running tokenizer on dataset #3:  56%|    | 38/68 [01:35<00:58,  1.96s/ba][A[A[A







Running tokenizer on dataset #8:  68%|   | 46/68 [01:31<00:42,  1.92s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  60%|    | 41/68 [01:33<00:51,  1.89s/ba][A[A[A[A[A[A








Running tokenizer on dataset #9:  60%|    | 41/68 [01:30<01:08,  2.52s/ba][A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  63%|   | 43/68 [01:37<00:50,  2.00s/ba][A[A
Running tokenizer on dataset #1:  72%|  | 49/68 [01:38<00:36,  1.92s/ba][A






Running tokenizer on dataset #7:  63%|   | 43/68 [01:32<00:49,  1.97s/ba][A[A[A[A[A[A[A









Running tokenizer on dataset #10:  50%|     | 34/68 [01:29<01:26,  2.54s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  51%|    | 35/68 [01:29<01:06,  2.01s/ba][A[A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  71%|   | 48/68 [01:34<00:37,  1.90s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  74%|  | 50/68 [01:39<00:33,  1.87s/ba]


Running tokenizer on dataset #3:  57%|    | 39/68 [01:37<00:56,  1.93s/ba][A[A[A



Running tokenizer on dataset #4:  62%|   | 42/68 [01:36<01:04,  2.47s/ba][A[A[A[A







Running tokenizer on dataset #8:  69%|   | 47/68 [01:33<00:40,  1.91s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  62%|   | 42/68 [01:35<00:49,  1.89s/ba][A[A[A[A[A[A

Running tokenizer on dataset #2:  65%|   | 44/68 [01:39<00:47,  1.97s/ba][A[A






Running tokenizer on dataset #7:  65%|   | 44/68 [01:34<00:46,  1.95s/ba][A[A[A[A[A[A[A
Running tokenizer on dataset #1:  74%|  | 50/68 [01:40<00:34,  1.93s/ba][A








Running tokenizer on dataset #9:  62%|   | 42/68 [01:33<01:05,  2.53s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  72%|  | 49/68 [01:36<00:35,  1.88s/ba][A[A[A[A[A










Running tokenizer on dataset #11:  53%|    | 36/68 [01:31<01:03,  1.99s/ba][A[A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  75%|  | 51/68 [01:41<00:31,  1.86s/ba]









Running tokenizer on dataset #10:  51%|    | 35/68 [01:32<01:23,  2.52s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  59%|    | 40/68 [01:38<00:54,  1.95s/ba][A[A[A







Running tokenizer on dataset #8:  71%|   | 48/68 [01:34<00:38,  1.91s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  63%|   | 43/68 [01:36<00:47,  1.90s/ba][A[A[A[A[A[A

Running tokenizer on dataset #2:  66%|   | 45/68 [01:40<00:45,  1.96s/ba][A[A



Running tokenizer on dataset #4:  63%|   | 43/68 [01:39<01:01,  2.48s/ba][A[A[A[A
Running tokenizer on dataset #1:  75%|  | 51/68 [01:41<00:32,  1.91s/ba][A






Running tokenizer on dataset #7:  66%|   | 45/68 [01:36<00:44,  1.95s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  74%|  | 50/68 [01:38<00:33,  1.89s/ba][A[A[A[A[A










Running tokenizer on dataset #11:  54%|    | 37/68 [01:33<01:01,  1.98s/ba][A[A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  76%|  | 52/68 [01:43<00:29,  1.86s/ba]








Running tokenizer on dataset #9:  63%|   | 43/68 [01:35<01:03,  2.52s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  60%|    | 41/68 [01:40<00:52,  1.94s/ba][A[A[A







Running tokenizer on dataset #8:  72%|  | 49/68 [01:36<00:36,  1.92s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  65%|   | 44/68 [01:38<00:45,  1.88s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  53%|    | 36/68 [01:35<01:21,  2.53s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  68%|   | 46/68 [01:42<00:42,  1.93s/ba][A[A
Running tokenizer on dataset #1:  76%|  | 52/68 [01:43<00:30,  1.89s/ba][A






Running tokenizer on dataset #7:  68%|   | 46/68 [01:38<00:42,  1.91s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  65%|   | 44/68 [01:41<00:59,  2.49s/ba][A[A[A[A




Running tokenizer on dataset #5:  75%|  | 51/68 [01:40<00:32,  1.88s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  78%|  | 53/68 [01:45<00:27,  1.86s/ba]










Running tokenizer on dataset #11:  56%|    | 38/68 [01:35<00:59,  1.97s/ba][A[A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  62%|   | 42/68 [01:42<00:50,  1.94s/ba][A[A[A







Running tokenizer on dataset #8:  74%|  | 50/68 [01:38<00:34,  1.90s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  66%|   | 45/68 [01:40<00:43,  1.88s/ba][A[A[A[A[A[A








Running tokenizer on dataset #9:  65%|   | 44/68 [01:38<01:00,  2.51s/ba][A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  69%|   | 47/68 [01:44<00:40,  1.94s/ba][A[A
Running tokenizer on dataset #1:  78%|  | 53/68 [01:45<00:28,  1.90s/ba][A









Running tokenizer on dataset #10:  54%|    | 37/68 [01:37<01:18,  2.53s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  69%|   | 47/68 [01:40<00:42,  2.02s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  76%|  | 52/68 [01:42<00:30,  1.88s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  79%|  | 54/68 [01:47<00:26,  1.86s/ba]










Running tokenizer on dataset #11:  57%|    | 39/68 [01:37<00:57,  1.97s/ba][A[A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  66%|   | 45/68 [01:44<00:56,  2.47s/ba][A[A[A[A


Running tokenizer on dataset #3:  63%|   | 43/68 [01:44<00:48,  1.93s/ba][A[A[A







Running tokenizer on dataset #8:  75%|  | 51/68 [01:40<00:32,  1.91s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  68%|   | 46/68 [01:42<00:41,  1.88s/ba][A[A[A[A[A[A

Running tokenizer on dataset #2:  71%|   | 48/68 [01:46<00:38,  1.93s/ba][A[A
Running tokenizer on dataset #1:  79%|  | 54/68 [01:47<00:26,  1.90s/ba][A








Running tokenizer on dataset #9:  66%|   | 45/68 [01:40<00:57,  2.51s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  78%|  | 53/68 [01:44<00:28,  1.89s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  81%|  | 55/68 [01:49<00:24,  1.87s/ba]









Running tokenizer on dataset #10:  56%|    | 38/68 [01:39<01:15,  2.50s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  59%|    | 40/68 [01:39<00:54,  1.95s/ba][A[A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  71%|   | 48/68 [01:42<00:43,  2.16s/ba][A[A[A[A[A[A[A


Running tokenizer on dataset #3:  65%|   | 44/68 [01:46<00:46,  1.94s/ba][A[A[A







Running tokenizer on dataset #8:  76%|  | 52/68 [01:42<00:30,  1.91s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  69%|   | 47/68 [01:44<00:39,  1.89s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  68%|   | 46/68 [01:46<00:54,  2.48s/ba][A[A[A[A

Running tokenizer on dataset #2:  72%|  | 49/68 [01:48<00:36,  1.91s/ba][A[A
Running tokenizer on dataset #1:  81%|  | 55/68 [01:49<00:25,  1.98s/ba][A




Running tokenizer on dataset #5:  79%|  | 54/68 [01:46<00:26,  1.89s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  82%| | 56/68 [01:51<00:22,  1.87s/ba]








Running tokenizer on dataset #9:  68%|   | 46/68 [01:43<00:55,  2.51s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  60%|    | 41/68 [01:40<00:52,  1.94s/ba][A[A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  66%|   | 45/68 [01:48<00:44,  1.94s/ba][A[A[A







Running tokenizer on dataset #8:  78%|  | 53/68 [01:44<00:28,  1.90s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  71%|   | 48/68 [01:46<00:37,  1.89s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  57%|    | 39/68 [01:42<01:13,  2.52s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  72%|  | 49/68 [01:45<00:42,  2.26s/ba][A[A[A[A[A[A[A

Running tokenizer on dataset #2:  74%|  | 50/68 [01:50<00:34,  1.91s/ba][A[A



Running tokenizer on dataset #4:  69%|   | 47/68 [01:49<00:52,  2.48s/ba][A[A[A[A




Running tokenizer on dataset #5:  81%|  | 55/68 [01:48<00:24,  1.91s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  84%| | 57/68 [01:53<00:20,  1.90s/ba]
Running tokenizer on dataset #1:  82%| | 56/68 [01:52<00:25,  2.12s/ba][A


Running tokenizer on dataset #3:  68%|   | 46/68 [01:50<00:42,  1.94s/ba][A[A[A







Running tokenizer on dataset #8:  79%|  | 54/68 [01:46<00:26,  1.89s/ba][A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  72%|  | 49/68 [01:48<00:35,  1.88s/ba][A[A[A[A[A[A










Running tokenizer on dataset #11:  62%|   | 42/68 [01:43<00:54,  2.08s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  69%|   | 47/68 [01:45<00:52,  2.51s/ba][A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  75%|  | 51/68 [01:52<00:32,  1.89s/ba][A[A









Running tokenizer on dataset #10:  59%|    | 40/68 [01:45<01:10,  2.50s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  74%|  | 50/68 [01:47<00:41,  2.31s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  82%| | 56/68 [01:50<00:22,  1.90s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  85%| | 58/68 [01:54<00:18,  1.88s/ba]



Running tokenizer on dataset #4:  71%|   | 48/68 [01:51<00:49,  2.47s/ba][A[A[A[A







Running tokenizer on dataset #8:  81%|  | 55/68 [01:48<00:24,  1.88s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  69%|   | 47/68 [01:52<00:40,  1.95s/ba][A[A[A





Running tokenizer on dataset #6:  74%|  | 50/68 [01:50<00:33,  1.88s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:  84%| | 57/68 [01:54<00:24,  2.22s/ba][A

Running tokenizer on dataset #2:  76%|  | 52/68 [01:54<00:30,  1.89s/ba][A[A










Running tokenizer on dataset #11:  63%|   | 43/68 [01:45<00:54,  2.20s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  71%|   | 48/68 [01:48<00:49,  2.49s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  84%| | 57/68 [01:51<00:20,  1.89s/ba][A[A[A[A[ARunning tokenizer on dataset #0:  87%| | 59/68 [01:56<00:16,  1.87s/ba]






Running tokenizer on dataset #7:  75%|  | 51/68 [01:50<00:39,  2.35s/ba][A[A[A[A[A[A[A









Running tokenizer on dataset #10:  60%|    | 41/68 [01:47<01:07,  2.51s/ba][A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  75%|  | 51/68 [01:51<00:31,  1.85s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  82%| | 56/68 [01:50<00:22,  1.89s/ba][A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  72%|  | 49/68 [01:53<00:46,  2.45s/ba][A[A[A[A


Running tokenizer on dataset #3:  71%|   | 48/68 [01:54<00:39,  1.98s/ba][A[A[A

Running tokenizer on dataset #2:  78%|  | 53/68 [01:56<00:28,  1.87s/ba][A[A
Running tokenizer on dataset #1:  85%| | 58/68 [01:57<00:23,  2.31s/ba][ARunning tokenizer on dataset #0:  88%| | 60/68 [01:58<00:14,  1.86s/ba]




Running tokenizer on dataset #5:  85%| | 58/68 [01:53<00:18,  1.89s/ba][A[A[A[A[A










Running tokenizer on dataset #11:  65%|   | 44/68 [01:48<00:54,  2.29s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  72%|  | 49/68 [01:50<00:47,  2.48s/ba][A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  76%|  | 52/68 [01:53<00:29,  1.86s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  84%| | 57/68 [01:52<00:20,  1.91s/ba][A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  76%|  | 52/68 [01:52<00:38,  2.41s/ba][A[A[A[A[A[A[A









Running tokenizer on dataset #10:  62%|   | 42/68 [01:50<01:05,  2.51s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  72%|  | 49/68 [01:56<00:37,  1.97s/ba][A[A[A

Running tokenizer on dataset #2:  79%|  | 54/68 [01:57<00:26,  1.88s/ba][A[A



Running tokenizer on dataset #4:  74%|  | 50/68 [01:56<00:44,  2.45s/ba][A[A[A[ARunning tokenizer on dataset #0:  90%| | 61/68 [02:00<00:13,  1.87s/ba]
Running tokenizer on dataset #1:  87%| | 59/68 [01:59<00:21,  2.36s/ba][A




Running tokenizer on dataset #5:  87%| | 59/68 [01:55<00:17,  1.92s/ba][A[A[A[A[A





Running tokenizer on dataset #6:  78%|  | 53/68 [01:55<00:27,  1.86s/ba][A[A[A[A[A[A










Running tokenizer on dataset #11:  66%|   | 45/68 [01:50<00:53,  2.34s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  74%|  | 50/68 [01:53<00:44,  2.48s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  85%| | 58/68 [01:53<00:19,  1.92s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  74%|  | 50/68 [01:58<00:35,  1.97s/ba][A[A[A

Running tokenizer on dataset #2:  81%|  | 55/68 [01:59<00:24,  1.90s/ba][A[A









Running tokenizer on dataset #10:  63%|   | 43/68 [01:52<01:02,  2.51s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  78%|  | 53/68 [01:55<00:36,  2.45s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #0:  91%| | 62/68 [02:02<00:11,  1.87s/ba]




Running tokenizer on dataset #5:  88%| | 60/68 [01:57<00:15,  1.91s/ba][A[A[A[A[A



Running tokenizer on dataset #4:  75%|  | 51/68 [01:58<00:42,  2.47s/ba][A[A[A[A





Running tokenizer on dataset #6:  79%|  | 54/68 [01:57<00:26,  1.87s/ba][A[A[A[A[A[A
Running tokenizer on dataset #1:  88%| | 60/68 [02:02<00:18,  2.37s/ba][A







Running tokenizer on dataset #8:  87%| | 59/68 [01:55<00:17,  1.90s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  75%|  | 51/68 [02:00<00:33,  1.96s/ba][A[A[A

Running tokenizer on dataset #2:  82%| | 56/68 [02:01<00:22,  1.90s/ba][A[A










Running tokenizer on dataset #11:  68%|   | 46/68 [01:53<00:52,  2.37s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  75%|  | 51/68 [01:55<00:42,  2.48s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  93%|| 63/68 [02:04<00:09,  1.86s/ba]









Running tokenizer on dataset #10:  65%|   | 44/68 [01:54<00:59,  2.48s/ba][A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  90%| | 61/68 [01:59<00:13,  1.91s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  79%|  | 54/68 [01:57<00:34,  2.45s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  81%|  | 55/68 [01:59<00:24,  1.87s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  76%|  | 52/68 [02:01<00:39,  2.47s/ba][A[A[A[A







Running tokenizer on dataset #8:  88%| | 60/68 [01:57<00:15,  1.89s/ba][A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  84%| | 57/68 [02:03<00:20,  1.90s/ba][A[A


Running tokenizer on dataset #3:  76%|  | 52/68 [02:02<00:31,  1.95s/ba][A[A[A
Running tokenizer on dataset #1:  90%| | 61/68 [02:04<00:16,  2.40s/ba][ARunning tokenizer on dataset #0:  94%|| 64/68 [02:06<00:07,  1.85s/ba]










Running tokenizer on dataset #11:  69%|   | 47/68 [01:55<00:50,  2.39s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  76%|  | 52/68 [01:57<00:39,  2.48s/ba][A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  91%| | 62/68 [02:01<00:11,  1.95s/ba][A[A[A[A[A





Running tokenizer on dataset #6:  82%| | 56/68 [02:01<00:22,  1.89s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  81%|  | 55/68 [02:00<00:31,  2.46s/ba][A[A[A[A[A[A[A









Running tokenizer on dataset #10:  66%|   | 45/68 [01:57<00:57,  2.49s/ba][A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  90%| | 61/68 [01:59<00:13,  1.89s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  78%|  | 53/68 [02:04<00:28,  1.93s/ba][A[A[A

Running tokenizer on dataset #2:  85%| | 58/68 [02:05<00:19,  1.91s/ba][A[A



Running tokenizer on dataset #4:  78%|  | 53/68 [02:03<00:37,  2.47s/ba][A[A[A[ARunning tokenizer on dataset #0:  96%|| 65/68 [02:07<00:05,  1.86s/ba]
Running tokenizer on dataset #1:  91%| | 62/68 [02:07<00:14,  2.47s/ba][A




Running tokenizer on dataset #5:  93%|| 63/68 [02:03<00:09,  1.93s/ba][A[A[A[A[A










Running tokenizer on dataset #11:  71%|   | 48/68 [01:58<00:48,  2.43s/ba][A[A[A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  84%| | 57/68 [02:03<00:20,  1.89s/ba][A[A[A[A[A[A








Running tokenizer on dataset #9:  78%|  | 53/68 [02:00<00:37,  2.51s/ba][A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  91%| | 62/68 [02:01<00:11,  1.94s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  79%|  | 54/68 [02:06<00:26,  1.91s/ba][A[A[A

Running tokenizer on dataset #2:  87%| | 59/68 [02:07<00:17,  1.91s/ba][A[A






Running tokenizer on dataset #7:  82%| | 56/68 [02:02<00:29,  2.46s/ba][A[A[A[A[A[A[A









Running tokenizer on dataset #10:  68%|   | 46/68 [01:59<00:54,  2.49s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  97%|| 66/68 [02:09<00:03,  1.86s/ba]



Running tokenizer on dataset #4:  79%|  | 54/68 [02:06<00:34,  2.47s/ba][A[A[A[A




Running tokenizer on dataset #5:  94%|| 64/68 [02:05<00:07,  1.91s/ba][A[A[A[A[A
Running tokenizer on dataset #1:  93%|| 63/68 [02:09<00:11,  2.38s/ba][A





Running tokenizer on dataset #6:  85%| | 58/68 [02:05<00:18,  1.89s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  93%|| 63/68 [02:03<00:09,  1.92s/ba][A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  72%|  | 49/68 [02:00<00:46,  2.43s/ba][A[A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  81%|  | 55/68 [02:08<00:24,  1.92s/ba][A[A[A

Running tokenizer on dataset #2:  88%| | 60/68 [02:09<00:15,  1.90s/ba][A[A








Running tokenizer on dataset #9:  79%|  | 54/68 [02:02<00:34,  2.48s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #0:  99%|| 67/68 [02:11<00:01,  1.84s/ba]









Running tokenizer on dataset #10:  69%|   | 47/68 [02:02<00:52,  2.48s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  84%| | 57/68 [02:05<00:27,  2.49s/ba][A[A[A[A[A[A[A




Running tokenizer on dataset #5:  96%|| 65/68 [02:07<00:05,  1.90s/ba][A[A[A[A[A
Running tokenizer on dataset #1:  94%|| 64/68 [02:11<00:08,  2.22s/ba][A



Running tokenizer on dataset #4:  81%|  | 55/68 [02:08<00:32,  2.46s/ba][A[A[A[A





Running tokenizer on dataset #6:  87%| | 59/68 [02:06<00:16,  1.88s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  94%|| 64/68 [02:05<00:07,  1.90s/ba][A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  90%| | 61/68 [02:11<00:13,  1.87s/ba][A[ARunning tokenizer on dataset #0: 100%|| 68/68 [02:13<00:00,  1.72s/ba]Running tokenizer on dataset #0: 100%|| 68/68 [02:13<00:00,  1.96s/ba]


Running tokenizer on dataset #3:  82%| | 56/68 [02:10<00:23,  1.92s/ba][A[A[A










Running tokenizer on dataset #11:  74%|  | 50/68 [02:03<00:44,  2.46s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  81%|  | 55/68 [02:05<00:32,  2.47s/ba][A[A[A[A[A[A[A[A[A
Running tokenizer on dataset #1:  96%|| 65/68 [02:12<00:06,  2.10s/ba][A




Running tokenizer on dataset #5:  97%|| 66/68 [02:09<00:03,  1.90s/ba][A[A[A[A[A






Running tokenizer on dataset #7:  85%| | 58/68 [02:07<00:24,  2.41s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  88%| | 60/68 [02:08<00:15,  1.88s/ba][A[A[A[A[A[A









Running tokenizer on dataset #10:  71%|   | 48/68 [02:04<00:49,  2.49s/ba][A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  96%|| 65/68 [02:07<00:05,  1.89s/ba][A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  82%| | 56/68 [02:11<00:29,  2.46s/ba][A[A[A[A


Running tokenizer on dataset #3:  84%| | 57/68 [02:11<00:21,  1.91s/ba][A[A[A

Running tokenizer on dataset #2:  91%| | 62/68 [02:13<00:11,  1.94s/ba][A[A
Running tokenizer on dataset #1:  97%|| 66/68 [02:14<00:04,  2.02s/ba][A










Running tokenizer on dataset #11:  75%|  | 51/68 [02:05<00:41,  2.43s/ba][A[A[A[A[A[A[A[A[A[A[A




Running tokenizer on dataset #5:  99%|| 67/68 [02:11<00:01,  1.91s/ba][A[A[A[A[A








Running tokenizer on dataset #9:  82%| | 56/68 [02:07<00:29,  2.46s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  87%| | 59/68 [02:09<00:20,  2.25s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  90%| | 61/68 [02:10<00:13,  1.87s/ba][A[A[A[A[A[A







Running tokenizer on dataset #8:  97%|| 66/68 [02:09<00:03,  1.88s/ba][A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  85%| | 58/68 [02:13<00:19,  1.92s/ba][A[A[A









Running tokenizer on dataset #10:  72%|  | 49/68 [02:07<00:47,  2.49s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  93%|| 63/68 [02:15<00:09,  1.92s/ba][A[A



Running tokenizer on dataset #4:  84%| | 57/68 [02:13<00:27,  2.46s/ba][A[A[A[A




Running tokenizer on dataset #5: 100%|| 68/68 [02:12<00:00,  1.78s/ba][A[A[A[A[ARunning tokenizer on dataset #5: 100%|| 68/68 [02:12<00:00,  1.95s/ba]
Running tokenizer on dataset #1:  99%|| 67/68 [02:16<00:01,  1.95s/ba][A






Running tokenizer on dataset #7:  88%| | 60/68 [02:11<00:17,  2.13s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  91%| | 62/68 [02:12<00:11,  1.90s/ba][A[A[A[A[A[A










Running tokenizer on dataset #11:  76%|  | 52/68 [02:07<00:39,  2.44s/ba][A[A[A[A[A[A[A[A[A[A[A







Running tokenizer on dataset #8:  99%|| 67/68 [02:11<00:01,  1.90s/ba][A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  84%| | 57/68 [02:10<00:27,  2.47s/ba][A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  94%|| 64/68 [02:17<00:07,  1.91s/ba][A[A


Running tokenizer on dataset #3:  87%| | 59/68 [02:15<00:17,  1.93s/ba][A[A[A
Running tokenizer on dataset #1: 100%|| 68/68 [02:18<00:00,  1.80s/ba][ARunning tokenizer on dataset #1: 100%|| 68/68 [02:18<00:00,  2.03s/ba]









Running tokenizer on dataset #10:  74%|  | 50/68 [02:09<00:44,  2.48s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  90%| | 61/68 [02:13<00:14,  2.06s/ba][A[A[A[A[A[A[A







Running tokenizer on dataset #8: 100%|| 68/68 [02:12<00:00,  1.75s/ba][A[A[A[A[A[A[A[ARunning tokenizer on dataset #8: 100%|| 68/68 [02:12<00:00,  1.95s/ba]



Running tokenizer on dataset #4:  85%| | 58/68 [02:16<00:24,  2.48s/ba][A[A[A[A





Running tokenizer on dataset #6:  93%|| 63/68 [02:14<00:09,  1.89s/ba][A[A[A[A[A[A

Running tokenizer on dataset #2:  96%|| 65/68 [02:18<00:05,  1.89s/ba][A[A


Running tokenizer on dataset #3:  88%| | 60/68 [02:17<00:15,  1.92s/ba][A[A[A










Running tokenizer on dataset #11:  78%|  | 53/68 [02:10<00:36,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  85%| | 58/68 [02:12<00:24,  2.47s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  75%|  | 51/68 [02:12<00:41,  2.47s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  91%| | 62/68 [02:15<00:12,  2.05s/ba][A[A[A[A[A[A[A





Running tokenizer on dataset #6:  94%|| 64/68 [02:16<00:07,  1.88s/ba][A[A[A[A[A[A



Running tokenizer on dataset #4:  87%| | 59/68 [02:18<00:22,  2.48s/ba][A[A[A[A

Running tokenizer on dataset #2:  97%|| 66/68 [02:20<00:03,  1.88s/ba][A[A


Running tokenizer on dataset #3:  90%| | 61/68 [02:19<00:13,  1.90s/ba][A[A[A










Running tokenizer on dataset #11:  79%|  | 54/68 [02:12<00:34,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  87%| | 59/68 [02:15<00:22,  2.47s/ba][A[A[A[A[A[A[A[A[A





Running tokenizer on dataset #6:  96%|| 65/68 [02:18<00:05,  1.87s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  93%|| 63/68 [02:17<00:10,  2.02s/ba][A[A[A[A[A[A[A









Running tokenizer on dataset #10:  76%|  | 52/68 [02:14<00:39,  2.46s/ba][A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2:  99%|| 67/68 [02:22<00:01,  1.86s/ba][A[A


Running tokenizer on dataset #3:  91%| | 62/68 [02:21<00:11,  1.96s/ba][A[A[A



Running tokenizer on dataset #4:  88%| | 60/68 [02:21<00:19,  2.48s/ba][A[A[A[A





Running tokenizer on dataset #6:  97%|| 66/68 [02:20<00:03,  1.86s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  94%|| 64/68 [02:18<00:07,  1.98s/ba][A[A[A[A[A[A[A










Running tokenizer on dataset #11:  81%|  | 55/68 [02:15<00:31,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A

Running tokenizer on dataset #2: 100%|| 68/68 [02:24<00:00,  1.73s/ba][A[ARunning tokenizer on dataset #2: 100%|| 68/68 [02:24<00:00,  2.12s/ba]








Running tokenizer on dataset #9:  88%| | 60/68 [02:17<00:19,  2.46s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  93%|| 63/68 [02:23<00:09,  1.96s/ba][A[A[A









Running tokenizer on dataset #10:  78%|  | 53/68 [02:17<00:36,  2.46s/ba][A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  90%| | 61/68 [02:23<00:17,  2.48s/ba][A[A[A[A





Running tokenizer on dataset #6:  99%|| 67/68 [02:21<00:01,  1.85s/ba][A[A[A[A[A[A






Running tokenizer on dataset #7:  96%|| 65/68 [02:20<00:05,  1.96s/ba][A[A[A[A[A[A[A










Running tokenizer on dataset #11:  82%| | 56/68 [02:17<00:29,  2.46s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  90%| | 61/68 [02:20<00:17,  2.46s/ba][A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  94%|| 64/68 [02:25<00:07,  1.94s/ba][A[A[A





Running tokenizer on dataset #6: 100%|| 68/68 [02:23<00:00,  1.72s/ba][A[A[A[A[A[ARunning tokenizer on dataset #6: 100%|| 68/68 [02:23<00:00,  2.11s/ba]









Running tokenizer on dataset #10:  79%|  | 54/68 [02:19<00:34,  2.45s/ba][A[A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  97%|| 66/68 [02:22<00:03,  1.91s/ba][A[A[A[A[A[A[A



Running tokenizer on dataset #4:  91%| | 62/68 [02:26<00:15,  2.52s/ba][A[A[A[A


Running tokenizer on dataset #3:  96%|| 65/68 [02:27<00:05,  1.92s/ba][A[A[A










Running tokenizer on dataset #11:  84%| | 57/68 [02:20<00:26,  2.44s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  91%| | 62/68 [02:22<00:15,  2.53s/ba][A[A[A[A[A[A[A[A[A






Running tokenizer on dataset #7:  99%|| 67/68 [02:24<00:01,  1.88s/ba][A[A[A[A[A[A[A









Running tokenizer on dataset #10:  81%|  | 55/68 [02:22<00:31,  2.46s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  97%|| 66/68 [02:29<00:03,  1.90s/ba][A[A[A



Running tokenizer on dataset #4:  93%|| 63/68 [02:28<00:12,  2.50s/ba][A[A[A[A






Running tokenizer on dataset #7: 100%|| 68/68 [02:25<00:00,  1.74s/ba][A[A[A[A[A[A[ARunning tokenizer on dataset #7: 100%|| 68/68 [02:25<00:00,  2.15s/ba]










Running tokenizer on dataset #11:  85%| | 58/68 [02:22<00:24,  2.42s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  93%|| 63/68 [02:25<00:12,  2.41s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  82%| | 56/68 [02:24<00:29,  2.44s/ba][A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3:  99%|| 67/68 [02:31<00:01,  1.89s/ba][A[A[A



Running tokenizer on dataset #4:  94%|| 64/68 [02:31<00:09,  2.49s/ba][A[A[A[A








Running tokenizer on dataset #9:  94%|| 64/68 [02:26<00:08,  2.24s/ba][A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  87%| | 59/68 [02:25<00:21,  2.42s/ba][A[A[A[A[A[A[A[A[A[A[A


Running tokenizer on dataset #3: 100%|| 68/68 [02:32<00:00,  1.76s/ba][A[A[ARunning tokenizer on dataset #3: 100%|| 68/68 [02:32<00:00,  2.24s/ba]









Running tokenizer on dataset #10:  84%| | 57/68 [02:26<00:26,  2.44s/ba][A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  96%|| 65/68 [02:28<00:06,  2.12s/ba][A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  96%|| 65/68 [02:33<00:07,  2.48s/ba][A[A[A[A










Running tokenizer on dataset #11:  88%| | 60/68 [02:27<00:19,  2.44s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  97%|| 66/68 [02:30<00:04,  2.01s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  85%| | 58/68 [02:29<00:24,  2.45s/ba][A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4:  97%|| 66/68 [02:36<00:04,  2.47s/ba][A[A[A[A










Running tokenizer on dataset #11:  90%| | 61/68 [02:29<00:17,  2.44s/ba][A[A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9:  99%|| 67/68 [02:32<00:01,  1.95s/ba][A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  87%| | 59/68 [02:31<00:21,  2.43s/ba][A[A[A[A[A[A[A[A[A[A








Running tokenizer on dataset #9: 100%|| 68/68 [02:33<00:00,  1.78s/ba][A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #9: 100%|| 68/68 [02:33<00:00,  2.26s/ba]



Running tokenizer on dataset #4:  99%|| 67/68 [02:38<00:02,  2.45s/ba][A[A[A[A










Running tokenizer on dataset #11:  91%| | 62/68 [02:32<00:14,  2.49s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  88%| | 60/68 [02:34<00:19,  2.40s/ba][A[A[A[A[A[A[A[A[A[A



Running tokenizer on dataset #4: 100%|| 68/68 [02:40<00:00,  2.26s/ba][A[A[A[ARunning tokenizer on dataset #4: 100%|| 68/68 [02:40<00:00,  2.36s/ba]










Running tokenizer on dataset #11:  93%|| 63/68 [02:34<00:12,  2.48s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  90%| | 61/68 [02:36<00:16,  2.41s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  94%|| 64/68 [02:37<00:09,  2.46s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  91%| | 62/68 [02:39<00:14,  2.48s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  96%|| 65/68 [02:39<00:07,  2.45s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  93%|| 63/68 [02:41<00:12,  2.45s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  97%|| 66/68 [02:42<00:04,  2.41s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  94%|| 64/68 [02:44<00:09,  2.43s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11:  99%|| 67/68 [02:44<00:02,  2.40s/ba][A[A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  96%|| 65/68 [02:46<00:07,  2.41s/ba][A[A[A[A[A[A[A[A[A[A










Running tokenizer on dataset #11: 100%|| 68/68 [02:46<00:00,  2.24s/ba][A[A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #11: 100%|| 68/68 [02:46<00:00,  2.45s/ba]









Running tokenizer on dataset #10:  97%|| 66/68 [02:48<00:04,  2.40s/ba][A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10:  99%|| 67/68 [02:51<00:02,  2.39s/ba][A[A[A[A[A[A[A[A[A[A









Running tokenizer on dataset #10: 100%|| 68/68 [02:52<00:00,  2.22s/ba][A[A[A[A[A[A[A[A[A[ARunning tokenizer on dataset #10: 100%|| 68/68 [02:52<00:00,  2.54s/ba]










Error executing job with overrides: ['model.name=facebook/opt-2.7b', 'training.eval_every=250', 'training.train_batch_size=32', 'training.weight_decay=0.05', 'training.eval_batch_size=16', 'training.learning_rate=0.000003', 'training.val_split_percent=20', 'training.num_epochs=4', 'training.lr_warmup_steps=5', 'training.gradient_accumulation_steps=2', 'dataset.name=ViktorThink/mountain_combined_813306', 'dataset.num_batches=2']
Traceback (most recent call last):
  File "finetune_using_clm_wandb.py", line 316, in main
    save_tokenized_datasets(tokenized_datasets)
  File "finetune_using_clm_wandb.py", line 238, in save_tokenized_datasets
    eval_dataset = tokenized_datasets["test"]
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/dataset_dict.py", line 57, in __getitem__
    return super().__getitem__(k)
KeyError: 'test'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "finetune_using_clm_wandb.py", line 20, in <module>
    from accelerate import Accelerator, DistributedType
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/__init__.py", line 7, in <module>
    from .accelerator import Accelerator
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/accelerator.py", line 27, in <module>
    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/checkpointing.py", line 24, in <module>
    from .utils import (
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/utils/__init__.py", line 120, in <module>
    from .other import (
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/utils/other.py", line 29, in <module>
    from deepspeed import DeepSpeedEngine
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/__init__.py", line 13, in <module>
    from . import ops
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/ops/__init__.py", line 7, in <module>
    from . import transformer
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/ops/transformer/__init__.py", line 2, in <module>
    from .inference.config import DeepSpeedInferenceConfig
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/ops/transformer/inference/__init__.py", line 5, in <module>
    from .diffusers_transformer_block import DeepSpeedDiffusersTransformerBlock
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/ops/transformer/inference/diffusers_transformer_block.py", line 8, in <module>
    from ....module_inject import GroupQuantizer
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/module_inject/__init__.py", line 1, in <module>
    from .replace_module import replace_transformer_layer, revert_transformer_layer, ReplaceWithTensorSlicing, GroupQuantizer
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py", line 1210, in <module>
    from ..pipe import PipelineModule
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/pipe/__init__.py", line 1, in <module>
    from ..runtime.pipe import PipelineModule, LayerSpec, TiedLayerSpec
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/runtime/pipe/__init__.py", line 1, in <module>
    from .module import PipelineModule, LayerSpec, TiedLayerSpec
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/runtime/pipe/module.py", line 14, in <module>
    from ..activation_checkpointing import checkpointing
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 25, in <module>
    from deepspeed.runtime.config import DeepSpeedConfig
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 34, in <module>
    from ..elasticity import (
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/elasticity/__init__.py", line 5, in <module>
    from .elastic_agent import DSElasticAgent
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/deepspeed/elasticity/elastic_agent.py", line 1, in <module>
    from torch.distributed.elastic.agent.server.local_elastic_agent import LocalElasticAgent
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/__init__.py", line 40, in <module>
    from .local_elastic_agent import TORCHELASTIC_ENABLE_FILE_TIMER, TORCHELASTIC_TIMER_FILE
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 35, in <module>
    log = get_logger()
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/torch/distributed/elastic/utils/logging.py", line 32, in get_logger
    return _setup_logger(name or _derive_module_name(depth=2))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/torch/distributed/elastic/utils/logging.py", line 49, in _derive_module_name
    stack = inspect.stack()
  File "/usr/lib/python3.8/inspect.py", line 1526, in stack
    return getouterframes(sys._getframe(1), context)
  File "/usr/lib/python3.8/inspect.py", line 1503, in getouterframes
    frameinfo = (frame,) + getframeinfo(frame, context)
  File "/usr/lib/python3.8/inspect.py", line 1477, in getframeinfo
    lines, lnum = findsource(frame)
  File "/usr/lib/python3.8/inspect.py", line 792, in findsource
    module = getmodule(object, file)
  File "/usr/lib/python3.8/inspect.py", line 744, in getmodule
    for modname, module in sys.modules.copy().items():
KeyboardInterrupt
