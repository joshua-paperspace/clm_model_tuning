[2022-11-18 14:48:25,460][__main__][INFO] - Setting random seed to 17
[2022-11-18 14:48:25,461][__main__][INFO] - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Mixed precision type: no

[2022-11-18 14:48:25,464][__main__][INFO] - output_dir: tuned-model
bittensor:
  network: nobunaga
dataset:
  name: ViktorThink/mountain_combined_813306
  config_name: null
  num_batches: 5000
  block_size: 256
  overwrite_cache: false
  keep_linebreaks: true
  concatenate_raw: false
  load_tokenized_data: false
model:
  name: facebook/opt-2.7b
  config_name: null
tokenizer:
  name: null
  use_fast: true
  preprocessing_num_workers: null
  pad_token: '[PAD]'
training:
  seed: 17
  val_split_percent: 20
  train_batch_size: 32
  eval_batch_size: 16
  learning_rate: 3.0e-06
  weight_decay: 0.05
  num_epochs: 4
  max_train_steps: null
  gradient_accumulation_steps: 2
  lr_scheduler: constant
  lr_warmup_steps: 5
  eval_every: 250
  max_eval_steps: 500
  checkpoint:
    resume_from_checkpoint: 0
    every_n_steps: null
tracking:
  enabled: true
  report_to: all
testing:
  enabled: false

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--EleutherAI--gpt-neo-2.7B/snapshots/51568a6e0ae813a3f2a9da558ab7beac5e3acc24/config.json
Model config GPTNeoConfig {
  "_name_or_path": "EleutherAI/gpt-neo-2.7B",
  "activation_function": "gelu_new",
  "architectures": [
    "GPTNeoForCausalLM"
  ],
  "attention_dropout": 0,
  "attention_layers": [
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local"
  ],
  "attention_types": [
    [
      [
        "global",
        "local"
      ],
      16
    ]
  ],
  "bos_token_id": 50256,
  "embed_dropout": 0,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "hidden_size": 2560,
  "initializer_range": 0.02,
  "intermediate_size": null,
  "layer_norm_epsilon": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neo",
  "num_heads": 20,
  "num_layers": 32,
  "resid_dropout": 0,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50,
      "temperature": 0.9
    }
  },
  "tokenizer_class": "GPT2Tokenizer",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50257,
  "window_size": 256
}

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading file vocab.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/vocab.json
loading file merges.txt from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/merges.txt
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/tokenizer_config.json
loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading weights file flax_model.msgpack from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Loading Flax weights from /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Some weights of the Flax model were not used when initializing the PyTorch model GPTNeoForCausalLM: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.18.fc1.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.bias']
- This IS expected if you are initializing GPTNeoForCausalLM from a Flax model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a FlaxBertForPreTraining model).
- This IS NOT expected if you are initializing GPTNeoForCausalLM from a Flax model that you expect to be exactly identical (e.g. initializing a BertForSequenceClassification model from a FlaxBertForSequenceClassification model).
Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['transformer.h.16.attn.attention.out_proj.weight', 'transformer.h.30.mlp.c_fc.bias', 'transformer.h.25.attn.attention.v_proj.weight', 'transformer.h.26.mlp.c_proj.weight', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.23.mlp.c_fc.weight', 'transformer.h.15.attn.attention.out_proj.weight', 'transformer.h.18.attn.attention.v_proj.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.1.attn.attention.masked_bias', 'transformer.h.0.attn.attention.out_proj.weight', 'transformer.h.29.attn.attention.masked_bias', 'transformer.h.13.mlp.c_fc.bias', 'transformer.h.24.mlp.c_proj.weight', 'lm_head.weight', 'transformer.h.8.attn.attention.k_proj.weight', 'transformer.h.13.mlp.c_fc.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.29.attn.attention.q_proj.weight', 'transformer.h.31.mlp.c_fc.weight', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.29.mlp.c_fc.weight', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.13.ln_2.weight', 'transformer.h.0.attn.attention.q_proj.weight', 'transformer.h.12.attn.attention.bias', 'transformer.h.13.attn.attention.out_proj.bias', 'transformer.h.15.attn.attention.k_proj.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.20.ln_2.weight', 'transformer.h.16.ln_1.bias', 'transformer.h.8.attn.attention.masked_bias', 'transformer.h.10.attn.attention.bias', 'transformer.h.2.attn.attention.bias', 'transformer.h.27.mlp.c_fc.weight', 'transformer.h.22.ln_1.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.28.mlp.c_proj.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.11.ln_1.weight', 'transformer.h.26.ln_1.weight', 'transformer.h.4.attn.attention.bias', 'transformer.h.20.mlp.c_proj.bias', 'transformer.h.2.attn.attention.out_proj.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.28.attn.attention.out_proj.bias', 'transformer.h.19.mlp.c_fc.bias', 'transformer.h.7.attn.attention.k_proj.weight', 'transformer.h.4.ln_1.weight', 'transformer.h.30.mlp.c_fc.weight', 'transformer.h.6.attn.attention.masked_bias', 'transformer.h.12.ln_1.weight', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.17.attn.attention.out_proj.bias', 'transformer.h.20.ln_1.bias', 'transformer.h.17.attn.attention.q_proj.weight', 'transformer.h.6.attn.attention.v_proj.weight', 'transformer.h.0.ln_2.weight', 'transformer.h.26.attn.attention.out_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.5.attn.attention.masked_bias', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.31.attn.attention.bias', 'transformer.h.20.attn.attention.out_proj.bias', 'transformer.h.28.attn.attention.k_proj.weight', 'transformer.h.3.ln_2.weight', 'transformer.h.13.attn.attention.out_proj.weight', 'transformer.h.15.ln_2.bias', 'transformer.h.8.ln_2.weight', 'transformer.h.5.attn.attention.bias', 'transformer.h.10.ln_1.bias', 'transformer.h.27.mlp.c_fc.bias', 'transformer.h.30.attn.attention.bias', 'transformer.h.18.mlp.c_fc.bias', 'transformer.h.22.attn.attention.bias', 'transformer.h.28.attn.attention.out_proj.weight', 'transformer.h.26.mlp.c_fc.weight', 'transformer.h.30.attn.attention.out_proj.weight', 'transformer.h.26.attn.attention.masked_bias', 'transformer.h.8.attn.attention.bias', 'transformer.h.25.mlp.c_proj.weight', 'transformer.h.22.ln_2.bias', 'transformer.h.29.mlp.c_fc.bias', 'transformer.h.14.attn.attention.masked_bias', 'transformer.h.22.mlp.c_fc.bias', 'transformer.h.30.attn.attention.out_proj.bias', 'transformer.h.21.ln_1.bias', 'transformer.h.14.mlp.c_proj.bias', 'transformer.wte.weight', 'transformer.h.14.mlp.c_fc.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.23.attn.attention.k_proj.weight', 'transformer.h.23.mlp.c_proj.weight', 'transformer.h.28.attn.attention.q_proj.weight', 'transformer.h.29.mlp.c_proj.weight', 'transformer.h.0.attn.attention.bias', 'transformer.h.7.attn.attention.v_proj.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.31.mlp.c_fc.bias', 'transformer.h.26.mlp.c_fc.bias', 'transformer.h.13.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.10.attn.attention.masked_bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.24.attn.attention.v_proj.weight', 'transformer.h.27.ln_2.bias', 'transformer.h.24.attn.attention.k_proj.weight', 'transformer.h.16.attn.attention.q_proj.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.3.ln_1.weight', 'transformer.wpe.weight', 'transformer.h.18.attn.attention.out_proj.weight', 'transformer.h.12.mlp.c_fc.bias', 'transformer.h.15.attn.attention.bias', 'transformer.h.14.ln_1.bias', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.30.ln_2.bias', 'transformer.h.23.attn.attention.v_proj.weight', 'transformer.h.20.mlp.c_fc.bias', 'transformer.h.27.attn.attention.q_proj.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.28.mlp.c_fc.weight', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.3.ln_2.bias', 'transformer.h.28.ln_2.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.27.ln_2.weight', 'transformer.h.6.attn.attention.out_proj.weight', 'transformer.h.2.attn.attention.v_proj.weight', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.21.attn.attention.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.23.mlp.c_fc.bias', 'transformer.h.31.attn.attention.q_proj.weight', 'transformer.h.4.attn.attention.out_proj.weight', 'transformer.h.10.attn.attention.q_proj.weight', 'transformer.h.26.attn.attention.q_proj.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.14.attn.attention.bias', 'transformer.h.27.attn.attention.v_proj.weight', 'transformer.h.19.attn.attention.out_proj.bias', 'transformer.h.23.attn.attention.bias', 'transformer.h.17.ln_1.bias', 'transformer.h.29.ln_2.weight', 'transformer.h.31.attn.attention.k_proj.weight', 'transformer.h.28.ln_1.weight', 'transformer.h.18.attn.attention.q_proj.weight', 'transformer.h.14.ln_1.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.21.ln_2.weight', 'transformer.h.30.ln_2.weight', 'transformer.h.16.attn.attention.v_proj.weight', 'transformer.h.9.ln_2.weight', 'transformer.h.31.ln_2.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.26.attn.attention.k_proj.weight', 'transformer.h.19.mlp.c_proj.bias', 'transformer.h.22.mlp.c_proj.weight', 'transformer.h.9.attn.attention.v_proj.weight', 'transformer.h.22.attn.attention.out_proj.weight', 'transformer.h.19.attn.attention.out_proj.weight', 'transformer.h.2.attn.attention.k_proj.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.2.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.17.attn.attention.k_proj.weight', 'transformer.h.10.attn.attention.out_proj.weight', 'transformer.h.19.ln_1.bias', 'transformer.h.11.ln_2.bias', 'transformer.h.14.mlp.c_fc.bias', 'transformer.h.7.attn.attention.masked_bias', 'transformer.h.29.ln_2.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.30.mlp.c_proj.bias', 'transformer.h.3.attn.attention.v_proj.weight', 'transformer.h.4.attn.attention.k_proj.weight', 'transformer.h.5.attn.attention.q_proj.weight', 'transformer.h.20.attn.attention.bias', 'transformer.h.11.ln_1.bias', 'transformer.h.31.attn.attention.masked_bias', 'transformer.h.30.mlp.c_proj.weight', 'transformer.h.29.attn.attention.out_proj.bias', 'transformer.h.28.ln_2.bias', 'transformer.h.21.attn.attention.out_proj.weight', 'transformer.h.29.attn.attention.k_proj.weight', 'transformer.h.4.attn.attention.q_proj.weight', 'transformer.h.5.ln_2.weight', 'transformer.h.7.attn.attention.out_proj.weight', 'transformer.h.19.mlp.c_proj.weight', 'transformer.h.20.mlp.c_fc.weight', 'transformer.h.20.ln_1.weight', 'transformer.h.29.ln_1.bias', 'transformer.h.31.attn.attention.out_proj.bias', 'transformer.h.25.attn.attention.k_proj.weight', 'transformer.h.26.attn.attention.bias', 'transformer.h.31.attn.attention.v_proj.weight', 'transformer.h.11.attn.attention.q_proj.weight', 'transformer.h.12.ln_2.bias', 'transformer.h.18.attn.attention.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.5.attn.attention.out_proj.weight', 'transformer.h.22.attn.attention.k_proj.weight', 'transformer.h.23.ln_1.weight', 'transformer.h.24.attn.attention.q_proj.weight', 'transformer.h.4.ln_2.weight', 'transformer.h.12.ln_1.bias', 'transformer.h.18.mlp.c_proj.weight', 'transformer.h.13.attn.attention.masked_bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.8.attn.attention.out_proj.weight', 'transformer.h.19.attn.attention.masked_bias', 'transformer.h.9.ln_2.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.25.attn.attention.q_proj.weight', 'transformer.h.26.attn.attention.out_proj.weight', 'transformer.h.25.ln_1.bias', 'transformer.h.27.mlp.c_proj.bias', 'transformer.h.6.attn.attention.bias', 'transformer.h.12.ln_2.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.25.attn.attention.out_proj.weight', 'transformer.h.8.ln_1.weight', 'transformer.h.28.ln_1.bias', 'transformer.h.4.attn.attention.masked_bias', 'transformer.h.21.attn.attention.masked_bias', 'transformer.h.0.attn.attention.k_proj.weight', 'transformer.h.0.attn.attention.out_proj.bias', 'transformer.h.22.mlp.c_fc.weight', 'transformer.h.15.attn.attention.out_proj.bias', 'transformer.h.18.attn.attention.out_proj.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.0.attn.attention.masked_bias', 'transformer.h.26.ln_2.weight', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.26.ln_2.bias', 'transformer.h.23.ln_2.weight', 'transformer.h.17.mlp.c_fc.weight', 'transformer.h.18.attn.attention.k_proj.weight', 'transformer.h.12.mlp.c_fc.weight', 'transformer.h.1.attn.attention.out_proj.weight', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.11.attn.attention.bias', 'transformer.h.22.attn.attention.v_proj.weight', 'transformer.h.10.attn.attention.v_proj.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.18.attn.attention.masked_bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.24.mlp.c_proj.bias', 'transformer.h.2.attn.attention.q_proj.weight', 'transformer.h.5.ln_1.weight', 'transformer.h.13.attn.attention.bias', 'transformer.h.7.attn.attention.out_proj.bias', 'transformer.h.21.mlp.c_proj.bias', 'transformer.h.23.mlp.c_proj.bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.19.attn.attention.k_proj.weight', 'transformer.h.22.attn.attention.out_proj.bias', 'transformer.h.5.attn.attention.k_proj.weight', 'transformer.h.25.ln_2.weight', 'transformer.h.10.attn.attention.out_proj.bias', 'transformer.h.13.attn.attention.v_proj.weight', 'transformer.h.19.ln_2.bias', 'transformer.h.6.attn.attention.q_proj.weight', 'transformer.h.21.attn.attention.v_proj.weight', 'transformer.h.15.attn.attention.v_proj.weight', 'transformer.h.19.attn.attention.v_proj.weight', 'transformer.h.14.attn.attention.k_proj.weight', 'transformer.h.24.ln_2.bias', 'transformer.h.25.attn.attention.out_proj.bias', 'transformer.h.21.mlp.c_proj.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.28.attn.attention.masked_bias', 'transformer.h.19.attn.attention.bias', 'transformer.h.17.ln_1.weight', 'transformer.h.24.ln_1.bias', 'transformer.h.29.ln_1.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.14.attn.attention.out_proj.bias', 'transformer.h.17.attn.attention.masked_bias', 'transformer.h.1.attn.attention.k_proj.weight', 'transformer.h.15.attn.attention.masked_bias', 'transformer.h.23.attn.attention.out_proj.weight', 'transformer.h.20.mlp.c_proj.weight', 'transformer.h.31.ln_2.bias', 'transformer.h.27.attn.attention.out_proj.weight', 'transformer.h.8.attn.attention.v_proj.weight', 'transformer.h.20.attn.attention.masked_bias', 'transformer.h.9.attn.attention.q_proj.weight', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.18.ln_2.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.3.attn.attention.k_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.26.attn.attention.v_proj.weight', 'transformer.h.16.ln_2.bias', 'transformer.h.20.attn.attention.v_proj.weight', 'transformer.h.15.mlp.c_fc.bias', 'transformer.h.12.attn.attention.out_proj.weight', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.27.attn.attention.out_proj.bias', 'transformer.h.12.attn.attention.masked_bias', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.17.mlp.c_fc.bias', 'transformer.h.30.attn.attention.masked_bias', 'transformer.ln_f.weight', 'transformer.h.31.attn.attention.out_proj.weight', 'transformer.h.27.ln_1.bias', 'transformer.h.24.attn.attention.masked_bias', 'transformer.h.3.attn.attention.out_proj.bias', 'transformer.h.22.ln_2.weight', 'transformer.h.16.mlp.c_fc.weight', 'transformer.h.1.attn.attention.out_proj.bias', 'transformer.h.25.attn.attention.bias', 'transformer.h.15.ln_2.weight', 'transformer.h.19.ln_1.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.1.attn.attention.q_proj.weight', 'transformer.h.16.ln_2.weight', 'transformer.h.21.attn.attention.out_proj.bias', 'transformer.h.26.ln_1.bias', 'transformer.h.25.ln_2.bias', 'transformer.h.17.attn.attention.v_proj.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.24.mlp.c_fc.weight', 'transformer.h.13.ln_2.bias', 'transformer.h.28.attn.attention.v_proj.weight', 'transformer.h.25.ln_1.weight', 'transformer.h.19.ln_2.weight', 'transformer.h.22.attn.attention.masked_bias', 'transformer.h.18.ln_1.weight', 'transformer.h.19.attn.attention.q_proj.weight', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.7.ln_2.weight', 'transformer.h.30.attn.attention.q_proj.weight', 'transformer.h.31.ln_1.weight', 'transformer.h.14.attn.attention.out_proj.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.16.attn.attention.bias', 'transformer.h.8.ln_1.bias', 'transformer.h.13.attn.attention.q_proj.weight', 'transformer.h.24.attn.attention.out_proj.weight', 'transformer.h.4.attn.attention.v_proj.weight', 'transformer.h.20.ln_2.bias', 'transformer.h.20.attn.attention.out_proj.weight', 'transformer.h.12.attn.attention.q_proj.weight', 'transformer.h.24.attn.attention.out_proj.bias', 'transformer.h.18.ln_1.bias', 'transformer.h.28.mlp.c_proj.weight', 'transformer.h.13.ln_1.bias', 'transformer.h.21.attn.attention.q_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.15.mlp.c_fc.weight', 'transformer.h.18.mlp.c_proj.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.4.attn.attention.out_proj.bias', 'transformer.ln_f.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.16.attn.attention.k_proj.weight', 'transformer.h.11.attn.attention.out_proj.bias', 'transformer.h.24.ln_2.weight', 'transformer.h.22.attn.attention.q_proj.weight', 'transformer.h.11.ln_2.weight', 'transformer.h.24.ln_1.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.31.mlp.c_proj.bias', 'transformer.h.28.mlp.c_fc.bias', 'transformer.h.16.attn.attention.out_proj.bias', 'transformer.h.2.attn.attention.out_proj.bias', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.29.attn.attention.bias', 'transformer.h.6.attn.attention.out_proj.bias', 'transformer.h.23.ln_2.bias', 'transformer.h.27.attn.attention.masked_bias', 'transformer.h.16.attn.attention.masked_bias', 'transformer.h.7.attn.attention.q_proj.weight', 'transformer.h.9.attn.attention.k_proj.weight', 'transformer.h.18.ln_2.bias', 'transformer.h.12.attn.attention.k_proj.weight', 'transformer.h.22.ln_1.bias', 'transformer.h.11.attn.attention.masked_bias', 'transformer.h.17.ln_2.weight', 'transformer.h.1.attn.attention.bias', 'transformer.h.30.ln_1.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.2.ln_1.weight', 'transformer.h.30.attn.attention.v_proj.weight', 'transformer.h.12.attn.attention.out_proj.bias', 'transformer.h.12.attn.attention.v_proj.weight', 'transformer.h.21.ln_1.weight', 'transformer.h.27.ln_1.weight', 'transformer.h.11.attn.attention.out_proj.weight', 'transformer.h.14.ln_2.weight', 'transformer.h.31.ln_1.bias', 'transformer.h.21.ln_2.bias', 'transformer.h.10.attn.attention.k_proj.weight', 'transformer.h.23.attn.attention.masked_bias', 'transformer.h.2.ln_1.bias', 'transformer.h.11.attn.attention.k_proj.weight', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.3.attn.attention.out_proj.weight', 'transformer.h.14.attn.attention.v_proj.weight', 'transformer.h.6.ln_1.weight', 'transformer.h.14.attn.attention.q_proj.weight', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.29.attn.attention.out_proj.weight', 'transformer.h.7.attn.attention.bias', 'transformer.h.24.mlp.c_fc.bias', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.23.attn.attention.out_proj.bias', 'transformer.h.3.attn.attention.masked_bias', 'transformer.h.17.attn.attention.out_proj.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.1.attn.attention.v_proj.weight', 'transformer.h.31.mlp.c_proj.weight', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.21.mlp.c_fc.bias', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.18.mlp.c_fc.weight', 'transformer.h.25.mlp.c_proj.bias', 'transformer.h.16.ln_1.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.28.attn.attention.bias', 'transformer.h.11.attn.attention.v_proj.weight', 'transformer.h.9.attn.attention.masked_bias', 'transformer.h.16.mlp.c_fc.bias', 'transformer.h.2.attn.attention.masked_bias', 'transformer.h.15.attn.attention.q_proj.weight', 'transformer.h.21.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.k_proj.weight', 'transformer.h.3.attn.attention.bias', 'transformer.h.5.attn.attention.v_proj.weight', 'transformer.h.6.attn.attention.k_proj.weight', 'transformer.h.2.ln_2.weight', 'transformer.h.27.mlp.c_proj.weight', 'transformer.h.9.attn.attention.bias', 'transformer.h.17.ln_2.bias', 'transformer.h.24.attn.attention.bias', 'transformer.h.20.attn.attention.k_proj.weight', 'transformer.h.21.mlp.c_fc.weight', 'transformer.h.10.ln_1.weight', 'transformer.h.9.attn.attention.out_proj.bias', 'transformer.h.8.attn.attention.q_proj.weight', 'transformer.h.5.attn.attention.out_proj.bias', 'transformer.h.14.ln_2.bias', 'transformer.h.29.mlp.c_proj.bias', 'transformer.h.15.ln_1.bias', 'transformer.h.25.mlp.c_fc.bias', 'transformer.h.23.ln_1.bias', 'transformer.h.25.mlp.c_fc.weight', 'transformer.h.8.attn.attention.out_proj.bias', 'transformer.h.3.attn.attention.q_proj.weight', 'transformer.h.25.attn.attention.masked_bias', 'transformer.h.17.attn.attention.bias', 'transformer.h.23.attn.attention.q_proj.weight', 'transformer.h.22.mlp.c_proj.bias', 'transformer.h.29.attn.attention.v_proj.weight', 'transformer.h.9.attn.attention.out_proj.weight', 'transformer.h.13.attn.attention.k_proj.weight', 'transformer.h.20.attn.attention.q_proj.weight', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.27.attn.attention.k_proj.weight', 'transformer.h.30.ln_1.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.15.ln_1.weight', 'transformer.h.27.attn.attention.bias', 'transformer.h.19.mlp.c_fc.weight', 'transformer.h.0.attn.attention.v_proj.weight', 'transformer.h.26.mlp.c_proj.bias', 'transformer.h.2.mlp.c_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2022-11-18 14:48:52,230][datasets.builder][WARNING] - Using custom data configuration ViktorThink--mountain_combined_813306-6918b9ea07482433
[2022-11-18 14:48:52,318][datasets.builder][WARNING] - Found cached dataset csv (/home/paperspace/.cache/huggingface/datasets/ViktorThink___csv/ViktorThink--mountain_combined_813306-6918b9ea07482433/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.96it/s]100%|██████████| 2/2 [00:00<00:00, 11.30it/s]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 1/814 [00:02<35:29,  2.62s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:04<32:35,  2.41s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:07<31:32,  2.33s/ba]Running tokenizer on dataset:   0%|          | 4/814 [00:09<30:30,  2.26s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:11<29:47,  2.21s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:13<28:57,  2.15s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:15<28:40,  2.13s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:17<28:16,  2.11s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:19<27:45,  2.07s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:21<27:18,  2.04s/ba]Running tokenizer on dataset:   1%|▏         | 11/814 [00:23<27:17,  2.04s/ba]Running tokenizer on dataset:   1%|▏         | 12/814 [00:26<29:54,  2.24s/ba]Running tokenizer on dataset:   2%|▏         | 13/814 [00:28<31:37,  2.37s/ba]Running tokenizer on dataset:   2%|▏         | 14/814 [00:31<32:10,  2.41s/ba]Running tokenizer on dataset:   2%|▏         | 15/814 [00:33<30:14,  2.27s/ba]Running tokenizer on dataset:   2%|▏         | 16/814 [00:35<28:55,  2.18s/ba]Running tokenizer on dataset:   2%|▏         | 17/814 [00:37<27:53,  2.10s/ba]Running tokenizer on dataset:   2%|▏         | 18/814 [00:39<27:06,  2.04s/ba]Running tokenizer on dataset:   2%|▏         | 19/814 [00:41<26:34,  2.01s/ba]Running tokenizer on dataset:   2%|▏         | 20/814 [00:43<26:17,  1.99s/ba]Running tokenizer on dataset:   3%|▎         | 21/814 [00:44<26:02,  1.97s/ba]Running tokenizer on dataset:   3%|▎         | 22/814 [00:46<25:36,  1.94s/ba]Running tokenizer on dataset:   3%|▎         | 23/814 [00:48<25:22,  1.92s/ba]Running tokenizer on dataset:   3%|▎         | 24/814 [00:51<27:03,  2.05s/ba]Running tokenizer on dataset:   3%|▎         | 25/814 [00:53<29:04,  2.21s/ba]Running tokenizer on dataset:   3%|▎         | 26/814 [00:56<30:16,  2.30s/ba]Running tokenizer on dataset:   3%|▎         | 27/814 [00:58<30:52,  2.35s/ba]Running tokenizer on dataset:   3%|▎         | 28/814 [01:01<31:50,  2.43s/ba]Running tokenizer on dataset:   4%|▎         | 29/814 [01:03<32:19,  2.47s/ba]Running tokenizer on dataset:   4%|▎         | 30/814 [01:06<32:36,  2.50s/ba]Running tokenizer on dataset:   4%|▍         | 31/814 [01:08<32:29,  2.49s/ba]Running tokenizer on dataset:   4%|▍         | 32/814 [01:11<32:58,  2.53s/ba]Running tokenizer on dataset:   4%|▍         | 33/814 [01:13<32:53,  2.53s/ba]Running tokenizer on dataset:   4%|▍         | 34/814 [01:16<32:39,  2.51s/ba]Running tokenizer on dataset:   4%|▍         | 35/814 [01:18<32:28,  2.50s/ba]Running tokenizer on dataset:   4%|▍         | 36/814 [01:21<32:11,  2.48s/ba]Running tokenizer on dataset:   5%|▍         | 37/814 [01:23<32:00,  2.47s/ba]Running tokenizer on dataset:   5%|▍         | 38/814 [01:26<31:41,  2.45s/ba]Running tokenizer on dataset:   5%|▍         | 39/814 [01:28<32:00,  2.48s/ba]Running tokenizer on dataset:   5%|▍         | 40/814 [01:31<32:02,  2.48s/ba]Running tokenizer on dataset:   5%|▌         | 41/814 [01:33<32:00,  2.48s/ba]Running tokenizer on dataset:   5%|▌         | 42/814 [01:36<32:02,  2.49s/ba]Running tokenizer on dataset:   5%|▌         | 43/814 [01:38<31:53,  2.48s/ba]Running tokenizer on dataset:   5%|▌         | 44/814 [01:41<32:17,  2.52s/ba]Running tokenizer on dataset:   6%|▌         | 45/814 [01:43<32:03,  2.50s/ba]Running tokenizer on dataset:   6%|▌         | 46/814 [01:46<31:46,  2.48s/ba]Running tokenizer on dataset:   6%|▌         | 47/814 [01:48<31:31,  2.47s/ba]Running tokenizer on dataset:   6%|▌         | 48/814 [01:51<31:12,  2.45s/ba]Running tokenizer on dataset:   6%|▌         | 49/814 [01:53<31:14,  2.45s/ba]Running tokenizer on dataset:   6%|▌         | 50/814 [01:55<31:11,  2.45s/ba]Running tokenizer on dataset:   6%|▋         | 51/814 [01:58<30:53,  2.43s/ba]Running tokenizer on dataset:   6%|▋         | 52/814 [02:00<31:06,  2.45s/ba]Running tokenizer on dataset:   7%|▋         | 53/814 [02:03<31:00,  2.44s/ba]Running tokenizer on dataset:   7%|▋         | 54/814 [02:05<31:18,  2.47s/ba]Running tokenizer on dataset:   7%|▋         | 55/814 [02:08<31:15,  2.47s/ba]Running tokenizer on dataset:   7%|▋         | 56/814 [02:10<31:16,  2.48s/ba]Running tokenizer on dataset:   7%|▋         | 57/814 [02:13<31:32,  2.50s/ba]Running tokenizer on dataset:   7%|▋         | 58/814 [02:15<31:13,  2.48s/ba]Running tokenizer on dataset:   7%|▋         | 59/814 [02:18<31:03,  2.47s/ba]Running tokenizer on dataset:   7%|▋         | 60/814 [02:20<30:49,  2.45s/ba]Running tokenizer on dataset:   7%|▋         | 61/814 [02:23<30:45,  2.45s/ba]Running tokenizer on dataset:   8%|▊         | 62/814 [02:25<30:51,  2.46s/ba]Running tokenizer on dataset:   8%|▊         | 63/814 [02:27<30:43,  2.45s/ba]Running tokenizer on dataset:   8%|▊         | 64/814 [02:30<30:30,  2.44s/ba]Running tokenizer on dataset:   8%|▊         | 65/814 [02:32<30:39,  2.46s/ba]Running tokenizer on dataset:   8%|▊         | 66/814 [02:35<30:41,  2.46s/ba]Running tokenizer on dataset:   8%|▊         | 67/814 [02:37<30:21,  2.44s/ba]Running tokenizer on dataset:   8%|▊         | 68/814 [02:40<30:14,  2.43s/ba]Running tokenizer on dataset:   8%|▊         | 69/814 [02:42<29:59,  2.42s/ba]Running tokenizer on dataset:   9%|▊         | 70/814 [02:44<29:53,  2.41s/ba]Running tokenizer on dataset:   9%|▊         | 71/814 [02:47<29:43,  2.40s/ba]Running tokenizer on dataset:   9%|▉         | 72/814 [02:50<32:39,  2.64s/ba]Running tokenizer on dataset:   9%|▉         | 73/814 [02:52<31:40,  2.57s/ba]Running tokenizer on dataset:   9%|▉         | 74/814 [02:55<30:58,  2.51s/ba]Running tokenizer on dataset:   9%|▉         | 75/814 [02:57<30:28,  2.47s/ba]Running tokenizer on dataset:   9%|▉         | 76/814 [03:00<30:58,  2.52s/ba]Running tokenizer on dataset:   9%|▉         | 77/814 [03:02<30:29,  2.48s/ba]Running tokenizer on dataset:  10%|▉         | 78/814 [03:05<30:23,  2.48s/ba]Running tokenizer on dataset:  10%|▉         | 79/814 [03:07<30:01,  2.45s/ba]Running tokenizer on dataset:  10%|▉         | 80/814 [03:09<29:50,  2.44s/ba]Running tokenizer on dataset:  10%|▉         | 81/814 [03:12<29:52,  2.45s/ba]Running tokenizer on dataset:  10%|█         | 82/814 [03:14<30:10,  2.47s/ba]Running tokenizer on dataset:  10%|█         | 83/814 [03:17<29:53,  2.45s/ba]Running tokenizer on dataset:  10%|█         | 84/814 [03:19<29:44,  2.44s/ba]Running tokenizer on dataset:  10%|█         | 85/814 [03:22<29:43,  2.45s/ba]Running tokenizer on dataset:  11%|█         | 86/814 [03:24<29:30,  2.43s/ba]Running tokenizer on dataset:  11%|█         | 87/814 [03:27<29:27,  2.43s/ba]Running tokenizer on dataset:  11%|█         | 88/814 [03:29<29:20,  2.42s/ba]Running tokenizer on dataset:  11%|█         | 89/814 [03:31<29:23,  2.43s/ba]Running tokenizer on dataset:  11%|█         | 90/814 [03:34<29:12,  2.42s/ba]Running tokenizer on dataset:  11%|█         | 91/814 [03:36<29:10,  2.42s/ba]Running tokenizer on dataset:  11%|█▏        | 92/814 [03:39<28:53,  2.40s/ba]Running tokenizer on dataset:  11%|█▏        | 93/814 [03:41<28:57,  2.41s/ba]Running tokenizer on dataset:  12%|█▏        | 94/814 [03:43<28:51,  2.41s/ba]Running tokenizer on dataset:  12%|█▏        | 95/814 [03:46<28:39,  2.39s/ba]Running tokenizer on dataset:  12%|█▏        | 96/814 [03:48<28:48,  2.41s/ba]Running tokenizer on dataset:  12%|█▏        | 97/814 [03:51<28:50,  2.41s/ba]Running tokenizer on dataset:  12%|█▏        | 98/814 [03:53<28:51,  2.42s/ba]Running tokenizer on dataset:  12%|█▏        | 99/814 [03:56<28:53,  2.42s/ba]Running tokenizer on dataset:  12%|█▏        | 100/814 [03:58<28:41,  2.41s/ba]Running tokenizer on dataset:  12%|█▏        | 101/814 [04:00<28:34,  2.40s/ba]Running tokenizer on dataset:  13%|█▎        | 102/814 [04:03<28:25,  2.40s/ba]Running tokenizer on dataset:  13%|█▎        | 103/814 [04:05<28:29,  2.40s/ba]Running tokenizer on dataset:  13%|█▎        | 104/814 [04:07<28:20,  2.39s/ba]Running tokenizer on dataset:  13%|█▎        | 105/814 [04:10<28:15,  2.39s/ba]Running tokenizer on dataset:  13%|█▎        | 106/814 [04:12<28:18,  2.40s/ba]Running tokenizer on dataset:  13%|█▎        | 107/814 [04:15<28:15,  2.40s/ba]Running tokenizer on dataset:  13%|█▎        | 108/814 [04:17<28:19,  2.41s/ba]Running tokenizer on dataset:  13%|█▎        | 109/814 [04:20<28:25,  2.42s/ba]Running tokenizer on dataset:  14%|█▎        | 110/814 [04:22<28:11,  2.40s/ba]Running tokenizer on dataset:  14%|█▎        | 111/814 [04:24<28:06,  2.40s/ba]Running tokenizer on dataset:  14%|█▍        | 112/814 [04:27<28:01,  2.40s/ba]Running tokenizer on dataset:  14%|█▍        | 113/814 [04:29<27:57,  2.39s/ba]Running tokenizer on dataset:  14%|█▍        | 114/814 [04:31<28:01,  2.40s/ba]Running tokenizer on dataset:  14%|█▍        | 115/814 [04:34<28:08,  2.42s/ba]Running tokenizer on dataset:  14%|█▍        | 116/814 [04:36<28:03,  2.41s/ba]Running tokenizer on dataset:  14%|█▍        | 117/814 [04:39<28:04,  2.42s/ba]Running tokenizer on dataset:  14%|█▍        | 118/814 [04:41<28:16,  2.44s/ba]Running tokenizer on dataset:  15%|█▍        | 119/814 [04:44<27:45,  2.40s/ba]Running tokenizer on dataset:  15%|█▍        | 120/814 [04:46<27:32,  2.38s/ba]Running tokenizer on dataset:  15%|█▍        | 121/814 [04:48<27:53,  2.42s/ba]Running tokenizer on dataset:  15%|█▍        | 122/814 [04:51<27:43,  2.40s/ba]Running tokenizer on dataset:  15%|█▌        | 123/814 [04:53<27:33,  2.39s/ba]Running tokenizer on dataset:  15%|█▌        | 124/814 [04:56<27:31,  2.39s/ba]Running tokenizer on dataset:  15%|█▌        | 125/814 [04:58<27:23,  2.39s/ba]Running tokenizer on dataset:  15%|█▌        | 126/814 [05:00<27:30,  2.40s/ba]Running tokenizer on dataset:  16%|█▌        | 127/814 [05:03<27:30,  2.40s/ba]Running tokenizer on dataset:  16%|█▌        | 128/814 [05:05<27:10,  2.38s/ba]Running tokenizer on dataset:  16%|█▌        | 129/814 [05:08<27:23,  2.40s/ba]Running tokenizer on dataset:  16%|█▌        | 130/814 [05:10<27:04,  2.38s/ba]Running tokenizer on dataset:  16%|█▌        | 131/814 [05:12<27:13,  2.39s/ba]Running tokenizer on dataset:  16%|█▌        | 132/814 [05:15<27:00,  2.38s/ba]Running tokenizer on dataset:  16%|█▋        | 133/814 [05:17<27:00,  2.38s/ba]Running tokenizer on dataset:  16%|█▋        | 134/814 [05:19<26:47,  2.36s/ba]Running tokenizer on dataset:  17%|█▋        | 135/814 [05:22<26:46,  2.37s/ba]Running tokenizer on dataset:  17%|█▋        | 136/814 [05:24<26:46,  2.37s/ba]Running tokenizer on dataset:  17%|█▋        | 137/814 [05:26<26:47,  2.37s/ba]Running tokenizer on dataset:  17%|█▋        | 138/814 [05:29<26:52,  2.39s/ba]Running tokenizer on dataset:  17%|█▋        | 139/814 [05:31<26:42,  2.37s/ba]Running tokenizer on dataset:  17%|█▋        | 140/814 [05:34<26:36,  2.37s/ba]Running tokenizer on dataset:  17%|█▋        | 141/814 [05:36<26:36,  2.37s/ba]Running tokenizer on dataset:  17%|█▋        | 142/814 [05:38<26:46,  2.39s/ba]Running tokenizer on dataset:  18%|█▊        | 143/814 [05:41<26:39,  2.38s/ba]Running tokenizer on dataset:  18%|█▊        | 144/814 [05:43<26:38,  2.39s/ba]Running tokenizer on dataset:  18%|█▊        | 145/814 [05:46<26:31,  2.38s/ba]Running tokenizer on dataset:  18%|█▊        | 146/814 [05:48<26:12,  2.35s/ba]Running tokenizer on dataset:  18%|█▊        | 147/814 [05:50<26:26,  2.38s/ba]Running tokenizer on dataset:  18%|█▊        | 148/814 [05:53<26:25,  2.38s/ba]Running tokenizer on dataset:  18%|█▊        | 149/814 [05:55<26:02,  2.35s/ba]Running tokenizer on dataset:  18%|█▊        | 150/814 [05:57<25:55,  2.34s/ba]Running tokenizer on dataset:  19%|█▊        | 151/814 [06:00<25:43,  2.33s/ba]Running tokenizer on dataset:  19%|█▊        | 152/814 [06:02<25:40,  2.33s/ba]Running tokenizer on dataset:  19%|█▉        | 153/814 [06:04<25:53,  2.35s/ba]Running tokenizer on dataset:  19%|█▉        | 154/814 [06:07<25:59,  2.36s/ba]Running tokenizer on dataset:  19%|█▉        | 155/814 [06:09<25:53,  2.36s/ba]Running tokenizer on dataset:  19%|█▉        | 156/814 [06:11<25:53,  2.36s/ba]Running tokenizer on dataset:  19%|█▉        | 157/814 [06:14<26:20,  2.41s/ba]Running tokenizer on dataset:  19%|█▉        | 158/814 [06:16<26:05,  2.39s/ba]Running tokenizer on dataset:  20%|█▉        | 159/814 [06:19<25:54,  2.37s/ba]Running tokenizer on dataset:  20%|█▉        | 160/814 [06:21<25:49,  2.37s/ba]Running tokenizer on dataset:  20%|█▉        | 161/814 [06:23<25:37,  2.35s/ba]Running tokenizer on dataset:  20%|█▉        | 162/814 [06:26<25:43,  2.37s/ba]Running tokenizer on dataset:  20%|██        | 163/814 [06:28<25:41,  2.37s/ba]Running tokenizer on dataset:  20%|██        | 164/814 [06:30<25:49,  2.38s/ba]Running tokenizer on dataset:  20%|██        | 165/814 [06:33<25:58,  2.40s/ba]Running tokenizer on dataset:  20%|██        | 166/814 [06:35<25:57,  2.40s/ba]Running tokenizer on dataset:  21%|██        | 167/814 [06:38<25:45,  2.39s/ba]Running tokenizer on dataset:  21%|██        | 168/814 [06:40<25:31,  2.37s/ba]Running tokenizer on dataset:  21%|██        | 169/814 [06:42<25:29,  2.37s/ba]Running tokenizer on dataset:  21%|██        | 170/814 [06:45<25:19,  2.36s/ba]Running tokenizer on dataset:  21%|██        | 171/814 [06:47<25:15,  2.36s/ba]Running tokenizer on dataset:  21%|██        | 172/814 [06:49<25:17,  2.36s/ba]Running tokenizer on dataset:  21%|██▏       | 173/814 [06:52<25:33,  2.39s/ba]Running tokenizer on dataset:  21%|██▏       | 174/814 [06:54<25:30,  2.39s/ba]Running tokenizer on dataset:  21%|██▏       | 175/814 [06:57<25:19,  2.38s/ba]Running tokenizer on dataset:  22%|██▏       | 176/814 [06:59<25:07,  2.36s/ba]Running tokenizer on dataset:  22%|██▏       | 177/814 [07:01<25:08,  2.37s/ba]Running tokenizer on dataset:  22%|██▏       | 178/814 [07:04<25:11,  2.38s/ba]Running tokenizer on dataset:  22%|██▏       | 179/814 [07:06<25:08,  2.37s/ba]Running tokenizer on dataset:  22%|██▏       | 180/814 [07:08<25:00,  2.37s/ba]Running tokenizer on dataset:  22%|██▏       | 181/814 [07:11<24:59,  2.37s/ba]Running tokenizer on dataset:  22%|██▏       | 182/814 [07:13<25:00,  2.37s/ba]Running tokenizer on dataset:  22%|██▏       | 183/814 [07:16<24:59,  2.38s/ba]Running tokenizer on dataset:  23%|██▎       | 184/814 [07:18<24:49,  2.36s/ba]Running tokenizer on dataset:  23%|██▎       | 185/814 [07:20<24:39,  2.35s/ba]Running tokenizer on dataset:  23%|██▎       | 186/814 [07:23<24:41,  2.36s/ba]Running tokenizer on dataset:  23%|██▎       | 187/814 [07:25<24:27,  2.34s/ba]Running tokenizer on dataset:  23%|██▎       | 188/814 [07:27<24:20,  2.33s/ba]Running tokenizer on dataset:  23%|██▎       | 189/814 [07:30<24:15,  2.33s/ba]Running tokenizer on dataset:  23%|██▎       | 190/814 [07:32<24:12,  2.33s/ba]Running tokenizer on dataset:  23%|██▎       | 191/814 [07:34<24:28,  2.36s/ba]Running tokenizer on dataset:  24%|██▎       | 192/814 [07:37<24:22,  2.35s/ba]Running tokenizer on dataset:  24%|██▎       | 193/814 [07:39<24:22,  2.36s/ba]Running tokenizer on dataset:  24%|██▍       | 194/814 [07:41<24:15,  2.35s/ba]Running tokenizer on dataset:  24%|██▍       | 195/814 [07:44<24:16,  2.35s/ba]Running tokenizer on dataset:  24%|██▍       | 196/814 [07:46<24:07,  2.34s/ba]Running tokenizer on dataset:  24%|██▍       | 197/814 [07:48<24:05,  2.34s/ba]Running tokenizer on dataset:  24%|██▍       | 198/814 [07:51<24:14,  2.36s/ba]Running tokenizer on dataset:  24%|██▍       | 199/814 [07:53<24:02,  2.34s/ba]Running tokenizer on dataset:  25%|██▍       | 200/814 [07:55<23:53,  2.33s/ba]Running tokenizer on dataset:  25%|██▍       | 201/814 [07:58<23:46,  2.33s/ba]Running tokenizer on dataset:  25%|██▍       | 202/814 [08:00<23:46,  2.33s/ba]Running tokenizer on dataset:  25%|██▍       | 203/814 [08:02<23:44,  2.33s/ba]Running tokenizer on dataset:  25%|██▌       | 204/814 [08:05<23:47,  2.34s/ba]Running tokenizer on dataset:  25%|██▌       | 205/814 [08:07<23:35,  2.33s/ba]Running tokenizer on dataset:  25%|██▌       | 206/814 [08:09<23:40,  2.34s/ba]Running tokenizer on dataset:  25%|██▌       | 207/814 [08:12<23:40,  2.34s/ba]Running tokenizer on dataset:  26%|██▌       | 208/814 [08:14<23:33,  2.33s/ba]Running tokenizer on dataset:  26%|██▌       | 209/814 [08:16<23:32,  2.33s/ba]Running tokenizer on dataset:  26%|██▌       | 210/814 [08:19<23:34,  2.34s/ba]Running tokenizer on dataset:  26%|██▌       | 211/814 [08:21<23:32,  2.34s/ba]Running tokenizer on dataset:  26%|██▌       | 212/814 [08:23<23:15,  2.32s/ba]Running tokenizer on dataset:  26%|██▌       | 213/814 [08:26<23:08,  2.31s/ba]Running tokenizer on dataset:  26%|██▋       | 214/814 [08:28<22:57,  2.30s/ba]Running tokenizer on dataset:  26%|██▋       | 215/814 [08:30<23:08,  2.32s/ba]Running tokenizer on dataset:  27%|██▋       | 216/814 [08:33<23:05,  2.32s/ba]Running tokenizer on dataset:  27%|██▋       | 217/814 [08:35<23:17,  2.34s/ba]Running tokenizer on dataset:  27%|██▋       | 218/814 [08:37<23:18,  2.35s/ba]Running tokenizer on dataset:  27%|██▋       | 219/814 [08:40<23:22,  2.36s/ba]Running tokenizer on dataset:  27%|██▋       | 220/814 [08:42<23:12,  2.34s/ba]Running tokenizer on dataset:  27%|██▋       | 221/814 [08:44<23:13,  2.35s/ba]Running tokenizer on dataset:  27%|██▋       | 222/814 [08:47<22:59,  2.33s/ba]Running tokenizer on dataset:  27%|██▋       | 223/814 [08:49<23:00,  2.34s/ba]Running tokenizer on dataset:  28%|██▊       | 224/814 [08:51<23:00,  2.34s/ba]Running tokenizer on dataset:  28%|██▊       | 225/814 [08:54<23:01,  2.35s/ba]Running tokenizer on dataset:  28%|██▊       | 226/814 [08:56<22:59,  2.35s/ba]Running tokenizer on dataset:  28%|██▊       | 227/814 [08:58<23:00,  2.35s/ba]Running tokenizer on dataset:  28%|██▊       | 228/814 [09:01<22:43,  2.33s/ba]Running tokenizer on dataset:  28%|██▊       | 229/814 [09:03<22:49,  2.34s/ba]Running tokenizer on dataset:  28%|██▊       | 230/814 [09:05<22:44,  2.34s/ba]Running tokenizer on dataset:  28%|██▊       | 231/814 [09:08<22:42,  2.34s/ba]Running tokenizer on dataset:  29%|██▊       | 232/814 [09:10<22:31,  2.32s/ba]Running tokenizer on dataset:  29%|██▊       | 233/814 [09:12<22:37,  2.34s/ba]Running tokenizer on dataset:  29%|██▊       | 234/814 [09:15<22:36,  2.34s/ba]Running tokenizer on dataset:  29%|██▉       | 235/814 [09:17<22:43,  2.35s/ba]Running tokenizer on dataset:  29%|██▉       | 236/814 [09:19<22:39,  2.35s/ba]Running tokenizer on dataset:  29%|██▉       | 237/814 [09:22<22:31,  2.34s/ba]Running tokenizer on dataset:  29%|██▉       | 238/814 [09:24<23:00,  2.40s/ba]Running tokenizer on dataset:  29%|██▉       | 239/814 [09:27<22:49,  2.38s/ba]Running tokenizer on dataset:  29%|██▉       | 240/814 [09:29<22:39,  2.37s/ba]Running tokenizer on dataset:  30%|██▉       | 241/814 [09:31<22:27,  2.35s/ba]Running tokenizer on dataset:  30%|██▉       | 242/814 [09:34<22:17,  2.34s/ba]Running tokenizer on dataset:  30%|██▉       | 243/814 [09:36<22:07,  2.33s/ba]Running tokenizer on dataset:  30%|██▉       | 244/814 [09:38<22:23,  2.36s/ba]Running tokenizer on dataset:  30%|███       | 245/814 [09:41<22:18,  2.35s/ba]Running tokenizer on dataset:  30%|███       | 246/814 [09:43<22:23,  2.37s/ba]Running tokenizer on dataset:  30%|███       | 247/814 [09:45<22:17,  2.36s/ba]Running tokenizer on dataset:  30%|███       | 248/814 [09:48<22:00,  2.33s/ba]Running tokenizer on dataset:  31%|███       | 249/814 [09:50<22:08,  2.35s/ba]Running tokenizer on dataset:  31%|███       | 250/814 [09:52<22:04,  2.35s/ba]Running tokenizer on dataset:  31%|███       | 251/814 [09:55<22:00,  2.35s/ba]Running tokenizer on dataset:  31%|███       | 252/814 [09:57<21:55,  2.34s/ba]Running tokenizer on dataset:  31%|███       | 253/814 [09:59<22:01,  2.35s/ba]Running tokenizer on dataset:  31%|███       | 254/814 [10:02<21:58,  2.35s/ba]Running tokenizer on dataset:  31%|███▏      | 255/814 [10:04<21:52,  2.35s/ba]Running tokenizer on dataset:  31%|███▏      | 256/814 [10:06<21:39,  2.33s/ba]Running tokenizer on dataset:  32%|███▏      | 257/814 [10:09<21:30,  2.32s/ba]Running tokenizer on dataset:  32%|███▏      | 258/814 [10:11<21:35,  2.33s/ba]Running tokenizer on dataset:  32%|███▏      | 259/814 [10:13<21:30,  2.32s/ba]Running tokenizer on dataset:  32%|███▏      | 260/814 [10:16<21:31,  2.33s/ba]Running tokenizer on dataset:  32%|███▏      | 261/814 [10:18<21:29,  2.33s/ba]Running tokenizer on dataset:  32%|███▏      | 262/814 [10:20<21:33,  2.34s/ba]Running tokenizer on dataset:  32%|███▏      | 263/814 [10:23<21:32,  2.35s/ba]Running tokenizer on dataset:  32%|███▏      | 264/814 [10:25<21:27,  2.34s/ba]Running tokenizer on dataset:  33%|███▎      | 265/814 [10:27<21:25,  2.34s/ba]Running tokenizer on dataset:  33%|███▎      | 266/814 [10:30<21:26,  2.35s/ba]Running tokenizer on dataset:  33%|███▎      | 267/814 [10:32<21:16,  2.33s/ba]Running tokenizer on dataset:  33%|███▎      | 268/814 [10:34<21:06,  2.32s/ba]Running tokenizer on dataset:  33%|███▎      | 269/814 [10:37<21:07,  2.33s/ba]Running tokenizer on dataset:  33%|███▎      | 270/814 [10:39<21:05,  2.33s/ba]Running tokenizer on dataset:  33%|███▎      | 271/814 [10:41<21:00,  2.32s/ba]Running tokenizer on dataset:  33%|███▎      | 272/814 [10:44<20:58,  2.32s/ba]Running tokenizer on dataset:  34%|███▎      | 273/814 [10:46<21:01,  2.33s/ba]Running tokenizer on dataset:  34%|███▎      | 274/814 [10:48<20:48,  2.31s/ba]Running tokenizer on dataset:  34%|███▍      | 275/814 [10:51<20:42,  2.31s/ba]Running tokenizer on dataset:  34%|███▍      | 276/814 [10:53<20:47,  2.32s/ba]Running tokenizer on dataset:  34%|███▍      | 277/814 [10:55<20:48,  2.32s/ba]Running tokenizer on dataset:  34%|███▍      | 278/814 [10:58<20:47,  2.33s/ba]Running tokenizer on dataset:  34%|███▍      | 279/814 [11:00<20:40,  2.32s/ba]Running tokenizer on dataset:  34%|███▍      | 280/814 [11:02<20:35,  2.31s/ba]Running tokenizer on dataset:  35%|███▍      | 281/814 [11:05<20:34,  2.32s/ba]Running tokenizer on dataset:  35%|███▍      | 282/814 [11:07<20:37,  2.33s/ba]Running tokenizer on dataset:  35%|███▍      | 283/814 [11:09<20:33,  2.32s/ba]Running tokenizer on dataset:  35%|███▍      | 284/814 [11:12<20:31,  2.32s/ba]Running tokenizer on dataset:  35%|███▌      | 285/814 [11:14<20:24,  2.32s/ba]Running tokenizer on dataset:  35%|███▌      | 286/814 [11:16<20:21,  2.31s/ba]Running tokenizer on dataset:  35%|███▌      | 287/814 [11:19<20:24,  2.32s/ba]Running tokenizer on dataset:  35%|███▌      | 288/814 [11:21<20:21,  2.32s/ba]Running tokenizer on dataset:  36%|███▌      | 289/814 [11:23<20:27,  2.34s/ba]Running tokenizer on dataset:  36%|███▌      | 290/814 [11:26<20:20,  2.33s/ba]Running tokenizer on dataset:  36%|███▌      | 291/814 [11:28<20:17,  2.33s/ba]Running tokenizer on dataset:  36%|███▌      | 292/814 [11:30<20:14,  2.33s/ba]Running tokenizer on dataset:  36%|███▌      | 293/814 [11:33<20:14,  2.33s/ba]Running tokenizer on dataset:  36%|███▌      | 294/814 [11:35<20:09,  2.33s/ba]Running tokenizer on dataset:  36%|███▌      | 295/814 [11:37<20:02,  2.32s/ba]Running tokenizer on dataset:  36%|███▋      | 296/814 [11:39<20:04,  2.33s/ba]Running tokenizer on dataset:  36%|███▋      | 297/814 [11:42<20:09,  2.34s/ba]Running tokenizer on dataset:  37%|███▋      | 298/814 [11:44<20:09,  2.34s/ba]Running tokenizer on dataset:  37%|███▋      | 299/814 [11:47<20:05,  2.34s/ba]Running tokenizer on dataset:  37%|███▋      | 300/814 [11:49<20:04,  2.34s/ba]Running tokenizer on dataset:  37%|███▋      | 301/814 [11:51<19:55,  2.33s/ba]Running tokenizer on dataset:  37%|███▋      | 302/814 [11:53<19:39,  2.30s/ba]Running tokenizer on dataset:  37%|███▋      | 303/814 [11:56<19:43,  2.32s/ba]Running tokenizer on dataset:  37%|███▋      | 304/814 [11:58<19:43,  2.32s/ba]Running tokenizer on dataset:  37%|███▋      | 305/814 [12:00<19:40,  2.32s/ba]Running tokenizer on dataset:  38%|███▊      | 306/814 [12:03<19:35,  2.31s/ba]Running tokenizer on dataset:  38%|███▊      | 307/814 [12:05<19:34,  2.32s/ba]Running tokenizer on dataset:  38%|███▊      | 308/814 [12:07<19:31,  2.31s/ba]Running tokenizer on dataset:  38%|███▊      | 309/814 [12:10<19:34,  2.33s/ba]Running tokenizer on dataset:  38%|███▊      | 310/814 [12:12<19:45,  2.35s/ba]Running tokenizer on dataset:  38%|███▊      | 311/814 [12:14<19:37,  2.34s/ba]Running tokenizer on dataset:  38%|███▊      | 312/814 [12:17<19:31,  2.33s/ba]Running tokenizer on dataset:  38%|███▊      | 313/814 [12:19<19:20,  2.32s/ba]Running tokenizer on dataset:  39%|███▊      | 314/814 [12:21<19:33,  2.35s/ba]Running tokenizer on dataset:  39%|███▊      | 315/814 [12:24<19:29,  2.34s/ba]Running tokenizer on dataset:  39%|███▉      | 316/814 [12:26<19:20,  2.33s/ba]Running tokenizer on dataset:  39%|███▉      | 317/814 [12:28<19:10,  2.32s/ba]Running tokenizer on dataset:  39%|███▉      | 318/814 [12:31<19:02,  2.30s/ba]Running tokenizer on dataset:  39%|███▉      | 319/814 [12:33<19:26,  2.36s/ba]Running tokenizer on dataset:  39%|███▉      | 320/814 [12:35<19:07,  2.32s/ba]Running tokenizer on dataset:  39%|███▉      | 321/814 [12:38<19:04,  2.32s/ba]Running tokenizer on dataset:  40%|███▉      | 322/814 [12:40<19:06,  2.33s/ba]Running tokenizer on dataset:  40%|███▉      | 323/814 [12:42<19:05,  2.33s/ba]Running tokenizer on dataset:  40%|███▉      | 324/814 [12:45<18:59,  2.33s/ba]Running tokenizer on dataset:  40%|███▉      | 325/814 [12:47<18:57,  2.33s/ba]Running tokenizer on dataset:  40%|████      | 326/814 [12:49<18:53,  2.32s/ba]Running tokenizer on dataset:  40%|████      | 327/814 [12:52<18:47,  2.32s/ba]Running tokenizer on dataset:  40%|████      | 328/814 [12:54<18:48,  2.32s/ba]Running tokenizer on dataset:  40%|████      | 329/814 [12:56<18:51,  2.33s/ba]Running tokenizer on dataset:  41%|████      | 330/814 [12:59<18:47,  2.33s/ba]Running tokenizer on dataset:  41%|████      | 331/814 [13:01<18:51,  2.34s/ba]Running tokenizer on dataset:  41%|████      | 332/814 [13:03<18:47,  2.34s/ba]Running tokenizer on dataset:  41%|████      | 333/814 [13:06<18:40,  2.33s/ba]Running tokenizer on dataset:  41%|████      | 334/814 [13:08<18:40,  2.34s/ba]Running tokenizer on dataset:  41%|████      | 335/814 [13:10<18:38,  2.34s/ba]Running tokenizer on dataset:  41%|████▏     | 336/814 [13:13<18:38,  2.34s/ba]Running tokenizer on dataset:  41%|████▏     | 337/814 [13:15<18:37,  2.34s/ba]Running tokenizer on dataset:  42%|████▏     | 338/814 [13:17<18:23,  2.32s/ba]Running tokenizer on dataset:  42%|████▏     | 339/814 [13:20<18:13,  2.30s/ba]Running tokenizer on dataset:  42%|████▏     | 340/814 [13:22<18:17,  2.31s/ba]Running tokenizer on dataset:  42%|████▏     | 341/814 [13:24<18:19,  2.32s/ba]Running tokenizer on dataset:  42%|████▏     | 342/814 [13:27<18:08,  2.31s/ba]Running tokenizer on dataset:  42%|████▏     | 343/814 [13:29<18:09,  2.31s/ba]Running tokenizer on dataset:  42%|████▏     | 344/814 [13:31<18:01,  2.30s/ba]Running tokenizer on dataset:  42%|████▏     | 345/814 [13:33<18:03,  2.31s/ba]Running tokenizer on dataset:  43%|████▎     | 346/814 [13:36<17:59,  2.31s/ba]Running tokenizer on dataset:  43%|████▎     | 347/814 [13:38<18:07,  2.33s/ba]Running tokenizer on dataset:  43%|████▎     | 348/814 [13:40<18:00,  2.32s/ba]Running tokenizer on dataset:  43%|████▎     | 349/814 [13:43<17:53,  2.31s/ba]Running tokenizer on dataset:  43%|████▎     | 350/814 [13:45<17:55,  2.32s/ba]Running tokenizer on dataset:  43%|████▎     | 351/814 [13:47<17:46,  2.30s/ba]Running tokenizer on dataset:  43%|████▎     | 352/814 [13:50<17:39,  2.29s/ba]Running tokenizer on dataset:  43%|████▎     | 353/814 [13:52<17:45,  2.31s/ba]Running tokenizer on dataset:  43%|████▎     | 354/814 [13:54<17:32,  2.29s/ba]Running tokenizer on dataset:  44%|████▎     | 355/814 [13:57<18:05,  2.37s/ba]Running tokenizer on dataset:  44%|████▎     | 356/814 [13:59<18:02,  2.36s/ba]Running tokenizer on dataset:  44%|████▍     | 357/814 [14:01<17:47,  2.34s/ba]Running tokenizer on dataset:  44%|████▍     | 358/814 [14:04<17:44,  2.34s/ba]Running tokenizer on dataset:  44%|████▍     | 359/814 [14:06<17:38,  2.33s/ba]Running tokenizer on dataset:  44%|████▍     | 360/814 [14:08<17:31,  2.32s/ba]Running tokenizer on dataset:  44%|████▍     | 361/814 [14:11<17:19,  2.29s/ba]Running tokenizer on dataset:  44%|████▍     | 362/814 [14:13<17:17,  2.29s/ba]Running tokenizer on dataset:  45%|████▍     | 363/814 [14:15<17:11,  2.29s/ba]Running tokenizer on dataset:  45%|████▍     | 364/814 [14:17<17:09,  2.29s/ba]Running tokenizer on dataset:  45%|████▍     | 365/814 [14:20<17:08,  2.29s/ba]Running tokenizer on dataset:  45%|████▍     | 366/814 [14:22<17:18,  2.32s/ba]Running tokenizer on dataset:  45%|████▌     | 367/814 [14:24<17:12,  2.31s/ba]Running tokenizer on dataset:  45%|████▌     | 368/814 [14:27<17:00,  2.29s/ba]Running tokenizer on dataset:  45%|████▌     | 369/814 [14:29<17:01,  2.30s/ba]Running tokenizer on dataset:  45%|████▌     | 370/814 [14:31<17:01,  2.30s/ba]Running tokenizer on dataset:  46%|████▌     | 371/814 [14:34<16:57,  2.30s/ba]Running tokenizer on dataset:  46%|████▌     | 372/814 [14:36<16:47,  2.28s/ba]Running tokenizer on dataset:  46%|████▌     | 373/814 [14:38<16:49,  2.29s/ba]Running tokenizer on dataset:  46%|████▌     | 374/814 [14:40<16:51,  2.30s/ba]Running tokenizer on dataset:  46%|████▌     | 375/814 [14:43<16:55,  2.31s/ba]Running tokenizer on dataset:  46%|████▌     | 376/814 [14:45<16:59,  2.33s/ba]Running tokenizer on dataset:  46%|████▋     | 377/814 [14:47<16:52,  2.32s/ba]Running tokenizer on dataset:  46%|████▋     | 378/814 [14:50<16:44,  2.30s/ba]Running tokenizer on dataset:  47%|████▋     | 379/814 [14:52<16:40,  2.30s/ba]Running tokenizer on dataset:  47%|████▋     | 380/814 [14:54<16:39,  2.30s/ba]Running tokenizer on dataset:  47%|████▋     | 381/814 [14:57<16:39,  2.31s/ba]Running tokenizer on dataset:  47%|████▋     | 382/814 [14:59<16:31,  2.29s/ba]Running tokenizer on dataset:  47%|████▋     | 383/814 [15:01<16:23,  2.28s/ba]Running tokenizer on dataset:  47%|████▋     | 384/814 [15:03<16:34,  2.31s/ba]Running tokenizer on dataset:  47%|████▋     | 385/814 [15:06<16:36,  2.32s/ba]Running tokenizer on dataset:  47%|████▋     | 386/814 [15:08<16:30,  2.32s/ba]Running tokenizer on dataset:  48%|████▊     | 387/814 [15:10<16:26,  2.31s/ba]Running tokenizer on dataset:  48%|████▊     | 388/814 [15:13<16:18,  2.30s/ba]Running tokenizer on dataset:  48%|████▊     | 389/814 [15:15<16:20,  2.31s/ba]Running tokenizer on dataset:  48%|████▊     | 390/814 [15:17<16:15,  2.30s/ba]Running tokenizer on dataset:  48%|████▊     | 391/814 [15:20<16:11,  2.30s/ba]Running tokenizer on dataset:  48%|████▊     | 392/814 [15:22<16:15,  2.31s/ba]Running tokenizer on dataset:  48%|████▊     | 393/814 [15:24<16:13,  2.31s/ba]Running tokenizer on dataset:  48%|████▊     | 394/814 [15:27<16:14,  2.32s/ba]Running tokenizer on dataset:  49%|████▊     | 395/814 [15:29<16:09,  2.31s/ba]Running tokenizer on dataset:  49%|████▊     | 396/814 [15:31<16:05,  2.31s/ba]Running tokenizer on dataset:  49%|████▉     | 397/814 [15:33<15:59,  2.30s/ba]Running tokenizer on dataset:  49%|████▉     | 398/814 [15:36<16:03,  2.32s/ba]Running tokenizer on dataset:  49%|████▉     | 399/814 [15:38<15:54,  2.30s/ba]Running tokenizer on dataset:  49%|████▉     | 400/814 [15:41<16:13,  2.35s/ba]Running tokenizer on dataset:  49%|████▉     | 401/814 [15:43<16:00,  2.33s/ba]Running tokenizer on dataset:  49%|████▉     | 402/814 [15:45<15:54,  2.32s/ba]Running tokenizer on dataset:  50%|████▉     | 403/814 [15:47<15:51,  2.31s/ba]Running tokenizer on dataset:  50%|████▉     | 404/814 [15:50<15:48,  2.31s/ba]Running tokenizer on dataset:  50%|████▉     | 405/814 [15:52<15:50,  2.32s/ba]Running tokenizer on dataset:  50%|████▉     | 406/814 [15:54<15:51,  2.33s/ba]Running tokenizer on dataset:  50%|█████     | 407/814 [15:57<15:52,  2.34s/ba]Running tokenizer on dataset:  50%|█████     | 408/814 [15:59<15:47,  2.33s/ba]Running tokenizer on dataset:  50%|█████     | 409/814 [16:01<15:36,  2.31s/ba]Running tokenizer on dataset:  50%|█████     | 410/814 [16:04<15:27,  2.30s/ba]Running tokenizer on dataset:  50%|█████     | 411/814 [16:06<15:28,  2.30s/ba]Running tokenizer on dataset:  51%|█████     | 412/814 [16:08<15:25,  2.30s/ba]Running tokenizer on dataset:  51%|█████     | 413/814 [16:11<15:21,  2.30s/ba]Running tokenizer on dataset:  51%|█████     | 414/814 [16:13<15:27,  2.32s/ba]Running tokenizer on dataset:  51%|█████     | 415/814 [16:15<15:23,  2.31s/ba]Running tokenizer on dataset:  51%|█████     | 416/814 [16:18<15:23,  2.32s/ba]Running tokenizer on dataset:  51%|█████     | 417/814 [16:20<15:24,  2.33s/ba]Running tokenizer on dataset:  51%|█████▏    | 418/814 [16:22<15:16,  2.32s/ba]Running tokenizer on dataset:  51%|█████▏    | 419/814 [16:24<15:10,  2.31s/ba]Running tokenizer on dataset:  52%|█████▏    | 420/814 [16:27<15:13,  2.32s/ba]Running tokenizer on dataset:  52%|█████▏    | 421/814 [16:29<15:13,  2.32s/ba]Running tokenizer on dataset:  52%|█████▏    | 422/814 [16:31<15:12,  2.33s/ba]Running tokenizer on dataset:  52%|█████▏    | 423/814 [16:34<15:01,  2.31s/ba]Running tokenizer on dataset:  52%|█████▏    | 424/814 [16:36<14:54,  2.29s/ba]Running tokenizer on dataset:  52%|█████▏    | 425/814 [16:38<14:52,  2.29s/ba]Running tokenizer on dataset:  52%|█████▏    | 426/814 [16:41<14:53,  2.30s/ba]Running tokenizer on dataset:  52%|█████▏    | 427/814 [16:43<14:45,  2.29s/ba]Running tokenizer on dataset:  53%|█████▎    | 428/814 [16:45<14:46,  2.30s/ba]Running tokenizer on dataset:  53%|█████▎    | 429/814 [16:47<14:44,  2.30s/ba]Running tokenizer on dataset:  53%|█████▎    | 430/814 [16:50<14:44,  2.30s/ba]Running tokenizer on dataset:  53%|█████▎    | 431/814 [16:52<14:39,  2.30s/ba]Running tokenizer on dataset:  53%|█████▎    | 432/814 [16:54<14:32,  2.29s/ba]Running tokenizer on dataset:  53%|█████▎    | 433/814 [16:57<14:36,  2.30s/ba]Running tokenizer on dataset:  53%|█████▎    | 434/814 [16:59<14:33,  2.30s/ba]Running tokenizer on dataset:  53%|█████▎    | 435/814 [17:01<14:29,  2.29s/ba]Running tokenizer on dataset:  54%|█████▎    | 436/814 [17:04<14:25,  2.29s/ba]Running tokenizer on dataset:  54%|█████▎    | 437/814 [17:06<14:21,  2.28s/ba]Running tokenizer on dataset:  54%|█████▍    | 438/814 [17:08<14:19,  2.29s/ba]Running tokenizer on dataset:  54%|█████▍    | 439/814 [17:10<14:18,  2.29s/ba]Running tokenizer on dataset:  54%|█████▍    | 440/814 [17:13<14:21,  2.30s/ba]Running tokenizer on dataset:  54%|█████▍    | 441/814 [17:15<14:18,  2.30s/ba]Running tokenizer on dataset:  54%|█████▍    | 442/814 [17:17<14:17,  2.30s/ba]Running tokenizer on dataset:  54%|█████▍    | 443/814 [17:20<14:09,  2.29s/ba]Running tokenizer on dataset:  55%|█████▍    | 444/814 [17:22<14:08,  2.29s/ba]Running tokenizer on dataset:  55%|█████▍    | 445/814 [17:24<14:03,  2.28s/ba]Running tokenizer on dataset:  55%|█████▍    | 446/814 [17:26<14:06,  2.30s/ba]Running tokenizer on dataset:  55%|█████▍    | 447/814 [17:29<14:02,  2.30s/ba]Running tokenizer on dataset:  55%|█████▌    | 448/814 [17:31<14:02,  2.30s/ba]Running tokenizer on dataset:  55%|█████▌    | 449/814 [17:33<13:59,  2.30s/ba]Running tokenizer on dataset:  55%|█████▌    | 450/814 [17:36<13:57,  2.30s/ba]Running tokenizer on dataset:  55%|█████▌    | 451/814 [17:38<13:51,  2.29s/ba]Running tokenizer on dataset:  56%|█████▌    | 452/814 [17:40<13:51,  2.30s/ba]Running tokenizer on dataset:  56%|█████▌    | 453/814 [17:43<13:51,  2.30s/ba]Running tokenizer on dataset:  56%|█████▌    | 454/814 [17:45<13:52,  2.31s/ba]Running tokenizer on dataset:  56%|█████▌    | 455/814 [17:47<13:49,  2.31s/ba]Running tokenizer on dataset:  56%|█████▌    | 456/814 [17:50<13:47,  2.31s/ba]Running tokenizer on dataset:  56%|█████▌    | 457/814 [17:52<13:43,  2.31s/ba]Running tokenizer on dataset:  56%|█████▋    | 458/814 [17:54<13:33,  2.29s/ba]Running tokenizer on dataset:  56%|█████▋    | 459/814 [17:56<13:30,  2.28s/ba]Running tokenizer on dataset:  57%|█████▋    | 460/814 [17:59<13:30,  2.29s/ba]Running tokenizer on dataset:  57%|█████▋    | 461/814 [18:01<13:32,  2.30s/ba]Running tokenizer on dataset:  57%|█████▋    | 462/814 [18:03<13:28,  2.30s/ba]Running tokenizer on dataset:  57%|█████▋    | 463/814 [18:06<13:37,  2.33s/ba]Running tokenizer on dataset:  57%|█████▋    | 464/814 [18:08<13:29,  2.31s/ba]Running tokenizer on dataset:  57%|█████▋    | 465/814 [18:10<13:29,  2.32s/ba]Running tokenizer on dataset:  57%|█████▋    | 466/814 [18:13<13:25,  2.32s/ba]Running tokenizer on dataset:  57%|█████▋    | 467/814 [18:15<13:24,  2.32s/ba]Running tokenizer on dataset:  57%|█████▋    | 468/814 [18:17<13:20,  2.31s/ba]Running tokenizer on dataset:  58%|█████▊    | 469/814 [18:19<13:13,  2.30s/ba]Running tokenizer on dataset:  58%|█████▊    | 470/814 [18:22<13:08,  2.29s/ba]Running tokenizer on dataset:  58%|█████▊    | 471/814 [18:24<13:12,  2.31s/ba]Running tokenizer on dataset:  58%|█████▊    | 472/814 [18:26<13:10,  2.31s/ba]Running tokenizer on dataset:  58%|█████▊    | 473/814 [18:29<13:03,  2.30s/ba]Running tokenizer on dataset:  58%|█████▊    | 474/814 [18:31<12:58,  2.29s/ba]Running tokenizer on dataset:  58%|█████▊    | 475/814 [18:33<12:55,  2.29s/ba]Running tokenizer on dataset:  58%|█████▊    | 476/814 [18:36<12:52,  2.29s/ba]Running tokenizer on dataset:  59%|█████▊    | 477/814 [18:38<12:51,  2.29s/ba]Running tokenizer on dataset:  59%|█████▊    | 478/814 [18:40<12:50,  2.29s/ba]Running tokenizer on dataset:  59%|█████▉    | 479/814 [18:42<12:48,  2.29s/ba]Running tokenizer on dataset:  59%|█████▉    | 480/814 [18:45<12:48,  2.30s/ba]Running tokenizer on dataset:  59%|█████▉    | 481/814 [18:47<13:04,  2.36s/ba]Running tokenizer on dataset:  59%|█████▉    | 482/814 [18:50<13:00,  2.35s/ba]Running tokenizer on dataset:  59%|█████▉    | 483/814 [18:52<12:55,  2.34s/ba]Running tokenizer on dataset:  59%|█████▉    | 484/814 [18:54<12:55,  2.35s/ba]Running tokenizer on dataset:  60%|█████▉    | 485/814 [18:57<12:44,  2.32s/ba]Running tokenizer on dataset:  60%|█████▉    | 486/814 [18:59<12:32,  2.29s/ba]Running tokenizer on dataset:  60%|█████▉    | 487/814 [19:01<12:46,  2.34s/ba]Running tokenizer on dataset:  60%|█████▉    | 488/814 [19:04<12:41,  2.33s/ba]Running tokenizer on dataset:  60%|██████    | 489/814 [19:06<12:35,  2.32s/ba]Running tokenizer on dataset:  60%|██████    | 490/814 [19:08<12:43,  2.36s/ba]Running tokenizer on dataset:  60%|██████    | 491/814 [19:11<12:35,  2.34s/ba]Running tokenizer on dataset:  60%|██████    | 492/814 [19:13<12:25,  2.31s/ba]Running tokenizer on dataset:  61%|██████    | 493/814 [19:15<12:21,  2.31s/ba]Running tokenizer on dataset:  61%|██████    | 494/814 [19:17<12:17,  2.30s/ba]Running tokenizer on dataset:  61%|██████    | 495/814 [19:20<12:16,  2.31s/ba]Running tokenizer on dataset:  61%|██████    | 496/814 [19:22<12:13,  2.31s/ba]Running tokenizer on dataset:  61%|██████    | 497/814 [19:24<12:07,  2.30s/ba]Running tokenizer on dataset:  61%|██████    | 498/814 [19:27<12:03,  2.29s/ba]Running tokenizer on dataset:  61%|██████▏   | 499/814 [19:29<11:58,  2.28s/ba]Running tokenizer on dataset:  61%|██████▏   | 500/814 [19:31<11:57,  2.28s/ba]Running tokenizer on dataset:  62%|██████▏   | 501/814 [19:33<11:56,  2.29s/ba]Running tokenizer on dataset:  62%|██████▏   | 502/814 [19:36<11:54,  2.29s/ba]Running tokenizer on dataset:  62%|██████▏   | 503/814 [19:38<11:50,  2.28s/ba]Running tokenizer on dataset:  62%|██████▏   | 504/814 [19:40<11:49,  2.29s/ba]Running tokenizer on dataset:  62%|██████▏   | 505/814 [19:43<11:50,  2.30s/ba]Running tokenizer on dataset:  62%|██████▏   | 506/814 [19:45<11:42,  2.28s/ba]Running tokenizer on dataset:  62%|██████▏   | 507/814 [19:47<11:38,  2.27s/ba]Running tokenizer on dataset:  62%|██████▏   | 508/814 [19:49<11:35,  2.27s/ba]Running tokenizer on dataset:  63%|██████▎   | 509/814 [19:52<11:39,  2.29s/ba]Running tokenizer on dataset:  63%|██████▎   | 510/814 [19:54<11:36,  2.29s/ba]Running tokenizer on dataset:  63%|██████▎   | 511/814 [19:56<11:33,  2.29s/ba]Running tokenizer on dataset:  63%|██████▎   | 512/814 [19:59<11:31,  2.29s/ba]Running tokenizer on dataset:  63%|██████▎   | 513/814 [20:01<11:32,  2.30s/ba]Running tokenizer on dataset:  63%|██████▎   | 514/814 [20:03<11:27,  2.29s/ba]Running tokenizer on dataset:  63%|██████▎   | 515/814 [20:05<11:26,  2.30s/ba]Running tokenizer on dataset:  63%|██████▎   | 516/814 [20:08<11:27,  2.31s/ba]Running tokenizer on dataset:  64%|██████▎   | 517/814 [20:10<11:26,  2.31s/ba]Running tokenizer on dataset:  64%|██████▎   | 518/814 [20:12<11:23,  2.31s/ba]Running tokenizer on dataset:  64%|██████▍   | 519/814 [20:15<11:18,  2.30s/ba]Running tokenizer on dataset:  64%|██████▍   | 520/814 [20:17<11:25,  2.33s/ba]Running tokenizer on dataset:  64%|██████▍   | 521/814 [20:19<11:15,  2.30s/ba]Running tokenizer on dataset:  64%|██████▍   | 522/814 [20:22<11:12,  2.30s/ba]Running tokenizer on dataset:  64%|██████▍   | 523/814 [20:24<11:07,  2.29s/ba]Running tokenizer on dataset:  64%|██████▍   | 524/814 [20:26<11:04,  2.29s/ba]Running tokenizer on dataset:  64%|██████▍   | 525/814 [20:28<10:56,  2.27s/ba]Running tokenizer on dataset:  65%|██████▍   | 526/814 [20:31<10:55,  2.28s/ba]Running tokenizer on dataset:  65%|██████▍   | 527/814 [20:33<10:56,  2.29s/ba]Running tokenizer on dataset:  65%|██████▍   | 528/814 [20:35<10:55,  2.29s/ba]Running tokenizer on dataset:  65%|██████▍   | 529/814 [20:38<10:51,  2.29s/ba]Running tokenizer on dataset:  65%|██████▌   | 530/814 [20:40<10:53,  2.30s/ba]Running tokenizer on dataset:  65%|██████▌   | 531/814 [20:42<10:49,  2.29s/ba]Running tokenizer on dataset:  65%|██████▌   | 532/814 [20:45<10:52,  2.32s/ba]Running tokenizer on dataset:  65%|██████▌   | 533/814 [20:47<10:45,  2.30s/ba]Running tokenizer on dataset:  66%|██████▌   | 534/814 [20:49<10:39,  2.28s/ba]Running tokenizer on dataset:  66%|██████▌   | 535/814 [20:51<10:45,  2.31s/ba]Running tokenizer on dataset:  66%|██████▌   | 536/814 [20:54<10:40,  2.30s/ba]Running tokenizer on dataset:  66%|██████▌   | 537/814 [20:56<10:37,  2.30s/ba]Running tokenizer on dataset:  66%|██████▌   | 538/814 [20:58<10:40,  2.32s/ba]Running tokenizer on dataset:  66%|██████▌   | 539/814 [21:01<10:38,  2.32s/ba]Running tokenizer on dataset:  66%|██████▋   | 540/814 [21:03<10:32,  2.31s/ba]Running tokenizer on dataset:  66%|██████▋   | 541/814 [21:05<10:27,  2.30s/ba]Running tokenizer on dataset:  67%|██████▋   | 542/814 [21:08<10:23,  2.29s/ba]Running tokenizer on dataset:  67%|██████▋   | 543/814 [21:10<10:19,  2.28s/ba]Running tokenizer on dataset:  67%|██████▋   | 544/814 [21:12<10:17,  2.29s/ba]Running tokenizer on dataset:  67%|██████▋   | 545/814 [21:14<10:18,  2.30s/ba]Running tokenizer on dataset:  67%|██████▋   | 546/814 [21:17<10:14,  2.29s/ba]Running tokenizer on dataset:  67%|██████▋   | 547/814 [21:19<10:09,  2.28s/ba]Running tokenizer on dataset:  67%|██████▋   | 548/814 [21:21<10:07,  2.28s/ba]Running tokenizer on dataset:  67%|██████▋   | 549/814 [21:24<10:12,  2.31s/ba]Running tokenizer on dataset:  68%|██████▊   | 550/814 [21:26<10:04,  2.29s/ba]Running tokenizer on dataset:  68%|██████▊   | 551/814 [21:28<10:01,  2.29s/ba]Running tokenizer on dataset:  68%|██████▊   | 552/814 [21:30<09:57,  2.28s/ba]Running tokenizer on dataset:  68%|██████▊   | 553/814 [21:33<09:50,  2.26s/ba]Running tokenizer on dataset:  68%|██████▊   | 554/814 [21:35<09:45,  2.25s/ba]Running tokenizer on dataset:  68%|██████▊   | 555/814 [21:37<09:45,  2.26s/ba]Running tokenizer on dataset:  68%|██████▊   | 556/814 [21:40<09:58,  2.32s/ba]Running tokenizer on dataset:  68%|██████▊   | 557/814 [21:42<09:50,  2.30s/ba]Running tokenizer on dataset:  69%|██████▊   | 558/814 [21:44<09:47,  2.30s/ba]Running tokenizer on dataset:  69%|██████▊   | 559/814 [21:46<09:44,  2.29s/ba]Running tokenizer on dataset:  69%|██████▉   | 560/814 [21:49<09:39,  2.28s/ba]Running tokenizer on dataset:  69%|██████▉   | 561/814 [21:51<09:36,  2.28s/ba]Running tokenizer on dataset:  69%|██████▉   | 562/814 [21:53<09:41,  2.31s/ba]Running tokenizer on dataset:  69%|██████▉   | 563/814 [21:56<09:39,  2.31s/ba]Running tokenizer on dataset:  69%|██████▉   | 564/814 [21:58<09:33,  2.29s/ba]Running tokenizer on dataset:  69%|██████▉   | 565/814 [22:00<09:31,  2.29s/ba]Running tokenizer on dataset:  70%|██████▉   | 566/814 [22:03<09:28,  2.29s/ba]Running tokenizer on dataset:  70%|██████▉   | 567/814 [22:05<09:24,  2.29s/ba]Running tokenizer on dataset:  70%|██████▉   | 568/814 [22:07<09:19,  2.27s/ba]Running tokenizer on dataset:  70%|██████▉   | 569/814 [22:09<09:19,  2.28s/ba]Running tokenizer on dataset:  70%|███████   | 570/814 [22:12<09:19,  2.29s/ba]Running tokenizer on dataset:  70%|███████   | 571/814 [22:14<09:15,  2.28s/ba]Running tokenizer on dataset:  70%|███████   | 572/814 [22:16<09:10,  2.27s/ba]Running tokenizer on dataset:  70%|███████   | 573/814 [22:18<09:11,  2.29s/ba]Running tokenizer on dataset:  71%|███████   | 574/814 [22:21<09:03,  2.26s/ba]Running tokenizer on dataset:  71%|███████   | 575/814 [22:23<09:01,  2.27s/ba]Running tokenizer on dataset:  71%|███████   | 576/814 [22:25<09:03,  2.29s/ba]Running tokenizer on dataset:  71%|███████   | 577/814 [22:28<09:02,  2.29s/ba]Running tokenizer on dataset:  71%|███████   | 578/814 [22:30<09:00,  2.29s/ba]Running tokenizer on dataset:  71%|███████   | 579/814 [22:32<08:56,  2.28s/ba]Running tokenizer on dataset:  71%|███████▏  | 580/814 [22:34<08:54,  2.28s/ba]Running tokenizer on dataset:  71%|███████▏  | 581/814 [22:37<08:52,  2.28s/ba]Running tokenizer on dataset:  71%|███████▏  | 582/814 [22:39<08:45,  2.27s/ba]Running tokenizer on dataset:  72%|███████▏  | 583/814 [22:41<08:43,  2.27s/ba]Running tokenizer on dataset:  72%|███████▏  | 584/814 [22:43<08:40,  2.26s/ba]Running tokenizer on dataset:  72%|███████▏  | 585/814 [22:46<08:44,  2.29s/ba]Running tokenizer on dataset:  72%|███████▏  | 586/814 [22:48<08:42,  2.29s/ba]Running tokenizer on dataset:  72%|███████▏  | 587/814 [22:50<08:40,  2.29s/ba]Running tokenizer on dataset:  72%|███████▏  | 588/814 [22:53<08:36,  2.29s/ba]Running tokenizer on dataset:  72%|███████▏  | 589/814 [22:55<08:35,  2.29s/ba]Running tokenizer on dataset:  72%|███████▏  | 590/814 [22:57<08:32,  2.29s/ba]Running tokenizer on dataset:  73%|███████▎  | 591/814 [23:00<08:31,  2.29s/ba]Running tokenizer on dataset:  73%|███████▎  | 592/814 [23:02<08:27,  2.29s/ba]Running tokenizer on dataset:  73%|███████▎  | 593/814 [23:04<08:26,  2.29s/ba]Running tokenizer on dataset:  73%|███████▎  | 594/814 [23:06<08:24,  2.29s/ba]Running tokenizer on dataset:  73%|███████▎  | 595/814 [23:09<08:19,  2.28s/ba]Running tokenizer on dataset:  73%|███████▎  | 596/814 [23:11<08:14,  2.27s/ba]Running tokenizer on dataset:  73%|███████▎  | 597/814 [23:13<08:11,  2.27s/ba]Running tokenizer on dataset:  73%|███████▎  | 598/814 [23:15<08:11,  2.28s/ba]Running tokenizer on dataset:  74%|███████▎  | 599/814 [23:18<08:09,  2.28s/ba]Running tokenizer on dataset:  74%|███████▎  | 600/814 [23:20<08:07,  2.28s/ba]Running tokenizer on dataset:  74%|███████▍  | 601/814 [23:22<08:05,  2.28s/ba]Running tokenizer on dataset:  74%|███████▍  | 602/814 [23:25<08:02,  2.28s/ba]Running tokenizer on dataset:  74%|███████▍  | 603/814 [23:27<07:58,  2.27s/ba]Running tokenizer on dataset:  74%|███████▍  | 604/814 [23:29<07:56,  2.27s/ba]Running tokenizer on dataset:  74%|███████▍  | 605/814 [23:31<07:55,  2.27s/ba]Running tokenizer on dataset:  74%|███████▍  | 606/814 [23:34<07:53,  2.28s/ba]Running tokenizer on dataset:  75%|███████▍  | 607/814 [23:36<07:50,  2.27s/ba]Running tokenizer on dataset:  75%|███████▍  | 608/814 [23:38<07:47,  2.27s/ba]Running tokenizer on dataset:  75%|███████▍  | 609/814 [23:41<07:50,  2.29s/ba]Running tokenizer on dataset:  75%|███████▍  | 610/814 [23:43<07:45,  2.28s/ba]Running tokenizer on dataset:  75%|███████▌  | 611/814 [23:45<07:42,  2.28s/ba]Running tokenizer on dataset:  75%|███████▌  | 612/814 [23:47<07:40,  2.28s/ba]Running tokenizer on dataset:  75%|███████▌  | 613/814 [23:50<07:40,  2.29s/ba]Running tokenizer on dataset:  75%|███████▌  | 614/814 [23:52<07:39,  2.30s/ba]Running tokenizer on dataset:  76%|███████▌  | 615/814 [23:54<07:35,  2.29s/ba]Running tokenizer on dataset:  76%|███████▌  | 616/814 [23:57<07:33,  2.29s/ba]Running tokenizer on dataset:  76%|███████▌  | 617/814 [23:59<07:29,  2.28s/ba]Running tokenizer on dataset:  76%|███████▌  | 618/814 [24:01<07:25,  2.27s/ba]Running tokenizer on dataset:  76%|███████▌  | 619/814 [24:03<07:22,  2.27s/ba]Running tokenizer on dataset:  76%|███████▌  | 620/814 [24:06<07:18,  2.26s/ba]Running tokenizer on dataset:  76%|███████▋  | 621/814 [24:08<07:17,  2.26s/ba]Running tokenizer on dataset:  76%|███████▋  | 622/814 [24:10<07:16,  2.27s/ba]Running tokenizer on dataset:  77%|███████▋  | 623/814 [24:12<07:13,  2.27s/ba]Running tokenizer on dataset:  77%|███████▋  | 624/814 [24:15<07:12,  2.27s/ba]Running tokenizer on dataset:  77%|███████▋  | 625/814 [24:17<07:09,  2.27s/ba]Running tokenizer on dataset:  77%|███████▋  | 626/814 [24:19<07:08,  2.28s/ba]Running tokenizer on dataset:  77%|███████▋  | 627/814 [24:22<07:06,  2.28s/ba]Running tokenizer on dataset:  77%|███████▋  | 628/814 [24:24<07:07,  2.30s/ba]Running tokenizer on dataset:  77%|███████▋  | 629/814 [24:26<07:03,  2.29s/ba]Running tokenizer on dataset:  77%|███████▋  | 630/814 [24:28<07:01,  2.29s/ba]Running tokenizer on dataset:  78%|███████▊  | 631/814 [24:31<06:57,  2.28s/ba]Running tokenizer on dataset:  78%|███████▊  | 632/814 [24:33<06:57,  2.29s/ba]Running tokenizer on dataset:  78%|███████▊  | 633/814 [24:35<06:55,  2.29s/ba]Running tokenizer on dataset:  78%|███████▊  | 634/814 [24:38<06:50,  2.28s/ba]Running tokenizer on dataset:  78%|███████▊  | 635/814 [24:40<06:42,  2.25s/ba]Running tokenizer on dataset:  78%|███████▊  | 636/814 [24:42<06:42,  2.26s/ba]Running tokenizer on dataset:  78%|███████▊  | 637/814 [24:44<06:42,  2.27s/ba]Running tokenizer on dataset:  78%|███████▊  | 638/814 [24:47<06:40,  2.28s/ba]Running tokenizer on dataset:  79%|███████▊  | 639/814 [24:49<06:39,  2.29s/ba]Running tokenizer on dataset:  79%|███████▊  | 640/814 [24:51<06:36,  2.28s/ba]Running tokenizer on dataset:  79%|███████▊  | 641/814 [24:53<06:32,  2.27s/ba]Running tokenizer on dataset:  79%|███████▉  | 642/814 [24:56<06:31,  2.27s/ba]Running tokenizer on dataset:  79%|███████▉  | 643/814 [24:58<06:36,  2.32s/ba]Running tokenizer on dataset:  79%|███████▉  | 644/814 [25:00<06:31,  2.31s/ba]Running tokenizer on dataset:  79%|███████▉  | 645/814 [25:03<06:27,  2.29s/ba]Running tokenizer on dataset:  79%|███████▉  | 646/814 [25:05<06:25,  2.30s/ba]Running tokenizer on dataset:  79%|███████▉  | 647/814 [25:07<06:20,  2.28s/ba]Running tokenizer on dataset:  80%|███████▉  | 648/814 [25:09<06:17,  2.28s/ba]Running tokenizer on dataset:  80%|███████▉  | 649/814 [25:12<06:16,  2.28s/ba]Running tokenizer on dataset:  80%|███████▉  | 650/814 [25:14<06:15,  2.29s/ba]Running tokenizer on dataset:  80%|███████▉  | 651/814 [25:16<06:14,  2.30s/ba]Running tokenizer on dataset:  80%|████████  | 652/814 [25:19<06:13,  2.31s/ba]Running tokenizer on dataset:  80%|████████  | 653/814 [25:21<06:10,  2.30s/ba]Running tokenizer on dataset:  80%|████████  | 654/814 [25:23<06:06,  2.29s/ba]Running tokenizer on dataset:  80%|████████  | 655/814 [25:26<06:04,  2.29s/ba]Running tokenizer on dataset:  81%|████████  | 656/814 [25:28<06:02,  2.30s/ba]Running tokenizer on dataset:  81%|████████  | 657/814 [25:30<06:01,  2.30s/ba]Running tokenizer on dataset:  81%|████████  | 658/814 [25:32<05:55,  2.28s/ba]Running tokenizer on dataset:  81%|████████  | 659/814 [25:35<05:51,  2.27s/ba]Running tokenizer on dataset:  81%|████████  | 660/814 [25:37<05:51,  2.28s/ba]Running tokenizer on dataset:  81%|████████  | 661/814 [25:39<05:48,  2.28s/ba]Running tokenizer on dataset:  81%|████████▏ | 662/814 [25:42<05:45,  2.27s/ba]Running tokenizer on dataset:  81%|████████▏ | 663/814 [25:44<05:48,  2.31s/ba]Running tokenizer on dataset:  82%|████████▏ | 664/814 [25:46<05:42,  2.28s/ba]Running tokenizer on dataset:  82%|████████▏ | 665/814 [25:48<05:38,  2.27s/ba]Running tokenizer on dataset:  82%|████████▏ | 666/814 [25:51<05:35,  2.26s/ba]Running tokenizer on dataset:  82%|████████▏ | 667/814 [25:53<05:33,  2.27s/ba]Running tokenizer on dataset:  82%|████████▏ | 668/814 [25:55<05:31,  2.27s/ba]Running tokenizer on dataset:  82%|████████▏ | 669/814 [25:58<05:31,  2.28s/ba]Running tokenizer on dataset:  82%|████████▏ | 670/814 [26:00<05:27,  2.27s/ba]Running tokenizer on dataset:  82%|████████▏ | 671/814 [26:02<05:26,  2.29s/ba]Running tokenizer on dataset:  83%|████████▎ | 672/814 [26:04<05:25,  2.29s/ba]Running tokenizer on dataset:  83%|████████▎ | 673/814 [26:07<05:35,  2.38s/ba]Running tokenizer on dataset:  83%|████████▎ | 674/814 [26:09<05:29,  2.35s/ba]Running tokenizer on dataset:  83%|████████▎ | 675/814 [26:12<05:25,  2.34s/ba]Running tokenizer on dataset:  83%|████████▎ | 676/814 [26:14<05:19,  2.31s/ba]Running tokenizer on dataset:  83%|████████▎ | 677/814 [26:16<05:14,  2.30s/ba]Running tokenizer on dataset:  83%|████████▎ | 678/814 [26:18<05:13,  2.30s/ba]Running tokenizer on dataset:  83%|████████▎ | 679/814 [26:21<05:08,  2.28s/ba]Running tokenizer on dataset:  84%|████████▎ | 680/814 [26:23<05:04,  2.28s/ba]Running tokenizer on dataset:  84%|████████▎ | 681/814 [26:25<05:02,  2.27s/ba]Running tokenizer on dataset:  84%|████████▍ | 682/814 [26:27<04:57,  2.26s/ba]Running tokenizer on dataset:  84%|████████▍ | 683/814 [26:30<04:56,  2.26s/ba]Running tokenizer on dataset:  84%|████████▍ | 684/814 [26:32<04:53,  2.26s/ba]Running tokenizer on dataset:  84%|████████▍ | 685/814 [26:34<04:52,  2.27s/ba]Running tokenizer on dataset:  84%|████████▍ | 686/814 [26:36<04:50,  2.27s/ba]Running tokenizer on dataset:  84%|████████▍ | 687/814 [26:39<04:47,  2.27s/ba]Running tokenizer on dataset:  85%|████████▍ | 688/814 [26:41<04:44,  2.26s/ba]Running tokenizer on dataset:  85%|████████▍ | 689/814 [26:43<04:40,  2.24s/ba]Running tokenizer on dataset:  85%|████████▍ | 690/814 [26:45<04:40,  2.26s/ba]Running tokenizer on dataset:  85%|████████▍ | 691/814 [26:48<04:40,  2.28s/ba]Running tokenizer on dataset:  85%|████████▌ | 692/814 [26:50<04:38,  2.28s/ba]Running tokenizer on dataset:  85%|████████▌ | 693/814 [26:52<04:35,  2.27s/ba]Running tokenizer on dataset:  85%|████████▌ | 694/814 [26:55<04:31,  2.26s/ba]Running tokenizer on dataset:  85%|████████▌ | 695/814 [26:57<04:29,  2.26s/ba]Running tokenizer on dataset:  86%|████████▌ | 696/814 [26:59<04:28,  2.27s/ba]Running tokenizer on dataset:  86%|████████▌ | 697/814 [27:01<04:25,  2.27s/ba]Running tokenizer on dataset:  86%|████████▌ | 698/814 [27:04<04:23,  2.27s/ba]Running tokenizer on dataset:  86%|████████▌ | 699/814 [27:06<04:19,  2.25s/ba]Running tokenizer on dataset:  86%|████████▌ | 700/814 [27:08<04:16,  2.25s/ba]Running tokenizer on dataset:  86%|████████▌ | 701/814 [27:10<04:15,  2.26s/ba]Running tokenizer on dataset:  86%|████████▌ | 702/814 [27:13<04:12,  2.26s/ba]Running tokenizer on dataset:  86%|████████▋ | 703/814 [27:15<04:11,  2.27s/ba]Running tokenizer on dataset:  86%|████████▋ | 704/814 [27:17<04:08,  2.26s/ba]Running tokenizer on dataset:  87%|████████▋ | 705/814 [27:19<04:07,  2.27s/ba]Running tokenizer on dataset:  87%|████████▋ | 706/814 [27:22<04:04,  2.26s/ba]Running tokenizer on dataset:  87%|████████▋ | 707/814 [27:24<04:03,  2.27s/ba]Running tokenizer on dataset:  87%|████████▋ | 708/814 [27:26<04:01,  2.28s/ba]Running tokenizer on dataset:  87%|████████▋ | 709/814 [27:29<03:59,  2.28s/ba]Running tokenizer on dataset:  87%|████████▋ | 710/814 [27:31<03:54,  2.26s/ba]Running tokenizer on dataset:  87%|████████▋ | 711/814 [27:33<03:52,  2.26s/ba]Running tokenizer on dataset:  87%|████████▋ | 712/814 [27:35<03:51,  2.27s/ba]Running tokenizer on dataset:  88%|████████▊ | 713/814 [27:38<03:48,  2.27s/ba]Running tokenizer on dataset:  88%|████████▊ | 714/814 [27:40<03:47,  2.27s/ba]Running tokenizer on dataset:  88%|████████▊ | 715/814 [27:42<03:44,  2.27s/ba]Running tokenizer on dataset:  88%|████████▊ | 716/814 [27:44<03:41,  2.26s/ba]Running tokenizer on dataset:  88%|████████▊ | 717/814 [27:47<03:39,  2.27s/ba]Running tokenizer on dataset:  88%|████████▊ | 718/814 [27:49<03:38,  2.28s/ba]Running tokenizer on dataset:  88%|████████▊ | 719/814 [27:51<03:37,  2.29s/ba]Running tokenizer on dataset:  88%|████████▊ | 720/814 [27:54<03:34,  2.28s/ba]Running tokenizer on dataset:  89%|████████▊ | 721/814 [27:56<03:31,  2.28s/ba]Running tokenizer on dataset:  89%|████████▊ | 722/814 [27:58<03:29,  2.28s/ba]Running tokenizer on dataset:  89%|████████▉ | 723/814 [28:00<03:26,  2.27s/ba]Running tokenizer on dataset:  89%|████████▉ | 724/814 [28:03<03:27,  2.30s/ba]Running tokenizer on dataset:  89%|████████▉ | 725/814 [28:05<03:24,  2.30s/ba]Running tokenizer on dataset:  89%|████████▉ | 726/814 [28:07<03:20,  2.27s/ba]Running tokenizer on dataset:  89%|████████▉ | 727/814 [28:10<03:18,  2.28s/ba]Running tokenizer on dataset:  89%|████████▉ | 728/814 [28:12<03:15,  2.28s/ba]Running tokenizer on dataset:  90%|████████▉ | 729/814 [28:14<03:13,  2.28s/ba]Running tokenizer on dataset:  90%|████████▉ | 730/814 [28:16<03:10,  2.26s/ba]Running tokenizer on dataset:  90%|████████▉ | 731/814 [28:19<03:08,  2.27s/ba]Running tokenizer on dataset:  90%|████████▉ | 732/814 [28:21<03:06,  2.28s/ba]Running tokenizer on dataset:  90%|█████████ | 733/814 [28:23<03:04,  2.28s/ba]Running tokenizer on dataset:  90%|█████████ | 734/814 [28:25<03:00,  2.26s/ba]Running tokenizer on dataset:  90%|█████████ | 735/814 [28:28<02:59,  2.27s/ba]Running tokenizer on dataset:  90%|█████████ | 736/814 [28:30<02:57,  2.27s/ba]Running tokenizer on dataset:  91%|█████████ | 737/814 [28:32<02:53,  2.26s/ba]Running tokenizer on dataset:  91%|█████████ | 738/814 [28:35<02:52,  2.28s/ba]Running tokenizer on dataset:  91%|█████████ | 739/814 [28:37<02:50,  2.28s/ba]Running tokenizer on dataset:  91%|█████████ | 740/814 [28:39<02:48,  2.28s/ba]Running tokenizer on dataset:  91%|█████████ | 741/814 [28:41<02:46,  2.28s/ba]Running tokenizer on dataset:  91%|█████████ | 742/814 [28:44<02:43,  2.27s/ba]Running tokenizer on dataset:  91%|█████████▏| 743/814 [28:46<02:40,  2.26s/ba]Running tokenizer on dataset:  91%|█████████▏| 744/814 [28:48<02:37,  2.25s/ba]Running tokenizer on dataset:  92%|█████████▏| 745/814 [28:50<02:35,  2.26s/ba]Running tokenizer on dataset:  92%|█████████▏| 746/814 [28:53<02:33,  2.25s/ba]Running tokenizer on dataset:  92%|█████████▏| 747/814 [28:55<02:31,  2.26s/ba]Running tokenizer on dataset:  92%|█████████▏| 748/814 [28:57<02:28,  2.25s/ba]Running tokenizer on dataset:  92%|█████████▏| 749/814 [28:59<02:26,  2.25s/ba]Running tokenizer on dataset:  92%|█████████▏| 750/814 [29:02<02:24,  2.26s/ba]Running tokenizer on dataset:  92%|█████████▏| 751/814 [29:04<02:22,  2.26s/ba]Running tokenizer on dataset:  92%|█████████▏| 752/814 [29:06<02:20,  2.27s/ba]Running tokenizer on dataset:  93%|█████████▎| 753/814 [29:08<02:19,  2.28s/ba]Running tokenizer on dataset:  93%|█████████▎| 754/814 [29:11<02:16,  2.27s/ba]Running tokenizer on dataset:  93%|█████████▎| 755/814 [29:13<02:14,  2.28s/ba]Running tokenizer on dataset:  93%|█████████▎| 756/814 [29:15<02:11,  2.27s/ba]Running tokenizer on dataset:  93%|█████████▎| 757/814 [29:17<02:08,  2.25s/ba]Running tokenizer on dataset:  93%|█████████▎| 758/814 [29:20<02:06,  2.25s/ba]Running tokenizer on dataset:  93%|█████████▎| 759/814 [29:22<02:04,  2.26s/ba]Running tokenizer on dataset:  93%|█████████▎| 760/814 [29:24<02:02,  2.27s/ba]Running tokenizer on dataset:  93%|█████████▎| 761/814 [29:27<02:00,  2.28s/ba]Running tokenizer on dataset:  94%|█████████▎| 762/814 [29:29<01:58,  2.28s/ba]Running tokenizer on dataset:  94%|█████████▎| 763/814 [29:31<01:56,  2.29s/ba]Running tokenizer on dataset:  94%|█████████▍| 764/814 [29:33<01:54,  2.28s/ba]Running tokenizer on dataset:  94%|█████████▍| 765/814 [29:36<01:51,  2.27s/ba]Running tokenizer on dataset:  94%|█████████▍| 766/814 [29:38<01:49,  2.28s/ba]Running tokenizer on dataset:  94%|█████████▍| 767/814 [29:40<01:46,  2.28s/ba]Running tokenizer on dataset:  94%|█████████▍| 768/814 [29:43<01:45,  2.28s/ba]Running tokenizer on dataset:  94%|█████████▍| 769/814 [29:45<01:42,  2.28s/ba]Running tokenizer on dataset:  95%|█████████▍| 770/814 [29:48<01:56,  2.64s/ba]Running tokenizer on dataset:  95%|█████████▍| 771/814 [29:51<01:48,  2.53s/ba]Running tokenizer on dataset:  95%|█████████▍| 772/814 [29:53<01:42,  2.44s/ba]Running tokenizer on dataset:  95%|█████████▍| 773/814 [29:55<01:37,  2.38s/ba]Running tokenizer on dataset:  95%|█████████▌| 774/814 [29:57<01:33,  2.34s/ba]Running tokenizer on dataset:  95%|█████████▌| 775/814 [30:00<01:30,  2.32s/ba]Running tokenizer on dataset:  95%|█████████▌| 776/814 [30:02<01:27,  2.31s/ba]Running tokenizer on dataset:  95%|█████████▌| 777/814 [30:04<01:25,  2.30s/ba]Running tokenizer on dataset:  96%|█████████▌| 778/814 [30:06<01:22,  2.29s/ba]Running tokenizer on dataset:  96%|█████████▌| 779/814 [30:09<01:19,  2.28s/ba]Running tokenizer on dataset:  96%|█████████▌| 780/814 [30:11<01:17,  2.27s/ba]Running tokenizer on dataset:  96%|█████████▌| 781/814 [30:13<01:17,  2.34s/ba]Running tokenizer on dataset:  96%|█████████▌| 782/814 [30:16<01:14,  2.33s/ba]Running tokenizer on dataset:  96%|█████████▌| 783/814 [30:18<01:11,  2.31s/ba]Running tokenizer on dataset:  96%|█████████▋| 784/814 [30:20<01:08,  2.30s/ba]Running tokenizer on dataset:  96%|█████████▋| 785/814 [30:23<01:07,  2.31s/ba]Running tokenizer on dataset:  97%|█████████▋| 786/814 [30:25<01:04,  2.29s/ba]Running tokenizer on dataset:  97%|█████████▋| 787/814 [30:27<01:01,  2.28s/ba]Running tokenizer on dataset:  97%|█████████▋| 788/814 [30:29<00:58,  2.26s/ba]Running tokenizer on dataset:  97%|█████████▋| 789/814 [30:32<00:58,  2.33s/ba]Running tokenizer on dataset:  97%|█████████▋| 790/814 [30:34<00:55,  2.32s/ba]Running tokenizer on dataset:  97%|█████████▋| 791/814 [30:36<00:52,  2.28s/ba]Running tokenizer on dataset:  97%|█████████▋| 792/814 [30:39<00:49,  2.27s/ba]Running tokenizer on dataset:  97%|█████████▋| 793/814 [30:41<00:47,  2.28s/ba]Running tokenizer on dataset:  98%|█████████▊| 794/814 [30:43<00:45,  2.27s/ba]Running tokenizer on dataset:  98%|█████████▊| 795/814 [30:45<00:42,  2.26s/ba]Running tokenizer on dataset:  98%|█████████▊| 796/814 [30:48<00:40,  2.25s/ba]Running tokenizer on dataset:  98%|█████████▊| 797/814 [30:50<00:38,  2.24s/ba]Running tokenizer on dataset:  98%|█████████▊| 798/814 [30:52<00:35,  2.24s/ba]Running tokenizer on dataset:  98%|█████████▊| 799/814 [30:54<00:33,  2.25s/ba]Running tokenizer on dataset:  98%|█████████▊| 800/814 [30:57<00:31,  2.25s/ba]Running tokenizer on dataset:  98%|█████████▊| 801/814 [30:59<00:29,  2.27s/ba]Running tokenizer on dataset:  99%|█████████▊| 802/814 [31:01<00:27,  2.27s/ba]Running tokenizer on dataset:  99%|█████████▊| 803/814 [31:03<00:24,  2.25s/ba]Running tokenizer on dataset:  99%|█████████▉| 804/814 [31:06<00:22,  2.26s/ba]Running tokenizer on dataset:  99%|█████████▉| 805/814 [31:08<00:20,  2.31s/ba]Running tokenizer on dataset:  99%|█████████▉| 806/814 [31:10<00:18,  2.30s/ba]Running tokenizer on dataset:  99%|█████████▉| 807/814 [31:13<00:16,  2.29s/ba]Running tokenizer on dataset:  99%|█████████▉| 808/814 [31:15<00:13,  2.29s/ba]Running tokenizer on dataset:  99%|█████████▉| 809/814 [31:17<00:11,  2.30s/ba]Running tokenizer on dataset: 100%|█████████▉| 810/814 [31:19<00:09,  2.29s/ba]Running tokenizer on dataset: 100%|█████████▉| 811/814 [31:22<00:06,  2.28s/ba]Running tokenizer on dataset: 100%|█████████▉| 812/814 [31:24<00:04,  2.27s/ba]Running tokenizer on dataset: 100%|█████████▉| 813/814 [31:26<00:02,  2.26s/ba]Running tokenizer on dataset: 100%|██████████| 814/814 [31:27<00:00,  1.79s/ba]Running tokenizer on dataset: 100%|██████████| 814/814 [31:27<00:00,  2.32s/ba]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 1/814 [00:02<28:21,  2.09s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:04<28:47,  2.13s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:06<28:59,  2.14s/ba]Running tokenizer on dataset:   0%|          | 4/814 [00:08<29:05,  2.16s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:10<28:54,  2.14s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:12<28:44,  2.13s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:15<28:58,  2.15s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:17<28:52,  2.15s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:19<28:45,  2.14s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:21<28:37,  2.14s/ba]Running tokenizer on dataset:   1%|▏         | 11/814 [00:23<28:53,  2.16s/ba]Running tokenizer on dataset:   1%|▏         | 12/814 [00:25<28:53,  2.16s/ba]Running tokenizer on dataset:   2%|▏         | 13/814 [00:27<28:58,  2.17s/ba]Running tokenizer on dataset:   2%|▏         | 14/814 [00:30<29:03,  2.18s/ba]Running tokenizer on dataset:   2%|▏         | 15/814 [00:32<29:00,  2.18s/ba]Running tokenizer on dataset:   2%|▏         | 16/814 [00:34<28:56,  2.18s/ba]Running tokenizer on dataset:   2%|▏         | 17/814 [00:36<28:48,  2.17s/ba]Running tokenizer on dataset:   2%|▏         | 18/814 [00:38<28:41,  2.16s/ba]Running tokenizer on dataset:   2%|▏         | 19/814 [00:41<28:44,  2.17s/ba]Running tokenizer on dataset:   2%|▏         | 20/814 [00:43<28:34,  2.16s/ba]Running tokenizer on dataset:   3%|▎         | 21/814 [00:45<28:31,  2.16s/ba]Running tokenizer on dataset:   3%|▎         | 22/814 [00:47<28:23,  2.15s/ba]Running tokenizer on dataset:   3%|▎         | 23/814 [00:49<28:18,  2.15s/ba]Running tokenizer on dataset:   3%|▎         | 24/814 [00:51<28:13,  2.14s/ba]Running tokenizer on dataset:   3%|▎         | 25/814 [00:53<28:11,  2.14s/ba]Running tokenizer on dataset:   3%|▎         | 26/814 [00:55<28:06,  2.14s/ba]Running tokenizer on dataset:   3%|▎         | 27/814 [00:58<28:04,  2.14s/ba]Running tokenizer on dataset:   3%|▎         | 28/814 [01:00<28:08,  2.15s/ba]Running tokenizer on dataset:   4%|▎         | 29/814 [01:02<28:23,  2.17s/ba]Running tokenizer on dataset:   4%|▎         | 30/814 [01:04<28:27,  2.18s/ba]Running tokenizer on dataset:   4%|▍         | 31/814 [01:06<28:22,  2.17s/ba]Running tokenizer on dataset:   4%|▍         | 32/814 [01:09<28:24,  2.18s/ba]Running tokenizer on dataset:   4%|▍         | 33/814 [01:11<28:19,  2.18s/ba]Running tokenizer on dataset:   4%|▍         | 34/814 [01:13<28:08,  2.17s/ba]Running tokenizer on dataset:   4%|▍         | 35/814 [01:15<28:05,  2.16s/ba]Running tokenizer on dataset:   4%|▍         | 36/814 [01:17<27:52,  2.15s/ba]Running tokenizer on dataset:   5%|▍         | 37/814 [01:19<27:47,  2.15s/ba]Running tokenizer on dataset:   5%|▍         | 38/814 [01:21<27:39,  2.14s/ba]Running tokenizer on dataset:   5%|▍         | 39/814 [01:24<27:51,  2.16s/ba]Running tokenizer on dataset:   5%|▍         | 40/814 [01:26<27:44,  2.15s/ba]Running tokenizer on dataset:   5%|▌         | 41/814 [01:28<27:46,  2.16s/ba]Running tokenizer on dataset:   5%|▌         | 42/814 [01:30<27:47,  2.16s/ba]Running tokenizer on dataset:   5%|▌         | 43/814 [01:32<27:43,  2.16s/ba]Running tokenizer on dataset:   5%|▌         | 44/814 [01:34<27:42,  2.16s/ba]Running tokenizer on dataset:   6%|▌         | 45/814 [01:37<27:40,  2.16s/ba]Running tokenizer on dataset:   6%|▌         | 46/814 [01:39<27:34,  2.15s/ba]Running tokenizer on dataset:   6%|▌         | 47/814 [01:41<27:30,  2.15s/ba]Running tokenizer on dataset:   6%|▌         | 48/814 [01:43<27:19,  2.14s/ba]Running tokenizer on dataset:   6%|▌         | 49/814 [01:45<27:26,  2.15s/ba]Running tokenizer on dataset:   6%|▌         | 50/814 [01:47<27:23,  2.15s/ba]Running tokenizer on dataset:   6%|▋         | 51/814 [01:49<27:16,  2.14s/ba]Running tokenizer on dataset:   6%|▋         | 52/814 [01:52<27:23,  2.16s/ba]Running tokenizer on dataset:   7%|▋         | 53/814 [01:54<27:27,  2.17s/ba]Running tokenizer on dataset:   7%|▋         | 54/814 [01:56<27:27,  2.17s/ba]Running tokenizer on dataset:   7%|▋         | 55/814 [01:58<27:30,  2.17s/ba]Running tokenizer on dataset:   7%|▋         | 56/814 [02:00<27:23,  2.17s/ba]Running tokenizer on dataset:   7%|▋         | 57/814 [02:02<27:27,  2.18s/ba]Running tokenizer on dataset:   7%|▋         | 58/814 [02:05<27:18,  2.17s/ba]Running tokenizer on dataset:   7%|▋         | 59/814 [02:07<27:15,  2.17s/ba]Running tokenizer on dataset:   7%|▋         | 60/814 [02:09<27:09,  2.16s/ba]Running tokenizer on dataset:   7%|▋         | 61/814 [02:11<27:04,  2.16s/ba]Running tokenizer on dataset:   8%|▊         | 62/814 [02:13<27:05,  2.16s/ba]Running tokenizer on dataset:   8%|▊         | 63/814 [02:15<26:58,  2.16s/ba]Running tokenizer on dataset:   8%|▊         | 64/814 [02:18<26:57,  2.16s/ba]Running tokenizer on dataset:   8%|▊         | 65/814 [02:20<27:04,  2.17s/ba]Running tokenizer on dataset:   8%|▊         | 66/814 [02:22<27:09,  2.18s/ba]Running tokenizer on dataset:   8%|▊         | 67/814 [02:24<26:55,  2.16s/ba]Running tokenizer on dataset:   8%|▊         | 68/814 [02:26<26:49,  2.16s/ba]Running tokenizer on dataset:   8%|▊         | 69/814 [02:28<26:46,  2.16s/ba]Running tokenizer on dataset:   9%|▊         | 70/814 [02:31<26:46,  2.16s/ba]Running tokenizer on dataset:   9%|▊         | 71/814 [02:33<26:43,  2.16s/ba]Running tokenizer on dataset:   9%|▉         | 72/814 [02:35<27:36,  2.23s/ba]Running tokenizer on dataset:   9%|▉         | 73/814 [02:37<27:15,  2.21s/ba]Running tokenizer on dataset:   9%|▉         | 74/814 [02:39<27:02,  2.19s/ba]Running tokenizer on dataset:   9%|▉         | 75/814 [02:42<26:50,  2.18s/ba]Running tokenizer on dataset:   9%|▉         | 76/814 [02:44<26:47,  2.18s/ba]Running tokenizer on dataset:   9%|▉         | 77/814 [02:46<26:37,  2.17s/ba]Running tokenizer on dataset:  10%|▉         | 78/814 [02:48<26:42,  2.18s/ba]Running tokenizer on dataset:  10%|▉         | 79/814 [02:50<26:32,  2.17s/ba]Running tokenizer on dataset:  10%|▉         | 80/814 [02:52<26:24,  2.16s/ba]Running tokenizer on dataset:  10%|▉         | 81/814 [02:55<26:22,  2.16s/ba]Running tokenizer on dataset:  10%|█         | 82/814 [02:57<26:27,  2.17s/ba]Running tokenizer on dataset:  10%|█         | 83/814 [02:59<26:18,  2.16s/ba]Running tokenizer on dataset:  10%|█         | 84/814 [03:01<26:13,  2.16s/ba]Running tokenizer on dataset:  10%|█         | 85/814 [03:03<26:13,  2.16s/ba]Running tokenizer on dataset:  11%|█         | 86/814 [03:05<26:43,  2.20s/ba]Running tokenizer on dataset:  11%|█         | 87/814 [03:08<26:33,  2.19s/ba]Running tokenizer on dataset:  11%|█         | 88/814 [03:10<26:25,  2.18s/ba]Running tokenizer on dataset:  11%|█         | 89/814 [03:12<26:32,  2.20s/ba]Running tokenizer on dataset:  11%|█         | 90/814 [03:14<26:19,  2.18s/ba]Running tokenizer on dataset:  11%|█         | 91/814 [03:16<26:14,  2.18s/ba]Running tokenizer on dataset:  11%|█▏        | 92/814 [03:19<26:04,  2.17s/ba]Running tokenizer on dataset:  11%|█▏        | 93/814 [03:21<26:04,  2.17s/ba]Running tokenizer on dataset:  12%|█▏        | 94/814 [03:23<26:05,  2.17s/ba]Running tokenizer on dataset:  12%|█▏        | 95/814 [03:25<25:59,  2.17s/ba]Running tokenizer on dataset:  12%|█▏        | 96/814 [03:27<26:01,  2.17s/ba]Running tokenizer on dataset:  12%|█▏        | 97/814 [03:29<26:06,  2.18s/ba]Running tokenizer on dataset:  12%|█▏        | 98/814 [03:32<26:04,  2.19s/ba]Running tokenizer on dataset:  12%|█▏        | 99/814 [03:34<26:09,  2.19s/ba]Running tokenizer on dataset:  12%|█▏        | 100/814 [03:36<26:04,  2.19s/ba]Running tokenizer on dataset:  12%|█▏        | 101/814 [03:38<25:59,  2.19s/ba]Running tokenizer on dataset:  13%|█▎        | 102/814 [03:40<25:53,  2.18s/ba]Running tokenizer on dataset:  13%|█▎        | 103/814 [03:43<25:52,  2.18s/ba]Running tokenizer on dataset:  13%|█▎        | 104/814 [03:45<25:45,  2.18s/ba]Running tokenizer on dataset:  13%|█▎        | 105/814 [03:47<25:41,  2.17s/ba]Running tokenizer on dataset:  13%|█▎        | 106/814 [03:49<25:32,  2.16s/ba]Running tokenizer on dataset:  13%|█▎        | 107/814 [03:51<25:35,  2.17s/ba]Running tokenizer on dataset:  13%|█▎        | 108/814 [03:53<25:37,  2.18s/ba]Running tokenizer on dataset:  13%|█▎        | 109/814 [03:56<25:33,  2.18s/ba]Running tokenizer on dataset:  14%|█▎        | 110/814 [03:58<25:30,  2.17s/ba]Running tokenizer on dataset:  14%|█▎        | 111/814 [04:00<25:24,  2.17s/ba]Running tokenizer on dataset:  14%|█▍        | 112/814 [04:02<25:24,  2.17s/ba]Running tokenizer on dataset:  14%|█▍        | 113/814 [04:04<25:24,  2.17s/ba]Running tokenizer on dataset:  14%|█▍        | 114/814 [04:06<25:25,  2.18s/ba]Running tokenizer on dataset:  14%|█▍        | 115/814 [04:09<25:23,  2.18s/ba]Running tokenizer on dataset:  14%|█▍        | 116/814 [04:11<25:18,  2.17s/ba]Running tokenizer on dataset:  14%|█▍        | 117/814 [04:13<25:22,  2.18s/ba]Running tokenizer on dataset:  14%|█▍        | 118/814 [04:15<25:32,  2.20s/ba]Running tokenizer on dataset:  15%|█▍        | 119/814 [04:17<25:11,  2.17s/ba]Running tokenizer on dataset:  15%|█▍        | 120/814 [04:20<25:05,  2.17s/ba]Running tokenizer on dataset:  15%|█▍        | 121/814 [04:22<25:11,  2.18s/ba]Running tokenizer on dataset:  15%|█▍        | 122/814 [04:24<25:07,  2.18s/ba]Running tokenizer on dataset:  15%|█▌        | 123/814 [04:26<24:59,  2.17s/ba]Running tokenizer on dataset:  15%|█▌        | 124/814 [04:28<24:58,  2.17s/ba]Running tokenizer on dataset:  15%|█▌        | 125/814 [04:30<24:52,  2.17s/ba]Running tokenizer on dataset:  15%|█▌        | 126/814 [04:33<24:55,  2.17s/ba]Running tokenizer on dataset:  16%|█▌        | 127/814 [04:35<24:56,  2.18s/ba]Running tokenizer on dataset:  16%|█▌        | 128/814 [04:37<24:45,  2.17s/ba]Running tokenizer on dataset:  16%|█▌        | 129/814 [04:39<24:50,  2.18s/ba]Running tokenizer on dataset:  16%|█▌        | 130/814 [04:41<24:40,  2.16s/ba]Running tokenizer on dataset:  16%|█▌        | 131/814 [04:43<24:43,  2.17s/ba]Running tokenizer on dataset:  16%|█▌        | 132/814 [04:46<24:33,  2.16s/ba]Running tokenizer on dataset:  16%|█▋        | 133/814 [04:48<24:34,  2.16s/ba]Running tokenizer on dataset:  16%|█▋        | 134/814 [04:50<24:30,  2.16s/ba]Running tokenizer on dataset:  17%|█▋        | 135/814 [04:52<24:28,  2.16s/ba]Running tokenizer on dataset:  17%|█▋        | 136/814 [04:54<24:28,  2.17s/ba]Running tokenizer on dataset:  17%|█▋        | 137/814 [04:56<24:28,  2.17s/ba]Running tokenizer on dataset:  17%|█▋        | 138/814 [04:59<24:23,  2.16s/ba]Running tokenizer on dataset:  17%|█▋        | 139/814 [05:01<24:19,  2.16s/ba]Running tokenizer on dataset:  17%|█▋        | 140/814 [05:03<24:17,  2.16s/ba]Running tokenizer on dataset:  17%|█▋        | 141/814 [05:05<24:17,  2.17s/ba]Running tokenizer on dataset:  17%|█▋        | 142/814 [05:07<24:25,  2.18s/ba]Running tokenizer on dataset:  18%|█▊        | 143/814 [05:09<24:21,  2.18s/ba]Running tokenizer on dataset:  18%|█▊        | 144/814 [05:12<24:14,  2.17s/ba]Running tokenizer on dataset:  18%|█▊        | 145/814 [05:14<24:13,  2.17s/ba]Running tokenizer on dataset:  18%|█▊        | 146/814 [05:16<24:06,  2.17s/ba]Running tokenizer on dataset:  18%|█▊        | 147/814 [05:18<24:17,  2.18s/ba]Running tokenizer on dataset:  18%|█▊        | 148/814 [05:20<24:18,  2.19s/ba]Running tokenizer on dataset:  18%|█▊        | 149/814 [05:22<24:01,  2.17s/ba]Running tokenizer on dataset:  18%|█▊        | 150/814 [05:25<23:56,  2.16s/ba]Running tokenizer on dataset:  19%|█▊        | 151/814 [05:27<23:49,  2.16s/ba]Running tokenizer on dataset:  19%|█▊        | 152/814 [05:29<23:45,  2.15s/ba]Running tokenizer on dataset:  19%|█▉        | 153/814 [05:31<23:51,  2.17s/ba]Running tokenizer on dataset:  19%|█▉        | 154/814 [05:33<23:54,  2.17s/ba]Running tokenizer on dataset:  19%|█▉        | 155/814 [05:35<23:48,  2.17s/ba]Running tokenizer on dataset:  19%|█▉        | 156/814 [05:38<23:48,  2.17s/ba]Running tokenizer on dataset:  19%|█▉        | 157/814 [05:40<23:45,  2.17s/ba]Running tokenizer on dataset:  19%|█▉        | 158/814 [05:42<23:35,  2.16s/ba]Running tokenizer on dataset:  20%|█▉        | 159/814 [05:44<23:39,  2.17s/ba]Running tokenizer on dataset:  20%|█▉        | 160/814 [05:46<23:35,  2.17s/ba]Running tokenizer on dataset:  20%|█▉        | 161/814 [05:48<23:29,  2.16s/ba]Running tokenizer on dataset:  20%|█▉        | 162/814 [05:51<23:30,  2.16s/ba]Running tokenizer on dataset:  20%|██        | 163/814 [05:53<23:25,  2.16s/ba]Running tokenizer on dataset:  20%|██        | 164/814 [05:55<23:27,  2.17s/ba]Running tokenizer on dataset:  20%|██        | 165/814 [05:57<23:30,  2.17s/ba]Running tokenizer on dataset:  20%|██        | 166/814 [05:59<23:32,  2.18s/ba]Running tokenizer on dataset:  21%|██        | 167/814 [06:01<23:28,  2.18s/ba]Running tokenizer on dataset:  21%|██        | 168/814 [06:04<23:18,  2.17s/ba]Running tokenizer on dataset:  21%|██        | 169/814 [06:06<23:20,  2.17s/ba]Running tokenizer on dataset:  21%|██        | 170/814 [06:08<23:15,  2.17s/ba]Running tokenizer on dataset:  21%|██        | 171/814 [06:10<23:42,  2.21s/ba]Running tokenizer on dataset:  21%|██        | 172/814 [06:12<23:35,  2.21s/ba]Running tokenizer on dataset:  21%|██▏       | 173/814 [06:15<23:32,  2.20s/ba]Running tokenizer on dataset:  21%|██▏       | 174/814 [06:17<23:20,  2.19s/ba]Running tokenizer on dataset:  21%|██▏       | 175/814 [06:19<23:12,  2.18s/ba]Running tokenizer on dataset:  22%|██▏       | 176/814 [06:21<23:02,  2.17s/ba]Running tokenizer on dataset:  22%|██▏       | 177/814 [06:23<23:01,  2.17s/ba]Running tokenizer on dataset:  22%|██▏       | 178/814 [06:25<22:59,  2.17s/ba]Running tokenizer on dataset:  22%|██▏       | 179/814 [06:28<23:00,  2.17s/ba]Running tokenizer on dataset:  22%|██▏       | 180/814 [06:30<22:49,  2.16s/ba]Running tokenizer on dataset:  22%|██▏       | 181/814 [06:32<22:46,  2.16s/ba]Running tokenizer on dataset:  22%|██▏       | 182/814 [06:34<22:51,  2.17s/ba]Running tokenizer on dataset:  22%|██▏       | 183/814 [06:36<22:52,  2.18s/ba]Running tokenizer on dataset:  23%|██▎       | 184/814 [06:38<22:46,  2.17s/ba]Running tokenizer on dataset:  23%|██▎       | 185/814 [06:41<22:41,  2.16s/ba]Running tokenizer on dataset:  23%|██▎       | 186/814 [06:43<22:36,  2.16s/ba]Running tokenizer on dataset:  23%|██▎       | 187/814 [06:45<22:31,  2.16s/ba]Running tokenizer on dataset:  23%|██▎       | 188/814 [06:47<22:28,  2.15s/ba]Running tokenizer on dataset:  23%|██▎       | 189/814 [06:49<22:24,  2.15s/ba]Running tokenizer on dataset:  23%|██▎       | 190/814 [06:51<22:25,  2.16s/ba]Running tokenizer on dataset:  23%|██▎       | 191/814 [06:54<22:33,  2.17s/ba]Running tokenizer on dataset:  24%|██▎       | 192/814 [06:56<22:26,  2.16s/ba]Running tokenizer on dataset:  24%|██▎       | 193/814 [06:58<22:26,  2.17s/ba]Running tokenizer on dataset:  24%|██▍       | 194/814 [07:00<22:19,  2.16s/ba]Running tokenizer on dataset:  24%|██▍       | 195/814 [07:02<22:19,  2.16s/ba]Running tokenizer on dataset:  24%|██▍       | 196/814 [07:04<22:14,  2.16s/ba]Running tokenizer on dataset:  24%|██▍       | 197/814 [07:07<22:11,  2.16s/ba]Running tokenizer on dataset:  24%|██▍       | 198/814 [07:09<22:16,  2.17s/ba]Running tokenizer on dataset:  24%|██▍       | 199/814 [07:11<22:11,  2.17s/ba]Running tokenizer on dataset:  25%|██▍       | 200/814 [07:13<22:00,  2.15s/ba]Running tokenizer on dataset:  25%|██▍       | 201/814 [07:15<21:55,  2.15s/ba]Running tokenizer on dataset:  25%|██▍       | 202/814 [07:17<21:54,  2.15s/ba]Running tokenizer on dataset:  25%|██▍       | 203/814 [07:19<21:55,  2.15s/ba]Running tokenizer on dataset:  25%|██▌       | 204/814 [07:22<21:56,  2.16s/ba]Running tokenizer on dataset:  25%|██▌       | 205/814 [07:24<21:46,  2.15s/ba]Running tokenizer on dataset:  25%|██▌       | 206/814 [07:26<21:51,  2.16s/ba]Running tokenizer on dataset:  25%|██▌       | 207/814 [07:28<21:48,  2.16s/ba]Running tokenizer on dataset:  26%|██▌       | 208/814 [07:30<21:42,  2.15s/ba]Running tokenizer on dataset:  26%|██▌       | 209/814 [07:32<21:46,  2.16s/ba]Running tokenizer on dataset:  26%|██▌       | 210/814 [07:35<21:41,  2.16s/ba]Running tokenizer on dataset:  26%|██▌       | 211/814 [07:37<21:38,  2.15s/ba]Running tokenizer on dataset:  26%|██▌       | 212/814 [07:39<21:29,  2.14s/ba]Running tokenizer on dataset:  26%|██▌       | 213/814 [07:41<21:24,  2.14s/ba]Running tokenizer on dataset:  26%|██▋       | 214/814 [07:43<21:17,  2.13s/ba]Running tokenizer on dataset:  26%|██▋       | 215/814 [07:45<21:20,  2.14s/ba]Running tokenizer on dataset:  27%|██▋       | 216/814 [07:47<21:14,  2.13s/ba]Running tokenizer on dataset:  27%|██▋       | 217/814 [07:49<21:19,  2.14s/ba]Running tokenizer on dataset:  27%|██▋       | 218/814 [07:52<21:22,  2.15s/ba]Running tokenizer on dataset:  27%|██▋       | 219/814 [07:54<21:25,  2.16s/ba]Running tokenizer on dataset:  27%|██▋       | 220/814 [07:56<21:19,  2.15s/ba]Running tokenizer on dataset:  27%|██▋       | 221/814 [07:58<21:16,  2.15s/ba]Running tokenizer on dataset:  27%|██▋       | 222/814 [08:00<21:04,  2.14s/ba]Running tokenizer on dataset:  27%|██▋       | 223/814 [08:02<21:02,  2.14s/ba]Running tokenizer on dataset:  28%|██▊       | 224/814 [08:05<21:07,  2.15s/ba]Running tokenizer on dataset:  28%|██▊       | 225/814 [08:07<21:06,  2.15s/ba]Running tokenizer on dataset:  28%|██▊       | 226/814 [08:09<21:09,  2.16s/ba]Running tokenizer on dataset:  28%|██▊       | 227/814 [08:11<21:07,  2.16s/ba]Running tokenizer on dataset:  28%|██▊       | 228/814 [08:13<20:55,  2.14s/ba]Running tokenizer on dataset:  28%|██▊       | 229/814 [08:15<20:57,  2.15s/ba]Running tokenizer on dataset:  28%|██▊       | 230/814 [08:17<20:53,  2.15s/ba]Running tokenizer on dataset:  28%|██▊       | 231/814 [08:20<20:49,  2.14s/ba]Running tokenizer on dataset:  29%|██▊       | 232/814 [08:22<20:41,  2.13s/ba]Running tokenizer on dataset:  29%|██▊       | 233/814 [08:24<20:45,  2.14s/ba]Running tokenizer on dataset:  29%|██▊       | 234/814 [08:26<20:44,  2.15s/ba]Running tokenizer on dataset:  29%|██▉       | 235/814 [08:28<20:44,  2.15s/ba]Running tokenizer on dataset:  29%|██▉       | 236/814 [08:30<20:46,  2.16s/ba]Running tokenizer on dataset:  29%|██▉       | 237/814 [08:32<20:44,  2.16s/ba]Running tokenizer on dataset:  29%|██▉       | 238/814 [08:35<20:49,  2.17s/ba]Running tokenizer on dataset:  29%|██▉       | 239/814 [08:37<20:46,  2.17s/ba]Running tokenizer on dataset:  29%|██▉       | 240/814 [08:39<20:43,  2.17s/ba]Running tokenizer on dataset:  30%|██▉       | 241/814 [08:41<20:40,  2.17s/ba]Running tokenizer on dataset:  30%|██▉       | 242/814 [08:43<20:35,  2.16s/ba]Running tokenizer on dataset:  30%|██▉       | 243/814 [08:45<20:27,  2.15s/ba]Running tokenizer on dataset:  30%|██▉       | 244/814 [08:48<20:30,  2.16s/ba]Running tokenizer on dataset:  30%|███       | 245/814 [08:50<20:28,  2.16s/ba]Running tokenizer on dataset:  30%|███       | 246/814 [08:52<20:17,  2.14s/ba]Running tokenizer on dataset:  30%|███       | 247/814 [08:54<20:15,  2.14s/ba]Running tokenizer on dataset:  30%|███       | 248/814 [08:56<20:05,  2.13s/ba]Running tokenizer on dataset:  31%|███       | 249/814 [08:58<20:13,  2.15s/ba]Running tokenizer on dataset:  31%|███       | 250/814 [09:00<20:12,  2.15s/ba]Running tokenizer on dataset:  31%|███       | 251/814 [09:03<20:13,  2.16s/ba]Running tokenizer on dataset:  31%|███       | 252/814 [09:05<20:07,  2.15s/ba]Running tokenizer on dataset:  31%|███       | 253/814 [09:07<20:08,  2.16s/ba]Running tokenizer on dataset:  31%|███       | 254/814 [09:09<20:07,  2.16s/ba]Running tokenizer on dataset:  31%|███▏      | 255/814 [09:11<20:04,  2.15s/ba]Running tokenizer on dataset:  31%|███▏      | 256/814 [09:13<20:01,  2.15s/ba]Running tokenizer on dataset:  32%|███▏      | 257/814 [09:16<19:57,  2.15s/ba]Running tokenizer on dataset:  32%|███▏      | 258/814 [09:18<19:55,  2.15s/ba]Running tokenizer on dataset:  32%|███▏      | 259/814 [09:20<19:48,  2.14s/ba]Running tokenizer on dataset:  32%|███▏      | 260/814 [09:22<19:52,  2.15s/ba]Running tokenizer on dataset:  32%|███▏      | 261/814 [09:24<19:49,  2.15s/ba]Running tokenizer on dataset:  32%|███▏      | 262/814 [09:26<19:50,  2.16s/ba]Running tokenizer on dataset:  32%|███▏      | 263/814 [09:28<19:48,  2.16s/ba]Running tokenizer on dataset:  32%|███▏      | 264/814 [09:31<19:44,  2.15s/ba]Running tokenizer on dataset:  33%|███▎      | 265/814 [09:33<19:40,  2.15s/ba]Running tokenizer on dataset:  33%|███▎      | 266/814 [09:35<19:43,  2.16s/ba]Running tokenizer on dataset:  33%|███▎      | 267/814 [09:37<19:38,  2.15s/ba]Running tokenizer on dataset:  33%|███▎      | 268/814 [09:39<19:32,  2.15s/ba]Running tokenizer on dataset:  33%|███▎      | 269/814 [09:41<19:27,  2.14s/ba]Running tokenizer on dataset:  33%|███▎      | 270/814 [09:43<19:25,  2.14s/ba]Running tokenizer on dataset:  33%|███▎      | 271/814 [09:46<19:26,  2.15s/ba]Running tokenizer on dataset:  33%|███▎      | 272/814 [09:48<19:21,  2.14s/ba]Running tokenizer on dataset:  34%|███▎      | 273/814 [09:50<19:22,  2.15s/ba]Running tokenizer on dataset:  34%|███▎      | 274/814 [09:52<19:16,  2.14s/ba]Running tokenizer on dataset:  34%|███▍      | 275/814 [09:54<19:13,  2.14s/ba]Running tokenizer on dataset:  34%|███▍      | 276/814 [09:56<19:16,  2.15s/ba]Running tokenizer on dataset:  34%|███▍      | 277/814 [09:59<19:17,  2.16s/ba]Running tokenizer on dataset:  34%|███▍      | 278/814 [10:01<19:17,  2.16s/ba]Running tokenizer on dataset:  34%|███▍      | 279/814 [10:03<19:12,  2.15s/ba]Running tokenizer on dataset:  34%|███▍      | 280/814 [10:05<19:07,  2.15s/ba]Running tokenizer on dataset:  35%|███▍      | 281/814 [10:07<19:09,  2.16s/ba]Running tokenizer on dataset:  35%|███▍      | 282/814 [10:09<19:09,  2.16s/ba]Running tokenizer on dataset:  35%|███▍      | 283/814 [10:11<19:06,  2.16s/ba]Running tokenizer on dataset:  35%|███▍      | 284/814 [10:14<19:03,  2.16s/ba]Running tokenizer on dataset:  35%|███▌      | 285/814 [10:16<18:57,  2.15s/ba]Running tokenizer on dataset:  35%|███▌      | 286/814 [10:18<18:55,  2.15s/ba]Running tokenizer on dataset:  35%|███▌      | 287/814 [10:20<19:00,  2.16s/ba]Running tokenizer on dataset:  35%|███▌      | 288/814 [10:22<19:00,  2.17s/ba]Running tokenizer on dataset:  36%|███▌      | 289/814 [10:24<18:58,  2.17s/ba]Running tokenizer on dataset:  36%|███▌      | 290/814 [10:27<18:58,  2.17s/ba]Running tokenizer on dataset:  36%|███▌      | 291/814 [10:29<18:56,  2.17s/ba]Running tokenizer on dataset:  36%|███▌      | 292/814 [10:31<18:46,  2.16s/ba]Running tokenizer on dataset:  36%|███▌      | 293/814 [10:33<18:42,  2.16s/ba]Running tokenizer on dataset:  36%|███▌      | 294/814 [10:35<18:37,  2.15s/ba]Running tokenizer on dataset:  36%|███▌      | 295/814 [10:37<18:34,  2.15s/ba]Running tokenizer on dataset:  36%|███▋      | 296/814 [10:40<18:38,  2.16s/ba]Running tokenizer on dataset:  36%|███▋      | 297/814 [10:42<18:42,  2.17s/ba]Running tokenizer on dataset:  37%|███▋      | 298/814 [10:44<18:42,  2.18s/ba]Running tokenizer on dataset:  37%|███▋      | 299/814 [10:46<18:38,  2.17s/ba]Running tokenizer on dataset:  37%|███▋      | 300/814 [10:48<18:37,  2.17s/ba]Running tokenizer on dataset:  37%|███▋      | 301/814 [10:50<18:31,  2.17s/ba]Running tokenizer on dataset:  37%|███▋      | 302/814 [10:53<18:18,  2.15s/ba]Running tokenizer on dataset:  37%|███▋      | 303/814 [10:55<18:18,  2.15s/ba]Running tokenizer on dataset:  37%|███▋      | 304/814 [10:57<18:16,  2.15s/ba]Running tokenizer on dataset:  37%|███▋      | 305/814 [10:59<18:16,  2.15s/ba]Running tokenizer on dataset:  38%|███▊      | 306/814 [11:01<18:34,  2.19s/ba]Running tokenizer on dataset:  38%|███▊      | 307/814 [11:03<18:28,  2.19s/ba]Running tokenizer on dataset:  38%|███▊      | 308/814 [11:06<18:16,  2.17s/ba]Running tokenizer on dataset:  38%|███▊      | 309/814 [11:08<18:14,  2.17s/ba]Running tokenizer on dataset:  38%|███▊      | 310/814 [11:10<18:04,  2.15s/ba]Running tokenizer on dataset:  38%|███▊      | 311/814 [11:12<18:02,  2.15s/ba]Running tokenizer on dataset:  38%|███▊      | 312/814 [11:14<18:01,  2.16s/ba]Running tokenizer on dataset:  38%|███▊      | 313/814 [11:16<17:57,  2.15s/ba]Running tokenizer on dataset:  39%|███▊      | 314/814 [11:19<17:59,  2.16s/ba]Running tokenizer on dataset:  39%|███▊      | 315/814 [11:21<18:01,  2.17s/ba]Running tokenizer on dataset:  39%|███▉      | 316/814 [11:23<17:50,  2.15s/ba]Running tokenizer on dataset:  39%|███▉      | 317/814 [11:25<17:46,  2.15s/ba]Running tokenizer on dataset:  39%|███▉      | 318/814 [11:27<17:42,  2.14s/ba]Running tokenizer on dataset:  39%|███▉      | 319/814 [11:29<17:44,  2.15s/ba]Running tokenizer on dataset:  39%|███▉      | 320/814 [11:31<17:37,  2.14s/ba]Running tokenizer on dataset:  39%|███▉      | 321/814 [11:34<17:39,  2.15s/ba]Running tokenizer on dataset:  40%|███▉      | 322/814 [11:36<17:42,  2.16s/ba]Running tokenizer on dataset:  40%|███▉      | 323/814 [11:38<17:39,  2.16s/ba]Running tokenizer on dataset:  40%|███▉      | 324/814 [11:40<17:35,  2.15s/ba]Running tokenizer on dataset:  40%|███▉      | 325/814 [11:42<17:36,  2.16s/ba]Running tokenizer on dataset:  40%|████      | 326/814 [11:44<17:33,  2.16s/ba]Running tokenizer on dataset:  40%|████      | 327/814 [11:46<17:27,  2.15s/ba]Running tokenizer on dataset:  40%|████      | 328/814 [11:49<17:30,  2.16s/ba]Running tokenizer on dataset:  40%|████      | 329/814 [11:51<17:35,  2.18s/ba]Running tokenizer on dataset:  41%|████      | 330/814 [11:53<17:27,  2.16s/ba]Running tokenizer on dataset:  41%|████      | 331/814 [11:55<17:27,  2.17s/ba]Running tokenizer on dataset:  41%|████      | 332/814 [11:57<17:22,  2.16s/ba]Running tokenizer on dataset:  41%|████      | 333/814 [11:59<17:17,  2.16s/ba]Running tokenizer on dataset:  41%|████      | 334/814 [12:02<17:14,  2.16s/ba]Running tokenizer on dataset:  41%|████      | 335/814 [12:04<17:12,  2.16s/ba]Running tokenizer on dataset:  41%|████▏     | 336/814 [12:06<17:14,  2.16s/ba]Running tokenizer on dataset:  41%|████▏     | 337/814 [12:08<17:14,  2.17s/ba]Running tokenizer on dataset:  42%|████▏     | 338/814 [12:10<17:06,  2.16s/ba]Running tokenizer on dataset:  42%|████▏     | 339/814 [12:12<17:04,  2.16s/ba]Running tokenizer on dataset:  42%|████▏     | 340/814 [12:15<17:05,  2.16s/ba]Running tokenizer on dataset:  42%|████▏     | 341/814 [12:17<17:05,  2.17s/ba]Running tokenizer on dataset:  42%|████▏     | 342/814 [12:19<16:56,  2.15s/ba]Running tokenizer on dataset:  42%|████▏     | 343/814 [12:21<16:56,  2.16s/ba]Running tokenizer on dataset:  42%|████▏     | 344/814 [12:23<16:50,  2.15s/ba]Running tokenizer on dataset:  42%|████▏     | 345/814 [12:25<16:50,  2.15s/ba]Running tokenizer on dataset:  43%|████▎     | 346/814 [12:28<16:47,  2.15s/ba]Running tokenizer on dataset:  43%|████▎     | 347/814 [12:30<16:51,  2.17s/ba]Running tokenizer on dataset:  43%|████▎     | 348/814 [12:32<16:47,  2.16s/ba]Running tokenizer on dataset:  43%|████▎     | 349/814 [12:34<16:44,  2.16s/ba]Running tokenizer on dataset:  43%|████▎     | 350/814 [12:36<16:43,  2.16s/ba]Running tokenizer on dataset:  43%|████▎     | 351/814 [12:38<16:40,  2.16s/ba]Running tokenizer on dataset:  43%|████▎     | 352/814 [12:40<16:33,  2.15s/ba]Running tokenizer on dataset:  43%|████▎     | 353/814 [12:43<16:34,  2.16s/ba]Running tokenizer on dataset:  43%|████▎     | 354/814 [12:45<16:26,  2.14s/ba]Running tokenizer on dataset:  44%|████▎     | 355/814 [12:47<16:28,  2.15s/ba]Running tokenizer on dataset:  44%|████▎     | 356/814 [12:49<16:22,  2.15s/ba]Running tokenizer on dataset:  44%|████▍     | 357/814 [12:51<16:18,  2.14s/ba]Running tokenizer on dataset:  44%|████▍     | 358/814 [12:53<16:19,  2.15s/ba]Running tokenizer on dataset:  44%|████▍     | 359/814 [12:56<16:16,  2.15s/ba]Running tokenizer on dataset:  44%|████▍     | 360/814 [12:58<16:11,  2.14s/ba]Running tokenizer on dataset:  44%|████▍     | 361/814 [13:00<16:06,  2.13s/ba]Running tokenizer on dataset:  44%|████▍     | 362/814 [13:02<16:08,  2.14s/ba]Running tokenizer on dataset:  45%|████▍     | 363/814 [13:04<16:04,  2.14s/ba]Running tokenizer on dataset:  45%|████▍     | 364/814 [13:06<16:02,  2.14s/ba]Running tokenizer on dataset:  45%|████▍     | 365/814 [13:08<15:59,  2.14s/ba]Running tokenizer on dataset:  45%|████▍     | 366/814 [13:11<16:05,  2.16s/ba]Running tokenizer on dataset:  45%|████▌     | 367/814 [13:13<15:58,  2.15s/ba]Running tokenizer on dataset:  45%|████▌     | 368/814 [13:15<15:51,  2.13s/ba]Running tokenizer on dataset:  45%|████▌     | 369/814 [13:17<15:52,  2.14s/ba]Running tokenizer on dataset:  45%|████▌     | 370/814 [13:19<15:49,  2.14s/ba]Running tokenizer on dataset:  46%|████▌     | 371/814 [13:21<15:48,  2.14s/ba]Running tokenizer on dataset:  46%|████▌     | 372/814 [13:23<15:42,  2.13s/ba]Running tokenizer on dataset:  46%|████▌     | 373/814 [13:25<15:46,  2.15s/ba]Running tokenizer on dataset:  46%|████▌     | 374/814 [13:28<15:46,  2.15s/ba]Running tokenizer on dataset:  46%|████▌     | 375/814 [13:30<15:48,  2.16s/ba]Running tokenizer on dataset:  46%|████▌     | 376/814 [13:32<15:48,  2.16s/ba]Running tokenizer on dataset:  46%|████▋     | 377/814 [13:34<15:46,  2.17s/ba]Running tokenizer on dataset:  46%|████▋     | 378/814 [13:36<15:40,  2.16s/ba]Running tokenizer on dataset:  47%|████▋     | 379/814 [13:38<15:36,  2.15s/ba]Running tokenizer on dataset:  47%|████▋     | 380/814 [13:41<15:35,  2.16s/ba]Running tokenizer on dataset:  47%|████▋     | 381/814 [13:43<15:33,  2.16s/ba]Running tokenizer on dataset:  47%|████▋     | 382/814 [13:45<15:28,  2.15s/ba]Running tokenizer on dataset:  47%|████▋     | 383/814 [13:47<15:23,  2.14s/ba]Running tokenizer on dataset:  47%|████▋     | 384/814 [13:49<15:22,  2.14s/ba]Running tokenizer on dataset:  47%|████▋     | 385/814 [13:51<15:23,  2.15s/ba]Running tokenizer on dataset:  47%|████▋     | 386/814 [13:53<15:21,  2.15s/ba]Running tokenizer on dataset:  48%|████▊     | 387/814 [13:56<15:19,  2.15s/ba]Running tokenizer on dataset:  48%|████▊     | 388/814 [13:58<15:14,  2.15s/ba]Running tokenizer on dataset:  48%|████▊     | 389/814 [14:00<15:16,  2.16s/ba]Running tokenizer on dataset:  48%|████▊     | 390/814 [14:02<15:11,  2.15s/ba]Running tokenizer on dataset:  48%|████▊     | 391/814 [14:04<15:09,  2.15s/ba]Running tokenizer on dataset:  48%|████▊     | 392/814 [14:06<15:14,  2.17s/ba]Running tokenizer on dataset:  48%|████▊     | 393/814 [14:09<15:11,  2.17s/ba]Running tokenizer on dataset:  48%|████▊     | 394/814 [14:11<15:10,  2.17s/ba]Running tokenizer on dataset:  49%|████▊     | 395/814 [14:13<15:08,  2.17s/ba]Running tokenizer on dataset:  49%|████▊     | 396/814 [14:15<15:07,  2.17s/ba]Running tokenizer on dataset:  49%|████▉     | 397/814 [14:17<15:00,  2.16s/ba]Running tokenizer on dataset:  49%|████▉     | 398/814 [14:19<15:04,  2.17s/ba]Running tokenizer on dataset:  49%|████▉     | 399/814 [14:22<15:15,  2.21s/ba]Running tokenizer on dataset:  49%|████▉     | 400/814 [14:24<15:07,  2.19s/ba]Running tokenizer on dataset:  49%|████▉     | 401/814 [14:26<14:57,  2.17s/ba]Running tokenizer on dataset:  49%|████▉     | 402/814 [14:28<14:52,  2.17s/ba]Running tokenizer on dataset:  50%|████▉     | 403/814 [14:30<14:46,  2.16s/ba]Running tokenizer on dataset:  50%|████▉     | 404/814 [14:32<14:42,  2.15s/ba]Running tokenizer on dataset:  50%|████▉     | 405/814 [14:35<14:46,  2.17s/ba]Running tokenizer on dataset:  50%|████▉     | 406/814 [14:37<14:46,  2.17s/ba]Running tokenizer on dataset:  50%|█████     | 407/814 [14:39<14:47,  2.18s/ba]Running tokenizer on dataset:  50%|█████     | 408/814 [14:41<14:40,  2.17s/ba]Running tokenizer on dataset:  50%|█████     | 409/814 [14:43<14:33,  2.16s/ba]Running tokenizer on dataset:  50%|█████     | 410/814 [14:45<14:28,  2.15s/ba]Running tokenizer on dataset:  50%|█████     | 411/814 [14:48<14:29,  2.16s/ba]Running tokenizer on dataset:  51%|█████     | 412/814 [14:50<14:26,  2.15s/ba]Running tokenizer on dataset:  51%|█████     | 413/814 [14:52<14:21,  2.15s/ba]Running tokenizer on dataset:  51%|█████     | 414/814 [14:54<14:26,  2.17s/ba]Running tokenizer on dataset:  51%|█████     | 415/814 [14:56<14:23,  2.16s/ba]Running tokenizer on dataset:  51%|█████     | 416/814 [14:58<14:22,  2.17s/ba]Running tokenizer on dataset:  51%|█████     | 417/814 [15:01<14:17,  2.16s/ba]Running tokenizer on dataset:  51%|█████▏    | 418/814 [15:03<14:14,  2.16s/ba]Running tokenizer on dataset:  51%|█████▏    | 419/814 [15:05<14:11,  2.16s/ba]Running tokenizer on dataset:  52%|█████▏    | 420/814 [15:07<14:13,  2.17s/ba]Running tokenizer on dataset:  52%|█████▏    | 421/814 [15:09<14:12,  2.17s/ba]Running tokenizer on dataset:  52%|█████▏    | 422/814 [15:11<14:12,  2.17s/ba]Running tokenizer on dataset:  52%|█████▏    | 423/814 [15:14<14:20,  2.20s/ba]Running tokenizer on dataset:  52%|█████▏    | 424/814 [15:16<14:09,  2.18s/ba]Running tokenizer on dataset:  52%|█████▏    | 425/814 [15:18<14:03,  2.17s/ba]Running tokenizer on dataset:  52%|█████▏    | 426/814 [15:20<14:01,  2.17s/ba]Running tokenizer on dataset:  52%|█████▏    | 427/814 [15:22<13:54,  2.16s/ba]Running tokenizer on dataset:  53%|█████▎    | 428/814 [15:24<13:52,  2.16s/ba]Running tokenizer on dataset:  53%|█████▎    | 429/814 [15:27<13:49,  2.15s/ba]Running tokenizer on dataset:  53%|█████▎    | 430/814 [15:29<13:47,  2.16s/ba]Running tokenizer on dataset:  53%|█████▎    | 431/814 [15:31<13:47,  2.16s/ba]Running tokenizer on dataset:  53%|█████▎    | 432/814 [15:33<13:40,  2.15s/ba]Running tokenizer on dataset:  53%|█████▎    | 433/814 [15:35<13:42,  2.16s/ba]Running tokenizer on dataset:  53%|█████▎    | 434/814 [15:37<13:37,  2.15s/ba]Running tokenizer on dataset:  53%|█████▎    | 435/814 [15:40<13:34,  2.15s/ba]Running tokenizer on dataset:  54%|█████▎    | 436/814 [15:42<13:30,  2.14s/ba]Running tokenizer on dataset:  54%|█████▎    | 437/814 [15:44<13:26,  2.14s/ba]Running tokenizer on dataset:  54%|█████▍    | 438/814 [15:46<13:22,  2.13s/ba]Running tokenizer on dataset:  54%|█████▍    | 439/814 [15:48<13:24,  2.15s/ba]Running tokenizer on dataset:  54%|█████▍    | 440/814 [15:50<13:26,  2.16s/ba]Running tokenizer on dataset:  54%|█████▍    | 441/814 [15:52<13:24,  2.16s/ba]Running tokenizer on dataset:  54%|█████▍    | 442/814 [15:55<13:22,  2.16s/ba]Running tokenizer on dataset:  54%|█████▍    | 443/814 [15:57<13:16,  2.15s/ba]Running tokenizer on dataset:  55%|█████▍    | 444/814 [15:59<13:14,  2.15s/ba]Running tokenizer on dataset:  55%|█████▍    | 445/814 [16:01<13:11,  2.15s/ba]Running tokenizer on dataset:  55%|█████▍    | 446/814 [16:03<13:17,  2.17s/ba]Running tokenizer on dataset:  55%|█████▍    | 447/814 [16:05<13:14,  2.16s/ba]Running tokenizer on dataset:  55%|█████▌    | 448/814 [16:08<13:12,  2.17s/ba]Running tokenizer on dataset:  55%|█████▌    | 449/814 [16:10<13:11,  2.17s/ba]Running tokenizer on dataset:  55%|█████▌    | 450/814 [16:12<13:07,  2.16s/ba]Running tokenizer on dataset:  55%|█████▌    | 451/814 [16:14<13:03,  2.16s/ba]Running tokenizer on dataset:  56%|█████▌    | 452/814 [16:16<13:02,  2.16s/ba]Running tokenizer on dataset:  56%|█████▌    | 453/814 [16:18<12:59,  2.16s/ba]Running tokenizer on dataset:  56%|█████▌    | 454/814 [16:20<12:59,  2.17s/ba]Running tokenizer on dataset:  56%|█████▌    | 455/814 [16:23<12:59,  2.17s/ba]Running tokenizer on dataset:  56%|█████▌    | 456/814 [16:25<12:55,  2.17s/ba]Running tokenizer on dataset:  56%|█████▌    | 457/814 [16:27<12:50,  2.16s/ba]Running tokenizer on dataset:  56%|█████▋    | 458/814 [16:29<12:43,  2.14s/ba]Running tokenizer on dataset:  56%|█████▋    | 459/814 [16:31<12:42,  2.15s/ba]Running tokenizer on dataset:  57%|█████▋    | 460/814 [16:33<12:41,  2.15s/ba]Running tokenizer on dataset:  57%|█████▋    | 461/814 [16:36<12:43,  2.16s/ba]Running tokenizer on dataset:  57%|█████▋    | 462/814 [16:38<12:38,  2.16s/ba]Running tokenizer on dataset:  57%|█████▋    | 463/814 [16:40<12:43,  2.18s/ba]Running tokenizer on dataset:  57%|█████▋    | 464/814 [16:42<12:42,  2.18s/ba]Running tokenizer on dataset:  57%|█████▋    | 465/814 [16:44<12:38,  2.17s/ba]Running tokenizer on dataset:  57%|█████▋    | 466/814 [16:46<12:34,  2.17s/ba]Running tokenizer on dataset:  57%|█████▋    | 467/814 [16:49<12:35,  2.18s/ba]Running tokenizer on dataset:  57%|█████▋    | 468/814 [16:51<12:30,  2.17s/ba]Running tokenizer on dataset:  58%|█████▊    | 469/814 [16:53<12:24,  2.16s/ba]Running tokenizer on dataset:  58%|█████▊    | 470/814 [16:55<12:21,  2.15s/ba]Running tokenizer on dataset:  58%|█████▊    | 471/814 [16:57<12:21,  2.16s/ba]Running tokenizer on dataset:  58%|█████▊    | 472/814 [16:59<12:18,  2.16s/ba]Running tokenizer on dataset:  58%|█████▊    | 473/814 [17:02<12:14,  2.15s/ba]Running tokenizer on dataset:  58%|█████▊    | 474/814 [17:04<12:13,  2.16s/ba]Running tokenizer on dataset:  58%|█████▊    | 475/814 [17:06<12:11,  2.16s/ba]Running tokenizer on dataset:  58%|█████▊    | 476/814 [17:08<12:05,  2.15s/ba]Running tokenizer on dataset:  59%|█████▊    | 477/814 [17:10<12:05,  2.15s/ba]Running tokenizer on dataset:  59%|█████▊    | 478/814 [17:12<12:05,  2.16s/ba]Running tokenizer on dataset:  59%|█████▉    | 479/814 [17:14<12:02,  2.16s/ba]Running tokenizer on dataset:  59%|█████▉    | 480/814 [17:17<12:02,  2.16s/ba]Running tokenizer on dataset:  59%|█████▉    | 481/814 [17:19<12:00,  2.16s/ba]Running tokenizer on dataset:  59%|█████▉    | 482/814 [17:21<12:01,  2.17s/ba]Running tokenizer on dataset:  59%|█████▉    | 483/814 [17:23<11:58,  2.17s/ba]Running tokenizer on dataset:  59%|█████▉    | 484/814 [17:25<11:56,  2.17s/ba]Running tokenizer on dataset:  60%|█████▉    | 485/814 [17:28<11:53,  2.17s/ba]Running tokenizer on dataset:  60%|█████▉    | 486/814 [17:30<11:46,  2.15s/ba]Running tokenizer on dataset:  60%|█████▉    | 487/814 [17:32<11:47,  2.16s/ba]Running tokenizer on dataset:  60%|█████▉    | 488/814 [17:34<11:45,  2.16s/ba]Running tokenizer on dataset:  60%|██████    | 489/814 [17:36<11:44,  2.17s/ba]Running tokenizer on dataset:  60%|██████    | 490/814 [17:38<11:42,  2.17s/ba]Running tokenizer on dataset:  60%|██████    | 491/814 [17:40<11:21,  2.11s/ba]Running tokenizer on dataset:  60%|██████    | 492/814 [17:42<10:30,  1.96s/ba]Running tokenizer on dataset:  61%|██████    | 493/814 [17:44<09:54,  1.85s/ba]Running tokenizer on dataset:  61%|██████    | 494/814 [17:45<09:28,  1.78s/ba]Running tokenizer on dataset:  61%|██████    | 495/814 [17:47<09:11,  1.73s/ba]Running tokenizer on dataset:  61%|██████    | 496/814 [17:48<08:57,  1.69s/ba]Running tokenizer on dataset:  61%|██████    | 497/814 [17:50<08:48,  1.67s/ba]Running tokenizer on dataset:  61%|██████    | 498/814 [17:52<08:40,  1.65s/ba]Running tokenizer on dataset:  61%|██████▏   | 499/814 [17:53<08:33,  1.63s/ba]Running tokenizer on dataset:  61%|██████▏   | 500/814 [17:55<08:29,  1.62s/ba]Running tokenizer on dataset:  62%|██████▏   | 501/814 [17:56<08:26,  1.62s/ba]Running tokenizer on dataset:  62%|██████▏   | 502/814 [17:58<08:23,  1.61s/ba]Running tokenizer on dataset:  62%|██████▏   | 503/814 [18:00<08:19,  1.61s/ba]Running tokenizer on dataset:  62%|██████▏   | 504/814 [18:01<08:20,  1.62s/ba]Running tokenizer on dataset:  62%|██████▏   | 505/814 [18:03<08:20,  1.62s/ba]Running tokenizer on dataset:  62%|██████▏   | 506/814 [18:04<08:15,  1.61s/ba]Running tokenizer on dataset:  62%|██████▏   | 507/814 [18:06<08:14,  1.61s/ba]Running tokenizer on dataset:  62%|██████▏   | 508/814 [18:08<08:10,  1.60s/ba]Running tokenizer on dataset:  63%|██████▎   | 509/814 [18:09<08:11,  1.61s/ba]Running tokenizer on dataset:  63%|██████▎   | 510/814 [18:11<08:10,  1.61s/ba]Running tokenizer on dataset:  63%|██████▎   | 511/814 [18:12<08:08,  1.61s/ba]Running tokenizer on dataset:  63%|██████▎   | 512/814 [18:14<08:06,  1.61s/ba]Running tokenizer on dataset:  63%|██████▎   | 513/814 [18:16<08:07,  1.62s/ba]Running tokenizer on dataset:  63%|██████▎   | 514/814 [18:17<08:04,  1.61s/ba]Running tokenizer on dataset:  63%|██████▎   | 515/814 [18:19<08:04,  1.62s/ba]Running tokenizer on dataset:  63%|██████▎   | 516/814 [18:21<08:02,  1.62s/ba]Running tokenizer on dataset:  64%|██████▎   | 517/814 [18:22<08:02,  1.62s/ba]Running tokenizer on dataset:  64%|██████▎   | 518/814 [18:24<08:00,  1.62s/ba]Running tokenizer on dataset:  64%|██████▍   | 519/814 [18:25<07:56,  1.62s/ba]Running tokenizer on dataset:  64%|██████▍   | 520/814 [18:27<07:56,  1.62s/ba]Running tokenizer on dataset:  64%|██████▍   | 521/814 [18:29<07:51,  1.61s/ba]Running tokenizer on dataset:  64%|██████▍   | 522/814 [18:30<07:51,  1.62s/ba]Running tokenizer on dataset:  64%|██████▍   | 523/814 [18:32<07:48,  1.61s/ba]Running tokenizer on dataset:  64%|██████▍   | 524/814 [18:33<07:47,  1.61s/ba]Running tokenizer on dataset:  64%|██████▍   | 525/814 [18:35<07:43,  1.60s/ba]Running tokenizer on dataset:  65%|██████▍   | 526/814 [18:37<07:42,  1.61s/ba]Running tokenizer on dataset:  65%|██████▍   | 527/814 [18:38<07:44,  1.62s/ba]Running tokenizer on dataset:  65%|██████▍   | 528/814 [18:40<07:54,  1.66s/ba]Running tokenizer on dataset:  65%|██████▍   | 529/814 [18:42<07:47,  1.64s/ba]Running tokenizer on dataset:  65%|██████▌   | 530/814 [18:44<08:19,  1.76s/ba]Running tokenizer on dataset:  65%|██████▌   | 531/814 [18:46<08:51,  1.88s/ba]Running tokenizer on dataset:  65%|██████▌   | 532/814 [18:48<09:15,  1.97s/ba]Running tokenizer on dataset:  65%|██████▌   | 533/814 [18:50<09:27,  2.02s/ba]Running tokenizer on dataset:  66%|██████▌   | 534/814 [18:52<09:33,  2.05s/ba]Running tokenizer on dataset:  66%|██████▌   | 535/814 [18:54<09:42,  2.09s/ba]Running tokenizer on dataset:  66%|██████▌   | 536/814 [18:57<09:42,  2.10s/ba]Running tokenizer on dataset:  66%|██████▌   | 537/814 [18:59<09:45,  2.12s/ba]Running tokenizer on dataset:  66%|██████▌   | 538/814 [19:01<09:49,  2.14s/ba]Running tokenizer on dataset:  66%|██████▌   | 539/814 [19:03<09:50,  2.15s/ba]Running tokenizer on dataset:  66%|██████▋   | 540/814 [19:05<09:49,  2.15s/ba]Running tokenizer on dataset:  66%|██████▋   | 541/814 [19:07<09:45,  2.14s/ba]Running tokenizer on dataset:  67%|██████▋   | 542/814 [19:10<09:45,  2.15s/ba]Running tokenizer on dataset:  67%|██████▋   | 543/814 [19:12<09:41,  2.14s/ba]Running tokenizer on dataset:  67%|██████▋   | 544/814 [19:14<09:39,  2.15s/ba]Running tokenizer on dataset:  67%|██████▋   | 545/814 [19:16<09:41,  2.16s/ba]Running tokenizer on dataset:  67%|██████▋   | 546/814 [19:18<09:36,  2.15s/ba]Running tokenizer on dataset:  67%|██████▋   | 547/814 [19:20<09:35,  2.15s/ba]Running tokenizer on dataset:  67%|██████▋   | 548/814 [19:22<09:31,  2.15s/ba]Running tokenizer on dataset:  67%|██████▋   | 549/814 [19:25<09:32,  2.16s/ba]Running tokenizer on dataset:  68%|██████▊   | 550/814 [19:27<09:27,  2.15s/ba]Running tokenizer on dataset:  68%|██████▊   | 551/814 [19:29<09:24,  2.15s/ba]Running tokenizer on dataset:  68%|██████▊   | 552/814 [19:31<09:22,  2.15s/ba]Running tokenizer on dataset:  68%|██████▊   | 553/814 [19:33<09:15,  2.13s/ba]Running tokenizer on dataset:  68%|██████▊   | 554/814 [19:35<09:13,  2.13s/ba]Running tokenizer on dataset:  68%|██████▊   | 555/814 [19:37<09:07,  2.11s/ba]Running tokenizer on dataset:  68%|██████▊   | 556/814 [19:39<08:26,  1.96s/ba]Running tokenizer on dataset:  68%|██████▊   | 557/814 [19:41<07:55,  1.85s/ba]Running tokenizer on dataset:  69%|██████▊   | 558/814 [19:42<07:33,  1.77s/ba]Running tokenizer on dataset:  69%|██████▊   | 559/814 [19:44<07:19,  1.72s/ba]Running tokenizer on dataset:  69%|██████▉   | 560/814 [19:45<07:08,  1.69s/ba]Running tokenizer on dataset:  69%|██████▉   | 561/814 [19:47<06:59,  1.66s/ba]Running tokenizer on dataset:  69%|██████▉   | 562/814 [19:49<06:53,  1.64s/ba]Running tokenizer on dataset:  69%|██████▉   | 563/814 [19:50<06:49,  1.63s/ba]Running tokenizer on dataset:  69%|██████▉   | 564/814 [19:52<06:44,  1.62s/ba]Running tokenizer on dataset:  69%|██████▉   | 565/814 [19:53<06:42,  1.62s/ba]Running tokenizer on dataset:  70%|██████▉   | 566/814 [19:55<06:41,  1.62s/ba]Running tokenizer on dataset:  70%|██████▉   | 567/814 [19:57<06:39,  1.62s/ba]Running tokenizer on dataset:  70%|██████▉   | 568/814 [19:58<06:35,  1.61s/ba]Running tokenizer on dataset:  70%|██████▉   | 569/814 [20:00<06:34,  1.61s/ba]Running tokenizer on dataset:  70%|███████   | 570/814 [20:01<06:34,  1.62s/ba]Running tokenizer on dataset:  70%|███████   | 571/814 [20:03<06:30,  1.61s/ba]Running tokenizer on dataset:  70%|███████   | 572/814 [20:05<06:28,  1.60s/ba]Running tokenizer on dataset:  70%|███████   | 573/814 [20:06<06:27,  1.61s/ba]Running tokenizer on dataset:  71%|███████   | 574/814 [20:08<06:22,  1.59s/ba]Running tokenizer on dataset:  71%|███████   | 575/814 [20:09<06:21,  1.60s/ba]Running tokenizer on dataset:  71%|███████   | 576/814 [20:11<06:22,  1.61s/ba]Running tokenizer on dataset:  71%|███████   | 577/814 [20:13<06:23,  1.62s/ba]Running tokenizer on dataset:  71%|███████   | 578/814 [20:14<06:21,  1.61s/ba]Running tokenizer on dataset:  71%|███████   | 579/814 [20:16<06:18,  1.61s/ba]Running tokenizer on dataset:  71%|███████▏  | 580/814 [20:17<06:17,  1.61s/ba]Running tokenizer on dataset:  71%|███████▏  | 581/814 [20:19<06:15,  1.61s/ba]Running tokenizer on dataset:  71%|███████▏  | 582/814 [20:21<06:12,  1.60s/ba]Running tokenizer on dataset:  72%|███████▏  | 583/814 [20:22<06:10,  1.60s/ba]Running tokenizer on dataset:  72%|███████▏  | 584/814 [20:24<06:07,  1.60s/ba]Running tokenizer on dataset:  72%|███████▏  | 585/814 [20:26<06:09,  1.62s/ba]Running tokenizer on dataset:  72%|███████▏  | 586/814 [20:27<06:07,  1.61s/ba]Running tokenizer on dataset:  72%|███████▏  | 587/814 [20:29<06:07,  1.62s/ba]Running tokenizer on dataset:  72%|███████▏  | 588/814 [20:30<06:04,  1.61s/ba]Running tokenizer on dataset:  72%|███████▏  | 589/814 [20:32<06:02,  1.61s/ba]Running tokenizer on dataset:  72%|███████▏  | 590/814 [20:34<06:01,  1.61s/ba]Running tokenizer on dataset:  73%|███████▎  | 591/814 [20:35<05:59,  1.61s/ba]Running tokenizer on dataset:  73%|███████▎  | 592/814 [20:37<05:58,  1.61s/ba]Running tokenizer on dataset:  73%|███████▎  | 593/814 [20:38<05:57,  1.62s/ba]Running tokenizer on dataset:  73%|███████▎  | 594/814 [20:40<05:54,  1.61s/ba]Running tokenizer on dataset:  73%|███████▎  | 595/814 [20:42<05:53,  1.61s/ba]Running tokenizer on dataset:  73%|███████▎  | 596/814 [20:43<05:50,  1.61s/ba]Running tokenizer on dataset:  73%|███████▎  | 597/814 [20:45<05:49,  1.61s/ba]Running tokenizer on dataset:  73%|███████▎  | 598/814 [20:46<05:47,  1.61s/ba]Running tokenizer on dataset:  74%|███████▎  | 599/814 [20:48<05:45,  1.61s/ba]Running tokenizer on dataset:  74%|███████▎  | 600/814 [20:50<05:45,  1.61s/ba]Running tokenizer on dataset:  74%|███████▍  | 601/814 [20:51<05:44,  1.62s/ba]Running tokenizer on dataset:  74%|███████▍  | 602/814 [20:53<05:42,  1.62s/ba]Running tokenizer on dataset:  74%|███████▍  | 603/814 [20:55<05:40,  1.61s/ba]Running tokenizer on dataset:  74%|███████▍  | 604/814 [20:56<05:37,  1.61s/ba]Running tokenizer on dataset:  74%|███████▍  | 605/814 [20:58<05:36,  1.61s/ba]Running tokenizer on dataset:  74%|███████▍  | 606/814 [20:59<05:34,  1.61s/ba]Running tokenizer on dataset:  75%|███████▍  | 607/814 [21:01<05:33,  1.61s/ba]Running tokenizer on dataset:  75%|███████▍  | 608/814 [21:03<05:30,  1.60s/ba]Running tokenizer on dataset:  75%|███████▍  | 609/814 [21:04<05:31,  1.62s/ba]Running tokenizer on dataset:  75%|███████▍  | 610/814 [21:06<05:28,  1.61s/ba]Running tokenizer on dataset:  75%|███████▌  | 611/814 [21:07<05:26,  1.61s/ba]Running tokenizer on dataset:  75%|███████▌  | 612/814 [21:09<05:25,  1.61s/ba]Running tokenizer on dataset:  75%|███████▌  | 613/814 [21:11<05:25,  1.62s/ba]Running tokenizer on dataset:  75%|███████▌  | 614/814 [21:12<05:24,  1.62s/ba]Running tokenizer on dataset:  76%|███████▌  | 615/814 [21:14<05:23,  1.62s/ba]Running tokenizer on dataset:  76%|███████▌  | 616/814 [21:16<05:19,  1.62s/ba]Running tokenizer on dataset:  76%|███████▌  | 617/814 [21:17<05:18,  1.62s/ba]Running tokenizer on dataset:  76%|███████▌  | 618/814 [21:19<05:16,  1.61s/ba]Running tokenizer on dataset:  76%|███████▌  | 619/814 [21:20<05:13,  1.61s/ba]Running tokenizer on dataset:  76%|███████▌  | 620/814 [21:22<05:12,  1.61s/ba]Running tokenizer on dataset:  76%|███████▋  | 621/814 [21:24<05:09,  1.61s/ba]Running tokenizer on dataset:  76%|███████▋  | 622/814 [21:25<05:09,  1.61s/ba]Running tokenizer on dataset:  77%|███████▋  | 623/814 [21:27<05:07,  1.61s/ba]Running tokenizer on dataset:  77%|███████▋  | 624/814 [21:28<05:06,  1.61s/ba]Running tokenizer on dataset:  77%|███████▋  | 625/814 [21:30<05:05,  1.62s/ba]Running tokenizer on dataset:  77%|███████▋  | 626/814 [21:32<05:04,  1.62s/ba]Running tokenizer on dataset:  77%|███████▋  | 627/814 [21:33<05:03,  1.62s/ba]Running tokenizer on dataset:  77%|███████▋  | 628/814 [21:35<05:02,  1.63s/ba]Running tokenizer on dataset:  77%|███████▋  | 629/814 [21:37<05:00,  1.62s/ba]Running tokenizer on dataset:  77%|███████▋  | 630/814 [21:38<05:06,  1.67s/ba]Running tokenizer on dataset:  78%|███████▊  | 631/814 [21:40<05:02,  1.65s/ba]Running tokenizer on dataset:  78%|███████▊  | 632/814 [21:42<04:59,  1.65s/ba]Running tokenizer on dataset:  78%|███████▊  | 633/814 [21:43<04:57,  1.64s/ba]Running tokenizer on dataset:  78%|███████▊  | 634/814 [21:45<04:52,  1.63s/ba]Running tokenizer on dataset:  78%|███████▊  | 635/814 [21:46<04:47,  1.61s/ba]Running tokenizer on dataset:  78%|███████▊  | 636/814 [21:48<04:47,  1.61s/ba]Running tokenizer on dataset:  78%|███████▊  | 637/814 [21:50<04:46,  1.62s/ba]Running tokenizer on dataset:  78%|███████▊  | 638/814 [21:51<04:45,  1.62s/ba]Running tokenizer on dataset:  79%|███████▊  | 639/814 [21:53<04:44,  1.62s/ba]Running tokenizer on dataset:  79%|███████▊  | 640/814 [21:55<04:42,  1.63s/ba]Running tokenizer on dataset:  79%|███████▊  | 641/814 [21:56<04:39,  1.62s/ba]Running tokenizer on dataset:  79%|███████▉  | 642/814 [21:58<04:38,  1.62s/ba]Running tokenizer on dataset:  79%|███████▉  | 643/814 [21:59<04:35,  1.61s/ba]Running tokenizer on dataset:  79%|███████▉  | 644/814 [22:01<04:33,  1.61s/ba]Running tokenizer on dataset:  79%|███████▉  | 645/814 [22:03<04:32,  1.61s/ba]Running tokenizer on dataset:  79%|███████▉  | 646/814 [22:04<04:31,  1.62s/ba]Running tokenizer on dataset:  79%|███████▉  | 647/814 [22:06<04:29,  1.61s/ba]Running tokenizer on dataset:  80%|███████▉  | 648/814 [22:07<04:27,  1.61s/ba]Running tokenizer on dataset:  80%|███████▉  | 649/814 [22:09<04:26,  1.61s/ba]Running tokenizer on dataset:  80%|███████▉  | 650/814 [22:11<04:25,  1.62s/ba]Running tokenizer on dataset:  80%|███████▉  | 651/814 [22:12<04:24,  1.62s/ba]Running tokenizer on dataset:  80%|████████  | 652/814 [22:14<04:22,  1.62s/ba]Running tokenizer on dataset:  80%|████████  | 653/814 [22:15<04:20,  1.62s/ba]Running tokenizer on dataset:  80%|████████  | 654/814 [22:17<04:18,  1.61s/ba]Running tokenizer on dataset:  80%|████████  | 655/814 [22:19<04:17,  1.62s/ba]Running tokenizer on dataset:  81%|████████  | 656/814 [22:20<04:16,  1.62s/ba]Running tokenizer on dataset:  81%|████████  | 657/814 [22:22<04:15,  1.63s/ba]Running tokenizer on dataset:  81%|████████  | 658/814 [22:24<04:11,  1.62s/ba]Running tokenizer on dataset:  81%|████████  | 659/814 [22:25<04:09,  1.61s/ba]Running tokenizer on dataset:  81%|████████  | 660/814 [22:27<04:08,  1.62s/ba]Running tokenizer on dataset:  81%|████████  | 661/814 [22:28<04:06,  1.61s/ba]Running tokenizer on dataset:  81%|████████▏ | 662/814 [22:30<04:05,  1.61s/ba]Running tokenizer on dataset:  81%|████████▏ | 663/814 [22:32<04:04,  1.62s/ba]Running tokenizer on dataset:  82%|████████▏ | 664/814 [22:33<04:01,  1.61s/ba]Running tokenizer on dataset:  82%|████████▏ | 665/814 [22:35<03:59,  1.60s/ba]Running tokenizer on dataset:  82%|████████▏ | 666/814 [22:36<03:56,  1.60s/ba]Running tokenizer on dataset:  82%|████████▏ | 667/814 [22:38<03:56,  1.61s/ba]Running tokenizer on dataset:  82%|████████▏ | 668/814 [22:40<03:55,  1.61s/ba]Running tokenizer on dataset:  82%|████████▏ | 669/814 [22:41<03:54,  1.62s/ba]Running tokenizer on dataset:  82%|████████▏ | 670/814 [22:43<03:51,  1.61s/ba]Running tokenizer on dataset:  82%|████████▏ | 671/814 [22:45<03:51,  1.62s/ba]Running tokenizer on dataset:  83%|████████▎ | 672/814 [22:46<03:50,  1.62s/ba]Running tokenizer on dataset:  83%|████████▎ | 673/814 [22:48<03:52,  1.65s/ba]Running tokenizer on dataset:  83%|████████▎ | 674/814 [22:49<03:49,  1.64s/ba]Running tokenizer on dataset:  83%|████████▎ | 675/814 [22:51<03:47,  1.64s/ba]Running tokenizer on dataset:  83%|████████▎ | 676/814 [22:53<03:44,  1.63s/ba]Running tokenizer on dataset:  83%|████████▎ | 677/814 [22:54<03:42,  1.63s/ba]Running tokenizer on dataset:  83%|████████▎ | 678/814 [22:56<03:40,  1.62s/ba]Running tokenizer on dataset:  83%|████████▎ | 679/814 [22:58<03:38,  1.62s/ba]Running tokenizer on dataset:  84%|████████▎ | 680/814 [22:59<03:36,  1.62s/ba]Running tokenizer on dataset:  84%|████████▎ | 681/814 [23:01<03:35,  1.62s/ba]Running tokenizer on dataset:  84%|████████▍ | 682/814 [23:02<03:32,  1.61s/ba]Running tokenizer on dataset:  84%|████████▍ | 683/814 [23:04<03:30,  1.60s/ba]Running tokenizer on dataset:  84%|████████▍ | 684/814 [23:06<03:28,  1.61s/ba]Running tokenizer on dataset:  84%|████████▍ | 685/814 [23:07<03:28,  1.61s/ba]Running tokenizer on dataset:  84%|████████▍ | 686/814 [23:09<03:26,  1.61s/ba]Running tokenizer on dataset:  84%|████████▍ | 687/814 [23:10<03:24,  1.61s/ba]Running tokenizer on dataset:  85%|████████▍ | 688/814 [23:12<03:21,  1.60s/ba]Running tokenizer on dataset:  85%|████████▍ | 689/814 [23:14<03:19,  1.59s/ba]Running tokenizer on dataset:  85%|████████▍ | 690/814 [23:15<03:17,  1.60s/ba]Running tokenizer on dataset:  85%|████████▍ | 691/814 [23:17<03:17,  1.61s/ba]Running tokenizer on dataset:  85%|████████▌ | 692/814 [23:18<03:16,  1.61s/ba]Running tokenizer on dataset:  85%|████████▌ | 693/814 [23:20<03:14,  1.61s/ba]Running tokenizer on dataset:  85%|████████▌ | 694/814 [23:22<03:11,  1.60s/ba]Running tokenizer on dataset:  85%|████████▌ | 695/814 [23:23<03:10,  1.60s/ba]Running tokenizer on dataset:  86%|████████▌ | 696/814 [23:25<03:09,  1.61s/ba]Running tokenizer on dataset:  86%|████████▌ | 697/814 [23:27<03:08,  1.62s/ba]Running tokenizer on dataset:  86%|████████▌ | 698/814 [23:28<03:06,  1.61s/ba]Running tokenizer on dataset:  86%|████████▌ | 699/814 [23:30<03:04,  1.60s/ba]Running tokenizer on dataset:  86%|████████▌ | 700/814 [23:31<03:02,  1.60s/ba]Running tokenizer on dataset:  86%|████████▌ | 701/814 [23:33<03:01,  1.61s/ba]Running tokenizer on dataset:  86%|████████▌ | 702/814 [23:35<03:00,  1.61s/ba]Running tokenizer on dataset:  86%|████████▋ | 703/814 [23:36<02:59,  1.61s/ba]Running tokenizer on dataset:  86%|████████▋ | 704/814 [23:38<03:05,  1.69s/ba]Running tokenizer on dataset:  87%|████████▋ | 705/814 [23:40<03:01,  1.67s/ba]Running tokenizer on dataset:  87%|████████▋ | 706/814 [23:41<02:57,  1.65s/ba]Running tokenizer on dataset:  87%|████████▋ | 707/814 [23:43<02:56,  1.64s/ba]Running tokenizer on dataset:  87%|████████▋ | 708/814 [23:44<02:53,  1.64s/ba]Running tokenizer on dataset:  87%|████████▋ | 709/814 [23:46<02:51,  1.63s/ba]Running tokenizer on dataset:  87%|████████▋ | 710/814 [23:48<02:48,  1.62s/ba]Running tokenizer on dataset:  87%|████████▋ | 711/814 [23:49<02:46,  1.62s/ba]Running tokenizer on dataset:  87%|████████▋ | 712/814 [23:51<02:45,  1.62s/ba]Running tokenizer on dataset:  88%|████████▊ | 713/814 [23:53<02:43,  1.61s/ba]Running tokenizer on dataset:  88%|████████▊ | 714/814 [23:54<02:41,  1.61s/ba]Running tokenizer on dataset:  88%|████████▊ | 715/814 [23:56<02:43,  1.66s/ba]Running tokenizer on dataset:  88%|████████▊ | 716/814 [23:57<02:40,  1.64s/ba]Running tokenizer on dataset:  88%|████████▊ | 717/814 [23:59<02:38,  1.63s/ba]Running tokenizer on dataset:  88%|████████▊ | 718/814 [24:01<02:35,  1.62s/ba]Running tokenizer on dataset:  88%|████████▊ | 719/814 [24:02<02:34,  1.62s/ba]Running tokenizer on dataset:  88%|████████▊ | 720/814 [24:04<02:32,  1.62s/ba]Running tokenizer on dataset:  89%|████████▊ | 721/814 [24:06<02:30,  1.62s/ba]Running tokenizer on dataset:  89%|████████▊ | 722/814 [24:07<02:28,  1.62s/ba]Running tokenizer on dataset:  89%|████████▉ | 723/814 [24:09<02:26,  1.61s/ba]Running tokenizer on dataset:  89%|████████▉ | 724/814 [24:10<02:23,  1.60s/ba]Running tokenizer on dataset:  89%|████████▉ | 725/814 [24:12<02:23,  1.61s/ba]Running tokenizer on dataset:  89%|████████▉ | 726/814 [24:14<02:20,  1.60s/ba]Running tokenizer on dataset:  89%|████████▉ | 727/814 [24:15<02:20,  1.61s/ba]Running tokenizer on dataset:  89%|████████▉ | 728/814 [24:17<02:18,  1.61s/ba]Running tokenizer on dataset:  90%|████████▉ | 729/814 [24:18<02:16,  1.61s/ba]Running tokenizer on dataset:  90%|████████▉ | 730/814 [24:20<02:14,  1.60s/ba]Running tokenizer on dataset:  90%|████████▉ | 731/814 [24:22<02:13,  1.61s/ba]Running tokenizer on dataset:  90%|████████▉ | 732/814 [24:23<02:11,  1.61s/ba]Running tokenizer on dataset:  90%|█████████ | 733/814 [24:25<02:10,  1.61s/ba]Running tokenizer on dataset:  90%|█████████ | 734/814 [24:26<02:08,  1.61s/ba]Running tokenizer on dataset:  90%|█████████ | 735/814 [24:28<02:07,  1.61s/ba]Running tokenizer on dataset:  90%|█████████ | 736/814 [24:30<02:05,  1.61s/ba]Running tokenizer on dataset:  91%|█████████ | 737/814 [24:31<02:03,  1.60s/ba]Running tokenizer on dataset:  91%|█████████ | 738/814 [24:33<02:01,  1.60s/ba]Running tokenizer on dataset:  91%|█████████ | 739/814 [24:34<02:00,  1.61s/ba]Running tokenizer on dataset:  91%|█████████ | 740/814 [24:36<01:59,  1.61s/ba]Running tokenizer on dataset:  91%|█████████ | 741/814 [24:38<01:57,  1.61s/ba]Running tokenizer on dataset:  91%|█████████ | 742/814 [24:39<01:56,  1.62s/ba]Running tokenizer on dataset:  91%|█████████▏| 743/814 [24:41<01:54,  1.61s/ba]Running tokenizer on dataset:  91%|█████████▏| 744/814 [24:43<01:52,  1.61s/ba]Running tokenizer on dataset:  92%|█████████▏| 745/814 [24:44<01:51,  1.61s/ba]Running tokenizer on dataset:  92%|█████████▏| 746/814 [24:46<01:49,  1.60s/ba]Running tokenizer on dataset:  92%|█████████▏| 747/814 [24:47<01:47,  1.61s/ba]Running tokenizer on dataset:  92%|█████████▏| 748/814 [24:49<01:45,  1.61s/ba]Running tokenizer on dataset:  92%|█████████▏| 749/814 [24:51<01:44,  1.61s/ba]Running tokenizer on dataset:  92%|█████████▏| 750/814 [24:52<01:43,  1.61s/ba]Running tokenizer on dataset:  92%|█████████▏| 751/814 [24:54<01:41,  1.61s/ba]Running tokenizer on dataset:  92%|█████████▏| 752/814 [24:55<01:40,  1.62s/ba]Running tokenizer on dataset:  93%|█████████▎| 753/814 [24:57<01:38,  1.62s/ba]Running tokenizer on dataset:  93%|█████████▎| 754/814 [24:59<01:36,  1.61s/ba]Running tokenizer on dataset:  93%|█████████▎| 755/814 [25:00<01:35,  1.62s/ba]Running tokenizer on dataset:  93%|█████████▎| 756/814 [25:02<01:33,  1.61s/ba]Running tokenizer on dataset:  93%|█████████▎| 757/814 [25:03<01:31,  1.61s/ba]Running tokenizer on dataset:  93%|█████████▎| 758/814 [25:05<01:29,  1.61s/ba]Running tokenizer on dataset:  93%|█████████▎| 759/814 [25:07<01:28,  1.61s/ba]Running tokenizer on dataset:  93%|█████████▎| 760/814 [25:08<01:27,  1.61s/ba]Running tokenizer on dataset:  93%|█████████▎| 761/814 [25:10<01:25,  1.62s/ba]Running tokenizer on dataset:  94%|█████████▎| 762/814 [25:12<01:24,  1.62s/ba]Running tokenizer on dataset:  94%|█████████▎| 763/814 [25:13<01:23,  1.63s/ba]Running tokenizer on dataset:  94%|█████████▍| 764/814 [25:15<01:21,  1.62s/ba]Running tokenizer on dataset:  94%|█████████▍| 765/814 [25:16<01:18,  1.61s/ba]Running tokenizer on dataset:  94%|█████████▍| 766/814 [25:18<01:17,  1.61s/ba]Running tokenizer on dataset:  94%|█████████▍| 767/814 [25:20<01:16,  1.62s/ba]Running tokenizer on dataset:  94%|█████████▍| 768/814 [25:21<01:14,  1.62s/ba]Running tokenizer on dataset:  94%|█████████▍| 769/814 [25:23<01:12,  1.62s/ba]Running tokenizer on dataset:  95%|█████████▍| 770/814 [25:25<01:13,  1.68s/ba]Running tokenizer on dataset:  95%|█████████▍| 771/814 [25:26<01:11,  1.66s/ba]Running tokenizer on dataset:  95%|█████████▍| 772/814 [25:28<01:09,  1.64s/ba]Running tokenizer on dataset:  95%|█████████▍| 773/814 [25:30<01:06,  1.63s/ba]Running tokenizer on dataset:  95%|█████████▌| 774/814 [25:31<01:04,  1.62s/ba]Running tokenizer on dataset:  95%|█████████▌| 775/814 [25:33<01:03,  1.62s/ba]Running tokenizer on dataset:  95%|█████████▌| 776/814 [25:34<01:01,  1.62s/ba]Running tokenizer on dataset:  95%|█████████▌| 777/814 [25:36<01:00,  1.63s/ba]Running tokenizer on dataset:  96%|█████████▌| 778/814 [25:38<00:58,  1.62s/ba]Running tokenizer on dataset:  96%|█████████▌| 779/814 [25:39<00:56,  1.62s/ba]Running tokenizer on dataset:  96%|█████████▌| 780/814 [25:41<00:54,  1.61s/ba]Running tokenizer on dataset:  96%|█████████▌| 781/814 [25:43<00:54,  1.66s/ba]Running tokenizer on dataset:  96%|█████████▌| 782/814 [25:44<00:53,  1.66s/ba]Running tokenizer on dataset:  96%|█████████▌| 783/814 [25:46<00:50,  1.64s/ba]Running tokenizer on dataset:  96%|█████████▋| 784/814 [25:47<00:48,  1.63s/ba]Running tokenizer on dataset:  96%|█████████▋| 785/814 [25:49<00:47,  1.64s/ba]Running tokenizer on dataset:  97%|█████████▋| 786/814 [25:51<00:45,  1.63s/ba]Running tokenizer on dataset:  97%|█████████▋| 787/814 [25:52<00:43,  1.63s/ba]Running tokenizer on dataset:  97%|█████████▋| 788/814 [25:54<00:41,  1.61s/ba]Running tokenizer on dataset:  97%|█████████▋| 789/814 [25:56<00:40,  1.61s/ba]Running tokenizer on dataset:  97%|█████████▋| 790/814 [25:57<00:38,  1.62s/ba]Running tokenizer on dataset:  97%|█████████▋| 791/814 [25:59<00:36,  1.61s/ba]Running tokenizer on dataset:  97%|█████████▋| 792/814 [26:00<00:35,  1.60s/ba]Running tokenizer on dataset:  97%|█████████▋| 793/814 [26:02<00:33,  1.61s/ba]Running tokenizer on dataset:  98%|█████████▊| 794/814 [26:04<00:32,  1.61s/ba]Running tokenizer on dataset:  98%|█████████▊| 795/814 [26:05<00:30,  1.61s/ba]Running tokenizer on dataset:  98%|█████████▊| 796/814 [26:07<00:28,  1.61s/ba]Running tokenizer on dataset:  98%|█████████▊| 797/814 [26:08<00:27,  1.60s/ba]Running tokenizer on dataset:  98%|█████████▊| 798/814 [26:10<00:25,  1.60s/ba]Running tokenizer on dataset:  98%|█████████▊| 799/814 [26:12<00:24,  1.61s/ba]Running tokenizer on dataset:  98%|█████████▊| 800/814 [26:13<00:22,  1.61s/ba]Running tokenizer on dataset:  98%|█████████▊| 801/814 [26:15<00:21,  1.62s/ba]Running tokenizer on dataset:  99%|█████████▊| 802/814 [26:17<00:19,  1.62s/ba]Running tokenizer on dataset:  99%|█████████▊| 803/814 [26:18<00:17,  1.61s/ba]Running tokenizer on dataset:  99%|█████████▉| 804/814 [26:20<00:16,  1.61s/ba]Running tokenizer on dataset:  99%|█████████▉| 805/814 [26:21<00:14,  1.61s/ba]Running tokenizer on dataset:  99%|█████████▉| 806/814 [26:23<00:12,  1.61s/ba]Running tokenizer on dataset:  99%|█████████▉| 807/814 [26:25<00:11,  1.61s/ba]Running tokenizer on dataset:  99%|█████████▉| 808/814 [26:26<00:09,  1.61s/ba]Running tokenizer on dataset:  99%|█████████▉| 809/814 [26:28<00:08,  1.62s/ba]Running tokenizer on dataset: 100%|█████████▉| 810/814 [26:29<00:06,  1.61s/ba]Running tokenizer on dataset: 100%|█████████▉| 811/814 [26:31<00:04,  1.62s/ba]Running tokenizer on dataset: 100%|█████████▉| 812/814 [26:33<00:03,  1.62s/ba]Running tokenizer on dataset: 100%|█████████▉| 813/814 [26:34<00:01,  1.61s/ba]Running tokenizer on dataset: 100%|██████████| 814/814 [26:35<00:00,  1.27s/ba]Running tokenizer on dataset: 100%|██████████| 814/814 [26:35<00:00,  1.96s/ba]
Error executing job with overrides: ['model.name=facebook/opt-2.7b', 'training.eval_every=250', 'training.train_batch_size=32', 'training.weight_decay=0.05', 'training.eval_batch_size=16', 'training.learning_rate=0.000003', 'training.val_split_percent=20', 'training.num_epochs=4', 'training.lr_warmup_steps=5', 'training.gradient_accumulation_steps=2', 'dataset.name=ViktorThink/mountain_combined_813306', 'dataset.num_batches=5000']
Traceback (most recent call last):
  File "finetune_using_clm_wandb.py", line 316, in main
    save_tokenized_datasets(tokenized_datasets)
  File "finetune_using_clm_wandb.py", line 238, in save_tokenized_datasets
    eval_dataset = tokenized_datasets["test"]
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/dataset_dict.py", line 57, in __getitem__
    return super().__getitem__(k)
KeyError: 'test'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2022-11-18 15:58:57,284][__main__][INFO] - Setting random seed to 17
[2022-11-18 15:58:57,285][__main__][INFO] - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Mixed precision type: no

[2022-11-18 15:58:57,287][__main__][INFO] - output_dir: tuned-model
bittensor:
  network: nobunaga
dataset:
  name: ViktorThink/mountain_combined_813306
  config_name: null
  num_batches: 5000
  block_size: 256
  overwrite_cache: false
  keep_linebreaks: true
  concatenate_raw: false
  load_tokenized_data: false
model:
  name: facebook/opt-2.7b
  config_name: null
tokenizer:
  name: null
  use_fast: true
  preprocessing_num_workers: null
  pad_token: '[PAD]'
training:
  seed: 17
  val_split_percent: 20
  train_batch_size: 32
  eval_batch_size: 16
  learning_rate: 3.0e-06
  weight_decay: 0.05
  num_epochs: 4
  max_train_steps: null
  gradient_accumulation_steps: 2
  lr_scheduler: constant
  lr_warmup_steps: 5
  eval_every: 250
  max_eval_steps: 500
  checkpoint:
    resume_from_checkpoint: 0
    every_n_steps: null
tracking:
  enabled: true
  report_to: all
testing:
  enabled: false

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--EleutherAI--gpt-neo-2.7B/snapshots/51568a6e0ae813a3f2a9da558ab7beac5e3acc24/config.json
Model config GPTNeoConfig {
  "_name_or_path": "EleutherAI/gpt-neo-2.7B",
  "activation_function": "gelu_new",
  "architectures": [
    "GPTNeoForCausalLM"
  ],
  "attention_dropout": 0,
  "attention_layers": [
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local"
  ],
  "attention_types": [
    [
      [
        "global",
        "local"
      ],
      16
    ]
  ],
  "bos_token_id": 50256,
  "embed_dropout": 0,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "hidden_size": 2560,
  "initializer_range": 0.02,
  "intermediate_size": null,
  "layer_norm_epsilon": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neo",
  "num_heads": 20,
  "num_layers": 32,
  "resid_dropout": 0,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50,
      "temperature": 0.9
    }
  },
  "tokenizer_class": "GPT2Tokenizer",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50257,
  "window_size": 256
}

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading file vocab.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/vocab.json
loading file merges.txt from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/merges.txt
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/tokenizer_config.json
loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading weights file flax_model.msgpack from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Loading Flax weights from /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Some weights of the Flax model were not used when initializing the PyTorch model GPTNeoForCausalLM: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.18.fc1.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.bias']
- This IS expected if you are initializing GPTNeoForCausalLM from a Flax model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a FlaxBertForPreTraining model).
- This IS NOT expected if you are initializing GPTNeoForCausalLM from a Flax model that you expect to be exactly identical (e.g. initializing a BertForSequenceClassification model from a FlaxBertForSequenceClassification model).
Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['transformer.h.10.mlp.c_fc.bias', 'transformer.h.27.mlp.c_fc.bias', 'transformer.h.1.ln_2.bias', 'transformer.h.15.mlp.c_fc.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.20.ln_2.weight', 'transformer.h.8.attn.attention.masked_bias', 'transformer.ln_f.weight', 'transformer.h.28.mlp.c_proj.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.12.ln_2.bias', 'transformer.h.13.ln_1.weight', 'transformer.h.16.mlp.c_fc.weight', 'transformer.h.3.attn.attention.masked_bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.30.mlp.c_proj.bias', 'transformer.h.17.attn.attention.bias', 'transformer.h.15.attn.attention.v_proj.weight', 'transformer.h.23.attn.attention.bias', 'transformer.h.7.attn.attention.k_proj.weight', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.13.attn.attention.out_proj.weight', 'transformer.h.3.attn.attention.out_proj.bias', 'transformer.h.2.attn.attention.out_proj.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.7.attn.attention.masked_bias', 'transformer.h.9.ln_2.weight', 'transformer.h.6.ln_1.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.attn.attention.out_proj.weight', 'transformer.h.28.attn.attention.v_proj.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.14.ln_1.weight', 'transformer.h.12.ln_2.weight', 'transformer.h.21.attn.attention.out_proj.weight', 'transformer.h.18.mlp.c_fc.bias', 'transformer.h.19.attn.attention.out_proj.weight', 'transformer.h.19.attn.attention.masked_bias', 'transformer.h.0.attn.attention.v_proj.weight', 'transformer.h.19.mlp.c_proj.bias', 'transformer.h.9.attn.attention.q_proj.weight', 'transformer.h.9.attn.attention.v_proj.weight', 'transformer.h.14.mlp.c_fc.bias', 'transformer.h.31.mlp.c_proj.bias', 'transformer.h.2.ln_1.bias', 'transformer.h.28.mlp.c_proj.weight', 'transformer.h.24.mlp.c_proj.weight', 'transformer.h.24.mlp.c_fc.bias', 'transformer.h.7.attn.attention.out_proj.bias', 'transformer.h.15.attn.attention.q_proj.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.16.ln_2.weight', 'transformer.h.5.attn.attention.v_proj.weight', 'transformer.h.19.mlp.c_proj.weight', 'transformer.h.14.attn.attention.v_proj.weight', 'transformer.h.21.attn.attention.k_proj.weight', 'transformer.h.25.attn.attention.bias', 'transformer.h.0.ln_1.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.3.ln_2.weight', 'transformer.h.20.attn.attention.out_proj.weight', 'transformer.h.9.attn.attention.out_proj.bias', 'transformer.h.9.attn.attention.out_proj.weight', 'transformer.h.31.attn.attention.q_proj.weight', 'transformer.h.14.attn.attention.q_proj.weight', 'transformer.h.25.attn.attention.v_proj.weight', 'transformer.h.25.mlp.c_proj.bias', 'transformer.h.31.mlp.c_proj.weight', 'transformer.h.21.ln_2.weight', 'transformer.h.30.mlp.c_fc.weight', 'transformer.h.25.ln_2.weight', 'transformer.h.19.mlp.c_fc.weight', 'transformer.h.1.ln_2.weight', 'transformer.h.17.mlp.c_fc.weight', 'transformer.h.13.ln_1.bias', 'transformer.h.1.attn.attention.bias', 'transformer.h.18.attn.attention.v_proj.weight', 'transformer.h.31.attn.attention.masked_bias', 'transformer.h.21.attn.attention.q_proj.weight', 'transformer.h.20.ln_1.weight', 'transformer.h.18.attn.attention.masked_bias', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.6.attn.attention.bias', 'transformer.h.16.attn.attention.q_proj.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.17.ln_1.weight', 'transformer.h.10.attn.attention.out_proj.weight', 'transformer.h.13.ln_2.weight', 'transformer.h.12.ln_1.weight', 'transformer.h.19.ln_1.bias', 'transformer.h.23.ln_1.weight', 'transformer.h.31.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.5.ln_1.weight', 'transformer.h.14.ln_2.bias', 'transformer.h.20.attn.attention.k_proj.weight', 'transformer.h.0.ln_2.weight', 'transformer.h.20.attn.attention.bias', 'transformer.h.2.ln_2.bias', 'transformer.h.11.ln_2.weight', 'transformer.h.28.attn.attention.out_proj.weight', 'transformer.h.29.attn.attention.bias', 'transformer.h.27.ln_1.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.26.ln_1.weight', 'transformer.ln_f.bias', 'transformer.h.10.attn.attention.bias', 'transformer.h.26.attn.attention.k_proj.weight', 'transformer.h.23.attn.attention.q_proj.weight', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.15.ln_1.weight', 'transformer.h.15.ln_2.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.9.ln_2.bias', 'transformer.h.15.mlp.c_fc.weight', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.22.attn.attention.bias', 'transformer.h.5.attn.attention.masked_bias', 'transformer.h.2.ln_2.weight', 'transformer.h.3.attn.attention.k_proj.weight', 'transformer.h.26.ln_2.weight', 'transformer.h.8.attn.attention.bias', 'transformer.h.0.ln_1.weight', 'transformer.h.10.attn.attention.q_proj.weight', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.13.attn.attention.out_proj.bias', 'transformer.h.6.ln_1.bias', 'transformer.h.24.attn.attention.masked_bias', 'transformer.h.14.attn.attention.masked_bias', 'transformer.h.19.mlp.c_fc.bias', 'transformer.h.24.attn.attention.bias', 'transformer.h.18.mlp.c_proj.weight', 'transformer.h.15.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.24.mlp.c_proj.bias', 'transformer.h.16.attn.attention.masked_bias', 'transformer.h.6.ln_2.weight', 'transformer.h.8.ln_1.weight', 'transformer.h.23.attn.attention.v_proj.weight', 'transformer.h.5.attn.attention.out_proj.bias', 'transformer.h.7.attn.attention.out_proj.weight', 'transformer.h.9.attn.attention.bias', 'transformer.h.20.mlp.c_fc.weight', 'transformer.h.26.mlp.c_fc.weight', 'transformer.h.12.attn.attention.out_proj.weight', 'transformer.h.22.mlp.c_fc.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.18.ln_1.bias', 'transformer.h.15.attn.attention.masked_bias', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.1.attn.attention.q_proj.weight', 'transformer.h.23.mlp.c_proj.weight', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.12.mlp.c_fc.weight', 'transformer.h.24.attn.attention.q_proj.weight', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.23.mlp.c_proj.bias', 'transformer.h.12.attn.attention.out_proj.bias', 'transformer.wpe.weight', 'transformer.h.1.attn.attention.masked_bias', 'transformer.h.0.attn.attention.out_proj.bias', 'transformer.h.14.mlp.c_proj.bias', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.22.mlp.c_proj.weight', 'transformer.h.26.mlp.c_proj.bias', 'transformer.h.29.ln_1.weight', 'transformer.h.1.attn.attention.k_proj.weight', 'transformer.h.10.attn.attention.k_proj.weight', 'transformer.h.27.attn.attention.v_proj.weight', 'transformer.h.29.attn.attention.masked_bias', 'transformer.h.21.mlp.c_proj.weight', 'transformer.h.13.attn.attention.k_proj.weight', 'transformer.h.25.attn.attention.k_proj.weight', 'transformer.h.2.attn.attention.masked_bias', 'transformer.h.24.ln_1.weight', 'transformer.h.22.ln_2.bias', 'transformer.h.2.attn.attention.v_proj.weight', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.13.attn.attention.bias', 'transformer.h.4.attn.attention.q_proj.weight', 'transformer.h.17.attn.attention.v_proj.weight', 'transformer.h.23.ln_2.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.26.ln_2.bias', 'transformer.h.31.attn.attention.k_proj.weight', 'transformer.h.26.mlp.c_fc.bias', 'transformer.h.4.ln_2.bias', 'transformer.h.24.ln_2.weight', 'transformer.h.25.mlp.c_fc.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.30.ln_1.bias', 'transformer.h.1.ln_1.bias', 'transformer.h.15.attn.attention.out_proj.bias', 'transformer.h.31.ln_1.weight', 'transformer.h.21.mlp.c_fc.weight', 'transformer.h.23.mlp.c_fc.bias', 'transformer.h.14.mlp.c_fc.weight', 'transformer.h.15.ln_1.bias', 'transformer.h.25.attn.attention.q_proj.weight', 'transformer.h.16.attn.attention.k_proj.weight', 'transformer.h.27.attn.attention.k_proj.weight', 'transformer.h.23.attn.attention.masked_bias', 'transformer.h.22.attn.attention.out_proj.weight', 'transformer.h.9.attn.attention.k_proj.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.20.attn.attention.out_proj.bias', 'transformer.h.24.attn.attention.out_proj.weight', 'transformer.h.31.attn.attention.bias', 'transformer.h.15.attn.attention.out_proj.weight', 'transformer.h.28.attn.attention.bias', 'transformer.h.23.ln_1.bias', 'transformer.h.27.ln_2.weight', 'transformer.h.17.ln_2.bias', 'transformer.h.22.mlp.c_proj.bias', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.14.attn.attention.k_proj.weight', 'transformer.h.28.attn.attention.masked_bias', 'transformer.h.20.attn.attention.masked_bias', 'transformer.h.14.ln_2.weight', 'transformer.h.30.attn.attention.q_proj.weight', 'transformer.h.6.attn.attention.k_proj.weight', 'transformer.h.13.attn.attention.masked_bias', 'transformer.h.31.mlp.c_fc.weight', 'transformer.h.20.attn.attention.q_proj.weight', 'transformer.h.1.attn.attention.out_proj.bias', 'transformer.wte.weight', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.17.attn.attention.out_proj.bias', 'transformer.h.6.attn.attention.out_proj.weight', 'transformer.h.14.attn.attention.bias', 'transformer.h.17.ln_1.bias', 'lm_head.weight', 'transformer.h.26.attn.attention.masked_bias', 'transformer.h.22.attn.attention.q_proj.weight', 'transformer.h.31.ln_1.bias', 'transformer.h.11.attn.attention.v_proj.weight', 'transformer.h.30.ln_1.weight', 'transformer.h.8.attn.attention.out_proj.weight', 'transformer.h.21.attn.attention.bias', 'transformer.h.23.mlp.c_fc.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.31.attn.attention.out_proj.weight', 'transformer.h.7.attn.attention.bias', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.26.attn.attention.out_proj.bias', 'transformer.h.24.attn.attention.v_proj.weight', 'transformer.h.8.ln_2.weight', 'transformer.h.24.attn.attention.k_proj.weight', 'transformer.h.11.ln_1.weight', 'transformer.h.29.ln_2.bias', 'transformer.h.14.ln_1.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.19.ln_2.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.3.attn.attention.q_proj.weight', 'transformer.h.15.attn.attention.k_proj.weight', 'transformer.h.31.attn.attention.v_proj.weight', 'transformer.h.19.attn.attention.q_proj.weight', 'transformer.h.10.attn.attention.masked_bias', 'transformer.h.7.ln_2.weight', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.29.mlp.c_fc.bias', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.18.attn.attention.k_proj.weight', 'transformer.h.22.mlp.c_fc.bias', 'transformer.h.25.ln_1.bias', 'transformer.h.2.attn.attention.q_proj.weight', 'transformer.h.3.ln_1.weight', 'transformer.h.14.attn.attention.out_proj.weight', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.27.attn.attention.q_proj.weight', 'transformer.h.30.attn.attention.out_proj.bias', 'transformer.h.16.mlp.c_fc.bias', 'transformer.h.18.attn.attention.out_proj.weight', 'transformer.h.12.attn.attention.k_proj.weight', 'transformer.h.10.attn.attention.v_proj.weight', 'transformer.h.19.attn.attention.k_proj.weight', 'transformer.h.20.ln_1.bias', 'transformer.h.7.attn.attention.q_proj.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.4.attn.attention.bias', 'transformer.h.23.ln_2.bias', 'transformer.h.30.ln_2.bias', 'transformer.h.29.attn.attention.out_proj.weight', 'transformer.h.22.attn.attention.v_proj.weight', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.26.attn.attention.bias', 'transformer.h.20.attn.attention.v_proj.weight', 'transformer.h.4.attn.attention.masked_bias', 'transformer.h.18.ln_2.weight', 'transformer.h.24.ln_1.bias', 'transformer.h.29.attn.attention.q_proj.weight', 'transformer.h.29.mlp.c_proj.bias', 'transformer.h.27.ln_1.bias', 'transformer.h.30.attn.attention.k_proj.weight', 'transformer.h.18.attn.attention.out_proj.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.22.attn.attention.masked_bias', 'transformer.h.29.attn.attention.v_proj.weight', 'transformer.h.3.attn.attention.v_proj.weight', 'transformer.h.18.mlp.c_proj.bias', 'transformer.h.26.attn.attention.v_proj.weight', 'transformer.h.29.mlp.c_proj.weight', 'transformer.h.30.attn.attention.out_proj.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.29.mlp.c_fc.weight', 'transformer.h.5.attn.attention.out_proj.weight', 'transformer.h.2.attn.attention.bias', 'transformer.h.28.attn.attention.k_proj.weight', 'transformer.h.30.ln_2.weight', 'transformer.h.26.mlp.c_proj.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.26.attn.attention.q_proj.weight', 'transformer.h.0.attn.attention.bias', 'transformer.h.6.attn.attention.v_proj.weight', 'transformer.h.21.attn.attention.masked_bias', 'transformer.h.29.ln_1.bias', 'transformer.h.17.attn.attention.out_proj.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.16.attn.attention.bias', 'transformer.h.18.ln_2.bias', 'transformer.h.21.ln_1.bias', 'transformer.h.18.attn.attention.q_proj.weight', 'transformer.h.22.ln_2.weight', 'transformer.h.19.ln_2.bias', 'transformer.h.13.attn.attention.q_proj.weight', 'transformer.h.6.attn.attention.out_proj.bias', 'transformer.h.25.mlp.c_proj.weight', 'transformer.h.12.attn.attention.masked_bias', 'transformer.h.21.attn.attention.v_proj.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.26.ln_1.bias', 'transformer.h.9.ln_1.bias', 'transformer.h.16.attn.attention.out_proj.weight', 'transformer.h.28.ln_2.weight', 'transformer.h.12.attn.attention.bias', 'transformer.h.24.mlp.c_fc.weight', 'transformer.h.25.attn.attention.out_proj.weight', 'transformer.h.28.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.5.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.bias', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.30.mlp.c_fc.bias', 'transformer.h.31.attn.attention.out_proj.bias', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.3.ln_1.bias', 'transformer.h.17.attn.attention.k_proj.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.21.ln_1.weight', 'transformer.h.13.mlp.c_fc.bias', 'transformer.h.28.ln_1.bias', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.31.ln_2.weight', 'transformer.h.21.mlp.c_proj.bias', 'transformer.h.25.ln_1.weight', 'transformer.h.21.attn.attention.out_proj.bias', 'transformer.h.19.attn.attention.bias', 'transformer.h.30.mlp.c_proj.weight', 'transformer.h.12.attn.attention.v_proj.weight', 'transformer.h.21.mlp.c_fc.bias', 'transformer.h.23.attn.attention.k_proj.weight', 'transformer.h.19.attn.attention.out_proj.bias', 'transformer.h.11.attn.attention.masked_bias', 'transformer.h.22.ln_1.weight', 'transformer.h.4.attn.attention.out_proj.bias', 'transformer.h.5.attn.attention.bias', 'transformer.h.6.attn.attention.q_proj.weight', 'transformer.h.14.attn.attention.out_proj.bias', 'transformer.h.20.ln_2.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.18.ln_1.weight', 'transformer.h.19.ln_1.weight', 'transformer.h.22.ln_1.bias', 'transformer.h.23.attn.attention.out_proj.bias', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.2.attn.attention.k_proj.weight', 'transformer.h.9.attn.attention.masked_bias', 'transformer.h.26.attn.attention.out_proj.weight', 'transformer.h.1.attn.attention.out_proj.weight', 'transformer.h.10.attn.attention.out_proj.bias', 'transformer.h.24.ln_2.bias', 'transformer.h.16.ln_1.bias', 'transformer.h.16.attn.attention.out_proj.bias', 'transformer.h.3.attn.attention.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.11.attn.attention.out_proj.bias', 'transformer.h.11.attn.attention.bias', 'transformer.h.5.ln_2.bias', 'transformer.h.3.attn.attention.out_proj.weight', 'transformer.h.15.attn.attention.bias', 'transformer.h.16.attn.attention.v_proj.weight', 'transformer.h.6.attn.attention.masked_bias', 'transformer.h.2.ln_1.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.27.mlp.c_fc.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.4.attn.attention.out_proj.weight', 'transformer.h.17.mlp.c_fc.bias', 'transformer.h.11.attn.attention.out_proj.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.28.attn.attention.out_proj.bias', 'transformer.h.27.attn.attention.bias', 'transformer.h.18.mlp.c_fc.weight', 'transformer.h.24.attn.attention.out_proj.bias', 'transformer.h.19.attn.attention.v_proj.weight', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.10.ln_1.weight', 'transformer.h.8.attn.attention.q_proj.weight', 'transformer.h.29.ln_2.weight', 'transformer.h.18.attn.attention.bias', 'transformer.h.21.ln_2.bias', 'transformer.h.28.attn.attention.q_proj.weight', 'transformer.h.22.attn.attention.k_proj.weight', 'transformer.h.27.attn.attention.out_proj.weight', 'transformer.h.1.attn.attention.v_proj.weight', 'transformer.h.13.ln_2.bias', 'transformer.h.22.attn.attention.out_proj.bias', 'transformer.h.17.attn.attention.masked_bias', 'transformer.h.0.attn.attention.k_proj.weight', 'transformer.h.20.mlp.c_proj.bias', 'transformer.h.28.ln_1.weight', 'transformer.h.29.attn.attention.k_proj.weight', 'transformer.h.13.attn.attention.v_proj.weight', 'transformer.h.11.attn.attention.k_proj.weight', 'transformer.h.31.ln_2.bias', 'transformer.h.20.mlp.c_fc.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.25.mlp.c_fc.bias', 'transformer.h.7.attn.attention.v_proj.weight', 'transformer.h.20.mlp.c_proj.weight', 'transformer.h.29.attn.attention.out_proj.bias', 'transformer.h.5.attn.attention.q_proj.weight', 'transformer.h.28.mlp.c_fc.weight', 'transformer.h.16.ln_2.bias', 'transformer.h.8.attn.attention.v_proj.weight', 'transformer.h.0.attn.attention.q_proj.weight', 'transformer.h.12.ln_1.bias', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.7.ln_1.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.30.attn.attention.masked_bias', 'transformer.h.4.ln_1.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.11.attn.attention.q_proj.weight', 'transformer.h.27.attn.attention.masked_bias', 'transformer.h.16.ln_1.weight', 'transformer.h.25.ln_2.bias', 'transformer.h.12.mlp.c_fc.bias', 'transformer.h.27.mlp.c_proj.bias', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.17.ln_2.weight', 'transformer.h.2.attn.attention.out_proj.weight', 'transformer.h.12.attn.attention.q_proj.weight', 'transformer.h.8.attn.attention.k_proj.weight', 'transformer.h.13.mlp.c_fc.weight', 'transformer.h.25.attn.attention.out_proj.bias', 'transformer.h.23.attn.attention.out_proj.weight', 'transformer.h.28.ln_2.bias', 'transformer.h.4.attn.attention.v_proj.weight', 'transformer.h.17.attn.attention.q_proj.weight', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.27.attn.attention.out_proj.bias', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.25.attn.attention.masked_bias', 'transformer.h.30.attn.attention.v_proj.weight', 'transformer.h.0.attn.attention.masked_bias', 'transformer.h.4.attn.attention.k_proj.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.27.ln_2.bias', 'transformer.h.27.mlp.c_proj.weight', 'transformer.h.8.attn.attention.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2022-11-18 15:59:25,458][datasets.builder][WARNING] - Using custom data configuration ViktorThink--mountain_combined_813306-6918b9ea07482433
[2022-11-18 15:59:25,557][datasets.builder][WARNING] - Found cached dataset csv (/home/paperspace/.cache/huggingface/datasets/ViktorThink___csv/ViktorThink--mountain_combined_813306-6918b9ea07482433/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.33it/s]100%|██████████| 2/2 [00:00<00:00, 10.03it/s]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 1/814 [00:03<46:28,  3.43s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:06<42:52,  3.17s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:08<37:56,  2.81s/ba]Running tokenizer on dataset:   0%|          | 4/814 [00:10<34:13,  2.54s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:13<32:01,  2.38s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:14<30:11,  2.24s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:17<29:17,  2.18s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:19<28:31,  2.12s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:20<27:45,  2.07s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:22<27:05,  2.02s/ba]Running tokenizer on dataset:   1%|▏         | 11/814 [00:24<26:58,  2.02s/ba]Running tokenizer on dataset:   1%|▏         | 12/814 [00:26<26:42,  2.00s/ba]Running tokenizer on dataset:   2%|▏         | 13/814 [00:28<26:31,  1.99s/ba]Running tokenizer on dataset:   2%|▏         | 14/814 [00:30<26:22,  1.98s/ba]Running tokenizer on dataset:   2%|▏         | 15/814 [00:32<26:07,  1.96s/ba]Running tokenizer on dataset:   2%|▏         | 16/814 [00:34<25:51,  1.94s/ba]Running tokenizer on dataset:   2%|▏         | 17/814 [00:36<25:37,  1.93s/ba]Running tokenizer on dataset:   2%|▏         | 18/814 [00:38<25:23,  1.91s/ba]Running tokenizer on dataset:   2%|▏         | 19/814 [00:40<25:15,  1.91s/ba]Running tokenizer on dataset:   2%|▏         | 20/814 [00:42<25:12,  1.91s/ba]Running tokenizer on dataset:   3%|▎         | 21/814 [00:44<25:15,  1.91s/ba]Running tokenizer on dataset:   3%|▎         | 22/814 [00:45<24:59,  1.89s/ba]Running tokenizer on dataset:   3%|▎         | 23/814 [00:47<24:47,  1.88s/ba]Running tokenizer on dataset:   3%|▎         | 24/814 [00:49<24:40,  1.87s/ba]Running tokenizer on dataset:   3%|▎         | 25/814 [00:51<24:41,  1.88s/ba]Running tokenizer on dataset:   3%|▎         | 26/814 [00:53<24:31,  1.87s/ba]Running tokenizer on dataset:   3%|▎         | 27/814 [00:55<24:14,  1.85s/ba]Running tokenizer on dataset:   3%|▎         | 28/814 [00:57<24:21,  1.86s/ba]Running tokenizer on dataset:   4%|▎         | 29/814 [00:59<24:35,  1.88s/ba]Running tokenizer on dataset:   4%|▎         | 30/814 [01:00<24:33,  1.88s/ba]Running tokenizer on dataset:   4%|▍         | 31/814 [01:02<24:22,  1.87s/ba]Running tokenizer on dataset:   4%|▍         | 32/814 [01:04<24:31,  1.88s/ba]Running tokenizer on dataset:   4%|▍         | 33/814 [01:06<24:24,  1.87s/ba]Running tokenizer on dataset:   4%|▍         | 34/814 [01:08<24:06,  1.85s/ba]Running tokenizer on dataset:   4%|▍         | 35/814 [01:10<23:53,  1.84s/ba]Running tokenizer on dataset:   4%|▍         | 36/814 [01:11<23:37,  1.82s/ba]Running tokenizer on dataset:   5%|▍         | 37/814 [01:13<23:29,  1.81s/ba]Running tokenizer on dataset:   5%|▍         | 38/814 [01:15<23:12,  1.79s/ba]Running tokenizer on dataset:   5%|▍         | 39/814 [01:17<23:28,  1.82s/ba]Running tokenizer on dataset:   5%|▍         | 40/814 [01:19<23:29,  1.82s/ba]Running tokenizer on dataset:   5%|▌         | 41/814 [01:20<23:31,  1.83s/ba]Running tokenizer on dataset:   5%|▌         | 42/814 [01:22<23:31,  1.83s/ba]Running tokenizer on dataset:   5%|▌         | 43/814 [01:24<23:27,  1.83s/ba]Running tokenizer on dataset:   5%|▌         | 44/814 [01:26<23:42,  1.85s/ba]Running tokenizer on dataset:   6%|▌         | 45/814 [01:28<23:35,  1.84s/ba]Running tokenizer on dataset:   6%|▌         | 46/814 [01:30<23:43,  1.85s/ba]Running tokenizer on dataset:   6%|▌         | 47/814 [01:32<23:31,  1.84s/ba]Running tokenizer on dataset:   6%|▌         | 48/814 [01:33<23:10,  1.82s/ba]Running tokenizer on dataset:   6%|▌         | 49/814 [01:35<23:08,  1.82s/ba]Running tokenizer on dataset:   6%|▌         | 49/814 [01:37<25:17,  1.98s/ba]
Error in sys.excepthook:
Traceback (most recent call last):
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1694, in print
    extend(render(renderable, render_options))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/constrain.py", line 29, in __rich_console__
    yield from console.render(self.renderable, child_options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/panel.py", line 220, in __rich_console__
    lines = console.render_lines(renderable, child_options, style=style)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 511, in __rich_console__
    yield from self._render(console, render_options, widths)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/table.py", line 824, in _render
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/syntax.py", line 609, in __rich_console__
    segments = Segments(self._get_syntax(console, options))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/segment.py", line 668, in __init__
    self.segments = list(segments)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/syntax.py", line 637, in _get_syntax
    text = self.highlight(processed_code, self.line_range)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/syntax.py", line 509, in highlight
    text.append_tokens(tokens_to_spans())
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/text.py", line 995, in append_tokens
    for content, style in tokens:
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/syntax.py", line 497, in tokens_to_spans
    _token_type, token = next(tokens)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/rich/syntax.py", line 484, in line_tokenize
    for token_type, token in lexer.get_tokens(code):
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/pygments/lexer.py", line 190, in streamer
    for _, t, v in self.get_tokens_unprocessed(text):
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/pygments/lexer.py", line 632, in get_tokens_unprocessed
    m = rexmatch(text, pos)
KeyboardInterrupt

Original exception was:
Traceback (most recent call last):
  File "finetune_using_clm_wandb.py", line 599, in <module>
    main()
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "finetune_using_clm_wandb.py", line 304, in main
    tokenized_datasets = preprocess(cfg, accelerator, tokenizer, raw_datasets)
  File "finetune_using_clm_wandb.py", line 215, in preprocess
    tokenized_datasets = raw_datasets.map(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/dataset_dict.py", line 777, in map
    {
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/dataset_dict.py", line 778, in <dictcomp>
    k: dataset.map(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2585, in map
    return self._map_single(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 585, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 552, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/fingerprint.py", line 480, in wrapper
    out = func(self, *args, **kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2982, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2865, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2545, in decorated
    result = f(decorated_item, *args, **kwargs)
  File "finetune_using_clm_wandb.py", line 204, in tokenize_fn
    result = tokenizer(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2488, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2574, in _call_one
    return self.batch_encode_plus(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2765, in batch_encode_plus
    return self._batch_encode_plus(
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 733, in _batch_encode_plus
    first_ids = get_input_ids(ids)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 701, in get_input_ids
    return self.convert_tokens_to_ids(tokens)
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 579, in convert_tokens_to_ids
    ids.append(self._convert_token_to_id_with_added_voc(token))
  File "/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 583, in _convert_token_to_id_with_added_voc
    if token is None:
KeyboardInterrupt
