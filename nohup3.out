WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/utils/dataclasses.py:346: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.
  warnings.warn("DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.")
[2022-11-18 13:27:06,703][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 1
/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/utils/dataclasses.py:346: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.
  warnings.warn("DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.")
/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/utils/dataclasses.py:346: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.
  warnings.warn("DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.")
[2022-11-18 13:27:06,935][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 3
[2022-11-18 13:27:06,965][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 2
/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/utils/dataclasses.py:346: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.
  warnings.warn("DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.")
[2022-11-18 13:27:07,066] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-18 13:27:07,143][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2022-11-18 13:27:07,143][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-11-18 13:27:07,146][torch.distributed.distributed_c10d][INFO] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-11-18 13:27:07,149][torch.distributed.distributed_c10d][INFO] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-11-18 13:27:07,152][torch.distributed.distributed_c10d][INFO] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-11-18 13:27:09,806][__main__][INFO] - Setting random seed to 17
[2022-11-18 13:27:09,806][__main__][INFO] - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}}

[2022-11-18 13:27:09,806][__main__][INFO] - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}}

[2022-11-18 13:27:09,806][__main__][INFO] - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}}

[2022-11-18 13:27:09,806][__main__][INFO] - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}}

[2022-11-18 13:27:09,808][__main__][INFO] - output_dir: tuned-model
bittensor:
  network: nobunaga
dataset:
  name: ViktorThink/mountain_combined_813306
  config_name: null
  num_batches: 5000
  block_size: 256
  overwrite_cache: false
  keep_linebreaks: true
  concatenate_raw: false
  load_tokenized_data: false
model:
  name: facebook/opt-2.7b
  config_name: null
tokenizer:
  name: null
  use_fast: true
  preprocessing_num_workers: null
  pad_token: '[PAD]'
training:
  seed: 17
  val_split_percent: 20
  train_batch_size: 32
  eval_batch_size: 16
  learning_rate: 3.0e-06
  weight_decay: 0.05
  num_epochs: 4
  max_train_steps: null
  gradient_accumulation_steps: 2
  lr_scheduler: constant
  lr_warmup_steps: 5
  eval_every: 250
  max_eval_steps: 500
  checkpoint:
    resume_from_checkpoint: 0
    every_n_steps: null
tracking:
  enabled: true
  report_to: all
testing:
  enabled: false

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--EleutherAI--gpt-neo-2.7B/snapshots/51568a6e0ae813a3f2a9da558ab7beac5e3acc24/config.json
Model config GPTNeoConfig {
  "_name_or_path": "EleutherAI/gpt-neo-2.7B",
  "activation_function": "gelu_new",
  "architectures": [
    "GPTNeoForCausalLM"
  ],
  "attention_dropout": 0,
  "attention_layers": [
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local"
  ],
  "attention_types": [
    [
      [
        "global",
        "local"
      ],
      16
    ]
  ],
  "bos_token_id": 50256,
  "embed_dropout": 0,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "hidden_size": 2560,
  "initializer_range": 0.02,
  "intermediate_size": null,
  "layer_norm_epsilon": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neo",
  "num_heads": 20,
  "num_layers": 32,
  "resid_dropout": 0,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50,
      "temperature": 0.9
    }
  },
  "tokenizer_class": "GPT2Tokenizer",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50257,
  "window_size": 256
}

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading file vocab.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/vocab.json
loading file merges.txt from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/merges.txt
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/tokenizer_config.json
loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading weights file flax_model.msgpack from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Loading Flax weights from /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
  0%|          | 0/2 [00:00<?, ?it/s]  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.47it/s]100%|██████████| 2/2 [00:00<00:00, 10.40it/s]
 50%|█████     | 1/2 [00:00<00:00,  5.63it/s]100%|██████████| 2/2 [00:00<00:00, 10.71it/s]
Some weights of the Flax model were not used when initializing the PyTorch model GPTNeoForCausalLM: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.18.fc1.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.bias']
- This IS expected if you are initializing GPTNeoForCausalLM from a Flax model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a FlaxBertForPreTraining model).
- This IS NOT expected if you are initializing GPTNeoForCausalLM from a Flax model that you expect to be exactly identical (e.g. initializing a BertForSequenceClassification model from a FlaxBertForSequenceClassification model).
Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['transformer.h.18.attn.attention.masked_bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.27.mlp.c_fc.bias', 'transformer.h.29.mlp.c_fc.weight', 'transformer.h.19.attn.attention.out_proj.weight', 'transformer.h.0.ln_2.weight', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.7.attn.attention.v_proj.weight', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.9.attn.attention.k_proj.weight', 'transformer.h.31.ln_1.bias', 'transformer.h.18.ln_2.weight', 'transformer.h.12.ln_1.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.26.mlp.c_proj.weight', 'transformer.h.12.attn.attention.out_proj.bias', 'transformer.h.28.attn.attention.out_proj.bias', 'transformer.h.20.attn.attention.bias', 'transformer.h.30.attn.attention.bias', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.10.attn.attention.v_proj.weight', 'transformer.h.20.ln_2.weight', 'transformer.h.20.ln_1.bias', 'transformer.h.19.ln_1.bias', 'transformer.h.19.attn.attention.out_proj.bias', 'transformer.h.17.attn.attention.k_proj.weight', 'transformer.h.24.mlp.c_fc.weight', 'transformer.h.4.attn.attention.q_proj.weight', 'transformer.h.13.mlp.c_fc.bias', 'transformer.h.10.attn.attention.k_proj.weight', 'transformer.h.24.ln_2.weight', 'transformer.h.27.mlp.c_fc.weight', 'transformer.h.21.attn.attention.masked_bias', 'transformer.h.14.mlp.c_fc.bias', 'transformer.h.20.attn.attention.out_proj.weight', 'transformer.h.27.attn.attention.bias', 'transformer.h.23.mlp.c_fc.weight', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.16.mlp.c_fc.weight', 'transformer.h.17.ln_2.bias', 'transformer.h.18.attn.attention.k_proj.weight', 'transformer.h.1.attn.attention.bias', 'transformer.h.22.ln_2.bias', 'transformer.h.19.attn.attention.v_proj.weight', 'transformer.h.9.attn.attention.bias', 'transformer.h.13.attn.attention.v_proj.weight', 'transformer.h.18.ln_1.bias', 'transformer.h.26.mlp.c_proj.bias', 'transformer.h.2.ln_2.bias', 'transformer.h.11.attn.attention.k_proj.weight', 'transformer.h.14.attn.attention.v_proj.weight', 'transformer.h.5.attn.attention.out_proj.weight', 'transformer.h.26.attn.attention.masked_bias', 'transformer.h.29.attn.attention.v_proj.weight', 'transformer.h.3.ln_2.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.8.ln_2.weight', 'transformer.h.21.attn.attention.out_proj.bias', 'transformer.h.30.mlp.c_proj.bias', 'transformer.h.18.mlp.c_proj.weight', 'transformer.h.2.attn.attention.v_proj.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.21.attn.attention.k_proj.weight', 'transformer.h.25.attn.attention.k_proj.weight', 'transformer.h.8.ln_1.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.26.ln_1.weight', 'transformer.h.15.attn.attention.masked_bias', 'transformer.h.6.ln_2.bias', 'transformer.h.14.attn.attention.q_proj.weight', 'transformer.h.1.attn.attention.out_proj.weight', 'transformer.h.31.ln_2.weight', 'transformer.h.31.attn.attention.k_proj.weight', 'transformer.h.18.mlp.c_fc.weight', 'transformer.h.23.ln_2.weight', 'transformer.h.13.ln_1.weight', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.2.ln_1.bias', 'transformer.ln_f.bias', 'transformer.h.27.ln_1.weight', 'transformer.h.27.ln_1.bias', 'transformer.h.28.ln_1.bias', 'transformer.h.13.attn.attention.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.8.attn.attention.v_proj.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.11.attn.attention.masked_bias', 'transformer.h.31.mlp.c_fc.weight', 'transformer.h.0.attn.attention.q_proj.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.16.attn.attention.masked_bias', 'transformer.h.3.attn.attention.out_proj.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.25.mlp.c_fc.weight', 'transformer.h.10.ln_2.weight', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.12.ln_2.weight', 'transformer.h.17.attn.attention.q_proj.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.22.mlp.c_fc.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.6.ln_1.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.0.attn.attention.k_proj.weight', 'transformer.h.22.attn.attention.q_proj.weight', 'transformer.h.5.attn.attention.q_proj.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.28.mlp.c_fc.bias', 'transformer.h.19.mlp.c_fc.weight', 'transformer.h.23.attn.attention.k_proj.weight', 'transformer.h.8.attn.attention.q_proj.weight', 'transformer.h.11.attn.attention.out_proj.bias', 'transformer.h.16.mlp.c_fc.bias', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.17.attn.attention.v_proj.weight', 'transformer.h.17.mlp.c_fc.weight', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.22.attn.attention.k_proj.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.13.ln_2.weight', 'transformer.h.23.attn.attention.masked_bias', 'transformer.h.1.attn.attention.v_proj.weight', 'transformer.h.24.attn.attention.out_proj.bias', 'transformer.h.6.attn.attention.k_proj.weight', 'transformer.h.25.attn.attention.bias', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.20.ln_2.bias', 'transformer.h.29.ln_2.weight', 'transformer.h.30.mlp.c_fc.weight', 'transformer.h.25.ln_1.weight', 'transformer.h.1.attn.attention.masked_bias', 'transformer.h.1.ln_2.bias', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.4.attn.attention.k_proj.weight', 'transformer.h.18.mlp.c_proj.bias', 'transformer.h.16.ln_1.weight', 'transformer.h.26.ln_2.bias', 'transformer.h.2.attn.attention.k_proj.weight', 'transformer.h.24.mlp.c_proj.weight', 'transformer.h.8.attn.attention.bias', 'transformer.h.6.attn.attention.out_proj.bias', 'transformer.h.15.attn.attention.out_proj.bias', 'transformer.h.5.attn.attention.out_proj.bias', 'transformer.h.3.attn.attention.masked_bias', 'transformer.h.9.ln_1.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.10.attn.attention.out_proj.weight', 'transformer.h.12.mlp.c_fc.weight', 'transformer.h.13.attn.attention.k_proj.weight', 'transformer.h.24.ln_1.weight', 'transformer.h.14.attn.attention.out_proj.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.1.ln_1.weight', 'transformer.h.19.mlp.c_fc.bias', 'transformer.h.24.attn.attention.k_proj.weight', 'transformer.h.3.attn.attention.out_proj.bias', 'transformer.h.16.attn.attention.k_proj.weight', 'transformer.h.10.attn.attention.masked_bias', 'transformer.h.25.mlp.c_fc.bias', 'transformer.h.30.ln_2.weight', 'transformer.h.8.attn.attention.out_proj.weight', 'transformer.h.15.attn.attention.v_proj.weight', 'transformer.h.25.mlp.c_proj.weight', 'transformer.h.30.ln_2.bias', 'transformer.h.9.attn.attention.out_proj.bias', 'transformer.h.11.attn.attention.out_proj.weight', 'transformer.h.31.attn.attention.v_proj.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.21.attn.attention.q_proj.weight', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.16.attn.attention.q_proj.weight', 'transformer.h.20.ln_1.weight', 'transformer.h.7.attn.attention.q_proj.weight', 'transformer.h.23.ln_2.bias', 'transformer.h.30.mlp.c_fc.bias', 'transformer.h.25.attn.attention.v_proj.weight', 'transformer.h.30.attn.attention.out_proj.weight', 'transformer.h.2.attn.attention.bias', 'transformer.h.25.attn.attention.masked_bias', 'transformer.h.27.ln_2.weight', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.12.attn.attention.v_proj.weight', 'transformer.h.26.mlp.c_fc.bias', 'transformer.h.6.attn.attention.masked_bias', 'transformer.h.5.attn.attention.bias', 'transformer.h.19.attn.attention.masked_bias', 'transformer.h.28.attn.attention.masked_bias', 'transformer.h.0.attn.attention.masked_bias', 'transformer.h.15.attn.attention.k_proj.weight', 'transformer.h.27.ln_2.bias', 'transformer.h.29.attn.attention.out_proj.bias', 'transformer.h.0.attn.attention.bias', 'transformer.h.20.mlp.c_proj.bias', 'transformer.h.26.attn.attention.out_proj.bias', 'transformer.h.25.ln_2.weight', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.15.mlp.c_fc.weight', 'transformer.h.16.ln_2.weight', 'transformer.h.12.attn.attention.bias', 'transformer.h.31.attn.attention.out_proj.weight', 'transformer.h.19.attn.attention.bias', 'transformer.h.18.attn.attention.out_proj.bias', 'transformer.h.17.mlp.c_fc.bias', 'transformer.h.19.ln_2.bias', 'transformer.h.21.ln_2.bias', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.24.ln_2.bias', 'transformer.h.25.mlp.c_proj.bias', 'transformer.h.20.mlp.c_fc.weight', 'transformer.h.4.ln_1.weight', 'transformer.h.4.attn.attention.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.1.attn.attention.out_proj.bias', 'transformer.h.10.ln_1.bias', 'transformer.h.27.mlp.c_proj.weight', 'transformer.h.13.ln_1.bias', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.7.attn.attention.bias', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.6.attn.attention.q_proj.weight', 'transformer.h.20.attn.attention.k_proj.weight', 'transformer.h.14.ln_1.bias', 'transformer.h.11.ln_2.bias', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.17.ln_2.weight', 'transformer.h.11.ln_1.weight', 'transformer.h.22.mlp.c_proj.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.13.attn.attention.masked_bias', 'transformer.h.12.attn.attention.q_proj.weight', 'transformer.h.15.mlp.c_fc.bias', 'transformer.h.24.ln_1.bias', 'transformer.h.25.attn.attention.q_proj.weight', 'transformer.h.2.attn.attention.masked_bias', 'transformer.h.23.mlp.c_proj.weight', 'transformer.h.30.attn.attention.q_proj.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.21.ln_1.weight', 'transformer.h.19.ln_1.weight', 'transformer.h.26.ln_2.weight', 'transformer.h.27.attn.attention.q_proj.weight', 'transformer.h.23.attn.attention.out_proj.bias', 'transformer.h.23.attn.attention.v_proj.weight', 'transformer.h.15.ln_2.bias', 'transformer.h.15.ln_1.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.31.mlp.c_proj.weight', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.30.mlp.c_proj.weight', 'transformer.h.16.attn.attention.out_proj.weight', 'transformer.h.12.ln_2.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.27.mlp.c_proj.bias', 'transformer.h.1.attn.attention.q_proj.weight', 'transformer.h.28.attn.attention.out_proj.weight', 'transformer.h.19.mlp.c_proj.bias', 'transformer.h.21.attn.attention.bias', 'transformer.h.24.mlp.c_proj.bias', 'transformer.h.26.ln_1.bias', 'transformer.h.9.attn.attention.q_proj.weight', 'transformer.h.24.attn.attention.masked_bias', 'transformer.h.28.mlp.c_proj.weight', 'transformer.h.3.ln_1.weight', 'transformer.h.8.attn.attention.out_proj.bias', 'transformer.h.26.attn.attention.out_proj.weight', 'transformer.h.29.attn.attention.q_proj.weight', 'transformer.h.10.attn.attention.bias', 'transformer.h.23.attn.attention.q_proj.weight', 'transformer.h.28.ln_1.weight', 'transformer.h.4.attn.attention.out_proj.bias', 'transformer.h.14.attn.attention.bias', 'transformer.h.21.mlp.c_proj.weight', 'transformer.h.20.mlp.c_proj.weight', 'transformer.h.4.attn.attention.out_proj.weight', 'transformer.h.22.ln_1.weight', 'transformer.h.7.attn.attention.masked_bias', 'transformer.h.30.attn.attention.out_proj.bias', 'transformer.h.28.ln_2.bias', 'transformer.h.14.mlp.c_proj.bias', 'transformer.h.23.attn.attention.bias', 'transformer.h.8.attn.attention.k_proj.weight', 'transformer.h.25.ln_2.bias', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.17.attn.attention.masked_bias', 'transformer.h.3.ln_1.bias', 'transformer.h.22.mlp.c_proj.weight', 'transformer.h.17.attn.attention.out_proj.weight', 'transformer.h.5.attn.attention.masked_bias', 'transformer.h.26.mlp.c_fc.weight', 'transformer.h.30.ln_1.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.22.attn.attention.v_proj.weight', 'transformer.h.31.attn.attention.bias', 'transformer.h.20.attn.attention.out_proj.bias', 'transformer.h.6.attn.attention.out_proj.weight', 'transformer.h.26.attn.attention.q_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.23.mlp.c_proj.bias', 'transformer.h.9.attn.attention.out_proj.weight', 'transformer.h.27.attn.attention.v_proj.weight', 'transformer.h.21.attn.attention.out_proj.weight', 'transformer.h.11.attn.attention.v_proj.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.20.attn.attention.q_proj.weight', 'transformer.h.22.attn.attention.out_proj.bias', 'transformer.h.5.attn.attention.k_proj.weight', 'transformer.h.24.attn.attention.v_proj.weight', 'transformer.h.29.attn.attention.k_proj.weight', 'transformer.ln_f.weight', 'transformer.h.9.attn.attention.masked_bias', 'transformer.h.17.ln_1.bias', 'transformer.h.13.ln_2.bias', 'transformer.h.1.mlp.c_fc.bias', 'transformer.wpe.weight', 'transformer.h.18.ln_2.bias', 'transformer.h.19.attn.attention.q_proj.weight', 'transformer.h.20.attn.attention.masked_bias', 'transformer.h.28.mlp.c_proj.bias', 'transformer.h.23.attn.attention.out_proj.weight', 'lm_head.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.3.attn.attention.q_proj.weight', 'transformer.h.2.attn.attention.out_proj.weight', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.2.ln_1.weight', 'transformer.h.14.attn.attention.masked_bias', 'transformer.h.6.attn.attention.v_proj.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.22.mlp.c_fc.bias', 'transformer.h.19.attn.attention.k_proj.weight', 'transformer.h.0.attn.attention.out_proj.bias', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.9.attn.attention.v_proj.weight', 'transformer.h.4.attn.attention.v_proj.weight', 'transformer.h.0.attn.attention.v_proj.weight', 'transformer.h.7.attn.attention.out_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.24.attn.attention.q_proj.weight', 'transformer.h.29.ln_1.weight', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.16.attn.attention.v_proj.weight', 'transformer.h.19.mlp.c_proj.weight', 'transformer.h.27.attn.attention.out_proj.weight', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.15.attn.attention.bias', 'transformer.h.31.attn.attention.q_proj.weight', 'transformer.h.27.attn.attention.masked_bias', 'transformer.h.16.attn.attention.out_proj.bias', 'transformer.h.29.attn.attention.masked_bias', 'transformer.h.11.ln_2.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.28.attn.attention.k_proj.weight', 'transformer.h.21.ln_2.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.14.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.masked_bias', 'transformer.h.0.ln_1.bias', 'transformer.h.8.ln_2.bias', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.5.attn.attention.v_proj.weight', 'transformer.h.18.attn.attention.out_proj.weight', 'transformer.h.24.attn.attention.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.19.ln_2.weight', 'transformer.h.12.mlp.c_fc.bias', 'transformer.h.23.mlp.c_fc.bias', 'transformer.h.16.ln_2.bias', 'transformer.h.31.ln_1.weight', 'transformer.h.15.ln_2.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.21.attn.attention.v_proj.weight', 'transformer.h.21.mlp.c_fc.bias', 'transformer.h.22.attn.attention.out_proj.weight', 'transformer.h.2.attn.attention.out_proj.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.13.mlp.c_fc.weight', 'transformer.h.29.ln_1.bias', 'transformer.h.4.attn.attention.masked_bias', 'transformer.h.20.attn.attention.v_proj.weight', 'transformer.h.8.attn.attention.masked_bias', 'transformer.h.4.ln_2.bias', 'transformer.h.26.attn.attention.bias', 'transformer.h.12.attn.attention.out_proj.weight', 'transformer.h.29.mlp.c_proj.bias', 'transformer.h.13.attn.attention.out_proj.bias', 'transformer.h.21.mlp.c_proj.bias', 'transformer.h.4.ln_1.bias', 'transformer.h.12.attn.attention.k_proj.weight', 'transformer.h.16.ln_1.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.1.attn.attention.k_proj.weight', 'transformer.h.9.ln_2.weight', 'transformer.h.22.attn.attention.masked_bias', 'transformer.h.3.attn.attention.bias', 'transformer.h.14.mlp.c_fc.weight', 'transformer.h.13.attn.attention.out_proj.weight', 'transformer.h.18.attn.attention.q_proj.weight', 'transformer.h.7.attn.attention.k_proj.weight', 'transformer.h.31.ln_2.bias', 'transformer.h.29.mlp.c_fc.bias', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.3.attn.attention.v_proj.weight', 'transformer.h.17.attn.attention.out_proj.bias', 'transformer.h.28.mlp.c_fc.weight', 'transformer.h.18.mlp.c_fc.bias', 'transformer.h.17.attn.attention.bias', 'transformer.h.25.attn.attention.out_proj.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.12.ln_1.bias', 'transformer.h.22.attn.attention.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.24.attn.attention.out_proj.weight', 'transformer.h.31.mlp.c_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.29.attn.attention.out_proj.weight', 'transformer.h.10.attn.attention.q_proj.weight', 'transformer.h.2.ln_2.weight', 'transformer.h.7.attn.attention.out_proj.bias', 'transformer.h.30.attn.attention.k_proj.weight', 'transformer.h.22.ln_2.weight', 'transformer.h.13.attn.attention.q_proj.weight', 'transformer.h.14.ln_2.bias', 'transformer.h.10.attn.attention.out_proj.bias', 'transformer.h.28.attn.attention.v_proj.weight', 'transformer.h.31.attn.attention.masked_bias', 'transformer.h.6.attn.attention.bias', 'transformer.h.24.mlp.c_fc.bias', 'transformer.h.21.mlp.c_fc.weight', 'transformer.h.25.ln_1.bias', 'transformer.h.28.attn.attention.bias', 'transformer.h.3.attn.attention.k_proj.weight', 'transformer.h.14.ln_2.weight', 'transformer.h.23.ln_1.weight', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.29.mlp.c_proj.weight', 'transformer.h.25.attn.attention.out_proj.weight', 'transformer.h.26.attn.attention.k_proj.weight', 'transformer.h.15.ln_1.weight', 'transformer.h.27.attn.attention.k_proj.weight', 'transformer.h.15.attn.attention.out_proj.weight', 'transformer.h.29.attn.attention.bias', 'transformer.h.30.attn.attention.v_proj.weight', 'transformer.h.11.attn.attention.q_proj.weight', 'transformer.h.2.attn.attention.q_proj.weight', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.31.mlp.c_fc.bias', 'transformer.h.27.attn.attention.out_proj.bias', 'transformer.h.31.attn.attention.out_proj.bias', 'transformer.wte.weight', 'transformer.h.15.attn.attention.q_proj.weight', 'transformer.h.18.ln_1.weight', 'transformer.h.18.attn.attention.bias', 'transformer.h.28.ln_2.weight', 'transformer.h.0.attn.attention.out_proj.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.21.ln_1.bias', 'transformer.h.28.attn.attention.q_proj.weight', 'transformer.h.14.attn.attention.out_proj.weight', 'transformer.h.14.ln_1.weight', 'transformer.h.30.ln_1.weight', 'transformer.h.11.attn.attention.bias', 'transformer.h.17.ln_1.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.18.attn.attention.v_proj.weight', 'transformer.h.26.attn.attention.v_proj.weight', 'transformer.h.20.mlp.c_fc.bias', 'transformer.h.12.attn.attention.masked_bias', 'transformer.h.23.ln_1.bias', 'transformer.h.29.ln_2.bias', 'transformer.h.16.attn.attention.bias', 'transformer.h.22.ln_1.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2022-11-18 13:27:43,677][datasets.builder][WARNING] - Using custom data configuration ViktorThink--mountain_combined_813306-6918b9ea07482433
[2022-11-18 13:27:43,755][datasets.builder][WARNING] - Found cached dataset csv (/home/paperspace/.cache/huggingface/datasets/ViktorThink___csv/ViktorThink--mountain_combined_813306-6918b9ea07482433/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.66it/s]100%|██████████| 2/2 [00:00<00:00, 10.60it/s]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.68it/s]100%|██████████| 2/2 [00:00<00:00, 10.67it/s]
Running tokenizer on dataset:   0%|          | 1/814 [00:03<46:52,  3.46s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:06<43:11,  3.19s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:09<41:46,  3.09s/ba]Running tokenizer on dataset:   0%|          | 4/814 [00:12<40:30,  3.00s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:15<39:40,  2.94s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:17<38:30,  2.86s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:20<38:03,  2.83s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:23<37:28,  2.79s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:25<36:46,  2.74s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:28<36:10,  2.70s/ba]Running tokenizer on dataset:   1%|▏         | 11/814 [00:31<36:34,  2.73s/ba]Running tokenizer on dataset:   1%|▏         | 12/814 [00:34<36:13,  2.71s/ba]Running tokenizer on dataset:   2%|▏         | 13/814 [00:36<35:58,  2.69s/ba]Running tokenizer on dataset:   2%|▏         | 14/814 [00:39<35:50,  2.69s/ba]Running tokenizer on dataset:   2%|▏         | 15/814 [00:41<35:30,  2.67s/ba]Running tokenizer on dataset:   2%|▏         | 16/814 [00:44<35:12,  2.65s/ba]Running tokenizer on dataset:   2%|▏         | 17/814 [00:47<34:52,  2.62s/ba]Running tokenizer on dataset:   2%|▏         | 18/814 [00:49<34:32,  2.60s/ba]Running tokenizer on dataset:   2%|▏         | 19/814 [00:52<34:21,  2.59s/ba]Running tokenizer on dataset:   2%|▏         | 20/814 [00:54<34:18,  2.59s/ba]Running tokenizer on dataset:   3%|▎         | 21/814 [00:57<34:14,  2.59s/ba]Running tokenizer on dataset:   3%|▎         | 22/814 [00:59<33:52,  2.57s/ba]Running tokenizer on dataset:   3%|▎         | 23/814 [01:02<33:43,  2.56s/ba]Running tokenizer on dataset:   3%|▎         | 24/814 [01:05<33:33,  2.55s/ba]Running tokenizer on dataset:   3%|▎         | 25/814 [01:07<33:31,  2.55s/ba]Running tokenizer on dataset:   3%|▎         | 26/814 [01:10<33:18,  2.54s/ba]Running tokenizer on dataset:   3%|▎         | 27/814 [01:12<32:53,  2.51s/ba]Running tokenizer on dataset:   3%|▎         | 28/814 [01:15<33:01,  2.52s/ba]Running tokenizer on dataset:   4%|▎         | 29/814 [01:17<33:08,  2.53s/ba]Running tokenizer on dataset:   4%|▎         | 30/814 [01:20<33:07,  2.54s/ba]Running tokenizer on dataset:   4%|▍         | 31/814 [01:22<32:49,  2.52s/ba]Running tokenizer on dataset:   4%|▍         | 32/814 [01:25<33:04,  2.54s/ba]Running tokenizer on dataset:   4%|▍         | 33/814 [01:27<32:57,  2.53s/ba]Running tokenizer on dataset:   4%|▍         | 34/814 [01:30<32:36,  2.51s/ba]Running tokenizer on dataset:   4%|▍         | 35/814 [01:32<32:22,  2.49s/ba]Running tokenizer on dataset:   4%|▍         | 36/814 [01:35<32:04,  2.47s/ba]Running tokenizer on dataset:   5%|▍         | 37/814 [01:37<31:52,  2.46s/ba]Running tokenizer on dataset:   5%|▍         | 38/814 [01:39<31:34,  2.44s/ba]Running tokenizer on dataset:   5%|▍         | 39/814 [01:42<31:54,  2.47s/ba]Running tokenizer on dataset:   5%|▍         | 40/814 [01:44<31:56,  2.48s/ba]Running tokenizer on dataset:   5%|▌         | 41/814 [01:47<31:57,  2.48s/ba]Running tokenizer on dataset:   5%|▌         | 42/814 [01:49<31:58,  2.49s/ba]Running tokenizer on dataset:   5%|▌         | 43/814 [01:52<31:47,  2.47s/ba]Running tokenizer on dataset:   5%|▌         | 44/814 [01:54<32:08,  2.50s/ba]Running tokenizer on dataset:   6%|▌         | 45/814 [01:57<31:57,  2.49s/ba]Running tokenizer on dataset:   6%|▌         | 46/814 [01:59<31:37,  2.47s/ba]Running tokenizer on dataset:   6%|▌         | 47/814 [02:02<31:26,  2.46s/ba]Running tokenizer on dataset:   6%|▌         | 48/814 [02:04<31:08,  2.44s/ba]Running tokenizer on dataset:   6%|▌         | 49/814 [02:07<31:10,  2.45s/ba]Running tokenizer on dataset:   6%|▌         | 50/814 [02:09<31:27,  2.47s/ba]Running tokenizer on dataset:   6%|▋         | 51/814 [02:12<31:05,  2.44s/ba]Running tokenizer on dataset:   6%|▋         | 52/814 [02:14<31:12,  2.46s/ba]Running tokenizer on dataset:   7%|▋         | 53/814 [02:16<31:05,  2.45s/ba]Running tokenizer on dataset:   7%|▋         | 54/814 [02:19<31:02,  2.45s/ba]Running tokenizer on dataset:   7%|▋         | 55/814 [02:21<31:00,  2.45s/ba]Running tokenizer on dataset:   7%|▋         | 56/814 [02:24<31:05,  2.46s/ba]Running tokenizer on dataset:   7%|▋         | 57/814 [02:26<31:24,  2.49s/ba]Running tokenizer on dataset:   7%|▋         | 58/814 [02:29<31:05,  2.47s/ba]Running tokenizer on dataset:   7%|▋         | 59/814 [02:31<30:52,  2.45s/ba]Running tokenizer on dataset:   7%|▋         | 60/814 [02:34<30:43,  2.44s/ba]Running tokenizer on dataset:   7%|▋         | 61/814 [02:36<30:39,  2.44s/ba]Running tokenizer on dataset:   8%|▊         | 62/814 [02:39<30:44,  2.45s/ba]Running tokenizer on dataset:   8%|▊         | 63/814 [02:41<30:28,  2.44s/ba]Running tokenizer on dataset:   8%|▊         | 64/814 [02:43<30:17,  2.42s/ba]Running tokenizer on dataset:   8%|▊         | 65/814 [02:46<30:29,  2.44s/ba]Running tokenizer on dataset:   8%|▊         | 66/814 [02:48<30:27,  2.44s/ba]Running tokenizer on dataset:   8%|▊         | 67/814 [02:51<30:07,  2.42s/ba]Running tokenizer on dataset:   8%|▊         | 68/814 [02:53<30:02,  2.42s/ba]Running tokenizer on dataset:   8%|▊         | 69/814 [02:55<29:56,  2.41s/ba]Running tokenizer on dataset:   9%|▊         | 70/814 [02:58<29:48,  2.40s/ba]Running tokenizer on dataset:   9%|▊         | 71/814 [03:00<29:38,  2.39s/ba]Running tokenizer on dataset:   9%|▉         | 72/814 [03:03<32:30,  2.63s/ba]Running tokenizer on dataset:   9%|▉         | 73/814 [03:06<31:52,  2.58s/ba]Running tokenizer on dataset:   9%|▉         | 74/814 [03:08<31:03,  2.52s/ba]Running tokenizer on dataset:   9%|▉         | 75/814 [03:11<30:34,  2.48s/ba]Running tokenizer on dataset:   9%|▉         | 76/814 [03:13<30:58,  2.52s/ba]Running tokenizer on dataset:   9%|▉         | 77/814 [03:16<30:33,  2.49s/ba]Running tokenizer on dataset:  10%|▉         | 78/814 [03:18<30:23,  2.48s/ba]Running tokenizer on dataset:  10%|▉         | 79/814 [03:21<30:02,  2.45s/ba]Running tokenizer on dataset:  10%|▉         | 80/814 [03:23<29:50,  2.44s/ba]Running tokenizer on dataset:  10%|▉         | 81/814 [03:25<29:56,  2.45s/ba]Running tokenizer on dataset:  10%|█         | 82/814 [03:28<29:58,  2.46s/ba]Running tokenizer on dataset:  10%|█         | 83/814 [03:30<29:45,  2.44s/ba]Running tokenizer on dataset:  10%|█         | 84/814 [03:33<29:37,  2.43s/ba]Running tokenizer on dataset:  10%|█         | 85/814 [03:35<29:30,  2.43s/ba]Running tokenizer on dataset:  11%|█         | 86/814 [03:38<29:21,  2.42s/ba]Running tokenizer on dataset:  11%|█         | 87/814 [03:40<29:19,  2.42s/ba]Running tokenizer on dataset:  11%|█         | 88/814 [03:42<29:18,  2.42s/ba]Running tokenizer on dataset:  11%|█         | 89/814 [03:45<29:23,  2.43s/ba]Running tokenizer on dataset:  11%|█         | 90/814 [03:47<29:07,  2.41s/ba]Running tokenizer on dataset:  11%|█         | 91/814 [03:50<29:10,  2.42s/ba]Running tokenizer on dataset:  11%|█▏        | 92/814 [03:52<28:53,  2.40s/ba]Running tokenizer on dataset:  11%|█▏        | 93/814 [03:54<28:58,  2.41s/ba]Running tokenizer on dataset:  12%|█▏        | 94/814 [03:57<28:53,  2.41s/ba]Running tokenizer on dataset:  12%|█▏        | 95/814 [03:59<28:37,  2.39s/ba]Running tokenizer on dataset:  12%|█▏        | 96/814 [04:02<28:58,  2.42s/ba]Running tokenizer on dataset:  12%|█▏        | 97/814 [04:04<28:55,  2.42s/ba]Running tokenizer on dataset:  12%|█▏        | 98/814 [04:06<28:52,  2.42s/ba]Running tokenizer on dataset:  12%|█▏        | 99/814 [04:09<28:56,  2.43s/ba]Running tokenizer on dataset:  12%|█▏        | 100/814 [04:11<29:08,  2.45s/ba]Running tokenizer on dataset:  12%|█▏        | 101/814 [04:14<29:09,  2.45s/ba]Running tokenizer on dataset:  13%|█▎        | 102/814 [04:16<28:54,  2.44s/ba]Running tokenizer on dataset:  13%|█▎        | 103/814 [04:19<28:46,  2.43s/ba]Running tokenizer on dataset:  13%|█▎        | 104/814 [04:21<28:30,  2.41s/ba]Running tokenizer on dataset:  13%|█▎        | 105/814 [04:23<28:23,  2.40s/ba]Running tokenizer on dataset:  13%|█▎        | 106/814 [04:26<28:24,  2.41s/ba]Running tokenizer on dataset:  13%|█▎        | 107/814 [04:28<28:19,  2.40s/ba]Running tokenizer on dataset:  13%|█▎        | 108/814 [04:31<28:36,  2.43s/ba]Running tokenizer on dataset:  13%|█▎        | 109/814 [04:33<28:35,  2.43s/ba]Running tokenizer on dataset:  14%|█▎        | 110/814 [04:36<28:18,  2.41s/ba]Running tokenizer on dataset:  14%|█▎        | 111/814 [04:38<28:15,  2.41s/ba]Running tokenizer on dataset:  14%|█▍        | 112/814 [04:40<28:11,  2.41s/ba]Running tokenizer on dataset:  14%|█▍        | 113/814 [04:43<28:32,  2.44s/ba]Running tokenizer on dataset:  14%|█▍        | 114/814 [04:45<28:28,  2.44s/ba]Running tokenizer on dataset:  14%|█▍        | 115/814 [04:48<28:26,  2.44s/ba]Running tokenizer on dataset:  14%|█▍        | 116/814 [04:50<28:20,  2.44s/ba]Running tokenizer on dataset:  14%|█▍        | 117/814 [04:53<28:12,  2.43s/ba]Running tokenizer on dataset:  14%|█▍        | 118/814 [04:55<28:18,  2.44s/ba]Running tokenizer on dataset:  15%|█▍        | 119/814 [04:57<27:45,  2.40s/ba]Running tokenizer on dataset:  15%|█▍        | 120/814 [05:00<27:30,  2.38s/ba]Running tokenizer on dataset:  15%|█▍        | 121/814 [05:02<27:38,  2.39s/ba]Running tokenizer on dataset:  15%|█▍        | 122/814 [05:04<27:29,  2.38s/ba]Running tokenizer on dataset:  15%|█▌        | 123/814 [05:07<27:22,  2.38s/ba]Running tokenizer on dataset:  15%|█▌        | 124/814 [05:09<27:22,  2.38s/ba]Running tokenizer on dataset:  15%|█▌        | 125/814 [05:12<27:10,  2.37s/ba]Running tokenizer on dataset:  15%|█▌        | 126/814 [05:14<27:19,  2.38s/ba]Running tokenizer on dataset:  16%|█▌        | 127/814 [05:16<27:24,  2.39s/ba]Running tokenizer on dataset:  16%|█▌        | 128/814 [05:19<27:04,  2.37s/ba]Running tokenizer on dataset:  16%|█▌        | 129/814 [05:21<27:10,  2.38s/ba]Running tokenizer on dataset:  16%|█▌        | 130/814 [05:23<26:58,  2.37s/ba]Running tokenizer on dataset:  16%|█▌        | 131/814 [05:26<27:04,  2.38s/ba]Running tokenizer on dataset:  16%|█▌        | 132/814 [05:28<26:54,  2.37s/ba]Running tokenizer on dataset:  16%|█▋        | 133/814 [05:31<26:52,  2.37s/ba]Running tokenizer on dataset:  16%|█▋        | 134/814 [05:33<26:41,  2.36s/ba]Running tokenizer on dataset:  17%|█▋        | 135/814 [05:35<26:40,  2.36s/ba]Running tokenizer on dataset:  17%|█▋        | 136/814 [05:38<26:37,  2.36s/ba]Running tokenizer on dataset:  17%|█▋        | 137/814 [05:40<26:38,  2.36s/ba]Running tokenizer on dataset:  17%|█▋        | 138/814 [05:42<26:36,  2.36s/ba]Running tokenizer on dataset:  17%|█▋        | 139/814 [05:45<26:26,  2.35s/ba]Running tokenizer on dataset:  17%|█▋        | 140/814 [05:47<26:22,  2.35s/ba]Running tokenizer on dataset:  17%|█▋        | 141/814 [05:49<26:22,  2.35s/ba]Running tokenizer on dataset:  17%|█▋        | 142/814 [05:52<26:34,  2.37s/ba]Running tokenizer on dataset:  18%|█▊        | 143/814 [05:54<26:23,  2.36s/ba]Running tokenizer on dataset:  18%|█▊        | 144/814 [05:57<26:24,  2.37s/ba]Running tokenizer on dataset:  18%|█▊        | 145/814 [05:59<26:19,  2.36s/ba]Running tokenizer on dataset:  18%|█▊        | 146/814 [06:01<26:04,  2.34s/ba]Running tokenizer on dataset:  18%|█▊        | 147/814 [06:04<26:16,  2.36s/ba]Running tokenizer on dataset:  18%|█▊        | 148/814 [06:06<26:19,  2.37s/ba]Running tokenizer on dataset:  18%|█▊        | 149/814 [06:08<25:56,  2.34s/ba]Running tokenizer on dataset:  18%|█▊        | 150/814 [06:11<25:51,  2.34s/ba]Running tokenizer on dataset:  19%|█▊        | 151/814 [06:13<25:38,  2.32s/ba]Running tokenizer on dataset:  19%|█▊        | 152/814 [06:15<25:34,  2.32s/ba]Running tokenizer on dataset:  19%|█▉        | 153/814 [06:18<25:47,  2.34s/ba]Running tokenizer on dataset:  19%|█▉        | 154/814 [06:20<25:52,  2.35s/ba]Running tokenizer on dataset:  19%|█▉        | 155/814 [06:22<25:39,  2.34s/ba]Running tokenizer on dataset:  19%|█▉        | 156/814 [06:25<25:40,  2.34s/ba]Running tokenizer on dataset:  19%|█▉        | 157/814 [06:27<26:07,  2.39s/ba]Running tokenizer on dataset:  19%|█▉        | 158/814 [06:29<25:49,  2.36s/ba]Running tokenizer on dataset:  20%|█▉        | 159/814 [06:32<25:39,  2.35s/ba]Running tokenizer on dataset:  20%|█▉        | 160/814 [06:34<25:35,  2.35s/ba]Running tokenizer on dataset:  20%|█▉        | 161/814 [06:36<25:22,  2.33s/ba]Running tokenizer on dataset:  20%|█▉        | 162/814 [06:39<25:25,  2.34s/ba]Running tokenizer on dataset:  20%|██        | 163/814 [06:41<25:19,  2.33s/ba]Running tokenizer on dataset:  20%|██        | 164/814 [06:43<25:25,  2.35s/ba]Running tokenizer on dataset:  20%|██        | 165/814 [06:46<25:30,  2.36s/ba]Running tokenizer on dataset:  20%|██        | 166/814 [06:48<24:30,  2.27s/ba]Running tokenizer on dataset:  21%|██        | 167/814 [06:50<22:46,  2.11s/ba]Running tokenizer on dataset:  21%|██        | 168/814 [06:51<21:33,  2.00s/ba]Running tokenizer on dataset:  21%|██        | 169/814 [06:53<20:46,  1.93s/ba]Running tokenizer on dataset:  21%|██        | 170/814 [06:55<20:05,  1.87s/ba]Running tokenizer on dataset:  21%|██        | 171/814 [06:57<19:39,  1.83s/ba]Running tokenizer on dataset:  21%|██        | 172/814 [06:58<19:25,  1.82s/ba]Running tokenizer on dataset:  21%|██▏       | 173/814 [07:00<19:29,  1.82s/ba]Running tokenizer on dataset:  21%|██▏       | 174/814 [07:02<19:14,  1.80s/ba]Running tokenizer on dataset:  21%|██▏       | 175/814 [07:04<18:58,  1.78s/ba]Running tokenizer on dataset:  22%|██▏       | 176/814 [07:05<18:43,  1.76s/ba]Running tokenizer on dataset:  22%|██▏       | 177/814 [07:07<18:38,  1.76s/ba]Running tokenizer on dataset:  22%|██▏       | 178/814 [07:09<18:39,  1.76s/ba]Running tokenizer on dataset:  22%|██▏       | 179/814 [07:11<18:31,  1.75s/ba]Running tokenizer on dataset:  22%|██▏       | 180/814 [07:12<18:23,  1.74s/ba]Running tokenizer on dataset:  22%|██▏       | 181/814 [07:14<18:23,  1.74s/ba]Running tokenizer on dataset:  22%|██▏       | 182/814 [07:16<18:24,  1.75s/ba]Running tokenizer on dataset:  22%|██▏       | 183/814 [07:18<18:27,  1.76s/ba]Running tokenizer on dataset:  23%|██▎       | 184/814 [07:19<18:35,  1.77s/ba]Running tokenizer on dataset:  23%|██▎       | 185/814 [07:21<18:24,  1.76s/ba]Running tokenizer on dataset:  23%|██▎       | 186/814 [07:23<18:23,  1.76s/ba]Running tokenizer on dataset:  23%|██▎       | 187/814 [07:25<18:15,  1.75s/ba]Running tokenizer on dataset:  23%|██▎       | 188/814 [07:26<18:07,  1.74s/ba]Running tokenizer on dataset:  23%|██▎       | 189/814 [07:28<18:04,  1.74s/ba]Running tokenizer on dataset:  23%|██▎       | 190/814 [07:30<18:01,  1.73s/ba]Running tokenizer on dataset:  23%|██▎       | 191/814 [07:32<18:08,  1.75s/ba]Running tokenizer on dataset:  24%|██▎       | 192/814 [07:33<18:04,  1.74s/ba]Running tokenizer on dataset:  24%|██▎       | 193/814 [07:35<18:07,  1.75s/ba]Running tokenizer on dataset:  24%|██▍       | 194/814 [07:37<17:59,  1.74s/ba]Running tokenizer on dataset:  24%|██▍       | 195/814 [07:39<18:00,  1.75s/ba]Running tokenizer on dataset:  24%|██▍       | 196/814 [07:40<17:53,  1.74s/ba]Running tokenizer on dataset:  24%|██▍       | 197/814 [07:42<17:49,  1.73s/ba]Running tokenizer on dataset:  24%|██▍       | 198/814 [07:44<17:55,  1.75s/ba]Running tokenizer on dataset:  24%|██▍       | 199/814 [07:46<17:48,  1.74s/ba]Running tokenizer on dataset:  25%|██▍       | 200/814 [07:47<17:38,  1.72s/ba]Running tokenizer on dataset:  25%|██▍       | 201/814 [07:49<17:35,  1.72s/ba]Running tokenizer on dataset:  25%|██▍       | 202/814 [07:51<17:36,  1.73s/ba]Running tokenizer on dataset:  25%|██▍       | 203/814 [07:53<19:27,  1.91s/ba]Running tokenizer on dataset:  25%|██▌       | 204/814 [07:55<20:47,  2.04s/ba]Running tokenizer on dataset:  25%|██▌       | 205/814 [07:58<21:22,  2.11s/ba]Running tokenizer on dataset:  25%|██▌       | 206/814 [07:59<20:13,  2.00s/ba]Running tokenizer on dataset:  25%|██▌       | 207/814 [08:01<19:28,  1.92s/ba]Running tokenizer on dataset:  26%|██▌       | 208/814 [08:03<18:49,  1.86s/ba]Running tokenizer on dataset:  26%|██▌       | 209/814 [08:05<18:35,  1.84s/ba]Running tokenizer on dataset:  26%|██▌       | 210/814 [08:06<18:13,  1.81s/ba]Running tokenizer on dataset:  26%|██▌       | 211/814 [08:08<17:53,  1.78s/ba]Running tokenizer on dataset:  26%|██▌       | 212/814 [08:10<17:32,  1.75s/ba]Running tokenizer on dataset:  26%|██▌       | 213/814 [08:11<17:20,  1.73s/ba]Running tokenizer on dataset:  26%|██▋       | 214/814 [08:13<17:08,  1.71s/ba]Running tokenizer on dataset:  26%|██▋       | 215/814 [08:15<17:11,  1.72s/ba]Running tokenizer on dataset:  27%|██▋       | 216/814 [08:17<17:05,  1.72s/ba]Running tokenizer on dataset:  27%|██▋       | 217/814 [08:18<17:08,  1.72s/ba]Running tokenizer on dataset:  27%|██▋       | 218/814 [08:20<17:12,  1.73s/ba]Running tokenizer on dataset:  27%|██▋       | 219/814 [08:22<17:17,  1.74s/ba]Running tokenizer on dataset:  27%|██▋       | 220/814 [08:24<17:07,  1.73s/ba]Running tokenizer on dataset:  27%|██▋       | 221/814 [08:25<17:11,  1.74s/ba]Running tokenizer on dataset:  27%|██▋       | 222/814 [08:27<16:56,  1.72s/ba]Running tokenizer on dataset:  27%|██▋       | 223/814 [08:29<16:55,  1.72s/ba]Running tokenizer on dataset:  28%|██▊       | 224/814 [08:30<16:54,  1.72s/ba]Running tokenizer on dataset:  28%|██▊       | 225/814 [08:32<16:57,  1.73s/ba]Running tokenizer on dataset:  28%|██▊       | 226/814 [08:34<16:52,  1.72s/ba]Running tokenizer on dataset:  28%|██▊       | 227/814 [08:36<16:53,  1.73s/ba]Running tokenizer on dataset:  28%|██▊       | 228/814 [08:37<16:38,  1.70s/ba]Running tokenizer on dataset:  28%|██▊       | 229/814 [08:39<16:43,  1.72s/ba]Running tokenizer on dataset:  28%|██▊       | 230/814 [08:41<16:39,  1.71s/ba]Running tokenizer on dataset:  28%|██▊       | 231/814 [08:42<16:36,  1.71s/ba]Running tokenizer on dataset:  29%|██▊       | 232/814 [08:45<18:08,  1.87s/ba]Running tokenizer on dataset:  29%|██▊       | 233/814 [08:47<19:25,  2.01s/ba]Running tokenizer on dataset:  29%|██▊       | 234/814 [08:49<20:16,  2.10s/ba]Running tokenizer on dataset:  29%|██▉       | 235/814 [08:52<20:50,  2.16s/ba]Running tokenizer on dataset:  29%|██▉       | 236/814 [08:54<21:16,  2.21s/ba]Running tokenizer on dataset:  29%|██▉       | 237/814 [08:56<21:29,  2.23s/ba]Running tokenizer on dataset:  29%|██▉       | 238/814 [08:59<22:11,  2.31s/ba]Running tokenizer on dataset:  29%|██▉       | 239/814 [09:01<22:10,  2.31s/ba]Running tokenizer on dataset:  29%|██▉       | 240/814 [09:03<22:08,  2.31s/ba]Running tokenizer on dataset:  30%|██▉       | 241/814 [09:06<22:02,  2.31s/ba]Running tokenizer on dataset:  30%|██▉       | 242/814 [09:08<21:53,  2.30s/ba]Running tokenizer on dataset:  30%|██▉       | 243/814 [09:10<21:46,  2.29s/ba]Running tokenizer on dataset:  30%|██▉       | 244/814 [09:12<21:54,  2.31s/ba]Running tokenizer on dataset:  30%|███       | 245/814 [09:15<21:50,  2.30s/ba]Running tokenizer on dataset:  30%|███       | 246/814 [09:17<21:47,  2.30s/ba]Running tokenizer on dataset:  30%|███       | 247/814 [09:19<21:47,  2.31s/ba]Running tokenizer on dataset:  30%|███       | 248/814 [09:22<21:34,  2.29s/ba]Running tokenizer on dataset:  31%|███       | 249/814 [09:24<21:47,  2.31s/ba]Running tokenizer on dataset:  31%|███       | 250/814 [09:26<21:48,  2.32s/ba]Running tokenizer on dataset:  31%|███       | 251/814 [09:29<21:46,  2.32s/ba]Running tokenizer on dataset:  31%|███       | 252/814 [09:31<21:42,  2.32s/ba]Running tokenizer on dataset:  31%|███       | 253/814 [09:33<21:47,  2.33s/ba]Running tokenizer on dataset:  31%|███       | 254/814 [09:36<21:42,  2.33s/ba]Running tokenizer on dataset:  31%|███▏      | 255/814 [09:38<21:36,  2.32s/ba]Running tokenizer on dataset:  31%|███▏      | 256/814 [09:40<21:26,  2.30s/ba]Running tokenizer on dataset:  32%|███▏      | 257/814 [09:42<21:13,  2.29s/ba]Running tokenizer on dataset:  32%|███▏      | 258/814 [09:45<21:18,  2.30s/ba]Running tokenizer on dataset:  32%|███▏      | 259/814 [09:47<21:15,  2.30s/ba]Running tokenizer on dataset:  32%|███▏      | 260/814 [09:49<21:15,  2.30s/ba]Running tokenizer on dataset:  32%|███▏      | 261/814 [09:52<21:13,  2.30s/ba]Running tokenizer on dataset:  32%|███▏      | 262/814 [09:54<21:28,  2.34s/ba]Running tokenizer on dataset:  32%|███▏      | 263/814 [09:56<21:25,  2.33s/ba]Running tokenizer on dataset:  32%|███▏      | 264/814 [09:59<21:20,  2.33s/ba]Running tokenizer on dataset:  33%|███▎      | 265/814 [10:01<21:17,  2.33s/ba]Running tokenizer on dataset:  33%|███▎      | 266/814 [10:03<21:16,  2.33s/ba]Running tokenizer on dataset:  33%|███▎      | 267/814 [10:06<21:07,  2.32s/ba]Running tokenizer on dataset:  33%|███▎      | 268/814 [10:08<20:58,  2.31s/ba]Running tokenizer on dataset:  33%|███▎      | 269/814 [10:10<20:53,  2.30s/ba]Running tokenizer on dataset:  33%|███▎      | 270/814 [10:13<20:52,  2.30s/ba]Running tokenizer on dataset:  33%|███▎      | 271/814 [10:15<20:48,  2.30s/ba]Running tokenizer on dataset:  33%|███▎      | 272/814 [10:17<20:45,  2.30s/ba]Running tokenizer on dataset:  34%|███▎      | 273/814 [10:20<20:50,  2.31s/ba]Running tokenizer on dataset:  34%|███▎      | 274/814 [10:22<20:41,  2.30s/ba]Running tokenizer on dataset:  34%|███▍      | 275/814 [10:24<20:34,  2.29s/ba]Running tokenizer on dataset:  34%|███▍      | 276/814 [10:26<20:37,  2.30s/ba]Running tokenizer on dataset:  34%|███▍      | 277/814 [10:29<20:43,  2.32s/ba]Running tokenizer on dataset:  34%|███▍      | 278/814 [10:31<20:43,  2.32s/ba]Running tokenizer on dataset:  34%|███▍      | 279/814 [10:33<20:37,  2.31s/ba]Running tokenizer on dataset:  34%|███▍      | 280/814 [10:36<20:29,  2.30s/ba]Running tokenizer on dataset:  35%|███▍      | 281/814 [10:38<20:30,  2.31s/ba]Running tokenizer on dataset:  35%|███▍      | 282/814 [10:40<20:30,  2.31s/ba]Running tokenizer on dataset:  35%|███▍      | 283/814 [10:43<20:28,  2.31s/ba]Running tokenizer on dataset:  35%|███▍      | 284/814 [10:45<20:22,  2.31s/ba]Running tokenizer on dataset:  35%|███▌      | 285/814 [10:47<20:15,  2.30s/ba]Running tokenizer on dataset:  35%|███▌      | 286/814 [10:49<20:12,  2.30s/ba]Running tokenizer on dataset:  35%|███▌      | 287/814 [10:52<20:15,  2.31s/ba]Running tokenizer on dataset:  35%|███▌      | 288/814 [10:54<20:13,  2.31s/ba]Running tokenizer on dataset:  36%|███▌      | 289/814 [10:56<20:18,  2.32s/ba]Running tokenizer on dataset:  36%|███▌      | 290/814 [10:59<20:14,  2.32s/ba]Running tokenizer on dataset:  36%|███▌      | 291/814 [11:01<20:10,  2.31s/ba]Running tokenizer on dataset:  36%|███▌      | 292/814 [11:03<20:04,  2.31s/ba]Running tokenizer on dataset:  36%|███▌      | 293/814 [11:06<20:00,  2.30s/ba]Running tokenizer on dataset:  36%|███▌      | 294/814 [11:08<19:57,  2.30s/ba]Running tokenizer on dataset:  36%|███▌      | 295/814 [11:10<19:51,  2.30s/ba]Running tokenizer on dataset:  36%|███▋      | 296/814 [11:13<19:51,  2.30s/ba]Running tokenizer on dataset:  36%|███▋      | 297/814 [11:15<19:57,  2.32s/ba]Running tokenizer on dataset:  37%|███▋      | 298/814 [11:17<19:56,  2.32s/ba]Running tokenizer on dataset:  37%|███▋      | 299/814 [11:20<19:49,  2.31s/ba]Running tokenizer on dataset:  37%|███▋      | 300/814 [11:22<19:46,  2.31s/ba]Running tokenizer on dataset:  37%|███▋      | 301/814 [11:24<19:42,  2.30s/ba]Running tokenizer on dataset:  37%|███▋      | 302/814 [11:26<19:25,  2.28s/ba]Running tokenizer on dataset:  37%|███▋      | 303/814 [11:29<19:37,  2.30s/ba]Running tokenizer on dataset:  37%|███▋      | 304/814 [11:31<19:37,  2.31s/ba]Running tokenizer on dataset:  37%|███▋      | 305/814 [11:33<19:34,  2.31s/ba]Running tokenizer on dataset:  38%|███▊      | 306/814 [11:36<19:31,  2.31s/ba]Running tokenizer on dataset:  38%|███▊      | 307/814 [11:38<19:30,  2.31s/ba]Running tokenizer on dataset:  38%|███▊      | 308/814 [11:40<19:20,  2.29s/ba]Running tokenizer on dataset:  38%|███▊      | 309/814 [11:43<19:25,  2.31s/ba]Running tokenizer on dataset:  38%|███▊      | 310/814 [11:45<19:12,  2.29s/ba]Running tokenizer on dataset:  38%|███▊      | 311/814 [11:47<19:13,  2.29s/ba]Running tokenizer on dataset:  38%|███▊      | 312/814 [11:49<19:12,  2.30s/ba]Running tokenizer on dataset:  38%|███▊      | 313/814 [11:52<19:02,  2.28s/ba]Running tokenizer on dataset:  39%|███▊      | 314/814 [11:54<19:05,  2.29s/ba]Running tokenizer on dataset:  39%|███▊      | 315/814 [11:56<19:08,  2.30s/ba]Running tokenizer on dataset:  39%|███▉      | 316/814 [11:59<18:59,  2.29s/ba]Running tokenizer on dataset:  39%|███▉      | 317/814 [12:01<18:55,  2.28s/ba]Running tokenizer on dataset:  39%|███▉      | 318/814 [12:03<19:03,  2.31s/ba]Running tokenizer on dataset:  39%|███▉      | 319/814 [12:06<19:25,  2.35s/ba]Running tokenizer on dataset:  39%|███▉      | 320/814 [12:08<19:01,  2.31s/ba]Running tokenizer on dataset:  39%|███▉      | 321/814 [12:10<18:58,  2.31s/ba]Running tokenizer on dataset:  40%|███▉      | 322/814 [12:12<18:56,  2.31s/ba]Running tokenizer on dataset:  40%|███▉      | 323/814 [12:15<18:54,  2.31s/ba]Running tokenizer on dataset:  40%|███▉      | 324/814 [12:17<18:46,  2.30s/ba]Running tokenizer on dataset:  40%|███▉      | 325/814 [12:19<18:45,  2.30s/ba]Running tokenizer on dataset:  40%|████      | 326/814 [12:22<18:39,  2.29s/ba]Running tokenizer on dataset:  40%|████      | 327/814 [12:24<18:34,  2.29s/ba]Running tokenizer on dataset:  40%|████      | 328/814 [12:26<18:36,  2.30s/ba]Running tokenizer on dataset:  40%|████      | 329/814 [12:29<18:38,  2.31s/ba]Running tokenizer on dataset:  41%|████      | 330/814 [12:31<18:34,  2.30s/ba]Running tokenizer on dataset:  41%|████      | 331/814 [12:33<18:37,  2.31s/ba]Running tokenizer on dataset:  41%|████      | 332/814 [12:35<18:32,  2.31s/ba]Running tokenizer on dataset:  41%|████      | 333/814 [12:38<18:30,  2.31s/ba]Running tokenizer on dataset:  41%|████      | 334/814 [12:40<18:28,  2.31s/ba]Running tokenizer on dataset:  41%|████      | 335/814 [12:42<18:25,  2.31s/ba]Running tokenizer on dataset:  41%|████▏     | 336/814 [12:45<18:26,  2.31s/ba]Running tokenizer on dataset:  41%|████▏     | 337/814 [12:47<18:25,  2.32s/ba]Running tokenizer on dataset:  42%|████▏     | 338/814 [12:49<18:15,  2.30s/ba]Running tokenizer on dataset:  42%|████▏     | 339/814 [12:52<18:08,  2.29s/ba]Running tokenizer on dataset:  42%|████▏     | 340/814 [12:54<18:09,  2.30s/ba]Running tokenizer on dataset:  42%|████▏     | 341/814 [12:56<18:13,  2.31s/ba]Running tokenizer on dataset:  42%|████▏     | 342/814 [12:59<18:03,  2.30s/ba]Running tokenizer on dataset:  42%|████▏     | 343/814 [13:01<18:06,  2.31s/ba]Running tokenizer on dataset:  42%|████▏     | 344/814 [13:03<17:57,  2.29s/ba]Running tokenizer on dataset:  42%|████▏     | 345/814 [13:05<18:02,  2.31s/ba]Running tokenizer on dataset:  43%|████▎     | 346/814 [13:08<18:00,  2.31s/ba]Running tokenizer on dataset:  43%|████▎     | 347/814 [13:10<18:03,  2.32s/ba]Running tokenizer on dataset:  43%|████▎     | 348/814 [13:12<17:55,  2.31s/ba]Running tokenizer on dataset:  43%|████▎     | 349/814 [13:15<17:47,  2.29s/ba]Running tokenizer on dataset:  43%|████▎     | 350/814 [13:17<17:46,  2.30s/ba]Running tokenizer on dataset:  43%|████▎     | 351/814 [13:19<17:36,  2.28s/ba]Running tokenizer on dataset:  43%|████▎     | 352/814 [13:21<17:27,  2.27s/ba]Running tokenizer on dataset:  43%|████▎     | 353/814 [13:24<17:32,  2.28s/ba]Running tokenizer on dataset:  43%|████▎     | 354/814 [13:26<16:51,  2.20s/ba]Running tokenizer on dataset:  44%|████▎     | 355/814 [13:28<16:10,  2.11s/ba]Running tokenizer on dataset:  44%|████▎     | 356/814 [13:29<15:14,  2.00s/ba]Running tokenizer on dataset:  44%|████▍     | 357/814 [13:31<14:33,  1.91s/ba]Running tokenizer on dataset:  44%|████▍     | 358/814 [13:33<14:09,  1.86s/ba]Running tokenizer on dataset:  44%|████▍     | 359/814 [13:35<13:54,  1.83s/ba]Running tokenizer on dataset:  44%|████▍     | 360/814 [13:36<13:38,  1.80s/ba]Running tokenizer on dataset:  44%|████▍     | 361/814 [13:38<13:25,  1.78s/ba]Running tokenizer on dataset:  44%|████▍     | 362/814 [13:40<13:18,  1.77s/ba]Running tokenizer on dataset:  45%|████▍     | 363/814 [13:42<13:10,  1.75s/ba]Running tokenizer on dataset:  45%|████▍     | 364/814 [13:43<13:08,  1.75s/ba]Running tokenizer on dataset:  45%|████▍     | 365/814 [13:45<13:04,  1.75s/ba]Running tokenizer on dataset:  45%|████▍     | 366/814 [13:47<13:11,  1.77s/ba]Running tokenizer on dataset:  45%|████▌     | 367/814 [13:49<13:56,  1.87s/ba]Running tokenizer on dataset:  45%|████▌     | 368/814 [13:51<14:41,  1.98s/ba]Running tokenizer on dataset:  45%|████▌     | 369/814 [13:53<15:22,  2.07s/ba]Running tokenizer on dataset:  45%|████▌     | 370/814 [13:56<15:49,  2.14s/ba]Running tokenizer on dataset:  46%|████▌     | 371/814 [13:58<15:58,  2.16s/ba]Running tokenizer on dataset:  46%|████▌     | 372/814 [14:00<14:56,  2.03s/ba]Running tokenizer on dataset:  46%|████▌     | 373/814 [14:01<14:19,  1.95s/ba]Running tokenizer on dataset:  46%|████▌     | 374/814 [14:03<13:51,  1.89s/ba]Running tokenizer on dataset:  46%|████▌     | 375/814 [14:05<13:38,  1.86s/ba]Running tokenizer on dataset:  46%|████▌     | 376/814 [14:07<13:25,  1.84s/ba]Running tokenizer on dataset:  46%|████▋     | 377/814 [14:09<13:14,  1.82s/ba]Running tokenizer on dataset:  46%|████▋     | 378/814 [14:10<12:59,  1.79s/ba]Running tokenizer on dataset:  47%|████▋     | 379/814 [14:12<12:47,  1.76s/ba]Running tokenizer on dataset:  47%|████▋     | 380/814 [14:14<12:40,  1.75s/ba]Running tokenizer on dataset:  47%|████▋     | 381/814 [14:15<12:33,  1.74s/ba]Running tokenizer on dataset:  47%|████▋     | 382/814 [14:17<12:24,  1.72s/ba]Running tokenizer on dataset:  47%|████▋     | 383/814 [14:19<12:15,  1.71s/ba]Running tokenizer on dataset:  47%|████▋     | 384/814 [14:20<12:13,  1.71s/ba]Running tokenizer on dataset:  47%|████▋     | 385/814 [14:22<12:17,  1.72s/ba]Running tokenizer on dataset:  47%|████▋     | 386/814 [14:24<12:15,  1.72s/ba]Running tokenizer on dataset:  48%|████▊     | 387/814 [14:26<12:16,  1.72s/ba]Running tokenizer on dataset:  48%|████▊     | 388/814 [14:27<12:09,  1.71s/ba]Running tokenizer on dataset:  48%|████▊     | 389/814 [14:29<12:10,  1.72s/ba]Running tokenizer on dataset:  48%|████▊     | 390/814 [14:31<12:07,  1.72s/ba]Running tokenizer on dataset:  48%|████▊     | 391/814 [14:33<12:04,  1.71s/ba]Running tokenizer on dataset:  48%|████▊     | 392/814 [14:34<12:06,  1.72s/ba]Running tokenizer on dataset:  48%|████▊     | 393/814 [14:36<12:05,  1.72s/ba]Running tokenizer on dataset:  48%|████▊     | 394/814 [14:38<12:05,  1.73s/ba]Running tokenizer on dataset:  49%|████▊     | 395/814 [14:39<12:02,  1.72s/ba]Running tokenizer on dataset:  49%|████▊     | 396/814 [14:41<11:59,  1.72s/ba]Running tokenizer on dataset:  49%|████▉     | 397/814 [14:43<11:55,  1.72s/ba]Running tokenizer on dataset:  49%|████▉     | 398/814 [14:45<12:09,  1.75s/ba]Running tokenizer on dataset:  49%|████▉     | 399/814 [14:46<11:59,  1.73s/ba]Running tokenizer on dataset:  49%|████▉     | 400/814 [14:48<12:14,  1.77s/ba]Running tokenizer on dataset:  49%|████▉     | 401/814 [14:50<12:02,  1.75s/ba]Running tokenizer on dataset:  49%|████▉     | 402/814 [14:52<11:59,  1.75s/ba]Running tokenizer on dataset:  50%|████▉     | 403/814 [14:53<11:54,  1.74s/ba]Running tokenizer on dataset:  50%|████▉     | 404/814 [14:55<11:50,  1.73s/ba]Running tokenizer on dataset:  50%|████▉     | 405/814 [14:57<11:52,  1.74s/ba]Running tokenizer on dataset:  50%|████▉     | 406/814 [14:59<11:55,  1.75s/ba]Running tokenizer on dataset:  50%|█████     | 407/814 [15:00<11:53,  1.75s/ba]Running tokenizer on dataset:  50%|█████     | 408/814 [15:02<11:49,  1.75s/ba]Running tokenizer on dataset:  50%|█████     | 409/814 [15:04<11:42,  1.74s/ba]Running tokenizer on dataset:  50%|█████     | 410/814 [15:06<11:34,  1.72s/ba]Running tokenizer on dataset:  50%|█████     | 411/814 [15:07<11:34,  1.72s/ba]Running tokenizer on dataset:  51%|█████     | 412/814 [15:09<11:30,  1.72s/ba]Running tokenizer on dataset:  51%|█████     | 413/814 [15:11<11:29,  1.72s/ba]Running tokenizer on dataset:  51%|█████     | 414/814 [15:12<11:35,  1.74s/ba]Running tokenizer on dataset:  51%|█████     | 415/814 [15:14<11:33,  1.74s/ba]Running tokenizer on dataset:  51%|█████     | 416/814 [15:16<11:32,  1.74s/ba]Running tokenizer on dataset:  51%|█████     | 417/814 [15:18<11:29,  1.74s/ba]Running tokenizer on dataset:  51%|█████▏    | 418/814 [15:19<11:24,  1.73s/ba]Running tokenizer on dataset:  51%|█████▏    | 419/814 [15:21<11:22,  1.73s/ba]Running tokenizer on dataset:  52%|█████▏    | 420/814 [15:23<11:25,  1.74s/ba]Running tokenizer on dataset:  52%|█████▏    | 421/814 [15:25<11:24,  1.74s/ba]Running tokenizer on dataset:  52%|█████▏    | 422/814 [15:26<11:23,  1.74s/ba]Running tokenizer on dataset:  52%|█████▏    | 423/814 [15:28<11:16,  1.73s/ba]Running tokenizer on dataset:  52%|█████▏    | 424/814 [15:30<11:10,  1.72s/ba]Running tokenizer on dataset:  52%|█████▏    | 425/814 [15:32<11:08,  1.72s/ba]Running tokenizer on dataset:  52%|█████▏    | 426/814 [15:33<11:10,  1.73s/ba]Running tokenizer on dataset:  52%|█████▏    | 427/814 [15:35<11:05,  1.72s/ba]Running tokenizer on dataset:  53%|█████▎    | 428/814 [15:37<11:05,  1.72s/ba]Running tokenizer on dataset:  53%|█████▎    | 429/814 [15:38<11:04,  1.73s/ba]Running tokenizer on dataset:  53%|█████▎    | 430/814 [15:41<12:09,  1.90s/ba]Running tokenizer on dataset:  53%|█████▎    | 431/814 [15:43<12:51,  2.02s/ba]Running tokenizer on dataset:  53%|█████▎    | 432/814 [15:45<13:19,  2.09s/ba]Running tokenizer on dataset:  53%|█████▎    | 433/814 [15:48<13:45,  2.17s/ba]Running tokenizer on dataset:  53%|█████▎    | 434/814 [15:50<13:54,  2.20s/ba]Running tokenizer on dataset:  53%|█████▎    | 435/814 [15:52<13:52,  2.20s/ba]Running tokenizer on dataset:  54%|█████▎    | 436/814 [15:54<13:07,  2.08s/ba]Running tokenizer on dataset:  54%|█████▎    | 437/814 [15:56<13:24,  2.13s/ba]Running tokenizer on dataset:  54%|█████▍    | 438/814 [15:58<13:38,  2.18s/ba]Running tokenizer on dataset:  54%|█████▍    | 439/814 [16:01<13:49,  2.21s/ba]Running tokenizer on dataset:  54%|█████▍    | 440/814 [16:03<14:03,  2.26s/ba]Running tokenizer on dataset:  54%|█████▍    | 441/814 [16:05<14:04,  2.26s/ba]Running tokenizer on dataset:  54%|█████▍    | 442/814 [16:08<14:05,  2.27s/ba]Running tokenizer on dataset:  54%|█████▍    | 443/814 [16:10<13:57,  2.26s/ba]Running tokenizer on dataset:  55%|█████▍    | 444/814 [16:12<13:56,  2.26s/ba]Running tokenizer on dataset:  55%|█████▍    | 445/814 [16:14<13:54,  2.26s/ba]Running tokenizer on dataset:  55%|█████▍    | 446/814 [16:17<13:59,  2.28s/ba]Running tokenizer on dataset:  55%|█████▍    | 447/814 [16:19<13:57,  2.28s/ba]Running tokenizer on dataset:  55%|█████▌    | 448/814 [16:21<13:57,  2.29s/ba]Running tokenizer on dataset:  55%|█████▌    | 449/814 [16:24<13:53,  2.28s/ba]Running tokenizer on dataset:  55%|█████▌    | 450/814 [16:26<13:52,  2.29s/ba]Running tokenizer on dataset:  55%|█████▌    | 451/814 [16:28<13:47,  2.28s/ba]Running tokenizer on dataset:  56%|█████▌    | 452/814 [16:30<13:48,  2.29s/ba]Running tokenizer on dataset:  56%|█████▌    | 453/814 [16:33<13:47,  2.29s/ba]Running tokenizer on dataset:  56%|█████▌    | 454/814 [16:35<13:46,  2.30s/ba]Running tokenizer on dataset:  56%|█████▌    | 455/814 [16:37<13:43,  2.29s/ba]Running tokenizer on dataset:  56%|█████▌    | 456/814 [16:40<13:40,  2.29s/ba]Running tokenizer on dataset:  56%|█████▌    | 457/814 [16:42<13:35,  2.28s/ba]Running tokenizer on dataset:  56%|█████▋    | 458/814 [16:44<13:26,  2.27s/ba]Running tokenizer on dataset:  56%|█████▋    | 459/814 [16:46<13:26,  2.27s/ba]Running tokenizer on dataset:  57%|█████▋    | 460/814 [16:49<13:23,  2.27s/ba]Running tokenizer on dataset:  57%|█████▋    | 461/814 [16:51<13:29,  2.29s/ba]Running tokenizer on dataset:  57%|█████▋    | 462/814 [16:53<13:25,  2.29s/ba]Running tokenizer on dataset:  57%|█████▋    | 463/814 [16:56<13:34,  2.32s/ba]Running tokenizer on dataset:  57%|█████▋    | 464/814 [16:58<13:27,  2.31s/ba]Running tokenizer on dataset:  57%|█████▋    | 465/814 [17:00<13:27,  2.31s/ba]Running tokenizer on dataset:  57%|█████▋    | 466/814 [17:03<13:22,  2.30s/ba]Running tokenizer on dataset:  57%|█████▋    | 467/814 [17:05<13:21,  2.31s/ba]Running tokenizer on dataset:  57%|█████▋    | 468/814 [17:07<13:16,  2.30s/ba]Running tokenizer on dataset:  58%|█████▊    | 469/814 [17:09<13:07,  2.28s/ba]Running tokenizer on dataset:  58%|█████▊    | 470/814 [17:12<13:04,  2.28s/ba]Running tokenizer on dataset:  58%|█████▊    | 471/814 [17:14<13:05,  2.29s/ba]Running tokenizer on dataset:  58%|█████▊    | 472/814 [17:16<13:03,  2.29s/ba]Running tokenizer on dataset:  58%|█████▊    | 473/814 [17:19<12:58,  2.28s/ba]Running tokenizer on dataset:  58%|█████▊    | 474/814 [17:21<12:54,  2.28s/ba]Running tokenizer on dataset:  58%|█████▊    | 475/814 [17:23<12:50,  2.27s/ba]Running tokenizer on dataset:  58%|█████▊    | 476/814 [17:25<12:48,  2.27s/ba]Running tokenizer on dataset:  59%|█████▊    | 477/814 [17:28<12:47,  2.28s/ba]Running tokenizer on dataset:  59%|█████▊    | 478/814 [17:30<12:46,  2.28s/ba]Running tokenizer on dataset:  59%|█████▉    | 479/814 [17:32<12:43,  2.28s/ba]Running tokenizer on dataset:  59%|█████▉    | 480/814 [17:35<12:42,  2.28s/ba]Running tokenizer on dataset:  59%|█████▉    | 481/814 [17:37<13:00,  2.34s/ba]Running tokenizer on dataset:  59%|█████▉    | 482/814 [17:39<12:55,  2.34s/ba]Running tokenizer on dataset:  59%|█████▉    | 483/814 [17:42<12:50,  2.33s/ba]Running tokenizer on dataset:  59%|█████▉    | 484/814 [17:44<12:49,  2.33s/ba]Running tokenizer on dataset:  60%|█████▉    | 485/814 [17:46<12:35,  2.30s/ba]Running tokenizer on dataset:  60%|█████▉    | 486/814 [17:48<12:26,  2.28s/ba]Running tokenizer on dataset:  60%|█████▉    | 487/814 [17:51<12:24,  2.28s/ba]Running tokenizer on dataset:  60%|█████▉    | 488/814 [17:53<12:24,  2.28s/ba]Running tokenizer on dataset:  60%|██████    | 489/814 [17:55<12:21,  2.28s/ba]Running tokenizer on dataset:  60%|██████    | 490/814 [17:58<12:23,  2.29s/ba]Running tokenizer on dataset:  60%|██████    | 491/814 [18:00<12:19,  2.29s/ba]Running tokenizer on dataset:  60%|██████    | 492/814 [18:02<12:12,  2.27s/ba]Running tokenizer on dataset:  61%|██████    | 493/814 [18:04<12:11,  2.28s/ba]Running tokenizer on dataset:  61%|██████    | 494/814 [18:07<12:09,  2.28s/ba]Running tokenizer on dataset:  61%|██████    | 495/814 [18:09<12:10,  2.29s/ba]Running tokenizer on dataset:  61%|██████    | 496/814 [18:11<12:05,  2.28s/ba]Running tokenizer on dataset:  61%|██████    | 497/814 [18:14<12:00,  2.27s/ba]Running tokenizer on dataset:  61%|██████    | 498/814 [18:16<11:54,  2.26s/ba]Running tokenizer on dataset:  61%|██████▏   | 499/814 [18:18<11:51,  2.26s/ba]Running tokenizer on dataset:  61%|██████▏   | 500/814 [18:20<11:52,  2.27s/ba]Running tokenizer on dataset:  62%|██████▏   | 501/814 [18:23<11:53,  2.28s/ba]Running tokenizer on dataset:  62%|██████▏   | 502/814 [18:25<11:51,  2.28s/ba]Running tokenizer on dataset:  62%|██████▏   | 503/814 [18:27<11:46,  2.27s/ba]Running tokenizer on dataset:  62%|██████▏   | 504/814 [18:29<11:47,  2.28s/ba]Running tokenizer on dataset:  62%|██████▏   | 505/814 [18:32<11:47,  2.29s/ba]Running tokenizer on dataset:  62%|██████▏   | 506/814 [18:34<11:40,  2.27s/ba]Running tokenizer on dataset:  62%|██████▏   | 507/814 [18:36<11:36,  2.27s/ba]Running tokenizer on dataset:  62%|██████▏   | 508/814 [18:39<11:32,  2.26s/ba]Running tokenizer on dataset:  63%|██████▎   | 509/814 [18:41<11:37,  2.29s/ba]Running tokenizer on dataset:  63%|██████▎   | 510/814 [18:43<11:33,  2.28s/ba]Running tokenizer on dataset:  63%|██████▎   | 511/814 [18:45<11:29,  2.28s/ba]Running tokenizer on dataset:  63%|██████▎   | 512/814 [18:48<11:27,  2.28s/ba]Running tokenizer on dataset:  63%|██████▎   | 513/814 [18:50<11:30,  2.29s/ba]Running tokenizer on dataset:  63%|██████▎   | 514/814 [18:52<11:24,  2.28s/ba]Running tokenizer on dataset:  63%|██████▎   | 515/814 [18:55<11:24,  2.29s/ba]Running tokenizer on dataset:  63%|██████▎   | 516/814 [18:57<11:23,  2.30s/ba]Running tokenizer on dataset:  64%|██████▎   | 517/814 [18:59<11:24,  2.30s/ba]Running tokenizer on dataset:  64%|██████▎   | 518/814 [19:01<11:21,  2.30s/ba]Running tokenizer on dataset:  64%|██████▍   | 519/814 [19:04<11:15,  2.29s/ba]Running tokenizer on dataset:  64%|██████▍   | 520/814 [19:06<11:15,  2.30s/ba]Running tokenizer on dataset:  64%|██████▍   | 521/814 [19:08<11:06,  2.27s/ba]Running tokenizer on dataset:  64%|██████▍   | 522/814 [19:11<11:06,  2.28s/ba]Running tokenizer on dataset:  64%|██████▍   | 523/814 [19:13<11:01,  2.27s/ba]Running tokenizer on dataset:  64%|██████▍   | 524/814 [19:15<10:59,  2.27s/ba]Running tokenizer on dataset:  64%|██████▍   | 525/814 [19:17<10:52,  2.26s/ba]Running tokenizer on dataset:  65%|██████▍   | 526/814 [19:20<10:52,  2.27s/ba]Running tokenizer on dataset:  65%|██████▍   | 527/814 [19:22<10:54,  2.28s/ba]Running tokenizer on dataset:  65%|██████▍   | 528/814 [19:24<10:52,  2.28s/ba]Running tokenizer on dataset:  65%|██████▍   | 529/814 [19:26<10:48,  2.28s/ba]Running tokenizer on dataset:  65%|██████▌   | 530/814 [19:29<10:50,  2.29s/ba]Running tokenizer on dataset:  65%|██████▌   | 531/814 [19:31<10:47,  2.29s/ba]Running tokenizer on dataset:  65%|██████▌   | 532/814 [19:33<10:51,  2.31s/ba]Running tokenizer on dataset:  65%|██████▌   | 533/814 [19:36<10:42,  2.29s/ba]Running tokenizer on dataset:  66%|██████▌   | 534/814 [19:38<10:36,  2.27s/ba]Running tokenizer on dataset:  66%|██████▌   | 535/814 [19:40<10:38,  2.29s/ba]Running tokenizer on dataset:  66%|██████▌   | 536/814 [19:42<10:33,  2.28s/ba]Running tokenizer on dataset:  66%|██████▌   | 537/814 [19:45<10:32,  2.28s/ba]Running tokenizer on dataset:  66%|██████▌   | 538/814 [19:47<10:35,  2.30s/ba]Running tokenizer on dataset:  66%|██████▌   | 539/814 [19:49<10:34,  2.31s/ba]Running tokenizer on dataset:  66%|██████▋   | 540/814 [19:52<10:30,  2.30s/ba]Running tokenizer on dataset:  66%|██████▋   | 541/814 [19:54<10:23,  2.29s/ba]Running tokenizer on dataset:  67%|██████▋   | 542/814 [19:56<10:20,  2.28s/ba]Running tokenizer on dataset:  67%|██████▋   | 543/814 [19:59<10:15,  2.27s/ba]Running tokenizer on dataset:  67%|██████▋   | 544/814 [20:01<10:13,  2.27s/ba]Running tokenizer on dataset:  67%|██████▋   | 545/814 [20:03<10:16,  2.29s/ba]Running tokenizer on dataset:  67%|██████▋   | 546/814 [20:05<10:10,  2.28s/ba]Running tokenizer on dataset:  67%|██████▋   | 547/814 [20:08<10:07,  2.28s/ba]Running tokenizer on dataset:  67%|██████▋   | 548/814 [20:10<10:02,  2.26s/ba]Running tokenizer on dataset:  67%|██████▋   | 549/814 [20:12<10:07,  2.29s/ba]Running tokenizer on dataset:  68%|██████▊   | 550/814 [20:14<10:02,  2.28s/ba]Running tokenizer on dataset:  68%|██████▊   | 551/814 [20:17<09:59,  2.28s/ba]Running tokenizer on dataset:  68%|██████▊   | 552/814 [20:19<09:23,  2.15s/ba]Running tokenizer on dataset:  68%|██████▊   | 553/814 [20:20<08:40,  1.99s/ba]Running tokenizer on dataset:  68%|██████▊   | 554/814 [20:22<08:11,  1.89s/ba]Running tokenizer on dataset:  68%|██████▊   | 555/814 [20:24<07:55,  1.84s/ba]Running tokenizer on dataset:  68%|██████▊   | 556/814 [20:25<07:54,  1.84s/ba]Running tokenizer on dataset:  68%|██████▊   | 557/814 [20:27<07:40,  1.79s/ba]Running tokenizer on dataset:  69%|██████▊   | 558/814 [20:29<07:32,  1.77s/ba]Running tokenizer on dataset:  69%|██████▊   | 559/814 [20:31<07:25,  1.75s/ba]Running tokenizer on dataset:  69%|██████▉   | 560/814 [20:32<07:20,  1.73s/ba]Running tokenizer on dataset:  69%|██████▉   | 561/814 [20:34<07:16,  1.72s/ba]Running tokenizer on dataset:  69%|██████▉   | 562/814 [20:36<07:21,  1.75s/ba]Running tokenizer on dataset:  69%|██████▉   | 563/814 [20:37<07:18,  1.75s/ba]Running tokenizer on dataset:  69%|██████▉   | 564/814 [20:39<07:12,  1.73s/ba]Running tokenizer on dataset:  69%|██████▉   | 565/814 [20:41<07:10,  1.73s/ba]Running tokenizer on dataset:  70%|██████▉   | 566/814 [20:43<07:07,  1.72s/ba]Running tokenizer on dataset:  70%|██████▉   | 567/814 [20:44<07:04,  1.72s/ba]Running tokenizer on dataset:  70%|██████▉   | 568/814 [20:46<06:59,  1.71s/ba]Running tokenizer on dataset:  70%|██████▉   | 569/814 [20:48<06:59,  1.71s/ba]Running tokenizer on dataset:  70%|███████   | 570/814 [20:50<07:03,  1.74s/ba]Running tokenizer on dataset:  70%|███████   | 571/814 [20:51<06:58,  1.72s/ba]Running tokenizer on dataset:  70%|███████   | 572/814 [20:53<06:55,  1.72s/ba]Running tokenizer on dataset:  70%|███████   | 573/814 [20:55<06:53,  1.72s/ba]Running tokenizer on dataset:  71%|███████   | 574/814 [20:56<06:45,  1.69s/ba]Running tokenizer on dataset:  71%|███████   | 575/814 [20:58<06:45,  1.69s/ba]Running tokenizer on dataset:  71%|███████   | 576/814 [21:00<06:44,  1.70s/ba]Running tokenizer on dataset:  71%|███████   | 577/814 [21:01<06:43,  1.70s/ba]Running tokenizer on dataset:  71%|███████   | 578/814 [21:03<07:00,  1.78s/ba]Running tokenizer on dataset:  71%|███████   | 579/814 [21:06<07:31,  1.92s/ba]Running tokenizer on dataset:  71%|███████▏  | 580/814 [21:08<07:54,  2.03s/ba]Running tokenizer on dataset:  71%|███████▏  | 581/814 [21:10<08:11,  2.11s/ba]Running tokenizer on dataset:  71%|███████▏  | 582/814 [21:12<08:16,  2.14s/ba]Running tokenizer on dataset:  72%|███████▏  | 583/814 [21:15<08:21,  2.17s/ba]Running tokenizer on dataset:  72%|███████▏  | 584/814 [21:17<08:22,  2.19s/ba]Running tokenizer on dataset:  72%|███████▏  | 585/814 [21:19<08:31,  2.24s/ba]Running tokenizer on dataset:  72%|███████▏  | 586/814 [21:21<08:31,  2.24s/ba]Running tokenizer on dataset:  72%|███████▏  | 587/814 [21:24<08:33,  2.26s/ba]Running tokenizer on dataset:  72%|███████▏  | 588/814 [21:26<08:29,  2.26s/ba]Running tokenizer on dataset:  72%|███████▏  | 589/814 [21:28<08:30,  2.27s/ba]Running tokenizer on dataset:  72%|███████▏  | 590/814 [21:31<08:28,  2.27s/ba]Running tokenizer on dataset:  73%|███████▎  | 591/814 [21:33<08:26,  2.27s/ba]Running tokenizer on dataset:  73%|███████▎  | 592/814 [21:35<08:22,  2.26s/ba]Running tokenizer on dataset:  73%|███████▎  | 593/814 [21:37<08:20,  2.27s/ba]Running tokenizer on dataset:  73%|███████▎  | 594/814 [21:40<08:18,  2.27s/ba]Running tokenizer on dataset:  73%|███████▎  | 595/814 [21:42<08:15,  2.26s/ba]Running tokenizer on dataset:  73%|███████▎  | 596/814 [21:44<08:11,  2.25s/ba]Running tokenizer on dataset:  73%|███████▎  | 597/814 [21:46<08:08,  2.25s/ba]Running tokenizer on dataset:  73%|███████▎  | 598/814 [21:49<08:07,  2.26s/ba]Running tokenizer on dataset:  74%|███████▎  | 599/814 [21:51<08:04,  2.25s/ba]Running tokenizer on dataset:  74%|███████▎  | 600/814 [21:53<08:04,  2.26s/ba]Running tokenizer on dataset:  74%|███████▍  | 601/814 [21:55<08:03,  2.27s/ba]Running tokenizer on dataset:  74%|███████▍  | 602/814 [21:58<08:01,  2.27s/ba]Running tokenizer on dataset:  74%|███████▍  | 603/814 [22:00<07:56,  2.26s/ba]Running tokenizer on dataset:  74%|███████▍  | 604/814 [22:02<07:54,  2.26s/ba]Running tokenizer on dataset:  74%|███████▍  | 605/814 [22:05<07:54,  2.27s/ba]Running tokenizer on dataset:  74%|███████▍  | 606/814 [22:07<07:51,  2.27s/ba]Running tokenizer on dataset:  75%|███████▍  | 607/814 [22:09<07:48,  2.26s/ba]Running tokenizer on dataset:  75%|███████▍  | 608/814 [22:11<07:44,  2.26s/ba]Running tokenizer on dataset:  75%|███████▍  | 609/814 [22:14<07:47,  2.28s/ba]Running tokenizer on dataset:  75%|███████▍  | 610/814 [22:16<07:42,  2.27s/ba]Running tokenizer on dataset:  75%|███████▌  | 611/814 [22:18<07:40,  2.27s/ba]Running tokenizer on dataset:  75%|███████▌  | 612/814 [22:20<07:37,  2.27s/ba]Running tokenizer on dataset:  75%|███████▌  | 613/814 [22:23<07:37,  2.28s/ba]Running tokenizer on dataset:  75%|███████▌  | 614/814 [22:25<07:34,  2.27s/ba]Running tokenizer on dataset:  76%|███████▌  | 615/814 [22:27<07:32,  2.27s/ba]Running tokenizer on dataset:  76%|███████▌  | 616/814 [22:29<07:29,  2.27s/ba]Running tokenizer on dataset:  76%|███████▌  | 617/814 [22:32<07:26,  2.27s/ba]Running tokenizer on dataset:  76%|███████▌  | 618/814 [22:34<07:22,  2.26s/ba]Running tokenizer on dataset:  76%|███████▌  | 619/814 [22:36<07:18,  2.25s/ba]Running tokenizer on dataset:  76%|███████▌  | 620/814 [22:38<07:16,  2.25s/ba]Running tokenizer on dataset:  76%|███████▋  | 621/814 [22:41<07:15,  2.25s/ba]Running tokenizer on dataset:  76%|███████▋  | 622/814 [22:43<07:14,  2.26s/ba]Running tokenizer on dataset:  77%|███████▋  | 623/814 [22:45<07:11,  2.26s/ba]Running tokenizer on dataset:  77%|███████▋  | 624/814 [22:48<07:09,  2.26s/ba]Running tokenizer on dataset:  77%|███████▋  | 625/814 [22:50<07:08,  2.27s/ba]Running tokenizer on dataset:  77%|███████▋  | 626/814 [22:52<07:08,  2.28s/ba]Running tokenizer on dataset:  77%|███████▋  | 627/814 [22:54<07:05,  2.28s/ba]Running tokenizer on dataset:  77%|███████▋  | 628/814 [22:57<07:05,  2.29s/ba]Running tokenizer on dataset:  77%|███████▋  | 629/814 [22:59<07:02,  2.28s/ba]Running tokenizer on dataset:  77%|███████▋  | 630/814 [23:01<06:59,  2.28s/ba]Running tokenizer on dataset:  78%|███████▊  | 631/814 [23:04<06:55,  2.27s/ba]Running tokenizer on dataset:  78%|███████▊  | 632/814 [23:06<06:54,  2.28s/ba]Running tokenizer on dataset:  78%|███████▊  | 633/814 [23:08<06:52,  2.28s/ba]Running tokenizer on dataset:  78%|███████▊  | 634/814 [23:10<06:47,  2.26s/ba]Running tokenizer on dataset:  78%|███████▊  | 635/814 [23:12<06:40,  2.24s/ba]Running tokenizer on dataset:  78%|███████▊  | 636/814 [23:15<06:40,  2.25s/ba]Running tokenizer on dataset:  78%|███████▊  | 637/814 [23:17<06:42,  2.28s/ba]Running tokenizer on dataset:  78%|███████▊  | 638/814 [23:19<06:40,  2.28s/ba]Running tokenizer on dataset:  79%|███████▊  | 639/814 [23:22<06:40,  2.29s/ba]Running tokenizer on dataset:  79%|███████▊  | 640/814 [23:24<06:37,  2.28s/ba]Running tokenizer on dataset:  79%|███████▊  | 641/814 [23:26<06:32,  2.27s/ba]Running tokenizer on dataset:  79%|███████▉  | 642/814 [23:29<06:32,  2.28s/ba]Running tokenizer on dataset:  79%|███████▉  | 643/814 [23:31<06:37,  2.33s/ba]Running tokenizer on dataset:  79%|███████▉  | 644/814 [23:33<06:33,  2.32s/ba]Running tokenizer on dataset:  79%|███████▉  | 645/814 [23:36<06:30,  2.31s/ba]Running tokenizer on dataset:  79%|███████▉  | 646/814 [23:38<06:27,  2.31s/ba]Running tokenizer on dataset:  79%|███████▉  | 647/814 [23:40<06:22,  2.29s/ba]Running tokenizer on dataset:  80%|███████▉  | 648/814 [23:42<06:18,  2.28s/ba]Running tokenizer on dataset:  80%|███████▉  | 649/814 [23:45<06:16,  2.28s/ba]Running tokenizer on dataset:  80%|███████▉  | 650/814 [23:47<06:14,  2.29s/ba]Running tokenizer on dataset:  80%|███████▉  | 651/814 [23:49<06:14,  2.30s/ba]Running tokenizer on dataset:  80%|████████  | 652/814 [23:52<06:14,  2.31s/ba]Running tokenizer on dataset:  80%|████████  | 653/814 [23:54<06:11,  2.31s/ba]Running tokenizer on dataset:  80%|████████  | 654/814 [23:56<06:06,  2.29s/ba]Running tokenizer on dataset:  80%|████████  | 655/814 [23:58<06:03,  2.29s/ba]Running tokenizer on dataset:  81%|████████  | 656/814 [24:01<06:01,  2.29s/ba]Running tokenizer on dataset:  81%|████████  | 657/814 [24:03<06:00,  2.29s/ba]Running tokenizer on dataset:  81%|████████  | 658/814 [24:05<05:54,  2.27s/ba]Running tokenizer on dataset:  81%|████████  | 659/814 [24:07<05:50,  2.26s/ba]Running tokenizer on dataset:  81%|████████  | 660/814 [24:10<05:49,  2.27s/ba]Running tokenizer on dataset:  81%|████████  | 661/814 [24:12<05:45,  2.26s/ba]Running tokenizer on dataset:  81%|████████▏ | 662/814 [24:14<05:43,  2.26s/ba]Running tokenizer on dataset:  81%|████████▏ | 663/814 [24:17<05:46,  2.30s/ba]Running tokenizer on dataset:  82%|████████▏ | 664/814 [24:19<05:40,  2.27s/ba]Running tokenizer on dataset:  82%|████████▏ | 665/814 [24:21<05:37,  2.26s/ba]Running tokenizer on dataset:  82%|████████▏ | 666/814 [24:23<05:33,  2.25s/ba]Running tokenizer on dataset:  82%|████████▏ | 667/814 [24:26<05:31,  2.26s/ba]Running tokenizer on dataset:  82%|████████▏ | 668/814 [24:28<05:29,  2.26s/ba]Running tokenizer on dataset:  82%|████████▏ | 669/814 [24:30<05:33,  2.30s/ba]Running tokenizer on dataset:  82%|████████▏ | 670/814 [24:32<05:28,  2.28s/ba]Running tokenizer on dataset:  82%|████████▏ | 671/814 [24:35<05:26,  2.29s/ba]Running tokenizer on dataset:  83%|████████▎ | 672/814 [24:37<05:24,  2.28s/ba]Running tokenizer on dataset:  83%|████████▎ | 673/814 [24:40<05:34,  2.37s/ba]Running tokenizer on dataset:  83%|████████▎ | 674/814 [24:42<05:27,  2.34s/ba]Running tokenizer on dataset:  83%|████████▎ | 675/814 [24:44<05:23,  2.32s/ba]Running tokenizer on dataset:  83%|████████▎ | 676/814 [24:46<05:16,  2.30s/ba]Running tokenizer on dataset:  83%|████████▎ | 677/814 [24:49<05:13,  2.29s/ba]Running tokenizer on dataset:  83%|████████▎ | 678/814 [24:51<05:11,  2.29s/ba]Running tokenizer on dataset:  83%|████████▎ | 679/814 [24:53<05:06,  2.27s/ba]Running tokenizer on dataset:  84%|████████▎ | 680/814 [24:55<05:04,  2.27s/ba]Running tokenizer on dataset:  84%|████████▎ | 681/814 [24:58<05:02,  2.27s/ba]Running tokenizer on dataset:  84%|████████▍ | 682/814 [25:00<04:57,  2.25s/ba]Running tokenizer on dataset:  84%|████████▍ | 683/814 [25:02<04:54,  2.25s/ba]Running tokenizer on dataset:  84%|████████▍ | 684/814 [25:04<04:52,  2.25s/ba]Running tokenizer on dataset:  84%|████████▍ | 685/814 [25:07<04:51,  2.26s/ba]Running tokenizer on dataset:  84%|████████▍ | 686/814 [25:09<04:49,  2.26s/ba]Running tokenizer on dataset:  84%|████████▍ | 687/814 [25:11<04:47,  2.26s/ba]Running tokenizer on dataset:  85%|████████▍ | 688/814 [25:13<04:43,  2.25s/ba]Running tokenizer on dataset:  85%|████████▍ | 689/814 [25:16<04:39,  2.24s/ba]Running tokenizer on dataset:  85%|████████▍ | 690/814 [25:18<04:38,  2.25s/ba]Running tokenizer on dataset:  85%|████████▍ | 691/814 [25:20<04:38,  2.26s/ba]Running tokenizer on dataset:  85%|████████▌ | 692/814 [25:23<04:36,  2.27s/ba]Running tokenizer on dataset:  85%|████████▌ | 693/814 [25:25<04:33,  2.26s/ba]Running tokenizer on dataset:  85%|████████▌ | 694/814 [25:27<04:29,  2.25s/ba]Running tokenizer on dataset:  85%|████████▌ | 695/814 [25:29<04:27,  2.25s/ba]Running tokenizer on dataset:  86%|████████▌ | 696/814 [25:32<04:25,  2.25s/ba]Running tokenizer on dataset:  86%|████████▌ | 697/814 [25:34<04:23,  2.25s/ba]Running tokenizer on dataset:  86%|████████▌ | 698/814 [25:36<04:21,  2.26s/ba]Running tokenizer on dataset:  86%|████████▌ | 699/814 [25:38<04:17,  2.24s/ba]Running tokenizer on dataset:  86%|████████▌ | 700/814 [25:40<04:15,  2.24s/ba]Running tokenizer on dataset:  86%|████████▌ | 701/814 [25:43<04:14,  2.25s/ba]Running tokenizer on dataset:  86%|████████▌ | 702/814 [25:45<04:12,  2.25s/ba]Running tokenizer on dataset:  86%|████████▋ | 703/814 [25:47<04:10,  2.26s/ba]Running tokenizer on dataset:  86%|████████▋ | 704/814 [25:50<04:08,  2.26s/ba]Running tokenizer on dataset:  87%|████████▋ | 705/814 [25:52<04:06,  2.26s/ba]Running tokenizer on dataset:  87%|████████▋ | 706/814 [25:54<04:03,  2.26s/ba]Running tokenizer on dataset:  87%|████████▋ | 707/814 [25:56<04:02,  2.27s/ba]Running tokenizer on dataset:  87%|████████▋ | 708/814 [25:59<04:00,  2.27s/ba]Running tokenizer on dataset:  87%|████████▋ | 709/814 [26:01<03:58,  2.27s/ba]Running tokenizer on dataset:  87%|████████▋ | 710/814 [26:03<03:54,  2.25s/ba]Running tokenizer on dataset:  87%|████████▋ | 711/814 [26:05<03:52,  2.25s/ba]Running tokenizer on dataset:  87%|████████▋ | 712/814 [26:08<03:50,  2.26s/ba]Running tokenizer on dataset:  88%|████████▊ | 713/814 [26:10<03:48,  2.26s/ba]Running tokenizer on dataset:  88%|████████▊ | 714/814 [26:12<03:46,  2.26s/ba]Running tokenizer on dataset:  88%|████████▊ | 715/814 [26:14<03:42,  2.25s/ba]Running tokenizer on dataset:  88%|████████▊ | 716/814 [26:17<03:39,  2.24s/ba]Running tokenizer on dataset:  88%|████████▊ | 717/814 [26:19<03:38,  2.25s/ba]Running tokenizer on dataset:  88%|████████▊ | 718/814 [26:21<03:35,  2.25s/ba]Running tokenizer on dataset:  88%|████████▊ | 719/814 [26:23<03:35,  2.27s/ba]Running tokenizer on dataset:  88%|████████▊ | 720/814 [26:26<03:32,  2.26s/ba]Running tokenizer on dataset:  89%|████████▊ | 721/814 [26:28<03:29,  2.26s/ba]Running tokenizer on dataset:  89%|████████▊ | 722/814 [26:30<03:27,  2.26s/ba]Running tokenizer on dataset:  89%|████████▉ | 723/814 [26:32<03:24,  2.25s/ba]Running tokenizer on dataset:  89%|████████▉ | 724/814 [26:35<03:19,  2.21s/ba]Running tokenizer on dataset:  89%|████████▉ | 725/814 [26:36<03:03,  2.07s/ba]Running tokenizer on dataset:  89%|████████▉ | 726/814 [26:38<02:51,  1.95s/ba]Running tokenizer on dataset:  89%|████████▉ | 727/814 [26:40<02:43,  1.88s/ba]Running tokenizer on dataset:  89%|████████▉ | 728/814 [26:41<02:37,  1.83s/ba]Running tokenizer on dataset:  90%|████████▉ | 729/814 [26:43<02:32,  1.80s/ba]Running tokenizer on dataset:  90%|████████▉ | 730/814 [26:45<02:27,  1.76s/ba]Running tokenizer on dataset:  90%|████████▉ | 731/814 [26:46<02:25,  1.75s/ba]Running tokenizer on dataset:  90%|████████▉ | 732/814 [26:48<02:22,  1.74s/ba]Running tokenizer on dataset:  90%|█████████ | 733/814 [26:50<02:19,  1.73s/ba]Running tokenizer on dataset:  90%|█████████ | 734/814 [26:52<02:17,  1.72s/ba]Running tokenizer on dataset:  90%|█████████ | 735/814 [26:53<02:15,  1.72s/ba]Running tokenizer on dataset:  90%|█████████ | 736/814 [26:55<02:14,  1.72s/ba]Running tokenizer on dataset:  91%|█████████ | 737/814 [26:57<02:11,  1.71s/ba]Running tokenizer on dataset:  91%|█████████ | 738/814 [26:58<02:09,  1.70s/ba]Running tokenizer on dataset:  91%|█████████ | 739/814 [27:00<02:07,  1.70s/ba]Running tokenizer on dataset:  91%|█████████ | 740/814 [27:02<02:06,  1.71s/ba]Running tokenizer on dataset:  91%|█████████ | 741/814 [27:04<02:05,  1.71s/ba]Running tokenizer on dataset:  91%|█████████ | 742/814 [27:05<02:03,  1.71s/ba]Running tokenizer on dataset:  91%|█████████▏| 743/814 [27:07<02:01,  1.71s/ba]Running tokenizer on dataset:  91%|█████████▏| 744/814 [27:09<01:58,  1.70s/ba]Running tokenizer on dataset:  92%|█████████▏| 745/814 [27:10<01:57,  1.70s/ba]Running tokenizer on dataset:  92%|█████████▏| 746/814 [27:12<01:55,  1.69s/ba]Running tokenizer on dataset:  92%|█████████▏| 747/814 [27:14<01:53,  1.69s/ba]Running tokenizer on dataset:  92%|█████████▏| 748/814 [27:15<01:51,  1.69s/ba]Running tokenizer on dataset:  92%|█████████▏| 749/814 [27:17<01:49,  1.69s/ba]Running tokenizer on dataset:  92%|█████████▏| 750/814 [27:19<01:48,  1.70s/ba]Running tokenizer on dataset:  92%|█████████▏| 751/814 [27:20<01:46,  1.69s/ba]Running tokenizer on dataset:  92%|█████████▏| 752/814 [27:22<01:45,  1.71s/ba]Running tokenizer on dataset:  93%|█████████▎| 753/814 [27:24<01:44,  1.72s/ba]Running tokenizer on dataset:  93%|█████████▎| 754/814 [27:26<01:42,  1.71s/ba]Running tokenizer on dataset:  93%|█████████▎| 755/814 [27:27<01:41,  1.72s/ba]Running tokenizer on dataset:  93%|█████████▎| 756/814 [27:30<01:48,  1.88s/ba]Running tokenizer on dataset:  93%|█████████▎| 757/814 [27:32<01:52,  1.98s/ba]Running tokenizer on dataset:  93%|█████████▎| 758/814 [27:34<01:55,  2.06s/ba]Running tokenizer on dataset:  93%|█████████▎| 759/814 [27:36<01:57,  2.13s/ba]Running tokenizer on dataset:  93%|█████████▎| 760/814 [27:39<01:58,  2.19s/ba]Running tokenizer on dataset:  93%|█████████▎| 761/814 [27:41<01:57,  2.22s/ba]Running tokenizer on dataset:  94%|█████████▎| 762/814 [27:43<01:56,  2.24s/ba]Running tokenizer on dataset:  94%|█████████▎| 763/814 [27:46<01:55,  2.26s/ba]Running tokenizer on dataset:  94%|█████████▍| 764/814 [27:48<01:53,  2.26s/ba]Running tokenizer on dataset:  94%|█████████▍| 765/814 [27:50<01:50,  2.25s/ba]Running tokenizer on dataset:  94%|█████████▍| 766/814 [27:52<01:48,  2.25s/ba]Running tokenizer on dataset:  94%|█████████▍| 767/814 [27:55<01:46,  2.26s/ba]Running tokenizer on dataset:  94%|█████████▍| 768/814 [27:57<01:44,  2.27s/ba]Running tokenizer on dataset:  94%|█████████▍| 769/814 [27:59<01:42,  2.27s/ba]Running tokenizer on dataset:  95%|█████████▍| 770/814 [28:03<01:55,  2.63s/ba]Running tokenizer on dataset:  95%|█████████▍| 771/814 [28:05<01:48,  2.52s/ba]Running tokenizer on dataset:  95%|█████████▍| 772/814 [28:07<01:39,  2.36s/ba]Running tokenizer on dataset:  95%|█████████▍| 773/814 [28:09<01:28,  2.17s/ba]Running tokenizer on dataset:  95%|█████████▌| 774/814 [28:10<01:21,  2.03s/ba]Running tokenizer on dataset:  95%|█████████▌| 775/814 [28:12<01:15,  1.93s/ba]Running tokenizer on dataset:  95%|█████████▌| 776/814 [28:14<01:16,  2.00s/ba]Running tokenizer on dataset:  95%|█████████▌| 777/814 [28:17<01:17,  2.09s/ba]Running tokenizer on dataset:  96%|█████████▌| 778/814 [28:19<01:16,  2.14s/ba]Running tokenizer on dataset:  96%|█████████▌| 779/814 [28:21<01:16,  2.19s/ba]Running tokenizer on dataset:  96%|█████████▌| 780/814 [28:23<01:14,  2.20s/ba]Running tokenizer on dataset:  96%|█████████▌| 781/814 [28:26<01:15,  2.29s/ba]Running tokenizer on dataset:  96%|█████████▌| 782/814 [28:28<01:13,  2.30s/ba]Running tokenizer on dataset:  96%|█████████▌| 783/814 [28:30<01:10,  2.29s/ba]Running tokenizer on dataset:  96%|█████████▋| 784/814 [28:33<01:08,  2.29s/ba]Running tokenizer on dataset:  96%|█████████▋| 785/814 [28:35<01:06,  2.30s/ba]Running tokenizer on dataset:  97%|█████████▋| 786/814 [28:37<00:59,  2.14s/ba]Running tokenizer on dataset:  97%|█████████▋| 787/814 [28:38<00:54,  2.00s/ba]Running tokenizer on dataset:  97%|█████████▋| 788/814 [28:40<00:49,  1.90s/ba]Running tokenizer on dataset:  97%|█████████▋| 789/814 [28:42<00:46,  1.84s/ba]Running tokenizer on dataset:  97%|█████████▋| 790/814 [28:44<00:43,  1.80s/ba]Running tokenizer on dataset:  97%|█████████▋| 791/814 [28:45<00:40,  1.77s/ba]Running tokenizer on dataset:  97%|█████████▋| 792/814 [28:47<00:38,  1.75s/ba]Running tokenizer on dataset:  97%|█████████▋| 793/814 [28:49<00:36,  1.75s/ba]Running tokenizer on dataset:  98%|█████████▊| 794/814 [28:50<00:34,  1.74s/ba]Running tokenizer on dataset:  98%|█████████▊| 795/814 [28:52<00:32,  1.72s/ba]Running tokenizer on dataset:  98%|█████████▊| 796/814 [28:54<00:30,  1.71s/ba]Running tokenizer on dataset:  98%|█████████▊| 797/814 [28:55<00:28,  1.70s/ba]Running tokenizer on dataset:  98%|█████████▊| 798/814 [28:57<00:27,  1.71s/ba]Running tokenizer on dataset:  98%|█████████▊| 799/814 [28:59<00:28,  1.88s/ba]Running tokenizer on dataset:  98%|█████████▊| 800/814 [29:02<00:27,  1.99s/ba]Running tokenizer on dataset:  98%|█████████▊| 801/814 [29:04<00:27,  2.09s/ba]Running tokenizer on dataset:  99%|█████████▊| 802/814 [29:06<00:25,  2.14s/ba]Running tokenizer on dataset:  99%|█████████▊| 803/814 [29:08<00:23,  2.16s/ba]Running tokenizer on dataset:  99%|█████████▉| 804/814 [29:10<00:20,  2.06s/ba]Running tokenizer on dataset:  99%|█████████▉| 805/814 [29:12<00:17,  1.99s/ba]Running tokenizer on dataset:  99%|█████████▉| 806/814 [29:14<00:15,  1.90s/ba]Running tokenizer on dataset:  99%|█████████▉| 807/814 [29:15<00:12,  1.84s/ba]Running tokenizer on dataset:  99%|█████████▉| 808/814 [29:17<00:10,  1.79s/ba]Running tokenizer on dataset:  99%|█████████▉| 809/814 [29:19<00:08,  1.78s/ba]Running tokenizer on dataset: 100%|█████████▉| 810/814 [29:21<00:07,  1.75s/ba]Running tokenizer on dataset: 100%|█████████▉| 811/814 [29:22<00:05,  1.74s/ba]Running tokenizer on dataset: 100%|█████████▉| 812/814 [29:24<00:03,  1.78s/ba]Running tokenizer on dataset: 100%|█████████▉| 813/814 [29:26<00:01,  1.75s/ba]Running tokenizer on dataset: 100%|██████████| 814/814 [29:26<00:00,  1.39s/ba]Running tokenizer on dataset: 100%|██████████| 814/814 [29:26<00:00,  2.17s/ba]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 1/814 [00:01<21:22,  1.58s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:03<21:34,  1.59s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:04<21:44,  1.61s/ba]Running tokenizer on dataset:   0%|          | 4/814 [00:06<21:54,  1.62s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:08<21:48,  1.62s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:09<21:38,  1.61s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:11<21:45,  1.62s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:12<21:43,  1.62s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:14<21:34,  1.61s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:16<21:28,  1.60s/ba]Running tokenizer on dataset:   1%|▏         | 11/814 [00:17<21:50,  1.63s/ba]Running tokenizer on dataset:   1%|▏         | 12/814 [00:19<21:46,  1.63s/ba][E ProcessGroupNCCL.cpp:821] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=2, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1808095 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:821] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=2, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1808321 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:821] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=2, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1800509 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:456] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:461] To avoid data inconsistency, we are taking the entire process down.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=2, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1800509 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:456] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:461] To avoid data inconsistency, we are taking the entire process down.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=2, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1808321 milliseconds before timing out.
Running tokenizer on dataset:   2%|▏         | 13/814 [00:21<21:53,  1.64s/ba][E ProcessGroupNCCL.cpp:456] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:461] To avoid data inconsistency, we are taking the entire process down.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=2, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1808095 milliseconds before timing out.
Running tokenizer on dataset:   2%|▏         | 14/814 [00:22<21:58,  1.65s/ba]Running tokenizer on dataset:   2%|▏         | 15/814 [00:24<21:52,  1.64s/ba]Running tokenizer on dataset:   2%|▏         | 16/814 [00:26<23:00,  1.73s/ba]Running tokenizer on dataset:   2%|▏         | 17/814 [00:28<24:42,  1.86s/ba]Running tokenizer on dataset:   2%|▏         | 18/814 [00:30<25:49,  1.95s/ba]Running tokenizer on dataset:   2%|▏         | 19/814 [00:32<26:40,  2.01s/ba]Running tokenizer on dataset:   2%|▏         | 20/814 [00:34<27:08,  2.05s/ba]Running tokenizer on dataset:   3%|▎         | 21/814 [00:37<27:32,  2.08s/ba]Running tokenizer on dataset:   3%|▎         | 22/814 [00:39<27:43,  2.10s/ba]Running tokenizer on dataset:   3%|▎         | 23/814 [00:41<27:48,  2.11s/ba]Running tokenizer on dataset:   3%|▎         | 24/814 [00:43<27:54,  2.12s/ba]Running tokenizer on dataset:   3%|▎         | 25/814 [00:45<27:58,  2.13s/ba]Running tokenizer on dataset:   3%|▎         | 26/814 [00:47<27:59,  2.13s/ba]Running tokenizer on dataset:   3%|▎         | 27/814 [00:49<27:56,  2.13s/ba]WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 170377 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 170378 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 170379 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Unable to shutdown process 170379 via 15, forcefully exitting via 9
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -6) local_rank: 3 (pid: 170380) of binary: /home/paperspace/Documents/Repos/clm_model_tuning/venv/bin/python3
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/utils/dataclasses.py:346: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.
  warnings.warn("DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.")
/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/utils/dataclasses.py:346: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.
  warnings.warn("DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.")
/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/utils/dataclasses.py:346: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.
  warnings.warn("DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.")
/home/paperspace/Documents/Repos/clm_model_tuning/venv/lib/python3.8/site-packages/accelerate/utils/dataclasses.py:346: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.
  warnings.warn("DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.")
[2022-11-18 14:06:55,541] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-18 14:06:55,906][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 2
[2022-11-18 14:06:55,930][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 3
[2022-11-18 14:06:55,943][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 1
[2022-11-18 14:06:55,948][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2022-11-18 14:06:55,949][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-11-18 14:06:55,951][torch.distributed.distributed_c10d][INFO] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-11-18 14:06:55,955][torch.distributed.distributed_c10d][INFO] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-11-18 14:06:55,958][torch.distributed.distributed_c10d][INFO] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-11-18 14:06:58,615][__main__][INFO] - Setting random seed to 17
[2022-11-18 14:06:58,615][__main__][INFO] - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}}

[2022-11-18 14:06:58,615][__main__][INFO] - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}}

[2022-11-18 14:06:58,615][__main__][INFO] - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}}

[2022-11-18 14:06:58,615][__main__][INFO] - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}}

[2022-11-18 14:06:58,618][__main__][INFO] - output_dir: tuned-model
bittensor:
  network: nobunaga
dataset:
  name: ViktorThink/mountain_combined_813306
  config_name: null
  num_batches: 5000
  block_size: 256
  overwrite_cache: false
  keep_linebreaks: true
  concatenate_raw: false
  load_tokenized_data: false
model:
  name: facebook/opt-2.7b
  config_name: null
tokenizer:
  name: null
  use_fast: true
  preprocessing_num_workers: null
  pad_token: '[PAD]'
training:
  seed: 17
  val_split_percent: 20
  train_batch_size: 32
  eval_batch_size: 16
  learning_rate: 3.0e-06
  weight_decay: 0.05
  num_epochs: 4
  max_train_steps: null
  gradient_accumulation_steps: 2
  lr_scheduler: constant
  lr_warmup_steps: 5
  eval_every: 250
  max_eval_steps: 500
  checkpoint:
    resume_from_checkpoint: 0
    every_n_steps: null
tracking:
  enabled: true
  report_to: all
testing:
  enabled: false

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--EleutherAI--gpt-neo-2.7B/snapshots/51568a6e0ae813a3f2a9da558ab7beac5e3acc24/config.json
Model config GPTNeoConfig {
  "_name_or_path": "EleutherAI/gpt-neo-2.7B",
  "activation_function": "gelu_new",
  "architectures": [
    "GPTNeoForCausalLM"
  ],
  "attention_dropout": 0,
  "attention_layers": [
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local",
    "global",
    "local"
  ],
  "attention_types": [
    [
      [
        "global",
        "local"
      ],
      16
    ]
  ],
  "bos_token_id": 50256,
  "embed_dropout": 0,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "hidden_size": 2560,
  "initializer_range": 0.02,
  "intermediate_size": null,
  "layer_norm_epsilon": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neo",
  "num_heads": 20,
  "num_layers": 32,
  "resid_dropout": 0,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50,
      "temperature": 0.9
    }
  },
  "tokenizer_class": "GPT2Tokenizer",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50257,
  "window_size": 256
}

loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading file vocab.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/vocab.json
loading file merges.txt from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/merges.txt
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/tokenizer_config.json
loading configuration file config.json from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/config.json
Model config OPTConfig {
  "_name_or_path": "facebook/opt-2.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "eos_token_id": 2,
  "ffn_dim": 10240,
  "hidden_size": 2560,
  "init_std": 0.02,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.24.0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 2560
}

loading weights file flax_model.msgpack from cache at /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Loading Flax weights from /home/paperspace/.cache/huggingface/hub/models--facebook--opt-2.7b/snapshots/c9c15109b9dac40871c063892227d45b85cb3952/flax_model.msgpack
Some weights of the Flax model were not used when initializing the PyTorch model GPTNeoForCausalLM: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.18.fc1.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.bias']
- This IS expected if you are initializing GPTNeoForCausalLM from a Flax model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a FlaxBertForPreTraining model).
- This IS NOT expected if you are initializing GPTNeoForCausalLM from a Flax model that you expect to be exactly identical (e.g. initializing a BertForSequenceClassification model from a FlaxBertForSequenceClassification model).
Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['transformer.h.22.attn.attention.k_proj.weight', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.31.mlp.c_fc.bias', 'lm_head.weight', 'transformer.h.23.attn.attention.v_proj.weight', 'transformer.h.6.ln_1.weight', 'transformer.h.21.ln_1.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.5.ln_1.bias', 'transformer.h.14.attn.attention.v_proj.weight', 'transformer.h.11.attn.attention.v_proj.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.25.mlp.c_fc.bias', 'transformer.h.15.ln_1.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.11.attn.attention.masked_bias', 'transformer.h.1.attn.attention.masked_bias', 'transformer.h.13.ln_1.weight', 'transformer.h.16.attn.attention.bias', 'transformer.h.14.ln_2.weight', 'transformer.h.14.attn.attention.masked_bias', 'transformer.h.22.attn.attention.bias', 'transformer.h.18.attn.attention.q_proj.weight', 'transformer.h.6.attn.attention.k_proj.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.19.attn.attention.bias', 'transformer.h.18.ln_2.weight', 'transformer.h.1.attn.attention.v_proj.weight', 'transformer.h.28.ln_1.weight', 'transformer.h.17.attn.attention.out_proj.bias', 'transformer.h.19.mlp.c_proj.bias', 'transformer.h.24.attn.attention.masked_bias', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.30.attn.attention.q_proj.weight', 'transformer.h.20.ln_1.bias', 'transformer.h.8.attn.attention.out_proj.weight', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.24.ln_2.bias', 'transformer.h.27.attn.attention.out_proj.bias', 'transformer.h.14.ln_2.bias', 'transformer.h.1.attn.attention.q_proj.weight', 'transformer.h.15.mlp.c_fc.bias', 'transformer.h.8.attn.attention.q_proj.weight', 'transformer.h.19.mlp.c_fc.bias', 'transformer.h.24.attn.attention.out_proj.bias', 'transformer.h.15.ln_2.bias', 'transformer.h.11.ln_2.bias', 'transformer.h.5.attn.attention.out_proj.weight', 'transformer.h.9.attn.attention.out_proj.bias', 'transformer.h.7.attn.attention.out_proj.bias', 'transformer.h.23.attn.attention.k_proj.weight', 'transformer.h.28.mlp.c_proj.bias', 'transformer.h.11.attn.attention.k_proj.weight', 'transformer.h.6.attn.attention.out_proj.bias', 'transformer.h.21.attn.attention.k_proj.weight', 'transformer.h.8.attn.attention.masked_bias', 'transformer.h.30.mlp.c_proj.weight', 'transformer.h.5.attn.attention.v_proj.weight', 'transformer.h.5.ln_2.weight', 'transformer.h.24.mlp.c_fc.bias', 'transformer.h.26.attn.attention.masked_bias', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.31.attn.attention.k_proj.weight', 'transformer.h.1.ln_2.weight', 'transformer.h.7.attn.attention.out_proj.weight', 'transformer.h.19.ln_2.weight', 'transformer.h.13.ln_2.bias', 'transformer.h.8.ln_1.bias', 'transformer.h.2.attn.attention.k_proj.weight', 'transformer.h.22.mlp.c_fc.bias', 'transformer.h.7.attn.attention.v_proj.weight', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.21.attn.attention.q_proj.weight', 'transformer.h.9.attn.attention.bias', 'transformer.h.21.attn.attention.out_proj.bias', 'transformer.h.27.mlp.c_fc.weight', 'transformer.h.23.mlp.c_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.17.attn.attention.out_proj.weight', 'transformer.h.8.ln_1.weight', 'transformer.h.15.mlp.c_fc.weight', 'transformer.h.8.attn.attention.bias', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.2.attn.attention.out_proj.weight', 'transformer.h.0.attn.attention.out_proj.weight', 'transformer.h.14.attn.attention.out_proj.weight', 'transformer.h.26.attn.attention.v_proj.weight', 'transformer.h.16.ln_2.weight', 'transformer.h.25.ln_2.bias', 'transformer.h.17.attn.attention.v_proj.weight', 'transformer.h.14.mlp.c_fc.weight', 'transformer.h.17.attn.attention.masked_bias', 'transformer.h.30.attn.attention.out_proj.bias', 'transformer.h.31.attn.attention.q_proj.weight', 'transformer.h.29.attn.attention.k_proj.weight', 'transformer.h.29.ln_1.weight', 'transformer.h.2.attn.attention.v_proj.weight', 'transformer.h.29.attn.attention.masked_bias', 'transformer.h.29.ln_2.bias', 'transformer.h.29.attn.attention.out_proj.weight', 'transformer.h.26.ln_2.bias', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.26.mlp.c_fc.bias', 'transformer.h.15.attn.attention.k_proj.weight', 'transformer.h.1.attn.attention.out_proj.weight', 'transformer.h.13.attn.attention.masked_bias', 'transformer.h.22.ln_2.bias', 'transformer.h.12.attn.attention.q_proj.weight', 'transformer.h.21.attn.attention.out_proj.weight', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.5.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.23.attn.attention.out_proj.bias', 'transformer.h.18.ln_1.bias', 'transformer.h.6.ln_2.bias', 'transformer.h.21.attn.attention.v_proj.weight', 'transformer.h.10.attn.attention.bias', 'transformer.h.28.attn.attention.bias', 'transformer.h.27.ln_2.weight', 'transformer.h.12.attn.attention.k_proj.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.31.attn.attention.bias', 'transformer.h.19.attn.attention.q_proj.weight', 'transformer.h.30.mlp.c_proj.bias', 'transformer.h.29.mlp.c_proj.bias', 'transformer.h.24.mlp.c_proj.weight', 'transformer.h.30.ln_2.weight', 'transformer.h.16.attn.attention.out_proj.bias', 'transformer.h.20.attn.attention.q_proj.weight', 'transformer.h.19.attn.attention.k_proj.weight', 'transformer.h.16.attn.attention.out_proj.weight', 'transformer.h.13.attn.attention.bias', 'transformer.h.30.ln_1.weight', 'transformer.h.8.attn.attention.out_proj.bias', 'transformer.h.12.ln_1.weight', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.26.mlp.c_proj.bias', 'transformer.h.23.attn.attention.masked_bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.3.attn.attention.k_proj.weight', 'transformer.h.18.mlp.c_fc.weight', 'transformer.h.10.attn.attention.v_proj.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.6.attn.attention.v_proj.weight', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.25.attn.attention.v_proj.weight', 'transformer.h.24.attn.attention.k_proj.weight', 'transformer.h.4.attn.attention.out_proj.bias', 'transformer.h.0.attn.attention.out_proj.bias', 'transformer.h.20.attn.attention.out_proj.bias', 'transformer.h.18.attn.attention.bias', 'transformer.h.27.attn.attention.masked_bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.4.attn.attention.k_proj.weight', 'transformer.h.20.ln_2.bias', 'transformer.h.30.attn.attention.k_proj.weight', 'transformer.h.19.attn.attention.out_proj.weight', 'transformer.h.13.ln_2.weight', 'transformer.h.19.ln_1.bias', 'transformer.h.10.ln_1.bias', 'transformer.h.19.attn.attention.out_proj.bias', 'transformer.h.21.mlp.c_fc.bias', 'transformer.h.27.ln_2.bias', 'transformer.h.6.attn.attention.out_proj.weight', 'transformer.h.11.attn.attention.out_proj.weight', 'transformer.h.4.ln_1.weight', 'transformer.wte.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.26.attn.attention.q_proj.weight', 'transformer.h.23.attn.attention.out_proj.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.28.mlp.c_fc.bias', 'transformer.h.20.attn.attention.out_proj.weight', 'transformer.h.22.attn.attention.v_proj.weight', 'transformer.h.25.ln_2.weight', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.9.ln_1.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.10.attn.attention.out_proj.weight', 'transformer.h.24.attn.attention.q_proj.weight', 'transformer.h.18.mlp.c_fc.bias', 'transformer.h.29.ln_2.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.26.attn.attention.bias', 'transformer.h.25.ln_1.bias', 'transformer.h.24.ln_1.weight', 'transformer.h.20.attn.attention.v_proj.weight', 'transformer.h.21.attn.attention.masked_bias', 'transformer.h.7.attn.attention.masked_bias', 'transformer.h.28.attn.attention.v_proj.weight', 'transformer.h.26.attn.attention.out_proj.weight', 'transformer.h.31.ln_2.weight', 'transformer.h.24.mlp.c_fc.weight', 'transformer.h.15.attn.attention.bias', 'transformer.h.20.attn.attention.k_proj.weight', 'transformer.h.23.ln_1.bias', 'transformer.h.12.attn.attention.masked_bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.19.ln_2.bias', 'transformer.h.29.attn.attention.out_proj.bias', 'transformer.h.9.attn.attention.out_proj.weight', 'transformer.h.11.ln_1.weight', 'transformer.h.25.mlp.c_proj.weight', 'transformer.h.2.attn.attention.masked_bias', 'transformer.h.28.ln_2.bias', 'transformer.h.26.ln_1.bias', 'transformer.h.23.ln_1.weight', 'transformer.h.3.attn.attention.v_proj.weight', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.12.attn.attention.v_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.18.mlp.c_proj.weight', 'transformer.h.9.attn.attention.k_proj.weight', 'transformer.h.9.ln_2.weight', 'transformer.h.15.ln_1.weight', 'transformer.h.7.ln_1.weight', 'transformer.h.22.attn.attention.masked_bias', 'transformer.h.28.attn.attention.k_proj.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.23.attn.attention.q_proj.weight', 'transformer.h.19.ln_1.weight', 'transformer.h.13.attn.attention.k_proj.weight', 'transformer.h.0.attn.attention.q_proj.weight', 'transformer.h.6.ln_2.weight', 'transformer.h.9.attn.attention.masked_bias', 'transformer.h.28.mlp.c_proj.weight', 'transformer.h.24.ln_2.weight', 'transformer.h.25.attn.attention.masked_bias', 'transformer.h.26.attn.attention.k_proj.weight', 'transformer.h.30.ln_2.bias', 'transformer.h.2.attn.attention.bias', 'transformer.h.31.mlp.c_proj.bias', 'transformer.h.29.mlp.c_fc.bias', 'transformer.ln_f.bias', 'transformer.h.31.mlp.c_fc.weight', 'transformer.h.12.mlp.c_fc.weight', 'transformer.h.13.attn.attention.out_proj.weight', 'transformer.h.24.attn.attention.out_proj.weight', 'transformer.h.24.attn.attention.bias', 'transformer.h.30.mlp.c_fc.weight', 'transformer.h.28.attn.attention.out_proj.bias', 'transformer.h.7.attn.attention.k_proj.weight', 'transformer.h.10.attn.attention.q_proj.weight', 'transformer.h.20.mlp.c_fc.weight', 'transformer.h.19.mlp.c_fc.weight', 'transformer.h.30.ln_1.bias', 'transformer.h.16.ln_1.bias', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.13.attn.attention.out_proj.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.11.ln_2.weight', 'transformer.h.10.attn.attention.out_proj.bias', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.10.attn.attention.k_proj.weight', 'transformer.h.17.ln_1.weight', 'transformer.h.18.attn.attention.v_proj.weight', 'transformer.h.16.attn.attention.q_proj.weight', 'transformer.h.3.ln_2.weight', 'transformer.h.30.mlp.c_fc.bias', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.15.attn.attention.out_proj.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.23.attn.attention.bias', 'transformer.h.17.attn.attention.q_proj.weight', 'transformer.h.12.attn.attention.out_proj.weight', 'transformer.h.22.attn.attention.out_proj.weight', 'transformer.h.17.attn.attention.k_proj.weight', 'transformer.h.4.attn.attention.bias', 'transformer.h.22.mlp.c_fc.weight', 'transformer.h.20.mlp.c_fc.bias', 'transformer.h.22.ln_1.weight', 'transformer.h.22.ln_2.weight', 'transformer.h.5.attn.attention.q_proj.weight', 'transformer.h.29.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.24.ln_1.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.4.ln_2.weight', 'transformer.h.14.mlp.c_proj.bias', 'transformer.h.20.attn.attention.masked_bias', 'transformer.h.23.mlp.c_fc.weight', 'transformer.h.4.attn.attention.q_proj.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.3.attn.attention.q_proj.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.25.attn.attention.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.20.mlp.c_proj.weight', 'transformer.h.8.ln_2.weight', 'transformer.h.27.attn.attention.bias', 'transformer.h.25.attn.attention.k_proj.weight', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.15.attn.attention.q_proj.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.attn.attention.masked_bias', 'transformer.h.16.attn.attention.k_proj.weight', 'transformer.h.14.attn.attention.k_proj.weight', 'transformer.h.30.attn.attention.out_proj.weight', 'transformer.h.3.attn.attention.bias', 'transformer.h.31.attn.attention.v_proj.weight', 'transformer.h.18.attn.attention.masked_bias', 'transformer.h.21.ln_1.weight', 'transformer.h.27.mlp.c_proj.weight', 'transformer.h.0.ln_2.weight', 'transformer.h.17.mlp.c_fc.weight', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.15.attn.attention.v_proj.weight', 'transformer.h.8.attn.attention.v_proj.weight', 'transformer.h.6.attn.attention.masked_bias', 'transformer.h.10.attn.attention.masked_bias', 'transformer.h.7.ln_2.weight', 'transformer.h.4.attn.attention.out_proj.weight', 'transformer.h.8.attn.attention.k_proj.weight', 'transformer.h.21.attn.attention.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.5.attn.attention.out_proj.bias', 'transformer.h.14.mlp.c_fc.bias', 'transformer.h.2.attn.attention.out_proj.bias', 'transformer.h.3.attn.attention.out_proj.weight', 'transformer.h.23.mlp.c_fc.bias', 'transformer.h.3.ln_1.bias', 'transformer.h.16.attn.attention.masked_bias', 'transformer.h.2.attn.attention.q_proj.weight', 'transformer.h.4.attn.attention.masked_bias', 'transformer.h.21.ln_2.weight', 'transformer.h.17.ln_1.bias', 'transformer.h.31.ln_1.weight', 'transformer.h.12.ln_2.weight', 'transformer.h.28.ln_1.bias', 'transformer.h.13.attn.attention.q_proj.weight', 'transformer.h.0.attn.attention.k_proj.weight', 'transformer.h.23.ln_2.bias', 'transformer.h.31.ln_1.bias', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.5.attn.attention.bias', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.5.attn.attention.masked_bias', 'transformer.h.16.ln_1.weight', 'transformer.h.28.ln_2.weight', 'transformer.h.13.mlp.c_fc.bias', 'transformer.h.20.ln_2.weight', 'transformer.h.1.attn.attention.bias', 'transformer.h.9.attn.attention.v_proj.weight', 'transformer.h.20.attn.attention.bias', 'transformer.h.29.ln_1.bias', 'transformer.h.0.ln_1.weight', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.16.mlp.c_fc.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.12.attn.attention.bias', 'transformer.h.14.ln_1.weight', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.17.ln_2.weight', 'transformer.h.22.attn.attention.q_proj.weight', 'transformer.h.19.mlp.c_proj.weight', 'transformer.h.13.mlp.c_fc.weight', 'transformer.h.15.attn.attention.out_proj.weight', 'transformer.h.18.mlp.c_proj.bias', 'transformer.h.23.ln_2.weight', 'transformer.h.27.attn.attention.out_proj.weight', 'transformer.h.26.ln_2.weight', 'transformer.h.9.attn.attention.q_proj.weight', 'transformer.h.4.attn.attention.v_proj.weight', 'transformer.h.26.mlp.c_proj.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.4.ln_1.bias', 'transformer.h.6.attn.attention.bias', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.30.attn.attention.v_proj.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.18.ln_1.weight', 'transformer.h.17.attn.attention.bias', 'transformer.h.0.ln_1.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.16.attn.attention.v_proj.weight', 'transformer.h.0.attn.attention.bias', 'transformer.h.7.attn.attention.q_proj.weight', 'transformer.h.12.attn.attention.out_proj.bias', 'transformer.h.15.attn.attention.masked_bias', 'transformer.h.0.attn.attention.v_proj.weight', 'transformer.h.28.attn.attention.out_proj.weight', 'transformer.h.30.attn.attention.bias', 'transformer.h.22.ln_1.bias', 'transformer.h.14.ln_1.bias', 'transformer.h.31.attn.attention.masked_bias', 'transformer.h.27.attn.attention.v_proj.weight', 'transformer.h.14.attn.attention.bias', 'transformer.h.1.attn.attention.out_proj.bias', 'transformer.h.21.mlp.c_proj.bias', 'transformer.h.25.mlp.c_proj.bias', 'transformer.h.25.mlp.c_fc.weight', 'transformer.h.19.attn.attention.v_proj.weight', 'transformer.h.29.mlp.c_proj.weight', 'transformer.h.22.mlp.c_proj.bias', 'transformer.h.4.ln_2.bias', 'transformer.h.24.attn.attention.v_proj.weight', 'transformer.h.26.attn.attention.out_proj.bias', 'transformer.h.3.attn.attention.masked_bias', 'transformer.h.11.attn.attention.q_proj.weight', 'transformer.h.27.attn.attention.q_proj.weight', 'transformer.h.29.attn.attention.q_proj.weight', 'transformer.h.12.mlp.c_fc.bias', 'transformer.h.18.attn.attention.k_proj.weight', 'transformer.h.17.ln_2.bias', 'transformer.h.28.attn.attention.masked_bias', 'transformer.h.14.attn.attention.out_proj.bias', 'transformer.h.25.attn.attention.out_proj.weight', 'transformer.h.15.ln_2.weight', 'transformer.h.26.mlp.c_fc.weight', 'transformer.h.11.attn.attention.out_proj.bias', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.31.ln_2.bias', 'transformer.h.3.attn.attention.out_proj.bias', 'transformer.ln_f.weight', 'transformer.h.22.attn.attention.out_proj.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.21.ln_2.bias', 'transformer.h.14.attn.attention.q_proj.weight', 'transformer.h.13.ln_1.bias', 'transformer.h.5.attn.attention.k_proj.weight', 'transformer.h.20.mlp.c_proj.bias', 'transformer.h.6.attn.attention.q_proj.weight', 'transformer.h.2.ln_1.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.27.mlp.c_fc.bias', 'transformer.h.31.mlp.c_proj.weight', 'transformer.h.24.mlp.c_proj.bias', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.11.attn.attention.bias', 'transformer.h.27.ln_1.weight', 'transformer.h.21.mlp.c_fc.weight', 'transformer.h.27.mlp.c_proj.bias', 'transformer.h.18.ln_2.bias', 'transformer.h.17.mlp.c_fc.bias', 'transformer.h.9.ln_2.bias', 'transformer.h.1.attn.attention.k_proj.weight', 'transformer.h.28.mlp.c_fc.weight', 'transformer.h.25.ln_1.weight', 'transformer.h.27.ln_1.bias', 'transformer.h.1.ln_1.bias', 'transformer.wpe.weight', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.7.attn.attention.bias', 'transformer.h.10.ln_2.bias', 'transformer.h.28.attn.attention.q_proj.weight', 'transformer.h.12.ln_2.bias', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.25.attn.attention.out_proj.bias', 'transformer.h.21.mlp.c_proj.weight', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.31.attn.attention.out_proj.bias', 'transformer.h.29.attn.attention.v_proj.weight', 'transformer.h.12.ln_1.bias', 'transformer.h.25.attn.attention.q_proj.weight', 'transformer.h.13.attn.attention.v_proj.weight', 'transformer.h.29.attn.attention.bias', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.30.attn.attention.masked_bias', 'transformer.h.31.attn.attention.out_proj.weight', 'transformer.h.10.ln_2.weight', 'transformer.h.27.attn.attention.k_proj.weight', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.16.ln_2.bias', 'transformer.h.22.mlp.c_proj.weight', 'transformer.h.26.ln_1.weight', 'transformer.h.20.ln_1.weight', 'transformer.h.16.mlp.c_fc.bias', 'transformer.h.18.attn.attention.out_proj.weight', 'transformer.h.18.attn.attention.out_proj.bias', 'transformer.h.19.attn.attention.masked_bias', 'transformer.h.23.mlp.c_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2022-11-18 14:07:29,372][datasets.builder][WARNING] - Using custom data configuration ViktorThink--mountain_combined_813306-6918b9ea07482433
[2022-11-18 14:07:29,444][datasets.builder][WARNING] - Found cached dataset csv (/home/paperspace/.cache/huggingface/datasets/ViktorThink___csv/ViktorThink--mountain_combined_813306-6918b9ea07482433/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.74it/s]100%|██████████| 2/2 [00:00<00:00, 10.90it/s]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.26it/s]100%|██████████| 2/2 [00:00<00:00,  9.91it/s]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 1/814 [00:02<36:26,  2.69s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:04<33:04,  2.44s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:07<31:33,  2.33s/ba]  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.12it/s]100%|██████████| 2/2 [00:00<00:00, 11.60it/s]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.62it/s]100%|██████████| 2/2 [00:00<00:00, 10.71it/s]
Running tokenizer on dataset:   0%|          | 4/814 [00:09<30:34,  2.26s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:11<29:37,  2.20s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:13<28:44,  2.13s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:15<28:22,  2.11s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:17<27:54,  2.08s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:19<27:20,  2.04s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:21<26:51,  2.00s/ba]Running tokenizer on dataset:   1%|▏         | 11/814 [00:23<26:52,  2.01s/ba]Running tokenizer on dataset:   1%|▏         | 12/814 [00:25<26:40,  2.00s/ba]Running tokenizer on dataset:   2%|▏         | 13/814 [00:27<26:31,  1.99s/ba]Running tokenizer on dataset:   2%|▏         | 14/814 [00:29<26:29,  1.99s/ba]Running tokenizer on dataset:   2%|▏         | 15/814 [00:31<26:13,  1.97s/ba]Running tokenizer on dataset:   2%|▏         | 16/814 [00:33<26:01,  1.96s/ba]Running tokenizer on dataset:   2%|▏         | 17/814 [00:35<25:48,  1.94s/ba]Running tokenizer on dataset:   2%|▏         | 18/814 [00:36<25:30,  1.92s/ba]Running tokenizer on dataset:   2%|▏         | 19/814 [00:38<25:22,  1.91s/ba]Running tokenizer on dataset:   2%|▏         | 20/814 [00:40<25:19,  1.91s/ba]Running tokenizer on dataset:   3%|▎         | 21/814 [00:42<25:14,  1.91s/ba]Running tokenizer on dataset:   3%|▎         | 22/814 [00:44<24:59,  1.89s/ba]Running tokenizer on dataset:   3%|▎         | 23/814 [00:46<24:51,  1.89s/ba]Running tokenizer on dataset:   3%|▎         | 24/814 [00:48<24:50,  1.89s/ba]Running tokenizer on dataset:   3%|▎         | 25/814 [00:50<24:49,  1.89s/ba]Running tokenizer on dataset:   3%|▎         | 26/814 [00:51<24:38,  1.88s/ba]Running tokenizer on dataset:   3%|▎         | 27/814 [00:53<24:22,  1.86s/ba]Running tokenizer on dataset:   3%|▎         | 28/814 [00:55<24:27,  1.87s/ba]Running tokenizer on dataset:   4%|▎         | 29/814 [00:57<24:32,  1.88s/ba]Running tokenizer on dataset:   4%|▎         | 30/814 [00:59<24:37,  1.88s/ba]Running tokenizer on dataset:   4%|▍         | 31/814 [01:01<24:26,  1.87s/ba]Running tokenizer on dataset:   4%|▍         | 32/814 [01:03<24:38,  1.89s/ba]Running tokenizer on dataset:   4%|▍         | 33/814 [01:05<24:35,  1.89s/ba]Running tokenizer on dataset:   4%|▍         | 34/814 [01:06<24:18,  1.87s/ba]Running tokenizer on dataset:   4%|▍         | 35/814 [01:08<24:05,  1.86s/ba]Running tokenizer on dataset:   4%|▍         | 36/814 [01:10<23:52,  1.84s/ba]Running tokenizer on dataset:   5%|▍         | 37/814 [01:12<23:43,  1.83s/ba]Running tokenizer on dataset:   5%|▍         | 38/814 [01:14<23:30,  1.82s/ba]Running tokenizer on dataset:   5%|▍         | 39/814 [01:16<23:46,  1.84s/ba]Running tokenizer on dataset:   5%|▍         | 40/814 [01:17<23:45,  1.84s/ba]Running tokenizer on dataset:   5%|▌         | 41/814 [01:19<23:49,  1.85s/ba]Running tokenizer on dataset:   5%|▌         | 42/814 [01:21<23:50,  1.85s/ba]Running tokenizer on dataset:   5%|▌         | 43/814 [01:23<23:41,  1.84s/ba]Running tokenizer on dataset:   5%|▌         | 44/814 [01:25<24:00,  1.87s/ba]Running tokenizer on dataset:   6%|▌         | 45/814 [01:27<23:53,  1.86s/ba]Running tokenizer on dataset:   6%|▌         | 46/814 [01:29<23:37,  1.85s/ba]Running tokenizer on dataset:   6%|▌         | 47/814 [01:30<23:30,  1.84s/ba]Running tokenizer on dataset:   6%|▌         | 48/814 [01:32<23:12,  1.82s/ba]Running tokenizer on dataset:   6%|▌         | 49/814 [01:34<23:13,  1.82s/ba]Running tokenizer on dataset:   6%|▌         | 50/814 [01:36<23:12,  1.82s/ba]Running tokenizer on dataset:   6%|▋         | 51/814 [01:38<23:02,  1.81s/ba]Running tokenizer on dataset:   6%|▋         | 52/814 [01:39<23:09,  1.82s/ba]Running tokenizer on dataset:   7%|▋         | 53/814 [01:41<23:09,  1.83s/ba]Running tokenizer on dataset:   7%|▋         | 54/814 [01:43<23:06,  1.82s/ba]Running tokenizer on dataset:   7%|▋         | 55/814 [01:45<23:07,  1.83s/ba]Running tokenizer on dataset:   7%|▋         | 56/814 [01:47<23:09,  1.83s/ba]Running tokenizer on dataset:   7%|▋         | 57/814 [01:49<23:28,  1.86s/ba]Running tokenizer on dataset:   7%|▋         | 58/814 [01:51<23:12,  1.84s/ba]Running tokenizer on dataset:   7%|▋         | 59/814 [01:52<23:06,  1.84s/ba]Running tokenizer on dataset:   7%|▋         | 60/814 [01:54<22:54,  1.82s/ba]Running tokenizer on dataset:   7%|▋         | 61/814 [01:56<22:57,  1.83s/ba]Running tokenizer on dataset:   8%|▊         | 62/814 [01:58<22:59,  1.83s/ba]Running tokenizer on dataset:   8%|▊         | 63/814 [02:00<22:43,  1.82s/ba]Running tokenizer on dataset:   8%|▊         | 64/814 [02:01<22:34,  1.81s/ba]Running tokenizer on dataset:   8%|▊         | 65/814 [02:03<22:44,  1.82s/ba]Running tokenizer on dataset:   8%|▊         | 66/814 [02:05<22:44,  1.82s/ba]Running tokenizer on dataset:   8%|▊         | 67/814 [02:07<22:30,  1.81s/ba]Running tokenizer on dataset:   8%|▊         | 68/814 [02:09<22:26,  1.81s/ba]Running tokenizer on dataset:   8%|▊         | 69/814 [02:10<22:22,  1.80s/ba]Running tokenizer on dataset:   9%|▊         | 70/814 [02:12<22:17,  1.80s/ba]Running tokenizer on dataset:   9%|▊         | 71/814 [02:14<22:09,  1.79s/ba]Running tokenizer on dataset:   9%|▉         | 72/814 [02:16<24:16,  1.96s/ba]Running tokenizer on dataset:   9%|▉         | 73/814 [02:18<23:36,  1.91s/ba]Running tokenizer on dataset:   9%|▉         | 74/814 [02:20<23:02,  1.87s/ba]Running tokenizer on dataset:   9%|▉         | 75/814 [02:22<22:45,  1.85s/ba]Running tokenizer on dataset:   9%|▉         | 76/814 [02:24<23:13,  1.89s/ba]Running tokenizer on dataset:   9%|▉         | 77/814 [02:26<25:01,  2.04s/ba]Running tokenizer on dataset:  10%|▉         | 78/814 [02:28<24:15,  1.98s/ba]Running tokenizer on dataset:  10%|▉         | 79/814 [02:30<23:28,  1.92s/ba]Running tokenizer on dataset:  10%|▉         | 80/814 [02:32<23:03,  1.89s/ba]Running tokenizer on dataset:  10%|▉         | 81/814 [02:33<22:52,  1.87s/ba]Running tokenizer on dataset:  10%|█         | 82/814 [02:35<22:44,  1.86s/ba]Running tokenizer on dataset:  10%|█         | 83/814 [02:37<22:30,  1.85s/ba]Running tokenizer on dataset:  10%|█         | 84/814 [02:39<22:19,  1.83s/ba]Running tokenizer on dataset:  10%|█         | 85/814 [02:41<22:10,  1.82s/ba]Running tokenizer on dataset:  11%|█         | 86/814 [02:42<22:00,  1.81s/ba]Running tokenizer on dataset:  11%|█         | 87/814 [02:44<21:58,  1.81s/ba]Running tokenizer on dataset:  11%|█         | 88/814 [02:46<21:53,  1.81s/ba]Running tokenizer on dataset:  11%|█         | 89/814 [02:48<21:58,  1.82s/ba]Running tokenizer on dataset:  11%|█         | 90/814 [02:50<21:47,  1.81s/ba]Running tokenizer on dataset:  11%|█         | 91/814 [02:51<21:51,  1.81s/ba]Running tokenizer on dataset:  11%|█▏        | 92/814 [02:53<21:43,  1.80s/ba]Running tokenizer on dataset:  11%|█▏        | 93/814 [02:55<21:43,  1.81s/ba]Running tokenizer on dataset:  12%|█▏        | 94/814 [02:57<21:34,  1.80s/ba]Running tokenizer on dataset:  12%|█▏        | 95/814 [02:59<21:24,  1.79s/ba]Running tokenizer on dataset:  12%|█▏        | 96/814 [03:00<21:31,  1.80s/ba]Running tokenizer on dataset:  12%|█▏        | 97/814 [03:02<21:29,  1.80s/ba]Running tokenizer on dataset:  12%|█▏        | 98/814 [03:04<21:24,  1.79s/ba]Running tokenizer on dataset:  12%|█▏        | 99/814 [03:06<21:23,  1.79s/ba]Running tokenizer on dataset:  12%|█▏        | 100/814 [03:08<21:18,  1.79s/ba]Running tokenizer on dataset:  12%|█▏        | 101/814 [03:09<21:22,  1.80s/ba]Running tokenizer on dataset:  13%|█▎        | 102/814 [03:11<21:15,  1.79s/ba]Running tokenizer on dataset:  13%|█▎        | 103/814 [03:13<21:10,  1.79s/ba]Running tokenizer on dataset:  13%|█▎        | 104/814 [03:15<21:04,  1.78s/ba]Running tokenizer on dataset:  13%|█▎        | 105/814 [03:16<21:00,  1.78s/ba]Running tokenizer on dataset:  13%|█▎        | 106/814 [03:18<21:02,  1.78s/ba]Running tokenizer on dataset:  13%|█▎        | 107/814 [03:21<22:57,  1.95s/ba]Running tokenizer on dataset:  13%|█▎        | 108/814 [03:23<24:58,  2.12s/ba]Running tokenizer on dataset:  13%|█▎        | 109/814 [03:26<25:56,  2.21s/ba]Running tokenizer on dataset:  14%|█▎        | 110/814 [03:28<26:22,  2.25s/ba]Running tokenizer on dataset:  14%|█▎        | 111/814 [03:30<26:44,  2.28s/ba]Running tokenizer on dataset:  14%|█▍        | 112/814 [03:33<27:01,  2.31s/ba]Running tokenizer on dataset:  14%|█▍        | 113/814 [03:35<27:44,  2.38s/ba]Running tokenizer on dataset:  14%|█▍        | 114/814 [03:38<27:48,  2.38s/ba]Running tokenizer on dataset:  14%|█▍        | 115/814 [03:40<27:54,  2.40s/ba]Running tokenizer on dataset:  14%|█▍        | 116/814 [03:42<27:47,  2.39s/ba]Running tokenizer on dataset:  14%|█▍        | 117/814 [03:45<27:49,  2.39s/ba]Running tokenizer on dataset:  14%|█▍        | 118/814 [03:47<28:00,  2.41s/ba]Running tokenizer on dataset:  15%|█▍        | 119/814 [03:50<27:28,  2.37s/ba]Running tokenizer on dataset:  15%|█▍        | 120/814 [03:52<27:13,  2.35s/ba]Running tokenizer on dataset:  15%|█▍        | 121/814 [03:54<27:23,  2.37s/ba]Running tokenizer on dataset:  15%|█▍        | 122/814 [03:57<27:19,  2.37s/ba]Running tokenizer on dataset:  15%|█▌        | 123/814 [03:59<27:08,  2.36s/ba]Running tokenizer on dataset:  15%|█▌        | 124/814 [04:01<27:09,  2.36s/ba]Running tokenizer on dataset:  15%|█▌        | 125/814 [04:04<27:02,  2.35s/ba]Running tokenizer on dataset:  15%|█▌        | 126/814 [04:06<27:11,  2.37s/ba]Running tokenizer on dataset:  16%|█▌        | 127/814 [04:08<27:13,  2.38s/ba]Running tokenizer on dataset:  16%|█▌        | 128/814 [04:11<26:54,  2.35s/ba]Running tokenizer on dataset:  16%|█▌        | 129/814 [04:13<27:03,  2.37s/ba]Running tokenizer on dataset:  16%|█▌        | 130/814 [04:15<26:52,  2.36s/ba]Running tokenizer on dataset:  16%|█▌        | 131/814 [04:18<26:55,  2.37s/ba]Running tokenizer on dataset:  16%|█▌        | 132/814 [04:20<26:42,  2.35s/ba]Running tokenizer on dataset:  16%|█▋        | 133/814 [04:23<26:40,  2.35s/ba]Running tokenizer on dataset:  16%|█▋        | 134/814 [04:25<26:28,  2.34s/ba]Running tokenizer on dataset:  17%|█▋        | 135/814 [04:27<26:28,  2.34s/ba]Running tokenizer on dataset:  17%|█▋        | 136/814 [04:29<24:33,  2.17s/ba]Running tokenizer on dataset:  17%|█▋        | 137/814 [04:31<23:09,  2.05s/ba]Running tokenizer on dataset:  17%|█▋        | 138/814 [04:33<22:12,  1.97s/ba]Running tokenizer on dataset:  17%|█▋        | 139/814 [04:34<21:31,  1.91s/ba]Running tokenizer on dataset:  17%|█▋        | 140/814 [04:37<22:50,  2.03s/ba]Running tokenizer on dataset:  17%|█▋        | 141/814 [04:39<23:48,  2.12s/ba]Running tokenizer on dataset:  17%|█▋        | 142/814 [04:41<24:41,  2.21s/ba]Running tokenizer on dataset:  18%|█▊        | 143/814 [04:44<25:02,  2.24s/ba]Running tokenizer on dataset:  18%|█▊        | 144/814 [04:46<25:23,  2.27s/ba]Running tokenizer on dataset:  18%|█▊        | 145/814 [04:48<24:32,  2.20s/ba]Running tokenizer on dataset:  18%|█▊        | 146/814 [04:50<22:58,  2.06s/ba]Running tokenizer on dataset:  18%|█▊        | 147/814 [04:52<22:11,  2.00s/ba]Running tokenizer on dataset:  18%|█▊        | 148/814 [04:53<21:34,  1.94s/ba]Running tokenizer on dataset:  18%|█▊        | 149/814 [04:55<20:46,  1.88s/ba]Running tokenizer on dataset:  18%|█▊        | 150/814 [04:57<20:25,  1.85s/ba]Running tokenizer on dataset:  19%|█▊        | 151/814 [04:59<20:02,  1.81s/ba]Running tokenizer on dataset:  19%|█▊        | 152/814 [05:00<19:48,  1.80s/ba]Running tokenizer on dataset:  19%|█▉        | 153/814 [05:02<19:47,  1.80s/ba]Running tokenizer on dataset:  19%|█▉        | 154/814 [05:04<19:48,  1.80s/ba]Running tokenizer on dataset:  19%|█▉        | 155/814 [05:06<19:32,  1.78s/ba]Running tokenizer on dataset:  19%|█▉        | 156/814 [05:08<19:28,  1.78s/ba]Running tokenizer on dataset:  19%|█▉        | 157/814 [05:09<19:51,  1.81s/ba]Running tokenizer on dataset:  19%|█▉        | 158/814 [05:11<19:32,  1.79s/ba]Running tokenizer on dataset:  20%|█▉        | 159/814 [05:13<19:27,  1.78s/ba]Running tokenizer on dataset:  20%|█▉        | 160/814 [05:15<20:09,  1.85s/ba]Running tokenizer on dataset:  20%|█▉        | 161/814 [05:17<19:45,  1.82s/ba]Running tokenizer on dataset:  20%|█▉        | 162/814 [05:18<19:37,  1.81s/ba]Running tokenizer on dataset:  20%|██        | 163/814 [05:20<19:25,  1.79s/ba]Running tokenizer on dataset:  20%|██        | 164/814 [05:22<19:23,  1.79s/ba]Running tokenizer on dataset:  20%|██        | 165/814 [05:24<19:27,  1.80s/ba]Running tokenizer on dataset:  20%|██        | 166/814 [05:26<19:23,  1.80s/ba]Running tokenizer on dataset:  21%|██        | 167/814 [05:27<19:16,  1.79s/ba]Running tokenizer on dataset:  21%|██        | 168/814 [05:29<19:06,  1.77s/ba]Running tokenizer on dataset:  21%|██        | 169/814 [05:31<19:01,  1.77s/ba]Running tokenizer on dataset:  21%|██        | 170/814 [05:33<18:52,  1.76s/ba]Running tokenizer on dataset:  21%|██        | 171/814 [05:34<18:56,  1.77s/ba]Running tokenizer on dataset:  21%|██        | 172/814 [05:36<18:59,  1.77s/ba]Running tokenizer on dataset:  21%|██▏       | 173/814 [05:38<19:16,  1.80s/ba]Running tokenizer on dataset:  21%|██▏       | 174/814 [05:40<19:08,  1.79s/ba]Running tokenizer on dataset:  21%|██▏       | 175/814 [05:42<18:57,  1.78s/ba]Running tokenizer on dataset:  22%|██▏       | 176/814 [05:43<18:48,  1.77s/ba]Running tokenizer on dataset:  22%|██▏       | 177/814 [05:45<18:45,  1.77s/ba]Running tokenizer on dataset:  22%|██▏       | 178/814 [05:47<18:47,  1.77s/ba]Running tokenizer on dataset:  22%|██▏       | 179/814 [05:49<18:43,  1.77s/ba]Running tokenizer on dataset:  22%|██▏       | 180/814 [05:50<18:37,  1.76s/ba]Running tokenizer on dataset:  22%|██▏       | 181/814 [05:52<18:35,  1.76s/ba]Running tokenizer on dataset:  22%|██▏       | 182/814 [05:54<18:36,  1.77s/ba]Running tokenizer on dataset:  22%|██▏       | 183/814 [05:56<18:37,  1.77s/ba]Running tokenizer on dataset:  23%|██▎       | 184/814 [05:57<18:31,  1.76s/ba]Running tokenizer on dataset:  23%|██▎       | 185/814 [05:59<18:28,  1.76s/ba]Running tokenizer on dataset:  23%|██▎       | 186/814 [06:01<18:29,  1.77s/ba]Running tokenizer on dataset:  23%|██▎       | 187/814 [06:03<18:20,  1.76s/ba]Running tokenizer on dataset:  23%|██▎       | 188/814 [06:04<18:16,  1.75s/ba]Running tokenizer on dataset:  23%|██▎       | 189/814 [06:06<18:13,  1.75s/ba]Running tokenizer on dataset:  23%|██▎       | 190/814 [06:08<18:09,  1.75s/ba]Running tokenizer on dataset:  23%|██▎       | 191/814 [06:10<18:19,  1.76s/ba]Running tokenizer on dataset:  24%|██▎       | 192/814 [06:12<18:15,  1.76s/ba]Running tokenizer on dataset:  24%|██▎       | 193/814 [06:13<18:18,  1.77s/ba]Running tokenizer on dataset:  24%|██▍       | 194/814 [06:15<18:09,  1.76s/ba]Running tokenizer on dataset:  24%|██▍       | 195/814 [06:17<18:11,  1.76s/ba]Running tokenizer on dataset:  24%|██▍       | 196/814 [06:19<18:04,  1.75s/ba]Running tokenizer on dataset:  24%|██▍       | 197/814 [06:20<17:59,  1.75s/ba]Running tokenizer on dataset:  24%|██▍       | 198/814 [06:22<18:06,  1.76s/ba]Running tokenizer on dataset:  24%|██▍       | 199/814 [06:24<17:57,  1.75s/ba]Running tokenizer on dataset:  25%|██▍       | 200/814 [06:25<17:46,  1.74s/ba]Running tokenizer on dataset:  25%|██▍       | 201/814 [06:27<17:44,  1.74s/ba]Running tokenizer on dataset:  25%|██▍       | 202/814 [06:29<17:44,  1.74s/ba]Running tokenizer on dataset:  25%|██▍       | 203/814 [06:31<17:41,  1.74s/ba]Running tokenizer on dataset:  25%|██▌       | 204/814 [06:32<17:44,  1.75s/ba]Running tokenizer on dataset:  25%|██▌       | 205/814 [06:34<17:36,  1.74s/ba]Running tokenizer on dataset:  25%|██▌       | 206/814 [06:36<17:39,  1.74s/ba]Running tokenizer on dataset:  25%|██▌       | 207/814 [06:38<17:40,  1.75s/ba]Running tokenizer on dataset:  26%|██▌       | 208/814 [06:39<17:34,  1.74s/ba]Running tokenizer on dataset:  26%|██▌       | 209/814 [06:41<17:42,  1.76s/ba]Running tokenizer on dataset:  26%|██▌       | 210/814 [06:43<17:39,  1.75s/ba]Running tokenizer on dataset:  26%|██▌       | 211/814 [06:45<17:35,  1.75s/ba]Running tokenizer on dataset:  26%|██▌       | 212/814 [06:46<17:24,  1.73s/ba]Running tokenizer on dataset:  26%|██▌       | 213/814 [06:48<17:15,  1.72s/ba]Running tokenizer on dataset:  26%|██▋       | 214/814 [06:50<17:07,  1.71s/ba]Running tokenizer on dataset:  26%|██▋       | 215/814 [06:52<17:14,  1.73s/ba]Running tokenizer on dataset:  27%|██▋       | 216/814 [06:53<17:11,  1.72s/ba]Running tokenizer on dataset:  27%|██▋       | 217/814 [06:55<17:15,  1.74s/ba]Running tokenizer on dataset:  27%|██▋       | 218/814 [06:57<17:19,  1.74s/ba]Running tokenizer on dataset:  27%|██▋       | 219/814 [06:59<17:21,  1.75s/ba]Running tokenizer on dataset:  27%|██▋       | 220/814 [07:00<17:11,  1.74s/ba]Running tokenizer on dataset:  27%|██▋       | 221/814 [07:02<17:14,  1.74s/ba]Running tokenizer on dataset:  27%|██▋       | 222/814 [07:04<17:01,  1.73s/ba]Running tokenizer on dataset:  27%|██▋       | 223/814 [07:05<17:05,  1.73s/ba]Running tokenizer on dataset:  28%|██▊       | 224/814 [07:07<17:04,  1.74s/ba]Running tokenizer on dataset:  28%|██▊       | 225/814 [07:09<17:06,  1.74s/ba]Running tokenizer on dataset:  28%|██▊       | 226/814 [07:11<17:01,  1.74s/ba]Running tokenizer on dataset:  28%|██▊       | 227/814 [07:12<17:05,  1.75s/ba]Running tokenizer on dataset:  28%|██▊       | 228/814 [07:14<16:51,  1.73s/ba]Running tokenizer on dataset:  28%|██▊       | 229/814 [07:16<16:54,  1.73s/ba]Running tokenizer on dataset:  28%|██▊       | 230/814 [07:18<16:49,  1.73s/ba]Running tokenizer on dataset:  28%|██▊       | 231/814 [07:19<16:47,  1.73s/ba]Running tokenizer on dataset:  29%|██▊       | 232/814 [07:21<16:38,  1.72s/ba]Running tokenizer on dataset:  29%|██▊       | 233/814 [07:23<16:44,  1.73s/ba]Running tokenizer on dataset:  29%|██▊       | 234/814 [07:25<16:43,  1.73s/ba]Running tokenizer on dataset:  29%|██▉       | 235/814 [07:26<16:42,  1.73s/ba]Running tokenizer on dataset:  29%|██▉       | 236/814 [07:28<16:44,  1.74s/ba]Running tokenizer on dataset:  29%|██▉       | 237/814 [07:30<16:42,  1.74s/ba]Running tokenizer on dataset:  29%|██▉       | 238/814 [07:32<17:09,  1.79s/ba]Running tokenizer on dataset:  29%|██▉       | 239/814 [07:33<17:02,  1.78s/ba]Running tokenizer on dataset:  29%|██▉       | 240/814 [07:35<16:55,  1.77s/ba]Running tokenizer on dataset:  30%|██▉       | 241/814 [07:37<16:45,  1.75s/ba]Running tokenizer on dataset:  30%|██▉       | 242/814 [07:39<16:36,  1.74s/ba]Running tokenizer on dataset:  30%|██▉       | 243/814 [07:40<16:31,  1.74s/ba]Running tokenizer on dataset:  30%|██▉       | 244/814 [07:42<16:33,  1.74s/ba]Running tokenizer on dataset:  30%|███       | 245/814 [07:44<16:30,  1.74s/ba]Running tokenizer on dataset:  30%|███       | 246/814 [07:46<16:27,  1.74s/ba]Running tokenizer on dataset:  30%|███       | 247/814 [07:47<16:25,  1.74s/ba]Running tokenizer on dataset:  30%|███       | 248/814 [07:49<16:33,  1.75s/ba]Running tokenizer on dataset:  31%|███       | 249/814 [07:51<16:36,  1.76s/ba]Running tokenizer on dataset:  31%|███       | 250/814 [07:53<16:32,  1.76s/ba]Running tokenizer on dataset:  31%|███       | 251/814 [07:54<16:31,  1.76s/ba]Running tokenizer on dataset:  31%|███       | 252/814 [07:56<16:28,  1.76s/ba]Running tokenizer on dataset:  31%|███       | 253/814 [07:58<16:31,  1.77s/ba]Running tokenizer on dataset:  31%|███       | 254/814 [08:00<16:30,  1.77s/ba]Running tokenizer on dataset:  31%|███▏      | 255/814 [08:01<16:26,  1.76s/ba]Running tokenizer on dataset:  31%|███▏      | 256/814 [08:03<16:15,  1.75s/ba]Running tokenizer on dataset:  32%|███▏      | 257/814 [08:05<16:07,  1.74s/ba]Running tokenizer on dataset:  32%|███▏      | 258/814 [08:07<16:07,  1.74s/ba]Running tokenizer on dataset:  32%|███▏      | 259/814 [08:08<16:06,  1.74s/ba]Running tokenizer on dataset:  32%|███▏      | 260/814 [08:10<16:05,  1.74s/ba]Running tokenizer on dataset:  32%|███▏      | 261/814 [08:12<16:02,  1.74s/ba]Running tokenizer on dataset:  32%|███▏      | 262/814 [08:14<16:05,  1.75s/ba]Running tokenizer on dataset:  32%|███▏      | 263/814 [08:15<16:06,  1.75s/ba]Running tokenizer on dataset:  32%|███▏      | 264/814 [08:17<16:01,  1.75s/ba]Running tokenizer on dataset:  33%|███▎      | 265/814 [08:19<16:01,  1.75s/ba]Running tokenizer on dataset:  33%|███▎      | 266/814 [08:21<16:02,  1.76s/ba]Running tokenizer on dataset:  33%|███▎      | 267/814 [08:22<15:55,  1.75s/ba]Running tokenizer on dataset:  33%|███▎      | 268/814 [08:24<15:48,  1.74s/ba]Running tokenizer on dataset:  33%|███▎      | 269/814 [08:26<15:46,  1.74s/ba]Running tokenizer on dataset:  33%|███▎      | 270/814 [08:28<15:45,  1.74s/ba]Running tokenizer on dataset:  33%|███▎      | 271/814 [08:29<15:44,  1.74s/ba]Running tokenizer on dataset:  33%|███▎      | 272/814 [08:31<15:42,  1.74s/ba]Running tokenizer on dataset:  34%|███▎      | 273/814 [08:33<15:46,  1.75s/ba]Running tokenizer on dataset:  34%|███▎      | 274/814 [08:34<15:38,  1.74s/ba]Running tokenizer on dataset:  34%|███▍      | 275/814 [08:36<15:34,  1.73s/ba]Running tokenizer on dataset:  34%|███▍      | 276/814 [08:38<15:36,  1.74s/ba]Running tokenizer on dataset:  34%|███▍      | 277/814 [08:40<15:42,  1.76s/ba]Running tokenizer on dataset:  34%|███▍      | 278/814 [08:42<15:40,  1.76s/ba]Running tokenizer on dataset:  34%|███▍      | 279/814 [08:43<15:35,  1.75s/ba]Running tokenizer on dataset:  34%|███▍      | 280/814 [08:45<15:29,  1.74s/ba]Running tokenizer on dataset:  35%|███▍      | 281/814 [08:47<15:26,  1.74s/ba]Running tokenizer on dataset:  35%|███▍      | 282/814 [08:48<15:27,  1.74s/ba]Running tokenizer on dataset:  35%|███▍      | 283/814 [08:50<15:26,  1.74s/ba]Running tokenizer on dataset:  35%|███▍      | 284/814 [08:52<15:22,  1.74s/ba]Running tokenizer on dataset:  35%|███▌      | 285/814 [08:54<15:19,  1.74s/ba]Running tokenizer on dataset:  35%|███▌      | 286/814 [08:55<15:14,  1.73s/ba]Running tokenizer on dataset:  35%|███▌      | 287/814 [08:57<15:15,  1.74s/ba]Running tokenizer on dataset:  35%|███▌      | 288/814 [08:59<15:13,  1.74s/ba]Running tokenizer on dataset:  36%|███▌      | 289/814 [09:01<15:16,  1.75s/ba]Running tokenizer on dataset:  36%|███▌      | 290/814 [09:02<15:12,  1.74s/ba]Running tokenizer on dataset:  36%|███▌      | 291/814 [09:04<15:09,  1.74s/ba]Running tokenizer on dataset:  36%|███▌      | 292/814 [09:06<15:05,  1.73s/ba]Running tokenizer on dataset:  36%|███▌      | 293/814 [09:08<15:04,  1.74s/ba]Running tokenizer on dataset:  36%|███▌      | 294/814 [09:09<15:02,  1.73s/ba]Running tokenizer on dataset:  36%|███▌      | 295/814 [09:11<14:56,  1.73s/ba]Running tokenizer on dataset:  36%|███▋      | 296/814 [09:13<14:57,  1.73s/ba]Running tokenizer on dataset:  36%|███▋      | 297/814 [09:15<15:01,  1.74s/ba]Running tokenizer on dataset:  37%|███▋      | 298/814 [09:16<15:01,  1.75s/ba]Running tokenizer on dataset:  37%|███▋      | 299/814 [09:18<14:55,  1.74s/ba]Running tokenizer on dataset:  37%|███▋      | 300/814 [09:20<14:53,  1.74s/ba]Running tokenizer on dataset:  37%|███▋      | 301/814 [09:21<14:50,  1.74s/ba]Running tokenizer on dataset:  37%|███▋      | 302/814 [09:23<14:40,  1.72s/ba]Running tokenizer on dataset:  37%|███▋      | 303/814 [09:25<14:44,  1.73s/ba]Running tokenizer on dataset:  37%|███▋      | 304/814 [09:27<14:43,  1.73s/ba]Running tokenizer on dataset:  37%|███▋      | 305/814 [09:28<14:43,  1.73s/ba]Running tokenizer on dataset:  38%|███▊      | 306/814 [09:30<14:40,  1.73s/ba]Running tokenizer on dataset:  38%|███▊      | 307/814 [09:32<14:40,  1.74s/ba]Running tokenizer on dataset:  38%|███▊      | 308/814 [09:34<14:33,  1.73s/ba]Running tokenizer on dataset:  38%|███▊      | 309/814 [09:35<14:37,  1.74s/ba]Running tokenizer on dataset:  38%|███▊      | 310/814 [09:37<14:27,  1.72s/ba]Running tokenizer on dataset:  38%|███▊      | 311/814 [09:39<14:34,  1.74s/ba]Running tokenizer on dataset:  38%|███▊      | 312/814 [09:41<14:32,  1.74s/ba]Running tokenizer on dataset:  38%|███▊      | 313/814 [09:42<14:24,  1.73s/ba]Running tokenizer on dataset:  39%|███▊      | 314/814 [09:44<14:26,  1.73s/ba]Running tokenizer on dataset:  39%|███▊      | 315/814 [09:46<14:29,  1.74s/ba]Running tokenizer on dataset:  39%|███▉      | 316/814 [09:47<14:22,  1.73s/ba]Running tokenizer on dataset:  39%|███▉      | 317/814 [09:49<14:28,  1.75s/ba]Running tokenizer on dataset:  39%|███▉      | 318/814 [09:51<14:20,  1.73s/ba]Running tokenizer on dataset:  39%|███▉      | 319/814 [09:53<14:42,  1.78s/ba]Running tokenizer on dataset:  39%|███▉      | 320/814 [09:54<14:20,  1.74s/ba]Running tokenizer on dataset:  39%|███▉      | 321/814 [09:56<14:18,  1.74s/ba]Running tokenizer on dataset:  40%|███▉      | 322/814 [09:58<14:17,  1.74s/ba]Running tokenizer on dataset:  40%|███▉      | 323/814 [10:00<14:14,  1.74s/ba]Running tokenizer on dataset:  40%|███▉      | 324/814 [10:01<14:09,  1.73s/ba]Running tokenizer on dataset:  40%|███▉      | 325/814 [10:03<14:10,  1.74s/ba]Running tokenizer on dataset:  40%|████      | 326/814 [10:05<14:06,  1.73s/ba]Running tokenizer on dataset:  40%|████      | 327/814 [10:07<14:00,  1.73s/ba]Running tokenizer on dataset:  40%|████      | 328/814 [10:09<15:14,  1.88s/ba]Running tokenizer on dataset:  40%|████      | 329/814 [10:11<16:14,  2.01s/ba]Running tokenizer on dataset:  41%|████      | 330/814 [10:13<16:53,  2.09s/ba]Running tokenizer on dataset:  41%|████      | 331/814 [10:16<17:00,  2.11s/ba]Running tokenizer on dataset:  41%|████      | 332/814 [10:17<16:02,  2.00s/ba]Running tokenizer on dataset:  41%|████      | 333/814 [10:19<15:26,  1.93s/ba]Running tokenizer on dataset:  41%|████      | 334/814 [10:21<16:17,  2.04s/ba]Running tokenizer on dataset:  41%|████      | 335/814 [10:24<16:52,  2.11s/ba]Running tokenizer on dataset:  41%|████▏     | 336/814 [10:26<17:20,  2.18s/ba]Running tokenizer on dataset:  41%|████▏     | 337/814 [10:28<17:40,  2.22s/ba]Running tokenizer on dataset:  42%|████▏     | 338/814 [10:31<17:36,  2.22s/ba]Running tokenizer on dataset:  42%|████▏     | 339/814 [10:33<17:37,  2.23s/ba]Running tokenizer on dataset:  42%|████▏     | 340/814 [10:35<17:44,  2.25s/ba]Running tokenizer on dataset:  42%|████▏     | 341/814 [10:37<17:54,  2.27s/ba]Running tokenizer on dataset:  42%|████▏     | 342/814 [10:40<17:47,  2.26s/ba]Running tokenizer on dataset:  42%|████▏     | 343/814 [10:42<17:50,  2.27s/ba]Running tokenizer on dataset:  42%|████▏     | 344/814 [10:44<17:42,  2.26s/ba]Running tokenizer on dataset:  42%|████▏     | 345/814 [10:46<17:46,  2.27s/ba]Running tokenizer on dataset:  43%|████▎     | 346/814 [10:49<17:43,  2.27s/ba]Running tokenizer on dataset:  43%|████▎     | 347/814 [10:51<17:49,  2.29s/ba]Running tokenizer on dataset:  43%|████▎     | 348/814 [10:53<17:43,  2.28s/ba]Running tokenizer on dataset:  43%|████▎     | 349/814 [10:56<17:38,  2.28s/ba]Running tokenizer on dataset:  43%|████▎     | 350/814 [10:58<17:38,  2.28s/ba]Running tokenizer on dataset:  43%|████▎     | 351/814 [11:00<17:29,  2.27s/ba]Running tokenizer on dataset:  43%|████▎     | 352/814 [11:02<17:20,  2.25s/ba]Running tokenizer on dataset:  43%|████▎     | 353/814 [11:04<16:31,  2.15s/ba]Running tokenizer on dataset:  43%|████▎     | 354/814 [11:06<15:23,  2.01s/ba]Running tokenizer on dataset:  44%|████▎     | 355/814 [11:08<15:08,  1.98s/ba]Running tokenizer on dataset:  44%|████▎     | 356/814 [11:10<14:28,  1.90s/ba]Running tokenizer on dataset:  44%|████▍     | 357/814 [11:11<13:58,  1.84s/ba]Running tokenizer on dataset:  44%|████▍     | 358/814 [11:13<13:43,  1.81s/ba]Running tokenizer on dataset:  44%|████▍     | 359/814 [11:15<13:32,  1.79s/ba]Running tokenizer on dataset:  44%|████▍     | 360/814 [11:16<13:21,  1.77s/ba]Running tokenizer on dataset:  44%|████▍     | 361/814 [11:18<13:06,  1.74s/ba]Running tokenizer on dataset:  44%|████▍     | 362/814 [11:20<13:00,  1.73s/ba]Running tokenizer on dataset:  45%|████▍     | 363/814 [11:22<12:55,  1.72s/ba]Running tokenizer on dataset:  45%|████▍     | 364/814 [11:23<12:50,  1.71s/ba]Running tokenizer on dataset:  45%|████▍     | 365/814 [11:25<12:48,  1.71s/ba]Running tokenizer on dataset:  45%|████▍     | 366/814 [11:27<12:55,  1.73s/ba]Running tokenizer on dataset:  45%|████▌     | 367/814 [11:28<12:52,  1.73s/ba]Running tokenizer on dataset:  45%|████▌     | 368/814 [11:30<12:42,  1.71s/ba]Running tokenizer on dataset:  45%|████▌     | 369/814 [11:32<12:43,  1.72s/ba]Running tokenizer on dataset:  45%|████▌     | 370/814 [11:34<12:42,  1.72s/ba]Running tokenizer on dataset:  46%|████▌     | 371/814 [11:35<12:42,  1.72s/ba]Running tokenizer on dataset:  46%|████▌     | 372/814 [11:37<12:34,  1.71s/ba]Running tokenizer on dataset:  46%|████▌     | 373/814 [11:39<12:35,  1.71s/ba]Running tokenizer on dataset:  46%|████▌     | 374/814 [11:40<12:34,  1.71s/ba]Running tokenizer on dataset:  46%|████▌     | 375/814 [11:42<12:39,  1.73s/ba]Running tokenizer on dataset:  46%|████▌     | 376/814 [11:44<12:41,  1.74s/ba]Running tokenizer on dataset:  46%|████▋     | 377/814 [11:46<12:35,  1.73s/ba]Running tokenizer on dataset:  46%|████▋     | 378/814 [11:47<12:30,  1.72s/ba]Running tokenizer on dataset:  47%|████▋     | 379/814 [11:49<12:27,  1.72s/ba]Running tokenizer on dataset:  47%|████▋     | 380/814 [11:51<12:26,  1.72s/ba]Running tokenizer on dataset:  47%|████▋     | 381/814 [11:52<12:25,  1.72s/ba]Running tokenizer on dataset:  47%|████▋     | 382/814 [11:54<12:19,  1.71s/ba]Running tokenizer on dataset:  47%|████▋     | 383/814 [11:56<12:15,  1.71s/ba]Running tokenizer on dataset:  47%|████▋     | 384/814 [11:58<12:15,  1.71s/ba]Running tokenizer on dataset:  47%|████▋     | 385/814 [11:59<12:17,  1.72s/ba]Running tokenizer on dataset:  47%|████▋     | 386/814 [12:01<12:13,  1.71s/ba]Running tokenizer on dataset:  48%|████▊     | 387/814 [12:03<12:13,  1.72s/ba]Running tokenizer on dataset:  48%|████▊     | 388/814 [12:04<12:06,  1.71s/ba]Running tokenizer on dataset:  48%|████▊     | 389/814 [12:06<12:09,  1.72s/ba]Running tokenizer on dataset:  48%|████▊     | 390/814 [12:08<12:06,  1.71s/ba]Running tokenizer on dataset:  48%|████▊     | 391/814 [12:10<12:05,  1.71s/ba]Running tokenizer on dataset:  48%|████▊     | 392/814 [12:11<12:06,  1.72s/ba]Running tokenizer on dataset:  48%|████▊     | 393/814 [12:13<12:06,  1.73s/ba]Running tokenizer on dataset:  48%|████▊     | 394/814 [12:15<12:06,  1.73s/ba]Running tokenizer on dataset:  49%|████▊     | 395/814 [12:17<12:04,  1.73s/ba]Running tokenizer on dataset:  49%|████▊     | 396/814 [12:18<12:03,  1.73s/ba]Running tokenizer on dataset:  49%|████▉     | 397/814 [12:20<11:57,  1.72s/ba]Running tokenizer on dataset:  49%|████▉     | 398/814 [12:22<11:59,  1.73s/ba]Running tokenizer on dataset:  49%|████▉     | 399/814 [12:23<11:54,  1.72s/ba]Running tokenizer on dataset:  49%|████▉     | 400/814 [12:25<12:11,  1.77s/ba]Running tokenizer on dataset:  49%|████▉     | 401/814 [12:27<12:00,  1.74s/ba]Running tokenizer on dataset:  49%|████▉     | 402/814 [12:29<11:56,  1.74s/ba]Running tokenizer on dataset:  50%|████▉     | 403/814 [12:30<11:49,  1.73s/ba]Running tokenizer on dataset:  50%|████▉     | 404/814 [12:32<11:46,  1.72s/ba]Running tokenizer on dataset:  50%|████▉     | 405/814 [12:34<11:49,  1.74s/ba]Running tokenizer on dataset:  50%|████▉     | 406/814 [12:36<12:19,  1.81s/ba]Running tokenizer on dataset:  50%|█████     | 407/814 [12:38<13:19,  1.96s/ba]Running tokenizer on dataset:  50%|█████     | 408/814 [12:40<13:55,  2.06s/ba]Running tokenizer on dataset:  50%|█████     | 409/814 [12:43<14:16,  2.11s/ba]Running tokenizer on dataset:  50%|█████     | 410/814 [12:45<14:26,  2.14s/ba]Running tokenizer on dataset:  50%|█████     | 411/814 [12:47<14:37,  2.18s/ba]Running tokenizer on dataset:  51%|█████     | 412/814 [12:49<13:37,  2.03s/ba]Running tokenizer on dataset:  51%|█████     | 413/814 [12:51<12:57,  1.94s/ba]Running tokenizer on dataset:  51%|█████     | 414/814 [12:52<12:33,  1.88s/ba]Running tokenizer on dataset:  51%|█████     | 415/814 [12:54<12:14,  1.84s/ba]Running tokenizer on dataset:  51%|█████     | 416/814 [12:56<12:00,  1.81s/ba]Running tokenizer on dataset:  51%|█████     | 417/814 [12:58<11:46,  1.78s/ba]Running tokenizer on dataset:  51%|█████▏    | 418/814 [12:59<11:35,  1.76s/ba]Running tokenizer on dataset:  51%|█████▏    | 419/814 [13:01<11:29,  1.75s/ba]Running tokenizer on dataset:  52%|█████▏    | 420/814 [13:03<11:27,  1.74s/ba]Running tokenizer on dataset:  52%|█████▏    | 421/814 [13:04<11:24,  1.74s/ba]Running tokenizer on dataset:  52%|█████▏    | 422/814 [13:06<11:23,  1.74s/ba]Running tokenizer on dataset:  52%|█████▏    | 423/814 [13:08<11:15,  1.73s/ba]Running tokenizer on dataset:  52%|█████▏    | 424/814 [13:10<11:09,  1.72s/ba]Running tokenizer on dataset:  52%|█████▏    | 425/814 [13:11<11:09,  1.72s/ba]Running tokenizer on dataset:  52%|█████▏    | 426/814 [13:13<11:07,  1.72s/ba]Running tokenizer on dataset:  52%|█████▏    | 427/814 [13:15<11:02,  1.71s/ba]Running tokenizer on dataset:  53%|█████▎    | 428/814 [13:16<11:02,  1.72s/ba]Running tokenizer on dataset:  53%|█████▎    | 429/814 [13:18<11:02,  1.72s/ba]Running tokenizer on dataset:  53%|█████▎    | 430/814 [13:20<11:00,  1.72s/ba]Running tokenizer on dataset:  53%|█████▎    | 431/814 [13:22<10:58,  1.72s/ba]Running tokenizer on dataset:  53%|█████▎    | 432/814 [13:23<10:52,  1.71s/ba]Running tokenizer on dataset:  53%|█████▎    | 433/814 [13:25<10:55,  1.72s/ba]Running tokenizer on dataset:  53%|█████▎    | 434/814 [13:27<10:53,  1.72s/ba]Running tokenizer on dataset:  53%|█████▎    | 435/814 [13:28<10:49,  1.71s/ba]Running tokenizer on dataset:  54%|█████▎    | 436/814 [13:30<10:46,  1.71s/ba]Running tokenizer on dataset:  54%|█████▎    | 437/814 [13:32<10:45,  1.71s/ba]Running tokenizer on dataset:  54%|█████▍    | 438/814 [13:34<10:43,  1.71s/ba]Running tokenizer on dataset:  54%|█████▍    | 439/814 [13:35<10:44,  1.72s/ba]Running tokenizer on dataset:  54%|█████▍    | 440/814 [13:37<10:47,  1.73s/ba]Running tokenizer on dataset:  54%|█████▍    | 441/814 [13:39<10:44,  1.73s/ba]Running tokenizer on dataset:  54%|█████▍    | 442/814 [13:41<10:42,  1.73s/ba]Running tokenizer on dataset:  54%|█████▍    | 443/814 [13:42<10:38,  1.72s/ba]Running tokenizer on dataset:  55%|█████▍    | 444/814 [13:44<10:35,  1.72s/ba]Running tokenizer on dataset:  55%|█████▍    | 445/814 [13:46<10:32,  1.71s/ba]Running tokenizer on dataset:  55%|█████▍    | 446/814 [13:47<10:38,  1.73s/ba]Running tokenizer on dataset:  55%|█████▍    | 447/814 [13:49<10:36,  1.73s/ba]Running tokenizer on dataset:  55%|█████▌    | 448/814 [13:51<10:35,  1.74s/ba]Running tokenizer on dataset:  55%|█████▌    | 449/814 [13:53<10:33,  1.74s/ba]Running tokenizer on dataset:  55%|█████▌    | 450/814 [13:54<10:30,  1.73s/ba]Running tokenizer on dataset:  55%|█████▌    | 451/814 [13:56<10:24,  1.72s/ba]Running tokenizer on dataset:  56%|█████▌    | 452/814 [13:58<10:25,  1.73s/ba]Running tokenizer on dataset:  56%|█████▌    | 453/814 [14:00<10:24,  1.73s/ba]Running tokenizer on dataset:  56%|█████▌    | 454/814 [14:01<10:23,  1.73s/ba]Running tokenizer on dataset:  56%|█████▌    | 455/814 [14:03<10:23,  1.74s/ba]Running tokenizer on dataset:  56%|█████▌    | 456/814 [14:05<10:20,  1.73s/ba]Running tokenizer on dataset:  56%|█████▌    | 457/814 [14:06<10:17,  1.73s/ba]Running tokenizer on dataset:  56%|█████▋    | 458/814 [14:08<10:11,  1.72s/ba]Running tokenizer on dataset:  56%|█████▋    | 459/814 [14:10<10:09,  1.72s/ba]Running tokenizer on dataset:  57%|█████▋    | 460/814 [14:12<10:07,  1.72s/ba]Running tokenizer on dataset:  57%|█████▋    | 461/814 [14:13<10:11,  1.73s/ba]Running tokenizer on dataset:  57%|█████▋    | 462/814 [14:15<10:05,  1.72s/ba]Running tokenizer on dataset:  57%|█████▋    | 463/814 [14:17<10:12,  1.74s/ba]Running tokenizer on dataset:  57%|█████▋    | 464/814 [14:19<10:06,  1.73s/ba]Running tokenizer on dataset:  57%|█████▋    | 465/814 [14:20<10:05,  1.74s/ba]Running tokenizer on dataset:  57%|█████▋    | 466/814 [14:22<10:02,  1.73s/ba]Running tokenizer on dataset:  57%|█████▋    | 467/814 [14:24<10:03,  1.74s/ba]Running tokenizer on dataset:  57%|█████▋    | 468/814 [14:25<09:58,  1.73s/ba]Running tokenizer on dataset:  58%|█████▊    | 469/814 [14:27<09:52,  1.72s/ba]Running tokenizer on dataset:  58%|█████▊    | 470/814 [14:29<09:50,  1.72s/ba]Running tokenizer on dataset:  58%|█████▊    | 471/814 [14:31<09:51,  1.72s/ba]Running tokenizer on dataset:  58%|█████▊    | 472/814 [14:32<09:49,  1.72s/ba]Running tokenizer on dataset:  58%|█████▊    | 473/814 [14:34<09:45,  1.72s/ba]Running tokenizer on dataset:  58%|█████▊    | 474/814 [14:36<09:42,  1.71s/ba]Running tokenizer on dataset:  58%|█████▊    | 475/814 [14:37<09:39,  1.71s/ba]Running tokenizer on dataset:  58%|█████▊    | 476/814 [14:39<09:38,  1.71s/ba]Running tokenizer on dataset:  59%|█████▊    | 477/814 [14:41<09:38,  1.72s/ba]Running tokenizer on dataset:  59%|█████▊    | 478/814 [14:43<09:36,  1.72s/ba]Running tokenizer on dataset:  59%|█████▉    | 479/814 [14:44<09:35,  1.72s/ba]Running tokenizer on dataset:  59%|█████▉    | 480/814 [14:46<09:33,  1.72s/ba]Running tokenizer on dataset:  59%|█████▉    | 481/814 [14:48<09:48,  1.77s/ba]Running tokenizer on dataset:  59%|█████▉    | 482/814 [14:50<09:44,  1.76s/ba]Running tokenizer on dataset:  59%|█████▉    | 483/814 [14:51<09:38,  1.75s/ba]Running tokenizer on dataset:  59%|█████▉    | 484/814 [14:53<09:39,  1.75s/ba]Running tokenizer on dataset:  60%|█████▉    | 485/814 [14:55<09:31,  1.74s/ba]Running tokenizer on dataset:  60%|█████▉    | 486/814 [14:57<09:22,  1.71s/ba]Running tokenizer on dataset:  60%|█████▉    | 487/814 [14:58<09:20,  1.71s/ba]Running tokenizer on dataset:  60%|█████▉    | 488/814 [15:00<09:20,  1.72s/ba]Running tokenizer on dataset:  60%|██████    | 489/814 [15:02<09:21,  1.73s/ba]Running tokenizer on dataset:  60%|██████    | 490/814 [15:03<09:22,  1.73s/ba]Running tokenizer on dataset:  60%|██████    | 491/814 [15:05<09:19,  1.73s/ba]Running tokenizer on dataset:  60%|██████    | 492/814 [15:07<09:13,  1.72s/ba]Running tokenizer on dataset:  61%|██████    | 493/814 [15:09<09:11,  1.72s/ba]Running tokenizer on dataset:  61%|██████    | 494/814 [15:10<09:10,  1.72s/ba]Running tokenizer on dataset:  61%|██████    | 495/814 [15:12<09:10,  1.73s/ba]Running tokenizer on dataset:  61%|██████    | 496/814 [15:14<09:07,  1.72s/ba]Running tokenizer on dataset:  61%|██████    | 497/814 [15:15<09:02,  1.71s/ba]Running tokenizer on dataset:  61%|██████    | 498/814 [15:17<08:59,  1.71s/ba]Running tokenizer on dataset:  61%|██████▏   | 499/814 [15:19<08:57,  1.71s/ba]Running tokenizer on dataset:  61%|██████▏   | 500/814 [15:21<08:57,  1.71s/ba]Running tokenizer on dataset:  62%|██████▏   | 501/814 [15:22<08:58,  1.72s/ba]Running tokenizer on dataset:  62%|██████▏   | 502/814 [15:24<08:56,  1.72s/ba]Running tokenizer on dataset:  62%|██████▏   | 503/814 [15:26<08:53,  1.72s/ba]Running tokenizer on dataset:  62%|██████▏   | 504/814 [15:28<08:55,  1.73s/ba]Running tokenizer on dataset:  62%|██████▏   | 505/814 [15:29<08:55,  1.73s/ba]Running tokenizer on dataset:  62%|██████▏   | 506/814 [15:31<08:51,  1.73s/ba]Running tokenizer on dataset:  62%|██████▏   | 507/814 [15:33<08:49,  1.73s/ba]Running tokenizer on dataset:  62%|██████▏   | 508/814 [15:34<08:47,  1.72s/ba]Running tokenizer on dataset:  63%|██████▎   | 509/814 [15:36<08:51,  1.74s/ba]Running tokenizer on dataset:  63%|██████▎   | 510/814 [15:38<08:47,  1.74s/ba]Running tokenizer on dataset:  63%|██████▎   | 511/814 [15:40<08:44,  1.73s/ba]Running tokenizer on dataset:  63%|██████▎   | 512/814 [15:41<08:42,  1.73s/ba]Running tokenizer on dataset:  63%|██████▎   | 513/814 [15:43<08:45,  1.75s/ba]Running tokenizer on dataset:  63%|██████▎   | 514/814 [15:45<08:40,  1.73s/ba]Running tokenizer on dataset:  63%|██████▎   | 515/814 [15:47<08:39,  1.74s/ba]Running tokenizer on dataset:  63%|██████▎   | 516/814 [15:48<08:41,  1.75s/ba]Running tokenizer on dataset:  64%|██████▎   | 517/814 [15:50<08:41,  1.76s/ba]Running tokenizer on dataset:  64%|██████▎   | 518/814 [15:52<08:38,  1.75s/ba]Running tokenizer on dataset:  64%|██████▍   | 519/814 [15:54<08:34,  1.74s/ba]Running tokenizer on dataset:  64%|██████▍   | 520/814 [15:55<08:32,  1.74s/ba]Running tokenizer on dataset:  64%|██████▍   | 521/814 [15:57<08:27,  1.73s/ba]Running tokenizer on dataset:  64%|██████▍   | 522/814 [15:59<08:25,  1.73s/ba]Running tokenizer on dataset:  64%|██████▍   | 523/814 [16:00<08:20,  1.72s/ba]Running tokenizer on dataset:  64%|██████▍   | 524/814 [16:02<08:20,  1.73s/ba]Running tokenizer on dataset:  64%|██████▍   | 525/814 [16:04<08:15,  1.71s/ba]Running tokenizer on dataset:  65%|██████▍   | 526/814 [16:06<08:14,  1.72s/ba]Running tokenizer on dataset:  65%|██████▍   | 527/814 [16:07<08:16,  1.73s/ba]Running tokenizer on dataset:  65%|██████▍   | 528/814 [16:09<08:15,  1.73s/ba]Running tokenizer on dataset:  65%|██████▍   | 529/814 [16:11<08:12,  1.73s/ba]Running tokenizer on dataset:  65%|██████▌   | 530/814 [16:13<08:13,  1.74s/ba]Running tokenizer on dataset:  65%|██████▌   | 531/814 [16:14<08:11,  1.74s/ba]Running tokenizer on dataset:  65%|██████▌   | 532/814 [16:16<08:13,  1.75s/ba]Running tokenizer on dataset:  65%|██████▌   | 533/814 [16:18<08:08,  1.74s/ba]Running tokenizer on dataset:  66%|██████▌   | 534/814 [16:20<08:04,  1.73s/ba]Running tokenizer on dataset:  66%|██████▌   | 535/814 [16:21<08:05,  1.74s/ba]Running tokenizer on dataset:  66%|██████▌   | 536/814 [16:23<08:01,  1.73s/ba]Running tokenizer on dataset:  66%|██████▌   | 537/814 [16:25<07:59,  1.73s/ba]Running tokenizer on dataset:  66%|██████▌   | 538/814 [16:27<08:02,  1.75s/ba]Running tokenizer on dataset:  66%|██████▌   | 539/814 [16:28<08:01,  1.75s/ba]Running tokenizer on dataset:  66%|██████▋   | 540/814 [16:30<07:57,  1.74s/ba]Running tokenizer on dataset:  66%|██████▋   | 541/814 [16:32<07:53,  1.73s/ba]Running tokenizer on dataset:  67%|██████▋   | 542/814 [16:33<07:51,  1.73s/ba]Running tokenizer on dataset:  67%|██████▋   | 543/814 [16:35<07:47,  1.73s/ba]Running tokenizer on dataset:  67%|██████▋   | 544/814 [16:37<07:46,  1.73s/ba]Running tokenizer on dataset:  67%|██████▋   | 545/814 [16:39<07:49,  1.75s/ba]Running tokenizer on dataset:  67%|██████▋   | 546/814 [16:40<07:47,  1.74s/ba]Running tokenizer on dataset:  67%|██████▋   | 547/814 [16:42<07:44,  1.74s/ba]Running tokenizer on dataset:  67%|██████▋   | 548/814 [16:44<07:39,  1.73s/ba]Running tokenizer on dataset:  67%|██████▋   | 549/814 [16:46<07:42,  1.75s/ba]Running tokenizer on dataset:  68%|██████▊   | 550/814 [16:47<07:36,  1.73s/ba]Running tokenizer on dataset:  68%|██████▊   | 551/814 [16:49<07:34,  1.73s/ba]Running tokenizer on dataset:  68%|██████▊   | 552/814 [16:51<07:32,  1.73s/ba]Running tokenizer on dataset:  68%|██████▊   | 553/814 [16:52<07:27,  1.72s/ba]Running tokenizer on dataset:  68%|██████▊   | 554/814 [16:54<07:24,  1.71s/ba]Running tokenizer on dataset:  68%|██████▊   | 555/814 [16:56<07:23,  1.71s/ba]Running tokenizer on dataset:  68%|██████▊   | 556/814 [16:58<07:35,  1.76s/ba]Running tokenizer on dataset:  68%|██████▊   | 557/814 [16:59<07:28,  1.75s/ba]Running tokenizer on dataset:  69%|██████▊   | 558/814 [17:01<07:26,  1.74s/ba]Running tokenizer on dataset:  69%|██████▊   | 559/814 [17:03<07:24,  1.74s/ba]Running tokenizer on dataset:  69%|██████▉   | 560/814 [17:05<07:21,  1.74s/ba]Running tokenizer on dataset:  69%|██████▉   | 561/814 [17:06<07:19,  1.74s/ba]Running tokenizer on dataset:  69%|██████▉   | 562/814 [17:08<07:25,  1.77s/ba]Running tokenizer on dataset:  69%|██████▉   | 563/814 [17:10<07:24,  1.77s/ba]Running tokenizer on dataset:  69%|██████▉   | 564/814 [17:12<07:16,  1.75s/ba]Running tokenizer on dataset:  69%|██████▉   | 565/814 [17:13<07:13,  1.74s/ba]Running tokenizer on dataset:  70%|██████▉   | 566/814 [17:15<07:09,  1.73s/ba]Running tokenizer on dataset:  70%|██████▉   | 567/814 [17:17<07:14,  1.76s/ba]Running tokenizer on dataset:  70%|██████▉   | 568/814 [17:19<07:15,  1.77s/ba]Running tokenizer on dataset:  70%|██████▉   | 569/814 [17:21<07:10,  1.76s/ba]Running tokenizer on dataset:  70%|███████   | 570/814 [17:22<07:04,  1.74s/ba]Running tokenizer on dataset:  70%|███████   | 571/814 [17:24<06:58,  1.72s/ba]Running tokenizer on dataset:  70%|███████   | 572/814 [17:26<06:52,  1.70s/ba]Running tokenizer on dataset:  70%|███████   | 573/814 [17:27<06:51,  1.71s/ba]Running tokenizer on dataset:  71%|███████   | 574/814 [17:29<06:43,  1.68s/ba]Running tokenizer on dataset:  71%|███████   | 575/814 [17:31<06:42,  1.68s/ba]Running tokenizer on dataset:  71%|███████   | 576/814 [17:32<06:41,  1.69s/ba]Running tokenizer on dataset:  71%|███████   | 577/814 [17:34<06:40,  1.69s/ba]Running tokenizer on dataset:  71%|███████   | 578/814 [17:36<06:40,  1.70s/ba]Running tokenizer on dataset:  71%|███████   | 579/814 [17:37<06:37,  1.69s/ba]Running tokenizer on dataset:  71%|███████▏  | 580/814 [17:39<06:33,  1.68s/ba]Running tokenizer on dataset:  71%|███████▏  | 581/814 [17:41<06:34,  1.69s/ba]Running tokenizer on dataset:  71%|███████▏  | 582/814 [17:42<06:28,  1.67s/ba]Running tokenizer on dataset:  72%|███████▏  | 583/814 [17:44<06:26,  1.67s/ba]Running tokenizer on dataset:  72%|███████▏  | 584/814 [17:46<06:23,  1.67s/ba]Running tokenizer on dataset:  72%|███████▏  | 585/814 [17:47<06:26,  1.69s/ba]Running tokenizer on dataset:  72%|███████▏  | 586/814 [17:49<06:23,  1.68s/ba]Running tokenizer on dataset:  72%|███████▏  | 587/814 [17:51<06:23,  1.69s/ba]Running tokenizer on dataset:  72%|███████▏  | 588/814 [17:52<06:19,  1.68s/ba]Running tokenizer on dataset:  72%|███████▏  | 589/814 [17:54<06:18,  1.68s/ba]Running tokenizer on dataset:  72%|███████▏  | 590/814 [17:56<06:16,  1.68s/ba]Running tokenizer on dataset:  73%|███████▎  | 591/814 [17:58<06:16,  1.69s/ba]Running tokenizer on dataset:  73%|███████▎  | 592/814 [17:59<06:13,  1.68s/ba]Running tokenizer on dataset:  73%|███████▎  | 593/814 [18:01<06:12,  1.69s/ba]Running tokenizer on dataset:  73%|███████▎  | 594/814 [18:03<06:11,  1.69s/ba]Running tokenizer on dataset:  73%|███████▎  | 595/814 [18:04<06:07,  1.68s/ba]Running tokenizer on dataset:  73%|███████▎  | 596/814 [18:06<06:04,  1.67s/ba]Running tokenizer on dataset:  73%|███████▎  | 597/814 [18:08<06:03,  1.67s/ba]Running tokenizer on dataset:  73%|███████▎  | 598/814 [18:09<06:01,  1.68s/ba]Running tokenizer on dataset:  74%|███████▎  | 599/814 [18:11<06:00,  1.68s/ba]Running tokenizer on dataset:  74%|███████▎  | 600/814 [18:13<05:58,  1.68s/ba]Running tokenizer on dataset:  74%|███████▍  | 601/814 [18:14<05:58,  1.68s/ba]Running tokenizer on dataset:  74%|███████▍  | 602/814 [18:16<05:56,  1.68s/ba]Running tokenizer on dataset:  74%|███████▍  | 603/814 [18:18<05:53,  1.68s/ba]Running tokenizer on dataset:  74%|███████▍  | 604/814 [18:19<05:52,  1.68s/ba]Running tokenizer on dataset:  74%|███████▍  | 605/814 [18:21<05:51,  1.68s/ba]Running tokenizer on dataset:  74%|███████▍  | 606/814 [18:23<05:49,  1.68s/ba]Running tokenizer on dataset:  75%|███████▍  | 607/814 [18:24<05:47,  1.68s/ba]Running tokenizer on dataset:  75%|███████▍  | 608/814 [18:26<05:44,  1.67s/ba]Running tokenizer on dataset:  75%|███████▍  | 609/814 [18:28<05:47,  1.69s/ba]Running tokenizer on dataset:  75%|███████▍  | 610/814 [18:29<05:42,  1.68s/ba]Running tokenizer on dataset:  75%|███████▌  | 611/814 [18:31<05:41,  1.68s/ba]Running tokenizer on dataset:  75%|███████▌  | 612/814 [18:33<05:38,  1.68s/ba]Running tokenizer on dataset:  75%|███████▌  | 613/814 [18:35<05:38,  1.68s/ba]Running tokenizer on dataset:  75%|███████▌  | 614/814 [18:36<05:36,  1.68s/ba]Running tokenizer on dataset:  76%|███████▌  | 615/814 [18:38<05:35,  1.69s/ba]Running tokenizer on dataset:  76%|███████▌  | 616/814 [18:40<05:33,  1.68s/ba]Running tokenizer on dataset:  76%|███████▌  | 617/814 [18:41<05:31,  1.68s/ba]Running tokenizer on dataset:  76%|███████▌  | 618/814 [18:43<05:29,  1.68s/ba]Running tokenizer on dataset:  76%|███████▌  | 619/814 [18:45<05:26,  1.67s/ba]Running tokenizer on dataset:  76%|███████▌  | 620/814 [18:46<05:23,  1.67s/ba]Running tokenizer on dataset:  76%|███████▋  | 621/814 [18:48<05:22,  1.67s/ba]Running tokenizer on dataset:  76%|███████▋  | 622/814 [18:50<05:22,  1.68s/ba]Running tokenizer on dataset:  77%|███████▋  | 623/814 [18:51<05:20,  1.68s/ba]Running tokenizer on dataset:  77%|███████▋  | 624/814 [18:53<05:19,  1.68s/ba]Running tokenizer on dataset:  77%|███████▋  | 625/814 [18:55<05:17,  1.68s/ba]Running tokenizer on dataset:  77%|███████▋  | 626/814 [18:56<05:17,  1.69s/ba]Running tokenizer on dataset:  77%|███████▋  | 627/814 [18:58<05:15,  1.69s/ba]Running tokenizer on dataset:  77%|███████▋  | 628/814 [19:00<05:15,  1.70s/ba]Running tokenizer on dataset:  77%|███████▋  | 629/814 [19:01<05:13,  1.69s/ba]Running tokenizer on dataset:  77%|███████▋  | 630/814 [19:03<05:10,  1.69s/ba]Running tokenizer on dataset:  78%|███████▊  | 631/814 [19:05<05:08,  1.69s/ba]Running tokenizer on dataset:  78%|███████▊  | 632/814 [19:06<05:08,  1.69s/ba]Running tokenizer on dataset:  78%|███████▊  | 633/814 [19:08<05:06,  1.69s/ba]Running tokenizer on dataset:  78%|███████▊  | 634/814 [19:10<05:03,  1.68s/ba]Running tokenizer on dataset:  78%|███████▊  | 635/814 [19:11<04:57,  1.66s/ba]Running tokenizer on dataset:  78%|███████▊  | 636/814 [19:13<04:57,  1.67s/ba]Running tokenizer on dataset:  78%|███████▊  | 637/814 [19:15<04:57,  1.68s/ba]Running tokenizer on dataset:  78%|███████▊  | 638/814 [19:17<04:56,  1.69s/ba]Running tokenizer on dataset:  79%|███████▊  | 639/814 [19:18<04:55,  1.69s/ba]Running tokenizer on dataset:  79%|███████▊  | 640/814 [19:20<04:53,  1.69s/ba]Running tokenizer on dataset:  79%|███████▊  | 641/814 [19:22<04:50,  1.68s/ba]Running tokenizer on dataset:  79%|███████▉  | 642/814 [19:23<04:48,  1.68s/ba]Running tokenizer on dataset:  79%|███████▉  | 643/814 [19:25<04:57,  1.74s/ba]Running tokenizer on dataset:  79%|███████▉  | 644/814 [19:27<04:52,  1.72s/ba]Running tokenizer on dataset:  79%|███████▉  | 645/814 [19:29<04:49,  1.72s/ba]Running tokenizer on dataset:  79%|███████▉  | 646/814 [19:30<04:47,  1.71s/ba]Running tokenizer on dataset:  79%|███████▉  | 647/814 [19:32<04:42,  1.69s/ba]Running tokenizer on dataset:  80%|███████▉  | 648/814 [19:34<04:40,  1.69s/ba]Running tokenizer on dataset:  80%|███████▉  | 649/814 [19:35<04:38,  1.69s/ba]Running tokenizer on dataset:  80%|███████▉  | 650/814 [19:37<04:37,  1.69s/ba]Running tokenizer on dataset:  80%|███████▉  | 651/814 [19:39<04:36,  1.70s/ba]Running tokenizer on dataset:  80%|████████  | 652/814 [19:40<04:35,  1.70s/ba]Running tokenizer on dataset:  80%|████████  | 653/814 [19:42<04:33,  1.70s/ba]Running tokenizer on dataset:  80%|████████  | 654/814 [19:44<04:30,  1.69s/ba]Running tokenizer on dataset:  80%|████████  | 655/814 [19:45<04:29,  1.69s/ba]Running tokenizer on dataset:  81%|████████  | 656/814 [19:47<04:27,  1.70s/ba]Running tokenizer on dataset:  81%|████████  | 657/814 [19:49<04:28,  1.71s/ba]Running tokenizer on dataset:  81%|████████  | 658/814 [19:51<04:23,  1.69s/ba]Running tokenizer on dataset:  81%|████████  | 659/814 [19:52<04:20,  1.68s/ba]Running tokenizer on dataset:  81%|████████  | 660/814 [19:54<04:19,  1.69s/ba]Running tokenizer on dataset:  81%|████████  | 661/814 [19:56<04:17,  1.68s/ba]Running tokenizer on dataset:  81%|████████▏ | 662/814 [19:57<04:15,  1.68s/ba]Running tokenizer on dataset:  81%|████████▏ | 663/814 [19:59<04:22,  1.74s/ba]Running tokenizer on dataset:  82%|████████▏ | 664/814 [20:01<04:16,  1.71s/ba]Running tokenizer on dataset:  82%|████████▏ | 665/814 [20:02<04:12,  1.70s/ba]Running tokenizer on dataset:  82%|████████▏ | 666/814 [20:04<04:09,  1.69s/ba]Running tokenizer on dataset:  82%|████████▏ | 667/814 [20:06<04:08,  1.69s/ba]Running tokenizer on dataset:  82%|████████▏ | 668/814 [20:07<04:06,  1.69s/ba]Running tokenizer on dataset:  82%|████████▏ | 669/814 [20:09<04:06,  1.70s/ba]Running tokenizer on dataset:  82%|████████▏ | 670/814 [20:11<04:03,  1.69s/ba]Running tokenizer on dataset:  82%|████████▏ | 671/814 [20:13<04:03,  1.70s/ba]Running tokenizer on dataset:  83%|████████▎ | 672/814 [20:14<04:01,  1.70s/ba]Running tokenizer on dataset:  83%|████████▎ | 673/814 [20:16<04:08,  1.77s/ba]Running tokenizer on dataset:  83%|████████▎ | 674/814 [20:18<04:04,  1.74s/ba]Running tokenizer on dataset:  83%|████████▎ | 675/814 [20:20<04:00,  1.73s/ba]Running tokenizer on dataset:  83%|████████▎ | 676/814 [20:21<03:56,  1.71s/ba]Running tokenizer on dataset:  83%|████████▎ | 677/814 [20:23<03:53,  1.70s/ba]Running tokenizer on dataset:  83%|████████▎ | 678/814 [20:25<03:51,  1.70s/ba]Running tokenizer on dataset:  83%|████████▎ | 679/814 [20:26<03:48,  1.69s/ba]Running tokenizer on dataset:  84%|████████▎ | 680/814 [20:28<03:46,  1.69s/ba]Running tokenizer on dataset:  84%|████████▎ | 681/814 [20:30<03:44,  1.69s/ba]Running tokenizer on dataset:  84%|████████▍ | 682/814 [20:31<03:40,  1.67s/ba]Running tokenizer on dataset:  84%|████████▍ | 683/814 [20:33<03:39,  1.67s/ba]Running tokenizer on dataset:  84%|████████▍ | 684/814 [20:35<03:37,  1.67s/ba]Running tokenizer on dataset:  84%|████████▍ | 685/814 [20:36<03:36,  1.68s/ba]Running tokenizer on dataset:  84%|████████▍ | 686/814 [20:38<03:34,  1.68s/ba]Running tokenizer on dataset:  84%|████████▍ | 687/814 [20:40<03:32,  1.68s/ba]Running tokenizer on dataset:  85%|████████▍ | 688/814 [20:41<03:30,  1.67s/ba]Running tokenizer on dataset:  85%|████████▍ | 689/814 [20:43<03:26,  1.66s/ba]Running tokenizer on dataset:  85%|████████▍ | 690/814 [20:45<03:27,  1.67s/ba]Running tokenizer on dataset:  85%|████████▍ | 691/814 [20:46<03:28,  1.69s/ba]Running tokenizer on dataset:  85%|████████▌ | 692/814 [20:48<03:27,  1.70s/ba]Running tokenizer on dataset:  85%|████████▌ | 693/814 [20:50<03:25,  1.70s/ba]Running tokenizer on dataset:  85%|████████▌ | 694/814 [20:52<03:23,  1.69s/ba]Running tokenizer on dataset:  85%|████████▌ | 695/814 [20:53<03:21,  1.69s/ba]Running tokenizer on dataset:  86%|████████▌ | 696/814 [20:55<03:20,  1.70s/ba]Running tokenizer on dataset:  86%|████████▌ | 697/814 [20:57<03:19,  1.70s/ba]Running tokenizer on dataset:  86%|████████▌ | 698/814 [20:58<03:17,  1.70s/ba]Running tokenizer on dataset:  86%|████████▌ | 699/814 [21:00<03:14,  1.69s/ba]Running tokenizer on dataset:  86%|████████▌ | 700/814 [21:02<03:12,  1.69s/ba]Running tokenizer on dataset:  86%|████████▌ | 701/814 [21:03<03:12,  1.70s/ba]Running tokenizer on dataset:  86%|████████▌ | 702/814 [21:05<03:10,  1.70s/ba]Running tokenizer on dataset:  86%|████████▋ | 703/814 [21:07<03:09,  1.71s/ba]Running tokenizer on dataset:  86%|████████▋ | 704/814 [21:09<03:07,  1.71s/ba]Running tokenizer on dataset:  87%|████████▋ | 705/814 [21:10<03:06,  1.71s/ba]Running tokenizer on dataset:  87%|████████▋ | 706/814 [21:12<03:04,  1.71s/ba]Running tokenizer on dataset:  87%|████████▋ | 707/814 [21:14<03:03,  1.72s/ba]Running tokenizer on dataset:  87%|████████▋ | 708/814 [21:15<03:02,  1.72s/ba]Running tokenizer on dataset:  87%|████████▋ | 709/814 [21:17<03:00,  1.72s/ba]Running tokenizer on dataset:  87%|████████▋ | 710/814 [21:19<02:56,  1.70s/ba]Running tokenizer on dataset:  87%|████████▋ | 711/814 [21:20<02:54,  1.70s/ba]Running tokenizer on dataset:  87%|████████▋ | 712/814 [21:22<02:53,  1.70s/ba]Running tokenizer on dataset:  88%|████████▊ | 713/814 [21:24<02:52,  1.70s/ba]Running tokenizer on dataset:  88%|████████▊ | 714/814 [21:26<02:50,  1.71s/ba]Running tokenizer on dataset:  88%|████████▊ | 715/814 [21:27<02:48,  1.70s/ba]Running tokenizer on dataset:  88%|████████▊ | 716/814 [21:29<02:45,  1.69s/ba]Running tokenizer on dataset:  88%|████████▊ | 717/814 [21:31<02:45,  1.70s/ba]Running tokenizer on dataset:  88%|████████▊ | 718/814 [21:32<02:42,  1.70s/ba]Running tokenizer on dataset:  88%|████████▊ | 719/814 [21:34<02:42,  1.71s/ba]Running tokenizer on dataset:  88%|████████▊ | 720/814 [21:36<02:39,  1.70s/ba]Running tokenizer on dataset:  89%|████████▊ | 721/814 [21:38<02:38,  1.70s/ba]Running tokenizer on dataset:  89%|████████▊ | 722/814 [21:39<02:37,  1.71s/ba]Running tokenizer on dataset:  89%|████████▉ | 723/814 [21:41<02:34,  1.70s/ba]Running tokenizer on dataset:  89%|████████▉ | 724/814 [21:43<02:35,  1.73s/ba]Running tokenizer on dataset:  89%|████████▉ | 725/814 [21:44<02:34,  1.73s/ba]Running tokenizer on dataset:  89%|████████▉ | 726/814 [21:46<02:30,  1.71s/ba]Running tokenizer on dataset:  89%|████████▉ | 727/814 [21:48<02:28,  1.71s/ba]Running tokenizer on dataset:  89%|████████▉ | 728/814 [21:50<02:26,  1.71s/ba]Running tokenizer on dataset:  90%|████████▉ | 729/814 [21:51<02:24,  1.70s/ba]Running tokenizer on dataset:  90%|████████▉ | 730/814 [21:53<02:21,  1.69s/ba]Running tokenizer on dataset:  90%|████████▉ | 731/814 [21:55<02:20,  1.69s/ba]Running tokenizer on dataset:  90%|████████▉ | 732/814 [21:56<02:18,  1.69s/ba]Running tokenizer on dataset:  90%|█████████ | 733/814 [21:58<02:17,  1.69s/ba]Running tokenizer on dataset:  90%|█████████ | 734/814 [22:00<02:14,  1.68s/ba]Running tokenizer on dataset:  90%|█████████ | 735/814 [22:01<02:12,  1.68s/ba]Running tokenizer on dataset:  90%|█████████ | 736/814 [22:03<02:11,  1.69s/ba]Running tokenizer on dataset:  91%|█████████ | 737/814 [22:05<02:09,  1.68s/ba]Running tokenizer on dataset:  91%|█████████ | 738/814 [22:06<02:07,  1.68s/ba]Running tokenizer on dataset:  91%|█████████ | 739/814 [22:08<02:06,  1.69s/ba]Running tokenizer on dataset:  91%|█████████ | 740/814 [22:10<02:05,  1.69s/ba]Running tokenizer on dataset:  91%|█████████ | 741/814 [22:11<02:03,  1.70s/ba]Running tokenizer on dataset:  91%|█████████ | 742/814 [22:13<02:02,  1.69s/ba]Running tokenizer on dataset:  91%|█████████▏| 743/814 [22:15<02:00,  1.69s/ba]Running tokenizer on dataset:  91%|█████████▏| 744/814 [22:17<01:57,  1.68s/ba]Running tokenizer on dataset:  92%|█████████▏| 745/814 [22:18<01:56,  1.69s/ba]Running tokenizer on dataset:  92%|█████████▏| 746/814 [22:20<01:54,  1.68s/ba]Running tokenizer on dataset:  92%|█████████▏| 747/814 [22:22<01:52,  1.69s/ba]Running tokenizer on dataset:  92%|█████████▏| 748/814 [22:23<01:50,  1.68s/ba]Running tokenizer on dataset:  92%|█████████▏| 749/814 [22:25<01:49,  1.68s/ba]Running tokenizer on dataset:  92%|█████████▏| 750/814 [22:27<01:47,  1.69s/ba]Running tokenizer on dataset:  92%|█████████▏| 751/814 [22:28<01:45,  1.68s/ba]Running tokenizer on dataset:  92%|█████████▏| 752/814 [22:30<01:45,  1.69s/ba]Running tokenizer on dataset:  93%|█████████▎| 753/814 [22:32<01:43,  1.70s/ba]Running tokenizer on dataset:  93%|█████████▎| 754/814 [22:33<01:41,  1.69s/ba]Running tokenizer on dataset:  93%|█████████▎| 755/814 [22:35<01:40,  1.70s/ba]Running tokenizer on dataset:  93%|█████████▎| 756/814 [22:37<01:38,  1.69s/ba]Running tokenizer on dataset:  93%|█████████▎| 757/814 [22:38<01:36,  1.69s/ba]Running tokenizer on dataset:  93%|█████████▎| 758/814 [22:40<01:34,  1.69s/ba]Running tokenizer on dataset:  93%|█████████▎| 759/814 [22:42<01:33,  1.70s/ba]Running tokenizer on dataset:  93%|█████████▎| 760/814 [22:44<01:32,  1.70s/ba]Running tokenizer on dataset:  93%|█████████▎| 761/814 [22:45<01:30,  1.71s/ba]Running tokenizer on dataset:  94%|█████████▎| 762/814 [22:47<01:28,  1.70s/ba]Running tokenizer on dataset:  94%|█████████▎| 763/814 [22:49<01:26,  1.71s/ba]Running tokenizer on dataset:  94%|█████████▍| 764/814 [22:50<01:25,  1.71s/ba]Running tokenizer on dataset:  94%|█████████▍| 765/814 [22:52<01:23,  1.70s/ba]Running tokenizer on dataset:  94%|█████████▍| 766/814 [22:54<01:21,  1.70s/ba]Running tokenizer on dataset:  94%|█████████▍| 767/814 [22:55<01:19,  1.70s/ba]Running tokenizer on dataset:  94%|█████████▍| 768/814 [22:57<01:18,  1.71s/ba]Running tokenizer on dataset:  94%|█████████▍| 769/814 [22:59<01:16,  1.70s/ba]Running tokenizer on dataset:  95%|█████████▍| 770/814 [23:01<01:26,  1.96s/ba]Running tokenizer on dataset:  95%|█████████▍| 771/814 [23:03<01:21,  1.88s/ba]Running tokenizer on dataset:  95%|█████████▍| 772/814 [23:05<01:16,  1.81s/ba]Running tokenizer on dataset:  95%|█████████▍| 773/814 [23:06<01:12,  1.77s/ba]Running tokenizer on dataset:  95%|█████████▌| 774/814 [23:08<01:09,  1.74s/ba]Running tokenizer on dataset:  95%|█████████▌| 775/814 [23:10<01:07,  1.72s/ba]Running tokenizer on dataset:  95%|█████████▌| 776/814 [23:12<01:04,  1.71s/ba]Running tokenizer on dataset:  95%|█████████▌| 777/814 [23:13<01:03,  1.71s/ba]Running tokenizer on dataset:  96%|█████████▌| 778/814 [23:15<01:00,  1.69s/ba]Running tokenizer on dataset:  96%|█████████▌| 779/814 [23:17<00:59,  1.69s/ba]Running tokenizer on dataset:  96%|█████████▌| 780/814 [23:18<00:57,  1.68s/ba]Running tokenizer on dataset:  96%|█████████▌| 781/814 [23:20<00:57,  1.73s/ba]Running tokenizer on dataset:  96%|█████████▌| 782/814 [23:22<00:55,  1.73s/ba]Running tokenizer on dataset:  96%|█████████▌| 783/814 [23:23<00:53,  1.71s/ba]Running tokenizer on dataset:  96%|█████████▋| 784/814 [23:25<00:51,  1.70s/ba]Running tokenizer on dataset:  96%|█████████▋| 785/814 [23:27<00:49,  1.71s/ba]Running tokenizer on dataset:  97%|█████████▋| 786/814 [23:29<00:47,  1.70s/ba]Running tokenizer on dataset:  97%|█████████▋| 787/814 [23:30<00:45,  1.69s/ba]Running tokenizer on dataset:  97%|█████████▋| 788/814 [23:32<00:43,  1.68s/ba]Running tokenizer on dataset:  97%|█████████▋| 789/814 [23:34<00:42,  1.68s/ba]Running tokenizer on dataset:  97%|█████████▋| 790/814 [23:35<00:40,  1.68s/ba]Running tokenizer on dataset:  97%|█████████▋| 791/814 [23:37<00:38,  1.68s/ba]Running tokenizer on dataset:  97%|█████████▋| 792/814 [23:39<00:36,  1.67s/ba]Running tokenizer on dataset:  97%|█████████▋| 793/814 [23:40<00:35,  1.69s/ba]Running tokenizer on dataset:  98%|█████████▊| 794/814 [23:42<00:33,  1.68s/ba]Running tokenizer on dataset:  98%|█████████▊| 795/814 [23:44<00:31,  1.68s/ba]Running tokenizer on dataset:  98%|█████████▊| 796/814 [23:45<00:30,  1.67s/ba]Running tokenizer on dataset:  98%|█████████▊| 797/814 [23:47<00:28,  1.67s/ba]Running tokenizer on dataset:  98%|█████████▊| 798/814 [23:49<00:26,  1.67s/ba]Running tokenizer on dataset:  98%|█████████▊| 799/814 [23:50<00:25,  1.68s/ba]Running tokenizer on dataset:  98%|█████████▊| 800/814 [23:52<00:23,  1.67s/ba]Running tokenizer on dataset:  98%|█████████▊| 801/814 [23:54<00:21,  1.69s/ba]Running tokenizer on dataset:  99%|█████████▊| 802/814 [23:55<00:20,  1.69s/ba]Running tokenizer on dataset:  99%|█████████▊| 803/814 [23:57<00:18,  1.68s/ba]Running tokenizer on dataset:  99%|█████████▉| 804/814 [23:59<00:16,  1.68s/ba]Running tokenizer on dataset:  99%|█████████▉| 805/814 [24:01<00:15,  1.73s/ba]Running tokenizer on dataset:  99%|█████████▉| 806/814 [24:02<00:13,  1.72s/ba]Running tokenizer on dataset:  99%|█████████▉| 807/814 [24:04<00:11,  1.71s/ba]Running tokenizer on dataset:  99%|█████████▉| 808/814 [24:06<00:10,  1.70s/ba]Running tokenizer on dataset:  99%|█████████▉| 809/814 [24:07<00:08,  1.72s/ba]Running tokenizer on dataset: 100%|█████████▉| 810/814 [24:09<00:06,  1.71s/ba]Running tokenizer on dataset: 100%|█████████▉| 811/814 [24:11<00:05,  1.71s/ba]Running tokenizer on dataset: 100%|█████████▉| 812/814 [24:13<00:03,  1.70s/ba]Running tokenizer on dataset: 100%|█████████▉| 813/814 [24:14<00:01,  1.71s/ba]Running tokenizer on dataset: 100%|██████████| 814/814 [24:15<00:00,  1.35s/ba]Running tokenizer on dataset: 100%|██████████| 814/814 [24:15<00:00,  1.79s/ba]
Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 1/814 [00:01<21:16,  1.57s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:03<21:28,  1.59s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:04<21:33,  1.59s/ba]Running tokenizer on dataset:   0%|          | 4/814 [00:06<21:38,  1.60s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:07<21:30,  1.60s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:09<21:23,  1.59s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:11<21:32,  1.60s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:12<21:30,  1.60s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:14<21:25,  1.60s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:15<21:18,  1.59s/ba]Running tokenizer on dataset:   1%|▏         | 11/814 [00:17<21:31,  1.61s/ba]Running tokenizer on dataset:   1%|▏         | 12/814 [00:19<21:31,  1.61s/ba]Running tokenizer on dataset:   2%|▏         | 13/814 [00:20<21:37,  1.62s/ba]Running tokenizer on dataset:   2%|▏         | 14/814 [00:22<21:40,  1.63s/ba]Running tokenizer on dataset:   2%|▏         | 15/814 [00:24<21:36,  1.62s/ba]Running tokenizer on dataset:   2%|▏         | 16/814 [00:25<21:35,  1.62s/ba]Running tokenizer on dataset:   2%|▏         | 17/814 [00:27<21:30,  1.62s/ba]Running tokenizer on dataset:   2%|▏         | 18/814 [00:28<21:25,  1.61s/ba]Running tokenizer on dataset:   2%|▏         | 19/814 [00:30<21:26,  1.62s/ba]Running tokenizer on dataset:   2%|▏         | 20/814 [00:32<21:21,  1.61s/ba]Running tokenizer on dataset:   3%|▎         | 21/814 [00:33<21:18,  1.61s/ba]Running tokenizer on dataset:   3%|▎         | 22/814 [00:35<21:09,  1.60s/ba]Running tokenizer on dataset:   3%|▎         | 23/814 [00:36<21:08,  1.60s/ba]Running tokenizer on dataset:   3%|▎         | 24/814 [00:38<21:06,  1.60s/ba]Running tokenizer on dataset:   3%|▎         | 25/814 [00:40<21:04,  1.60s/ba]Running tokenizer on dataset:   3%|▎         | 26/814 [00:41<21:00,  1.60s/ba]Running tokenizer on dataset:   3%|▎         | 27/814 [00:43<20:55,  1.59s/ba]Running tokenizer on dataset:   3%|▎         | 28/814 [00:44<20:59,  1.60s/ba]Running tokenizer on dataset:   4%|▎         | 29/814 [00:46<21:14,  1.62s/ba]Running tokenizer on dataset:   4%|▎         | 30/814 [00:48<21:15,  1.63s/ba]Running tokenizer on dataset:   4%|▍         | 31/814 [00:49<21:07,  1.62s/ba]Running tokenizer on dataset:   4%|▍         | 32/814 [00:51<21:09,  1.62s/ba]Running tokenizer on dataset:   4%|▍         | 33/814 [00:53<21:08,  1.62s/ba]Running tokenizer on dataset:   4%|▍         | 34/814 [00:54<20:58,  1.61s/ba]Running tokenizer on dataset:   4%|▍         | 35/814 [00:56<20:54,  1.61s/ba]Running tokenizer on dataset:   4%|▍         | 36/814 [00:57<20:46,  1.60s/ba]Running tokenizer on dataset:   5%|▍         | 37/814 [00:59<20:44,  1.60s/ba]Running tokenizer on dataset:   5%|▍         | 38/814 [01:01<20:34,  1.59s/ba]Running tokenizer on dataset:   5%|▍         | 39/814 [01:02<20:43,  1.61s/ba]Running tokenizer on dataset:   5%|▍         | 40/814 [01:04<20:37,  1.60s/ba]Running tokenizer on dataset:   5%|▌         | 41/814 [01:05<20:37,  1.60s/ba]Running tokenizer on dataset:   5%|▌         | 42/814 [01:07<20:39,  1.61s/ba]Running tokenizer on dataset:   5%|▌         | 43/814 [01:09<20:36,  1.60s/ba]Running tokenizer on dataset:   5%|▌         | 44/814 [01:10<20:36,  1.61s/ba]Running tokenizer on dataset:   6%|▌         | 45/814 [01:12<20:40,  1.61s/ba]Running tokenizer on dataset:   6%|▌         | 46/814 [01:13<20:32,  1.61s/ba]Running tokenizer on dataset:   6%|▌         | 47/814 [01:15<20:28,  1.60s/ba]Running tokenizer on dataset:   6%|▌         | 48/814 [01:17<20:21,  1.60s/ba]Running tokenizer on dataset:   6%|▌         | 49/814 [01:18<20:27,  1.60s/ba]Running tokenizer on dataset:   6%|▌         | 50/814 [01:20<20:21,  1.60s/ba]Running tokenizer on dataset:   6%|▋         | 51/814 [01:21<20:15,  1.59s/ba]Running tokenizer on dataset:   6%|▋         | 52/814 [01:23<20:23,  1.61s/ba]Running tokenizer on dataset:   7%|▋         | 53/814 [01:25<20:23,  1.61s/ba]Running tokenizer on dataset:   7%|▋         | 54/814 [01:26<20:22,  1.61s/ba]Running tokenizer on dataset:   7%|▋         | 55/814 [01:28<20:25,  1.61s/ba]Running tokenizer on dataset:   7%|▋         | 56/814 [01:29<20:20,  1.61s/ba]Running tokenizer on dataset:   7%|▋         | 57/814 [01:31<20:23,  1.62s/ba]Running tokenizer on dataset:   7%|▋         | 58/814 [01:33<20:17,  1.61s/ba]Running tokenizer on dataset:   7%|▋         | 59/814 [01:34<20:13,  1.61s/ba]Running tokenizer on dataset:   7%|▋         | 60/814 [01:36<20:09,  1.60s/ba]Running tokenizer on dataset:   7%|▋         | 61/814 [01:38<20:07,  1.60s/ba]Running tokenizer on dataset:   8%|▊         | 62/814 [01:39<20:06,  1.60s/ba]Running tokenizer on dataset:   8%|▊         | 63/814 [01:41<19:58,  1.60s/ba]Running tokenizer on dataset:   8%|▊         | 64/814 [01:42<20:00,  1.60s/ba]Running tokenizer on dataset:   8%|▊         | 65/814 [01:44<20:04,  1.61s/ba]Running tokenizer on dataset:   8%|▊         | 66/814 [01:46<20:05,  1.61s/ba]Running tokenizer on dataset:   8%|▊         | 67/814 [01:47<19:56,  1.60s/ba]Running tokenizer on dataset:   8%|▊         | 68/814 [01:49<19:53,  1.60s/ba]Running tokenizer on dataset:   8%|▊         | 69/814 [01:50<19:49,  1.60s/ba]Running tokenizer on dataset:   9%|▊         | 70/814 [01:52<19:48,  1.60s/ba]Running tokenizer on dataset:   9%|▊         | 71/814 [01:54<19:48,  1.60s/ba]Running tokenizer on dataset:   9%|▉         | 72/814 [01:55<20:25,  1.65s/ba]Running tokenizer on dataset:   9%|▉         | 73/814 [01:57<20:12,  1.64s/ba]Running tokenizer on dataset:   9%|▉         | 74/814 [01:58<20:02,  1.63s/ba]Running tokenizer on dataset:   9%|▉         | 75/814 [02:00<19:53,  1.61s/ba]Running tokenizer on dataset:   9%|▉         | 76/814 [02:02<19:52,  1.62s/ba]Running tokenizer on dataset:   9%|▉         | 77/814 [02:03<19:48,  1.61s/ba]Running tokenizer on dataset:  10%|▉         | 78/814 [02:05<19:49,  1.62s/ba]Running tokenizer on dataset:  10%|▉         | 79/814 [02:07<19:39,  1.60s/ba]Running tokenizer on dataset:  10%|▉         | 80/814 [02:08<19:37,  1.60s/ba]Running tokenizer on dataset:  10%|▉         | 81/814 [02:10<19:34,  1.60s/ba]Running tokenizer on dataset:  10%|█         | 82/814 [02:11<19:35,  1.61s/ba]Running tokenizer on dataset:  10%|█         | 83/814 [02:13<19:31,  1.60s/ba]Running tokenizer on dataset:  10%|█         | 84/814 [02:15<19:28,  1.60s/ba]Running tokenizer on dataset:  10%|█         | 85/814 [02:16<19:27,  1.60s/ba]Running tokenizer on dataset:  11%|█         | 86/814 [02:18<19:56,  1.64s/ba]Running tokenizer on dataset:  11%|█         | 87/814 [02:19<19:52,  1.64s/ba]Running tokenizer on dataset:  11%|█         | 88/814 [02:21<19:46,  1.63s/ba]Running tokenizer on dataset:  11%|█         | 89/814 [02:23<19:50,  1.64s/ba]Running tokenizer on dataset:  11%|█         | 90/814 [02:24<19:39,  1.63s/ba]Running tokenizer on dataset:  11%|█         | 91/814 [02:26<19:39,  1.63s/ba]Running tokenizer on dataset:  11%|█▏        | 92/814 [02:28<19:29,  1.62s/ba]Running tokenizer on dataset:  11%|█▏        | 93/814 [02:29<19:30,  1.62s/ba]Running tokenizer on dataset:  12%|█▏        | 94/814 [02:31<19:30,  1.63s/ba]Running tokenizer on dataset:  12%|█▏        | 95/814 [02:32<19:26,  1.62s/ba]Running tokenizer on dataset:  12%|█▏        | 96/814 [02:34<19:26,  1.62s/ba]Running tokenizer on dataset:  12%|█▏        | 97/814 [02:36<19:30,  1.63s/ba]Running tokenizer on dataset:  12%|█▏        | 98/814 [02:37<19:30,  1.63s/ba]Running tokenizer on dataset:  12%|█▏        | 99/814 [02:39<19:34,  1.64s/ba]Running tokenizer on dataset:  12%|█▏        | 100/814 [02:41<19:29,  1.64s/ba]Running tokenizer on dataset:  12%|█▏        | 101/814 [02:42<19:25,  1.64s/ba]Running tokenizer on dataset:  13%|█▎        | 102/814 [02:44<19:22,  1.63s/ba]Running tokenizer on dataset:  13%|█▎        | 103/814 [02:46<19:20,  1.63s/ba]Running tokenizer on dataset:  13%|█▎        | 104/814 [02:47<19:14,  1.63s/ba]Running tokenizer on dataset:  13%|█▎        | 105/814 [02:49<19:13,  1.63s/ba]Running tokenizer on dataset:  13%|█▎        | 106/814 [02:50<19:08,  1.62s/ba]Running tokenizer on dataset:  13%|█▎        | 107/814 [02:52<19:10,  1.63s/ba]Running tokenizer on dataset:  13%|█▎        | 108/814 [02:54<19:12,  1.63s/ba]Running tokenizer on dataset:  13%|█▎        | 109/814 [02:55<19:12,  1.64s/ba]Running tokenizer on dataset:  14%|█▎        | 110/814 [02:57<19:08,  1.63s/ba]Running tokenizer on dataset:  14%|█▎        | 111/814 [02:59<19:02,  1.62s/ba]Running tokenizer on dataset:  14%|█▍        | 112/814 [03:00<19:01,  1.63s/ba]Running tokenizer on dataset:  14%|█▍        | 113/814 [03:02<19:00,  1.63s/ba]Running tokenizer on dataset:  14%|█▍        | 114/814 [03:03<19:03,  1.63s/ba]Running tokenizer on dataset:  14%|█▍        | 115/814 [03:05<19:03,  1.64s/ba]Running tokenizer on dataset:  14%|█▍        | 116/814 [03:07<18:56,  1.63s/ba]Running tokenizer on dataset:  14%|█▍        | 117/814 [03:08<19:02,  1.64s/ba]Running tokenizer on dataset:  14%|█▍        | 118/814 [03:11<20:48,  1.79s/ba]Running tokenizer on dataset:  15%|█▍        | 119/814 [03:13<21:52,  1.89s/ba]Running tokenizer on dataset:  15%|█▍        | 120/814 [03:14<20:58,  1.81s/ba]Running tokenizer on dataset:  15%|█▍        | 121/814 [03:16<20:25,  1.77s/ba]Running tokenizer on dataset:  15%|█▍        | 122/814 [03:18<19:54,  1.73s/ba]Running tokenizer on dataset:  15%|█▌        | 123/814 [03:19<19:28,  1.69s/ba]Running tokenizer on dataset:  15%|█▌        | 124/814 [03:21<19:14,  1.67s/ba]Running tokenizer on dataset:  15%|█▌        | 125/814 [03:22<19:01,  1.66s/ba]Running tokenizer on dataset:  15%|█▌        | 126/814 [03:24<18:57,  1.65s/ba]Running tokenizer on dataset:  16%|█▌        | 127/814 [03:26<18:52,  1.65s/ba]Running tokenizer on dataset:  16%|█▌        | 128/814 [03:27<18:41,  1.63s/ba]Running tokenizer on dataset:  16%|█▌        | 129/814 [03:29<18:46,  1.64s/ba]Running tokenizer on dataset:  16%|█▌        | 130/814 [03:31<18:35,  1.63s/ba]Running tokenizer on dataset:  16%|█▌        | 131/814 [03:32<18:36,  1.63s/ba]Running tokenizer on dataset:  16%|█▌        | 132/814 [03:34<18:27,  1.62s/ba]Running tokenizer on dataset:  16%|█▋        | 133/814 [03:35<18:26,  1.63s/ba]Running tokenizer on dataset:  16%|█▋        | 134/814 [03:37<18:23,  1.62s/ba]Running tokenizer on dataset:  17%|█▋        | 135/814 [03:39<18:24,  1.63s/ba]Running tokenizer on dataset:  17%|█▋        | 136/814 [03:40<18:21,  1.62s/ba]Running tokenizer on dataset:  17%|█▋        | 137/814 [03:42<18:22,  1.63s/ba]Running tokenizer on dataset:  17%|█▋        | 138/814 [03:44<18:21,  1.63s/ba]Running tokenizer on dataset:  17%|█▋        | 139/814 [03:45<18:16,  1.62s/ba]Running tokenizer on dataset:  17%|█▋        | 140/814 [03:47<18:13,  1.62s/ba]Running tokenizer on dataset:  17%|█▋        | 141/814 [03:48<18:14,  1.63s/ba]Running tokenizer on dataset:  17%|█▋        | 142/814 [03:50<18:16,  1.63s/ba]Running tokenizer on dataset:  18%|█▊        | 143/814 [03:52<18:14,  1.63s/ba]Running tokenizer on dataset:  18%|█▊        | 144/814 [03:53<18:13,  1.63s/ba]Running tokenizer on dataset:  18%|█▊        | 145/814 [03:55<18:09,  1.63s/ba]Running tokenizer on dataset:  18%|█▊        | 146/814 [03:57<18:01,  1.62s/ba]Running tokenizer on dataset:  18%|█▊        | 147/814 [03:58<18:11,  1.64s/ba]Running tokenizer on dataset:  18%|█▊        | 148/814 [04:00<18:11,  1.64s/ba]Running tokenizer on dataset:  18%|█▊        | 149/814 [04:02<17:57,  1.62s/ba]Running tokenizer on dataset:  18%|█▊        | 150/814 [04:03<17:53,  1.62s/ba]Running tokenizer on dataset:  19%|█▊        | 151/814 [04:05<17:47,  1.61s/ba]Running tokenizer on dataset:  19%|█▊        | 152/814 [04:06<17:45,  1.61s/ba]Running tokenizer on dataset:  19%|█▉        | 153/814 [04:08<17:50,  1.62s/ba]Running tokenizer on dataset:  19%|█▉        | 154/814 [04:10<17:52,  1.62s/ba]Running tokenizer on dataset:  19%|█▉        | 155/814 [04:11<17:47,  1.62s/ba]Running tokenizer on dataset:  19%|█▉        | 156/814 [04:13<17:44,  1.62s/ba]Running tokenizer on dataset:  19%|█▉        | 157/814 [04:14<17:45,  1.62s/ba]Running tokenizer on dataset:  19%|█▉        | 158/814 [04:16<17:38,  1.61s/ba]Running tokenizer on dataset:  20%|█▉        | 159/814 [04:18<17:42,  1.62s/ba]Running tokenizer on dataset:  20%|█▉        | 160/814 [04:19<17:44,  1.63s/ba]Running tokenizer on dataset:  20%|█▉        | 161/814 [04:21<17:39,  1.62s/ba]Running tokenizer on dataset:  20%|█▉        | 162/814 [04:23<17:40,  1.63s/ba]Running tokenizer on dataset:  20%|██        | 163/814 [04:24<17:38,  1.63s/ba]Running tokenizer on dataset:  20%|██        | 164/814 [04:26<17:38,  1.63s/ba]Running tokenizer on dataset:  20%|██        | 165/814 [04:27<17:39,  1.63s/ba]Running tokenizer on dataset:  20%|██        | 166/814 [04:29<17:45,  1.64s/ba]Running tokenizer on dataset:  21%|██        | 167/814 [04:31<17:40,  1.64s/ba]Running tokenizer on dataset:  21%|██        | 168/814 [04:32<17:34,  1.63s/ba]Running tokenizer on dataset:  21%|██        | 169/814 [04:34<17:35,  1.64s/ba]Running tokenizer on dataset:  21%|██        | 170/814 [04:36<17:29,  1.63s/ba]Running tokenizer on dataset:  21%|██        | 171/814 [04:37<17:55,  1.67s/ba]Running tokenizer on dataset:  21%|██        | 172/814 [04:39<17:49,  1.67s/ba]Running tokenizer on dataset:  21%|██▏       | 173/814 [04:41<17:46,  1.66s/ba]Running tokenizer on dataset:  21%|██▏       | 174/814 [04:42<17:39,  1.65s/ba]Running tokenizer on dataset:  21%|██▏       | 175/814 [04:44<17:31,  1.65s/ba]Running tokenizer on dataset:  22%|██▏       | 176/814 [04:46<17:23,  1.63s/ba]Running tokenizer on dataset:  22%|██▏       | 177/814 [04:47<17:21,  1.64s/ba]Running tokenizer on dataset:  22%|██▏       | 178/814 [04:49<17:20,  1.64s/ba]Running tokenizer on dataset:  22%|██▏       | 179/814 [04:51<17:18,  1.64s/ba]Running tokenizer on dataset:  22%|██▏       | 180/814 [04:52<17:09,  1.62s/ba]Running tokenizer on dataset:  22%|██▏       | 181/814 [04:54<17:10,  1.63s/ba]Running tokenizer on dataset:  22%|██▏       | 182/814 [04:55<17:12,  1.63s/ba]Running tokenizer on dataset:  22%|██▏       | 183/814 [04:57<17:12,  1.64s/ba]Running tokenizer on dataset:  23%|██▎       | 184/814 [04:59<17:08,  1.63s/ba]Running tokenizer on dataset:  23%|██▎       | 185/814 [05:00<17:04,  1.63s/ba]Running tokenizer on dataset:  23%|██▎       | 186/814 [05:02<17:01,  1.63s/ba]Running tokenizer on dataset:  23%|██▎       | 187/814 [05:04<16:58,  1.62s/ba]Running tokenizer on dataset:  23%|██▎       | 188/814 [05:05<16:55,  1.62s/ba]Running tokenizer on dataset:  23%|██▎       | 189/814 [05:07<16:54,  1.62s/ba]Running tokenizer on dataset:  23%|██▎       | 190/814 [05:08<16:52,  1.62s/ba]Running tokenizer on dataset:  23%|██▎       | 191/814 [05:10<16:59,  1.64s/ba]Running tokenizer on dataset:  24%|██▎       | 192/814 [05:12<16:54,  1.63s/ba]Running tokenizer on dataset:  24%|██▎       | 193/814 [05:13<16:55,  1.63s/ba]Running tokenizer on dataset:  24%|██▍       | 194/814 [05:15<16:48,  1.63s/ba]Running tokenizer on dataset:  24%|██▍       | 195/814 [05:17<16:49,  1.63s/ba]Running tokenizer on dataset:  24%|██▍       | 196/814 [05:18<16:44,  1.63s/ba]Running tokenizer on dataset:  24%|██▍       | 197/814 [05:20<16:41,  1.62s/ba]Running tokenizer on dataset:  24%|██▍       | 198/814 [05:21<16:45,  1.63s/ba]Running tokenizer on dataset:  24%|██▍       | 199/814 [05:23<16:40,  1.63s/ba]Running tokenizer on dataset:  25%|██▍       | 200/814 [05:25<16:32,  1.62s/ba]Running tokenizer on dataset:  25%|██▍       | 201/814 [05:26<16:30,  1.62s/ba]Running tokenizer on dataset:  25%|██▍       | 202/814 [05:28<16:31,  1.62s/ba]Running tokenizer on dataset:  25%|██▍       | 203/814 [05:30<16:32,  1.62s/ba]Running tokenizer on dataset:  25%|██▌       | 204/814 [05:31<16:32,  1.63s/ba]Running tokenizer on dataset:  25%|██▌       | 205/814 [05:33<16:23,  1.62s/ba]Running tokenizer on dataset:  25%|██▌       | 206/814 [05:34<16:26,  1.62s/ba][E ProcessGroupNCCL.cpp:821] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=2, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1805914 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:456] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:461] To avoid data inconsistency, we are taking the entire process down.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=2, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1805914 milliseconds before timing out.
Running tokenizer on dataset:  25%|██▌       | 207/814 [05:36<16:25,  1.62s/ba]Running tokenizer on dataset:   0%|          | 0/814 [00:00<?, ?ba/s]Running tokenizer on dataset:  26%|██▌       | 208/814 [05:38<16:21,  1.62s/ba]Running tokenizer on dataset:  26%|██▌       | 209/814 [05:39<16:25,  1.63s/ba]Running tokenizer on dataset:   0%|          | 1/814 [00:02<34:43,  2.56s/ba]Running tokenizer on dataset:  26%|██▌       | 210/814 [05:41<16:19,  1.62s/ba]Running tokenizer on dataset:   0%|          | 2/814 [00:04<31:56,  2.36s/ba]Running tokenizer on dataset:  26%|██▌       | 211/814 [05:43<16:16,  1.62s/ba]Running tokenizer on dataset:   0%|          | 3/814 [00:06<30:55,  2.29s/ba]Running tokenizer on dataset:  26%|██▌       | 212/814 [05:44<16:05,  1.60s/ba][E ProcessGroupNCCL.cpp:821] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=2, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1807295 milliseconds before timing out.
Running tokenizer on dataset:  26%|██▌       | 213/814 [05:46<16:00,  1.60s/ba][E ProcessGroupNCCL.cpp:456] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:461] To avoid data inconsistency, we are taking the entire process down.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=2, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1807295 milliseconds before timing out.
Running tokenizer on dataset:   0%|          | 4/814 [00:09<30:11,  2.24s/ba]Running tokenizer on dataset:  26%|██▋       | 214/814 [05:47<15:55,  1.59s/ba]Running tokenizer on dataset:   1%|          | 5/814 [00:11<29:33,  2.19s/ba]Running tokenizer on dataset:  26%|██▋       | 215/814 [05:49<15:55,  1.59s/ba]Running tokenizer on dataset:   1%|          | 6/814 [00:13<28:46,  2.14s/ba]Running tokenizer on dataset:  27%|██▋       | 216/814 [05:50<15:47,  1.58s/ba]Running tokenizer on dataset:  27%|██▋       | 217/814 [05:52<15:52,  1.60s/ba]Running tokenizer on dataset:   1%|          | 7/814 [00:15<28:27,  2.12s/ba]Running tokenizer on dataset:  27%|██▋       | 218/814 [05:54<15:53,  1.60s/ba]Running tokenizer on dataset:   1%|          | 8/814 [00:17<28:04,  2.09s/ba]Running tokenizer on dataset:  27%|██▋       | 219/814 [05:55<15:55,  1.61s/ba]Running tokenizer on dataset:   1%|          | 9/814 [00:19<27:32,  2.05s/ba]Running tokenizer on dataset:  27%|██▋       | 220/814 [05:57<15:50,  1.60s/ba]Running tokenizer on dataset:   1%|          | 10/814 [00:21<27:07,  2.02s/ba]Running tokenizer on dataset:  27%|██▋       | 221/814 [05:58<15:49,  1.60s/ba]Running tokenizer on dataset:  27%|██▋       | 222/814 [06:00<15:40,  1.59s/ba]Running tokenizer on dataset:   1%|▏         | 11/814 [00:23<27:09,  2.03s/ba]Running tokenizer on dataset:  27%|██▋       | 223/814 [06:02<15:37,  1.59s/ba]Running tokenizer on dataset:   1%|▏         | 12/814 [00:25<26:59,  2.02s/ba]Running tokenizer on dataset:  28%|██▊       | 224/814 [06:03<15:43,  1.60s/ba]Running tokenizer on dataset:   2%|▏         | 13/814 [00:27<26:55,  2.02s/ba]Running tokenizer on dataset:  28%|██▊       | 225/814 [06:05<15:44,  1.60s/ba]Running tokenizer on dataset:   2%|▏         | 14/814 [00:29<26:50,  2.01s/ba]Running tokenizer on dataset:  28%|██▊       | 226/814 [06:06<15:43,  1.60s/ba]Running tokenizer on dataset:  28%|██▊       | 227/814 [06:08<15:44,  1.61s/ba]Running tokenizer on dataset:   2%|▏         | 15/814 [00:31<26:34,  2.00s/ba]Running tokenizer on dataset:  28%|██▊       | 228/814 [06:10<15:36,  1.60s/ba]Running tokenizer on dataset:   2%|▏         | 16/814 [00:33<26:18,  1.98s/ba]Running tokenizer on dataset:  28%|██▊       | 229/814 [06:11<15:38,  1.60s/ba]Running tokenizer on dataset:   2%|▏         | 17/814 [00:35<25:59,  1.96s/ba]Running tokenizer on dataset:  28%|██▊       | 230/814 [06:13<15:33,  1.60s/ba]Running tokenizer on dataset:   2%|▏         | 18/814 [00:37<25:45,  1.94s/ba]Running tokenizer on dataset:  28%|██▊       | 231/814 [06:14<15:28,  1.59s/ba]Running tokenizer on dataset:  29%|██▊       | 232/814 [06:16<15:22,  1.59s/ba]Running tokenizer on dataset:   2%|▏         | 19/814 [00:39<25:40,  1.94s/ba]Running tokenizer on dataset:  29%|██▊       | 233/814 [06:18<15:30,  1.60s/ba]Running tokenizer on dataset:   2%|▏         | 20/814 [00:40<25:42,  1.94s/ba]Running tokenizer on dataset:  29%|██▊       | 234/814 [06:19<15:29,  1.60s/ba]Running tokenizer on dataset:   3%|▎         | 21/814 [00:42<25:38,  1.94s/ba]Running tokenizer on dataset:  29%|██▉       | 235/814 [06:21<15:25,  1.60s/ba]WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 182045 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 182047 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 182048 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Unable to shutdown process 182047 via 15, forcefully exitting via 9
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -6) local_rank: 1 (pid: 182046) of binary: /home/paperspace/Documents/Repos/clm_model_tuning/venv/bin/python3
